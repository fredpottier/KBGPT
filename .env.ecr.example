# =====================================================
# Configuration pour déploiement AWS EC2 avec images ECR
# =====================================================
# Copiez ce fichier vers .env.production et configurez vos valeurs
# Usage:
#   - En local: Copiez vers .env pour développement
#   - Sur EC2: Copiez vers .env pour production

# =====================================================
# AWS CONFIGURATION (OBLIGATOIRE)
# =====================================================
AWS_ACCOUNT_ID=715927975014  # Votre Account ID AWS
AWS_REGION=eu-west-1         # Région AWS de vos ressources ECR

# =====================================================
# PORTS SERVICES (conservez par défaut sauf conflit)
# =====================================================
APP_PORT=8000          # Port FastAPI backend
FRONTEND_PORT=3000     # Port Next.js frontend
APP_UI_PORT=8501       # Port Streamlit UI (legacy)

# =====================================================
# DEBUG MODE (désactiver en production)
# =====================================================
DEBUG_APP=false        # Debug backend FastAPI
DEBUG_WORKER=false     # Debug worker d'ingestion

# =====================================================
# API KEYS LLM (OBLIGATOIRE)
# =====================================================
# Obtenez vos clés:
#   OpenAI: https://platform.openai.com/api-keys
#   Anthropic: https://console.anthropic.com/
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here

# =====================================================
# CONFIGURATION MODÈLES LLM (optionnel)
# =====================================================
# Par défaut, utilise les modèles configurés dans config/llm_models.yaml
# Décommentez pour override :
# MODEL_VISION=gpt-4o
# MODEL_METADATA=gpt-4o
# MODEL_FAST=gpt-4o-mini
# MODEL_LONG_TEXT=claude-3-5-sonnet-20241022
# MODEL_ENRICHMENT=claude-3-5-haiku-20241022

# =====================================================
# NEO4J KNOWLEDGE GRAPH (OBLIGATOIRE)
# =====================================================
# Configuré automatiquement pour Docker Compose
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-secure-neo4j-password-here  # CHANGEZ en production !

# =====================================================
# QDRANT VECTOR DATABASE
# =====================================================
# Configuré automatiquement pour Docker Compose
QDRANT_URL=http://qdrant:6333
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION=knowbase
QDRANT_API_KEY=  # Optionnel, pour sécurisation supplémentaire

# =====================================================
# REDIS CACHE & QUEUE
# =====================================================
# Configuré automatiquement pour Docker Compose
REDIS_URL=redis://redis:6379/0

# =====================================================
# HUGGINGFACE MODEL CACHE
# =====================================================
HF_HOME=/data/models

# =====================================================
# AUTHENTIFICATION & SÉCURITÉ
# =====================================================
# Clé secrète JWT (OBLIGATOIRE pour authentification)
# Générez une clé aléatoire sécurisée:
#   - Python: python -c "import secrets; print(secrets.token_urlsafe(32))"
#   - OpenSSL: openssl rand -base64 32
JWT_SECRET=your-jwt-secret-key-change-in-production

# Mot de passe Grafana admin (monitoring)
GRAFANA_ADMIN_PASSWORD=admin

# =====================================================
# PERFORMANCE - PARALLÉLISATION MONO-DOCUMENT
# =====================================================
# Nombre de segments traités en parallèle (optimisé pour 8 vCPU)
# Recommandations par instance:
#   - t2.2xlarge / m5.2xlarge (8 vCPU): 5
#   - c5.4xlarge (16 vCPU): 10
#   - c5.9xlarge (36 vCPU): 15
MAX_PARALLEL_SEGMENTS=5

# LLM Rate Limits (OpenAI)
# Tier 1: 500 RPM, Tier 2: 5000 RPM
OPENAI_MAX_RPM=500
ANTHROPIC_MAX_RPM=100

# =====================================================
# FRONTEND API CONFIGURATION
# =====================================================
# Pour déploiement EC2, remplacez localhost par l'IP publique de votre instance
# Exemple: FRONTEND_API_BASE_URL=http://18.203.45.67:8000
FRONTEND_API_BASE_URL=http://localhost:8000

# API URLs internes (ne changez pas, pour communication inter-conteneurs)
NEXT_PUBLIC_API_INTERNAL_URL=http://app:8000
BACKEND_URL=http://app:8000

# =====================================================
# WORKER CONFIGURATION (production)
# =====================================================
DEV_MODE=false                # Mode développement (auto-reload code)
WORKER_CONCURRENCY=4          # Nombre de workers concurrents (ajuster selon CPU)

# =====================================================
# NGROK TUNNEL (optionnel, pour exposition externe)
# =====================================================
# Décommentez si vous utilisez ngrok pour exposer vos services
# Obtenez vos tokens: https://dashboard.ngrok.com/
# NGROK_AUTHTOKEN=your-ngrok-token-here
# NGROK_DOMAIN=your-domain.ngrok.app

# =====================================================
# PYTHON PATHS (ne changez pas)
# =====================================================
PYTHONPATH=/app:/app/src
KNOWBASE_DATA_DIR=/data

# =====================================================
# NOTES IMPORTANTES
# =====================================================
# 1. SÉCURITÉ:
#    - Ne commitez JAMAIS ce fichier avec vos vraies clés API
#    - Changez NEO4J_PASSWORD en production
#    - Utilisez des mots de passe forts (>16 caractères)
#
# 2. PERFORMANCE EC2:
#    - Instance recommandée: t3.xlarge minimum (4 vCPU, 16GB RAM)
#    - Pour charges lourdes: t3.2xlarge (8 vCPU, 32GB RAM)
#    - Ajustez WORKER_CONCURRENCY selon vos vCPUs
#
# 3. COÛTS:
#    - Suivez votre consommation OpenAI/Anthropic
#    - Les appels LLM représentent 80-90% des coûts opérationnels
#    - Voir doc/etudes/ARCHITECTURE_AGENTIQUE_OSMOSE.md pour optimisation
#
# 4. FRONTEND_API_BASE_URL:
#    - En local: http://localhost:8000
#    - Sur EC2: http://<IP_PUBLIQUE_EC2>:8000
#    - Avec domaine: https://api.votre-domaine.com
#
# 5. SECURITY GROUPS EC2:
#    - Port 22 (SSH): Votre IP uniquement
#    - Port 8000 (API): Votre IP ou 0.0.0.0/0 si public
#    - Port 3000 (Frontend): Votre IP ou 0.0.0.0/0 si public
#    - Port 7474 (Neo4j UI): Votre IP uniquement (admin)
#    - Port 6333 (Qdrant UI): Votre IP uniquement (admin)