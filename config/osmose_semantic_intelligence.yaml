# üåä OSMOSE Semantic Intelligence Configuration
# Phase 1 - Semantic Core

project:
  name: "KnowWhere"
  codename: "OSMOSE"
  version: "1.0.0-alpha"
  description: "Organic Semantic Memory Organization & Smart Extraction"

semantic_intelligence:
  enabled: true
  mode: "SEMANTIC"  # SEMANTIC | LEGACY

  # ===================================
  # SEMANTIC DOCUMENT PROFILER
  # ===================================
  profiler:
    enabled: true

    # Seuils de complexit√©
    complexity_thresholds:
      simple: 0.3    # Texte simple, direct
      medium: 0.6    # Complexit√© moyenne, concepts li√©s
      complex: 0.9   # Haute complexit√©, multiples concepts interd√©pendants

    # Classification domaine
    domain_classification:
      enabled: true
      models:
        - "finance"      # Documents financiers, comptabilit√©
        - "pharma"       # Documents pharmaceutiques, m√©dicaux
        - "consulting"   # Documents strat√©gie, conseil
        - "general"      # Domaine g√©n√©ral (fallback)

  # ===================================
  # NARRATIVE THREAD DETECTOR
  # ===================================
  narrative_detection:
    enabled: true
    min_confidence: 0.7  # Seuil minimum pour d√©tecter un fil narratif

    # Connecteurs causaux (because, therefore, etc.)
    causal_connectors:
      - "because"
      - "therefore"
      - "as a result"
      - "due to"
      - "consequently"
      - "leads to"
      - "causes"
      - "resulting in"
      - "stems from"

    # Marqueurs temporels (revised, updated, etc.)
    temporal_markers:
      - "revised"
      - "updated"
      - "replaced"
      - "deprecated"
      - "superseded"
      - "evolved"
      - "changed from"
      - "no longer"
      - "previously"

    # Patterns de r√©f√©rence cross-documents
    reference_patterns:
      - "refers to"
      - "see section"
      - "as mentioned in"
      - "according to"
      - "based on"
      - "described in"
      - "outlined in"

  # ===================================
  # INTELLIGENT SEGMENTATION ENGINE
  # ===================================
  segmentation:
    enabled: true
    min_cluster_size: 2       # Minimum chunks par cluster
    max_cluster_size: 10      # Maximum chunks par cluster
    similarity_threshold: 0.75  # Seuil similarit√© cosine
    preserve_narrative_context: true  # Pr√©server contexte narratif

  # ===================================
  # BUDGET ALLOCATION (Token/Co√ªt)
  # ===================================
  budget_allocation:
    default_per_doc: 2.0  # USD par document (par d√©faut)

    # Multiplicateurs selon complexit√©
    complexity_multipliers:
      simple: 0.5    # 50% du budget default
      medium: 1.0    # 100% du budget default
      complex: 2.0   # 200% du budget default

    narrative_bonus: 0.3  # +30% si narrative threads d√©tect√©s

# ===================================
# NEO4J PROTO-KG (STAGING)
# ===================================
neo4j_proto:
  database: "neo4j"

  labels:
    candidate_entity: "CandidateEntity"
    candidate_relation: "CandidateRelation"

  # Status workflow
  statuses:
    - "PENDING_REVIEW"    # En attente de review humaine
    - "AUTO_PROMOTED"     # Auto-promu (r√®gles automatiques)
    - "HUMAN_PROMOTED"    # Promu manuellement par humain
    - "REJECTED"          # Rejet√© (faux positif)

  # R√®gles auto-promotion
  auto_promotion_rules:
    entity_min_mentions: 3         # Minimum 3 mentions
    entity_min_confidence: 0.85    # Confidence >= 85%
    relation_min_confidence: 0.90  # Confidence >= 90%

# ===================================
# QDRANT PROTO COLLECTION
# ===================================
qdrant_proto:
  collection_name: "knowwhere_proto"
  vector_size: 1536  # OpenAI text-embedding-3-small
  distance: "Cosine"

  # Configuration performance
  hnsw_config:
    m: 16               # Connections par node
    ef_construct: 100   # Construction quality
    full_scan_threshold: 10000

  # Optimisation
  optimizer_config:
    deleted_threshold: 0.2
    vacuum_min_vector_number: 1000
    default_segment_number: 2

# ===================================
# LLM ROUTING
# ===================================
llm_routing:
  # Profiling & Complexity Analysis
  profiler_model: "gpt-4o-mini"     # Rapide et pas cher
  profiler_temperature: 0.1

  # Narrative Detection (plus sophistiqu√©)
  narrative_model: "gpt-4o"         # Plus intelligent
  narrative_temperature: 0.2

  # Entity Extraction
  extraction_model: "gpt-4o-mini"   # Bon ratio co√ªt/qualit√©
  extraction_temperature: 0.0

# ===================================
# LOGGING & MONITORING
# ===================================
monitoring:
  log_level: "INFO"                 # DEBUG | INFO | WARNING | ERROR
  log_narrative_detection: true     # Log d√©taill√© narrative threads
  log_proto_kg_operations: true     # Log op√©rations Proto-KG

  # M√©triques
  track_processing_time: true
  track_token_usage: true
  track_cost_per_document: true
