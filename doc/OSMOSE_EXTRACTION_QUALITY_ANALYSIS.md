# üîç OSMOSE - Analyse Qualit√© Extraction Concepts

**Date:** 2025-10-15
**Phase:** Phase 1 V2.1 - Diagnostic Post-Impl√©mentation
**Document Test:** CRITEO_ERP_RFP_-_SAP_Answer (47 slides)

---

## üìä R√©sultats Actuels

### M√©triques Pipeline

```
- 11 topics segment√©s
- 42 concepts canoniques extraits
- 19 connexions cross-documents
- 42 embeddings Qdrant
- 42 concepts Neo4j (37 apr√®s MERGE d√©dupe)
- Dur√©e: 223.8s (3min44s)
```

### Concepts Extraits (√âchantillon Neo4j)

| Concept | Type | D√©finition | Qualit√© |
|---------|------|------------|---------|
| SAP S/4HANA | ENTITY | (vide) | ‚úÖ Bon |
| HANA | ENTITY | (vide) | ‚úÖ Bon |
| GDPR | ENTITY | (vide) | ‚úÖ Bon |
| HighRadius | ENTITY | (vide) | ‚úÖ Bon |
| Kyriba | ENTITY | (vide) | ‚úÖ Bon |
| "ized" | ENTITY | (vide) | ‚ùå Fragment |
| "ial" | ENTITY | (vide) | ‚ùå Fragment |
| "the \"Invoice & Pay" | ENTITY | (vide) | ‚ùå Mal form√© |
| Finance | ENTITY | (vide) | ‚ö†Ô∏è Trop g√©n√©rique |
| Operations | ENTITY | (vide) | ‚ö†Ô∏è Trop g√©n√©rique |

---

## üêõ Probl√®mes Identifi√©s

### 1. **LLM Extraction D√©sactiv√©e** ‚ö†Ô∏è CRITIQUE

```yaml
# config/semantic_intelligence_v2.yaml ligne 22
methods:
  - "NER"                      # ‚úÖ Activ√©
  - "CLUSTERING"               # ‚úÖ Activ√©
  # - "LLM"                    # ‚ùå D√âSACTIV√â pour √©conomiser co√ªts debug
```

**Impact:**
- NER seul extrait des **noms propres** (organisations, personnes, lieux)
- Ne capture PAS les **concepts m√©tier cl√©s** (pratiques, processus, standards)
- Pas de **d√©finitions g√©n√©r√©es**
- Pas de **typage s√©mantique** (PRACTICE, STANDARD, TOOL, ROLE)

### 2. **Bruit NER - Fragments** ‚ùå

**Exemples:**
- "ized" (fragment de "specialized", "optimized", etc.)
- "ial" (fragment de "financial", "material", etc.)
- "the \"Invoice & Pay" (extraction mal d√©limit√©e)

**Cause:**
- Mod√®le spaCy `en_core_web_md` d√©coupe mal les entit√©s longues
- Pas de post-processing pour filtrer fragments courts
- Pas de validation de qualit√© des entit√©s extraites

### 3. **Concepts Trop G√©n√©riques** ‚ö†Ô∏è

**Exemples:**
- "Finance", "Operations", "AI", "treasury"
- Pas assez sp√©cifiques au contexte SAP/ERP
- Dilue le Knowledge Graph

### 4. **Aucune D√©finition G√©n√©r√©e** ‚ùå

```cypher
MATCH (c:CanonicalConcept) RETURN c.unified_definition
‚Üí Tous retournent "" (vide)
```

**Impact:**
- Impossible de comprendre le sens d'un concept sans lire les documents sources
- Pas de diff√©renciation entre homonymes
- Pas d'aide contextuelle pour l'utilisateur

### 5. **Pas de Typage S√©mantique** ‚ùå

**Actuel:**
```
Tous les concepts ‚Üí Type: ENTITY
```

**Attendu:**
```
- SAP S/4HANA          ‚Üí ENTITY
- Financial Closing    ‚Üí PRACTICE
- GDPR                 ‚Üí STANDARD
- HighRadius           ‚Üí TOOL
- CFO                  ‚Üí ROLE
```

---

## üí° Recommandations

### Phase 1: Corrections Imm√©diates (1-2h)

#### 1.1 R√©activer LLM Extraction ‚úÖ PRIORIT√â 1

```yaml
# config/semantic_intelligence_v2.yaml ligne 22
methods:
  - "NER"
  - "CLUSTERING"
  - "LLM"  # ‚úÖ R√âACTIVER
```

**B√©n√©fices:**
- Extraction concepts m√©tier (pratiques SAP, processus finance)
- G√©n√©ration d√©finitions automatiques
- Typage s√©mantique (PRACTICE, STANDARD, TOOL, ROLE)
- Filtrage intelligent (rejette fragments et concepts g√©n√©riques)

**Co√ªt estim√©:**
- ~$0.05-0.10 par document (gpt-4o-mini)
- Budget acceptable pour qualit√© sup√©rieure

#### 1.2 Ajouter Filtrage Post-NER

**Fichier:** `src/knowbase/semantic/utils/ner_manager.py`

```python
def _filter_low_quality_entities(self, entities: List[str]) -> List[str]:
    """
    Filtre les entit√©s NER de mauvaise qualit√©.

    Crit√®res de rejet:
    - Longueur < 3 caract√®res
    - Contient seulement minuscules/majuscules (pas de m√©lange)
    - Mots stop-words g√©n√©riques (the, and, etc.)
    - Fragments courants (ized, ial, ing, etc.)
    """
    filtered = []
    fragments = {"ized", "ial", "ing", "tion", "ness", "ment"}
    stopwords = {"the", "and", "or", "of", "in", "on", "at", "to"}

    for entity in entities:
        # Rejeter si trop court
        if len(entity) < 3:
            continue

        # Rejeter fragments connus
        if entity.lower() in fragments:
            continue

        # Rejeter stopwords
        if entity.lower() in stopwords:
            continue

        # Rejeter si commence par article
        if entity.lower().startswith(("the ", "a ", "an ")):
            entity = entity.split(" ", 1)[1]  # Enlever article

        filtered.append(entity)

    return filtered
```

#### 1.3 Am√©liorer Prompt LLM

**Fichier:** `config/prompts.yaml` (cr√©er section `concept_extraction`)

```yaml
concept_extraction:
  system: |
    You are an expert in SAP ERP, Finance, and Business Process Management.
    Your task is to extract KEY business concepts from technical documents.

    Focus on:
    - SAP-specific products/modules (S/4HANA, HANA, Fiori, etc.)
    - Business processes (Financial Closing, Order-to-Cash, etc.)
    - Standards/regulations (GDPR, SOX, IFRS, etc.)
    - Third-party tools integrated with SAP (HighRadius, Kyriba, etc.)
    - Business roles (CFO, Controller, Accountant, etc.)

    REJECT:
    - Generic terms (finance, operations, business)
    - Fragments (ized, ial, ing)
    - Articles/prepositions
    - Company names (unless SAP partners)

  user_template: |
    Extract business concepts from this text segment:

    ---
    {topic_text}
    ---

    Return JSON array:
    [
      {
        "name": "SAP S/4HANA Cloud",
        "type": "ENTITY",
        "definition": "Cloud-based ERP suite from SAP, successor to SAP ECC",
        "confidence": 0.95
      },
      {
        "name": "Three-Way Match",
        "type": "PRACTICE",
        "definition": "Accounts Payable control matching PO, receipt, and invoice",
        "confidence": 0.88
      }
    ]
```

### Phase 2: Am√©liorations Avanc√©es (4-6h)

#### 2.1 Ajouter Ontologie Domaine SAP

**Fichier:** `config/sap_ontology.yaml`

```yaml
entities:
  products:
    - SAP S/4HANA
    - SAP HANA
    - SAP Fiori
    - SAP BTP
    - SAP Ariba
    - SAP SuccessFactors

  modules:
    - Financial Accounting (FI)
    - Controlling (CO)
    - Materials Management (MM)
    - Sales & Distribution (SD)

practices:
  finance:
    - Financial Closing
    - Month-End Close
    - Order-to-Cash
    - Procure-to-Pay
    - Record-to-Report

standards:
  - GDPR
  - SOX (Sarbanes-Oxley)
  - IFRS
  - US GAAP

tools:
  partners:
    - HighRadius (Collections)
    - Kyriba (Treasury)
    - BlackLine (Reconciliation)
```

Utiliser cette ontologie pour :
1. **Boosting** : Augmenter score confiance si match ontologie
2. **Validation** : Rejeter concepts hors ontologie si confiance < 0.7
3. **Auto-compl√©tion** : Sugg√©rer concepts manquants

#### 2.2 Impl√©menter G√©n√©ration D√©finitions Multi-Sources

```python
async def generate_unified_definition(
    self,
    concept_name: str,
    context_texts: List[str]
) -> str:
    """
    G√©n√®re d√©finition unifi√©e depuis plusieurs sources.

    Strategy:
    1. Extraire toutes mentions du concept dans documents
    2. Identifier contextes cl√©s (premi√®re mention, listes, etc.)
    3. Appel LLM pour synth√©tiser d√©finition unifi√©e
    4. Valider longueur (50-200 chars) et coh√©rence
    """
    # Extraire contextes pertinents
    contexts = self._extract_concept_contexts(concept_name, context_texts)

    # Prompt LLM
    prompt = f"""
    Synthesize a concise definition (50-200 chars) for the concept "{concept_name}"
    based on these contexts:

    {chr(10).join(f"- {ctx}" for ctx in contexts[:5])}

    Definition:
    """

    definition = await self.llm_router.complete(prompt, max_tokens=100)
    return definition.strip()
```

#### 2.3 Ajouter M√©triques Qualit√©

```python
class ConceptQualityMetrics:
    """M√©triques qualit√© extraction concepts."""

    def calculate_quality_score(self, concept: Concept) -> float:
        """
        Calcule score qualit√© 0-1 bas√© sur:
        - Longueur nom (reject si < 3 ou > 50 chars)
        - Match ontologie (+0.2 si trouv√©)
        - Pr√©sence d√©finition (+0.3 si g√©n√©r√©e)
        - Confiance extraction (0-1)
        - Fr√©quence dans document (+0.1 si > 3 mentions)
        """
        score = 0.0

        # Longueur
        if 3 <= len(concept.name) <= 50:
            score += 0.2

        # Match ontologie
        if self._matches_ontology(concept.name):
            score += 0.2

        # D√©finition
        if concept.definition:
            score += 0.3

        # Confiance
        score += concept.confidence * 0.3

        return min(score, 1.0)
```

### Phase 3: Innovation - Extraction Contextuelle (8-12h)

#### 3.1 Graph-Based Concept Extraction

Utiliser le **contexte relationnel** pour identifier concepts importants :

```python
# Exemple: "SAP S/4HANA integrates with HighRadius for automated collections"
# ‚Üí Extraire: SAP S/4HANA (ENTITY), HighRadius (TOOL)
# ‚Üí Relation: INTEGRATES_WITH
# ‚Üí Context importance: Concepts li√©s √† SAP = prioritaires
```

#### 3.2 Document Role Detection

D√©tecter automatiquement le **r√¥le du document** :

```python
class DocumentRoleDetector:
    """D√©tecte le r√¥le d'un document."""

    def detect_role(self, document_text: str) -> DocumentRole:
        """
        D√©tecte si le document:
        - DEFINES: D√©finit des concepts (glossaire, spec technique)
        - IMPLEMENTS: D√©crit une impl√©mentation (guide config)
        - AUDITS: Rapport d'audit, compliance check
        - PROVES: Preuve de conformit√© (certification)
        - REFERENCES: Mentionne seulement (pr√©sentation, email)
        """
```

Utiliser le role pour **pond√©rer l'importance** des concepts extraits.

---

## üéØ Plan d'Action Recommand√©

### Semaine en Cours

- [x] **Diagnostic complet** (ce document)
- [ ] **R√©activer LLM extraction** (1h)
- [ ] **Ajouter filtrage post-NER** (2h)
- [ ] **Tester sur 5-10 documents** (2h)
- [ ] **Mesurer am√©lioration qualit√©** (1h)

**Crit√®res Succ√®s:**
- R√©duction fragments < 5%
- Augmentation concepts m√©tier > 80%
- G√©n√©ration d√©finitions > 90%
- Typage s√©mantique correct > 85%

### Semaines 11-12

- [ ] Impl√©menter ontologie SAP
- [ ] Ajouter g√©n√©ration d√©finitions multi-sources
- [ ] Cr√©er dashboard m√©triques qualit√©
- [ ] Tester sur corpus complet (50+ documents)

---

## üìà M√©triques Attendues Apr√®s Corrections

| M√©trique | Avant | Apr√®s (Cible) |
|----------|-------|---------------|
| Concepts extraits | 42 | 50-60 |
| Fragments/bruit | 15% | < 5% |
| Concepts m√©tier | 30% | > 80% |
| D√©finitions g√©n√©r√©es | 0% | > 90% |
| Typage s√©mantique | 0% (tous ENTITY) | > 85% |
| Score qualit√© moyen | 0.4 | > 0.75 |

---

## üîó R√©f√©rences

- Configuration: `config/semantic_intelligence_v2.yaml`
- Pipeline: `src/knowbase/semantic/semantic_pipeline_v2.py`
- Extracteur: `src/knowbase/semantic/extraction/concept_extractor.py`
- NER: `src/knowbase/semantic/utils/ner_manager.py`
- Ontologie: `config/sap_ontology.yaml` (√† cr√©er)

---

## ‚ö†Ô∏è Phase 4: Filtrage Contextuel Avanc√© (Best Practices 2025) ‚ú® **NOUVEAU**

### üìö Analyse Best Practices Extraction (Source: OpenAI, 2025-10-15)

**Documents sources** :
- `doc/ongoing/ANALYSE_BEST_PRACTICES_EXTRACTION_VS_OSMOSE.md`
- `doc/ongoing/ANALYSE_FILTRAGE_CONTEXTUEL_GENERALISTE.md`

**Pipeline 6 √âtapes Recommand√© (Industrie)** :
1. ‚úÖ Pr√©traitement et structuration (OSMOSE OK)
2. ‚ùå **R√©solution de cor√©f√©rence** (0% impl√©ment√©) ‚Üí **GAP P0**
3. ‚úÖ NER + Keywords extraction (OSMOSE OK)
4. ‚úÖ D√©sambigu√Øsation et enrichissement (OSMOSE OK)
5. ‚ö†Ô∏è **Filtrage intelligent contextuel** (20% impl√©ment√©) ‚Üí **GAP P0 CRITIQUE**
6. üü° √âvaluation continue (partiellement impl√©ment√©)

---

### üö® **GAP Critique Identifi√©: Filtrage Contextuel Insuffisant**

#### Probl√®me Majeur

**Situation actuelle** (GatekeeperDelegate) :
```python
# Filtrage uniquement par confidence, PAS par contexte
if entity["confidence"] < profile.min_confidence:
    rejected.append(entity)
```

**Impact** : Produits concurrents promus au m√™me niveau que produits principaux !

**Exemple concret** :
```
Document RFP SAP:
"Notre solution SAP S/4HANA Cloud r√©pond √† vos besoins.
Les concurrents Oracle et Workday proposent des alternatives."

Extraction actuelle (NER):
- SAP S/4HANA Cloud (confidence: 0.95)
- Oracle (confidence: 0.92)
- Workday (confidence: 0.90)

Gatekeeper actuel (BALANCED profile, seuil 0.70):
‚úÖ SAP S/4HANA Cloud promoted (0.95 > 0.70)
‚úÖ Oracle promoted (0.92 > 0.70)  ‚ùå ERREUR!
‚úÖ Workday promoted (0.90 > 0.70)  ‚ùå ERREUR!

R√©sultat: Les 3 produits au m√™me niveau dans le KG!
```

**Attendu** :
```
SAP S/4HANA Cloud ‚Üí PRIMARY (score: 1.0) ‚úÖ Promu
Oracle ‚Üí COMPETITOR (score: 0.3) ‚ùå Rejet√©
Workday ‚Üí COMPETITOR (score: 0.3) ‚ùå Rejet√©
```

---

### ‚úÖ Solution: Filtrage Contextuel Hybride (Production-Ready)

**Approche Recommand√©e** : Cascade Graph + Embeddings + LLM (optionnel)

#### Composant 1: Graph-Based Centrality ‚≠ê **OBLIGATOIRE**

**Principe** : Entit√©s centrales dans le document (souvent mentionn√©es, bien connect√©es) = importantes.

**Algorithme** :
```python
# src/knowbase/agents/gatekeeper/graph_centrality_scorer.py (300 lignes)

class GraphCentralityScorer:
    """Score entities based on graph structure"""

    def build_cooccurrence_graph_weighted(self, entities, full_text):
        """Build co-occurrence graph with TF-IDF weighting"""
        G = nx.Graph()

        # Node weights = TF-IDF (not just frequency)
        for entity in entities:
            tf = entity["frequency"] / len(full_text.split())
            idf = self._calculate_idf(entity["name"])
            tf_idf = tf * idf
            G.add_node(entity["name"], tf_idf=tf_idf)

        # Edge weights = distance-based decay
        for i, entity1 in enumerate(entities):
            for entity2 in entities[i+1:]:
                cooccurrences = self._count_cooccurrences_with_distance(
                    entity1, entity2, full_text, window=50
                )
                if cooccurrences:
                    distance_decay = 1.0 / (1.0 + avg_distance / 10)
                    weight = len(cooccurrences) * distance_decay
                    G.add_edge(entity1["name"], entity2["name"], weight=weight)

        return G

    def calculate_centrality_scores(self, G):
        """Combine Degree, PageRank, Betweenness"""
        degree = nx.degree_centrality(G)
        pagerank = nx.pagerank(G, weight='weight')
        betweenness = nx.betweenness_centrality(G, weight='weight')

        combined = {}
        for node in G.nodes():
            combined[node] = (
                0.4 * degree.get(node, 0.0) +
                0.4 * pagerank.get(node, 0.0) +
                0.2 * betweenness.get(node, 0.0)
            )
        return combined
```

**Am√©liorations Production** :
- ‚úÖ **TF-IDF weighting** (vs fr√©quence brute) ‚Üí +10-15% pr√©cision
- ‚úÖ **Salience score** (position + titre/abstract boost) ‚Üí +5-10% recall
- ‚úÖ **Fen√™tre adaptive** (30-100 mots selon taille doc) ‚Üí +5% pr√©cision

**Impact** : +20-30% pr√©cision, 100% language-agnostic, $0 co√ªt, <100ms

#### Composant 2: Embeddings Similarity ‚≠ê **OBLIGATOIRE**

**Principe** : Comparer contexte entit√© avec concepts abstraits ("main topic", "competitor").

**Algorithme** :
```python
# src/knowbase/agents/gatekeeper/embeddings_contextual_scorer.py (200 lignes)

class EmbeddingsContextualScorer:
    """Score entities based on semantic context"""

    REFERENCE_CONCEPTS_MULTILINGUAL = {
        "primary": [
            "main topic of the document", "primary solution proposed",
            "sujet principal du document", "solution principale propos√©e",
            "Hauptthema des Dokuments", "Hauptl√∂sung"
        ],
        "competitor": [
            "alternative solution", "competing product",
            "solution alternative", "produit concurrent",
            "alternative L√∂sung", "Konkurrenzprodukt"
        ]
    }

    def __init__(self, model_name="intfloat/multilingual-e5-large"):
        self.model = SentenceTransformer(model_name)
        # Pre-encode reference concepts
        self.reference_embeddings = {}
        for concept_name, phrases in self.REFERENCE_CONCEPTS_MULTILINGUAL.items():
            embeddings = self.model.encode(phrases, convert_to_tensor=True)
            self.reference_embeddings[concept_name] = embeddings.mean(dim=0)

    def score_entity_aggregated(self, entity, full_text):
        """Score using aggregated embeddings from ALL mentions"""
        # Extract ALL contexts (not just first)
        contexts = self._extract_all_mentions_contexts(entity["name"], full_text)

        # Encode and aggregate
        context_embeddings = self.model.encode(contexts, convert_to_tensor=True)
        aggregated_embedding = context_embeddings.mean(dim=0)

        # Compare with reference concepts
        scores = {}
        for concept_name, reference_emb in self.reference_embeddings.items():
            similarity = util.pytorch_cos_sim(aggregated_embedding, reference_emb).item()
            scores[f"{concept_name}_similarity"] = similarity

        # Classify role
        if scores["primary_similarity"] > 0.8:
            role = "PRIMARY"
        elif scores["competitor_similarity"] > 0.7:
            role = "COMPETITOR"
        else:
            role = "SECONDARY"

        return {"role": role, "scores": scores}
```

**Am√©liorations Production** :
- ‚úÖ **Agr√©gation multi-occurrences** (toutes mentions vs premi√®re) ‚Üí +15-20% pr√©cision
- ‚úÖ **Paraphrases multilingues** (EN/FR/DE/ES) ‚Üí +10% stabilit√©
- ‚úÖ **Stockage vecteurs Neo4j** (recalcul dynamique) ‚Üí clustering th√©matique

**Impact** : +25-35% pr√©cision, 100% language-agnostic, $0 co√ªt, <200ms

#### Composant 3: LLM Classification (OPTIONNEL)

**Principe** : LLM local distill√© pour cas ambigus uniquement.

**Algorithme** :
```python
# src/knowbase/agents/gatekeeper/llm_local_classifier.py (250 lignes)

class LocalContextualClassifier:
    """Local LLM for contextual classification (no API cost)"""

    def __init__(self, model_name="microsoft/phi-3-mini-4k-instruct"):
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name, num_labels=3  # PRIMARY, COMPETITOR, SECONDARY
        )

    async def classify_entity(self, entity_name, context, full_text):
        """Classify entity using local LLM"""
        prompt = f"""
Entity: {entity_name}
Context: {context}

Classify role: PRIMARY (main offering), COMPETITOR (alternative), SECONDARY (mentioned).
Output: PRIMARY/COMPETITOR/SECONDARY
"""
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
            predicted_class = torch.argmax(outputs.logits, dim=1).item()

        return {"role": self.labels[predicted_class]}
```

**Alternative** : Distillation depuis GPT-4 (one-time $30, puis $0 ongoing)

**Impact** : 75-85% pr√©cision, $0 co√ªt ongoing, <200ms

---

### üéØ Architecture Cascade Hybride (RECOMMAND√âE)

```python
# Dans GatekeeperDelegate._gate_check_tool()

async def _gate_check_with_contextual_filtering(self, candidates, full_text):
    """Hybrid cascade: Graph ‚Üí Embeddings ‚Üí LLM (optional)"""

    # Step 1: Graph Centrality (FREE, 100ms)
    candidates = self.graph_scorer.score_entities(candidates, full_text)
    candidates = [e for e in candidates if e.get("centrality_score", 0.0) >= 0.15]

    # Step 2: Embeddings Similarity (FREE, 200ms)
    candidates = self.embeddings_scorer.score_entities(candidates, full_text)
    clear_entities = [e for e in candidates if e.get("primary_similarity", 0.0) > 0.8]
    ambiguous_entities = [e for e in candidates if e not in clear_entities]

    # Step 3: LLM Classification (PAID, 500ms) - Only 3-5 ambiguous
    if ambiguous_entities and self.llm_classifier:
        ambiguous_entities = await self.llm_classifier.classify_ambiguous(
            ambiguous_entities, full_text, max_llm_calls=3
        )

    # Merge results
    final_candidates = clear_entities + ambiguous_entities

    # Final confidence adjustment
    for entity in final_candidates:
        role = entity.get("embedding_role", "SECONDARY")
        if role == "PRIMARY":
            entity["adjusted_confidence"] += 0.12
        elif role == "COMPETITOR":
            entity["adjusted_confidence"] -= 0.15

    return final_candidates
```

---

### üìä Impact Attendu (Filtrage Contextuel Hybride)

| M√©trique | Actuel (confidence only) | Avec Hybride | Delta |
|----------|-------------------------|--------------|-------|
| **Pr√©cision** | 60% | 85-92% | **+30%** |
| **Recall** | 80% | 85-90% | **+8%** |
| **F1-score** | 68% | 87% | **+19%** |
| **Probl√®me concurrents** | ‚ùå Promus (ERREUR) | ‚úÖ Rejet√©s | **R√âSOLU** |
| **Language coverage** | ‚úÖ Toutes | ‚úÖ Toutes | =0 |
| **Co√ªt/doc** | $0 | $0 (Graph+Emb only) | =0 |
| **Latence** | <50ms | <300ms | +250ms |
| **Maintenance** | Nulle | Nulle | =0 |

---

### üìã Plan d'Impl√©mentation P0 (Phase 1.5)

**Priorit√© P0** (√† int√©grer imm√©diatement Phase 1.5) :

#### Semaine 11 J7-8 (2 jours) ‚ö†Ô∏è **CRITIQUE**

**Jour 7** :
- ‚úÖ Impl√©menter `GraphCentralityScorer` (300 lignes)
  - TF-IDF weighting
  - Salience score (position + titre)
  - Fen√™tre adaptive
  - Tests unitaires (10 tests)

**Jour 8** :
- ‚úÖ Impl√©menter `EmbeddingsContextualScorer` (200 lignes)
  - Paraphrases multilingues
  - Agr√©gation multi-occurrences
  - Tests unitaires (8 tests)

**Jour 9** :
- ‚úÖ Int√©grer dans `GatekeeperDelegate._gate_check_tool()`
  - Cascade Graph ‚Üí Embeddings
  - Ajustement confidence selon role
  - Tests int√©gration (5 tests)

**Total effort** : 3 jours dev (vs 2.5j estim√© initial)

**Impact business** :
- ‚úÖ R√©sout probl√®me concurrents promus (CRITIQUE)
- ‚úÖ +30% pr√©cision extraction
- ‚úÖ $0 co√ªt suppl√©mentaire
- ‚úÖ 100% language-agnostic

---

### üîç GAP Secondaire: R√©solution Cor√©f√©rence

**Probl√®me** :
```
Document: "SAP S/4HANA Cloud is our ERP solution. It provides real-time analytics."

Extraction actuelle:
- SAP S/4HANA Cloud ‚úÖ
- "It" ‚ùå (not resolved to SAP S/4HANA Cloud)

Impact: -15-25% recall (mentions perdues)
```

**Solution** :
```python
# src/knowbase/semantic/preprocessing/coreference.py (150 lignes)

class CoreferenceResolver:
    """Resolve pronouns to entities using spaCy neuralcoref"""

    def __init__(self):
        import spacy
        import neuralcoref
        self.nlp = spacy.load("en_core_web_md")
        neuralcoref.add_to_pipe(self.nlp)

    def resolve_coreferences(self, text):
        """Replace pronouns with resolved entities"""
        doc = self.nlp(text)
        return doc._.coref_resolved  # "SAP S/4HANA Cloud is our ERP solution. SAP S/4HANA Cloud provides..."
```

**Priorit√©** : P1 (moins critique que filtrage contextuel)

**Effort** : 1 jour dev

**Impact** : +15-20% recall

---

### üìà M√©triques Cibles (Apr√®s Filtrage Contextuel + Cor√©f√©rence)

| M√©trique | Avant | Apr√®s (Cible) |
|----------|-------|---------------|
| **Pr√©cision** | 60% | **85-92%** |
| **Recall** | 80% | **90-95%** |
| **F1-score** | 68% | **87-93%** |
| **Fragments/bruit** | 15% | < 5% |
| **Concurrents mal promus** | 30% (ERREUR) | 0% (R√âSOLU) |
| **Concepts m√©tier** | 30% | > 80% |

---

**Conclusion (Mise √† Jour)** : Le pipeline OSMOSE Pure V2.1 fonctionne techniquement (Neo4j OK, Qdrant OK, extraction end-to-end), mais souffre de **2 gaps critiques** :

1. **LLM extraction d√©sactiv√©e** ‚Üí R√©activer (1h)
2. **Filtrage contextuel insuffisant** ‚Üí Impl√©menter Graph + Embeddings (3 jours) ‚ö†Ô∏è **P0 CRITIQUE**

Le **filtrage contextuel hybride** est la priorit√© absolue car il r√©sout le probl√®me majeur des concurrents promus au m√™me niveau que les produits principaux (+30% pr√©cision, $0 co√ªt).
