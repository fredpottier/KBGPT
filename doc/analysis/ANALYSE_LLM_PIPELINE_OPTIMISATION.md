# Analyse Pipeline PPTX - Opportunit√©s d'Optimisation LLM ‚Üí KG

**Date**: 30 septembre 2025
**Contexte**: Analyse des appels LLM durant l'import PPTX pour identifier les opportunit√©s de r√©utilisation pour alimenter le Knowledge Graph Graphiti

---

## üìä Architecture Actuelle du Pipeline PPTX

### Flux Global (`pptx_pipeline.py`)

```
1. Upload PPTX
   ‚Üì
2. Suppression slides cach√©s (remove_hidden_slides_inplace)
   ‚Üì
3. Conversion PPTX ‚Üí PDF (LibreOffice)
   ‚Üì
4. Extraction contenu texte (MegaParse ou python-pptx)
   ‚Üì
5. ü§ñ APPEL LLM #1: Analyse deck global (analyze_deck_summary)
   ‚Üì
6. Conversion PDF ‚Üí Images PNG (PyMuPDF)
   ‚Üì
7. Pour chaque slide:
      7a. ü§ñ APPEL LLM #2: Analyse slide + image (ask_gpt_slide_analysis)
      7b. Chunking avec overlap (recursive_chunk)
      7c. Embedding SentenceTransformer
      7d. Ingestion Qdrant (ingest_chunks)
   ‚Üì
8. D√©placement vers docs_done
```

---

## ü§ñ Appels LLM Identifi√©s

### APPEL LLM #1: Analyse Deck Global
**Fonction**: `analyze_deck_summary()` (ligne 832)
**Mod√®le**: LLMRouter avec `TaskType.METADATA_EXTRACTION`
**Input**:
- R√©sum√© agr√©g√© de tous les slides (limit√© √† MAX_TOKENS_THRESHOLD)
- Texte des notes si disponibles
- Nom du fichier source

**Output JSON**:
```json
{
  "summary": "R√©sum√© narratif complet du deck",
  "metadata": {
    "title": "Titre du document",
    "objective": "Objectif du document",
    "audience": ["Type audience 1", "Type audience 2"],
    "source_date": "2025-01-15",
    "main_solution": "SAP S/4HANA Cloud",
    "main_solution_id": "s4hana_cloud",
    "family": "ERP",
    "supporting_solutions": ["SAP Fiori", "SAP HANA"],
    "mentioned_solutions": ["SAP BTP", "SAP Analytics Cloud"],
    "version": "2024 FPS01",
    "deployment_model": "Public Cloud",
    "document_type": "technical_presentation"
  },
  "_prompt_meta": {
    "document_type": "default",
    "deck_prompt_id": "deck_analysis_v2",
    "prompts_version": "2.5.0"
  }
}
```

**Co√ªt estim√©**: ~$0.002-0.005 par deck (selon taille)
**Temps**: 1-3 secondes

---

### APPEL LLM #2: Analyse Slide Individuelle
**Fonction**: `ask_gpt_slide_analysis()` (ligne 913)
**Mod√®le**: LLMRouter avec `TaskType.VISION`
**Input**:
- Image PNG du slide (base64)
- R√©sum√© du deck (contexte)
- Texte extrait du slide
- Notes du pr√©sentateur
- Contenu MegaParse structur√©
- Index du slide

**Output JSON** (array de concepts):
```json
[
  {
    "full_explanation": "Explication d√©taill√©e du concept 1 avec contexte business...",
    "meta": {
      "scope": "solution-specific",
      "type": "feature_description",
      "level": "technical",
      "tags": ["integration", "API", "real-time"],
      "slide_role": "content",
      "mentioned_solutions": ["SAP BTP", "SAP Integration Suite"]
    },
    "prompt_meta": {
      "document_type": "default",
      "slide_prompt_id": "slide_vision_v3",
      "prompts_version": "2.5.0"
    }
  },
  {
    "full_explanation": "Explication d√©taill√©e du concept 2...",
    "meta": { /* ... */ }
  }
]
```

**Co√ªt estim√©**: ~$0.01-0.03 par slide (vision + texte)
**Temps**: 2-5 secondes par slide
**Volume**: 1 appel √ó nombre de slides (peut √™tre 50-500 slides)

---

## üí° Opportunit√©s d'Optimisation Identifi√©es

### Option 1: Enrichissement Direct Pendant l'Analyse Slide ‚úÖ **RECOMMAND√â**

**Principe**: Modifier le prompt de `ask_gpt_slide_analysis()` pour extraire aussi des **entit√©s structur√©es** et **relations** en plus des chunks textuels.

**Avantages**:
- ‚úÖ **Z√©ro appel LLM suppl√©mentaire** - r√©utilise l'appel vision existant
- ‚úÖ **Contexte riche** - le LLM a d√©j√† l'image + texte + contexte deck
- ‚úÖ **Latence nulle** - extraction parall√®le aux chunks
- ‚úÖ **Coh√©rence parfaite** - entit√©s align√©es avec les chunks ing√©r√©s

**Modifications n√©cessaires**:

#### 1. Extension du prompt slide (`config/prompts.yaml`)
```yaml
slide:
  default:
    system: "You analyze slides to extract concepts AND structured knowledge graph entities."
    template: |
      Deck summary: {{ deck_summary }}
      Slide {{ slide_index }}: {{ source_name }}

      Text: {{ text }}
      Notes: {{ notes }}
      MegaParse: {{ megaparse_content }}

      Extract:
      1. Concepts as before (full_explanation + meta)
      2. NEW: Entities (name, type, attributes)
      3. NEW: Relations (source, target, type, description)

      Return JSON:
      {
        "concepts": [ /* existing format */ ],
        "entities": [
          {
            "name": "SAP S/4HANA Cloud",
            "entity_type": "PRODUCT",
            "description": "Cloud ERP solution...",
            "attributes": {
              "version": "2024 FPS01",
              "deployment": "Public Cloud",
              "vendor": "SAP"
            }
          }
        ],
        "relations": [
          {
            "source": "SAP S/4HANA Cloud",
            "target": "SAP Fiori",
            "relation_type": "USES_TECHNOLOGY",
            "description": "Modern UX layer for S/4HANA"
          }
        ]
      }
```

#### 2. Modification de `ask_gpt_slide_analysis()` (ligne 913)
```python
def ask_gpt_slide_analysis(
    image_path,
    deck_summary,
    slide_index,
    source_name,
    text,
    notes,
    megaparse_content="",
    document_type="default",
    deck_prompt_id="unknown",
    retries=2,
):
    # ... existing code ...

    try:
        raw_content = llm_router.complete(TaskType.VISION, msg)
        cleaned_content = clean_gpt_response(raw_content or "")
        result = json.loads(cleaned_content)

        # Extraction existante des concepts
        concepts = result.get("concepts", [])
        enriched = []
        for it in concepts:
            # ... existing chunking logic ...

        # üÜï NOUVEAU: Extraction entit√©s et relations
        entities = result.get("entities", [])
        relations = result.get("relations", [])

        return {
            "chunks": enriched,  # Pour Qdrant (existant)
            "entities": entities,  # Pour Graphiti (nouveau)
            "relations": relations  # Pour Graphiti (nouveau)
        }
    except Exception as e:
        logger.warning(f"Slide {slide_index} attempt {attempt} failed: {e}")
        time.sleep(2 * (attempt + 1))

    return {"chunks": [], "entities": [], "relations": []}
```

#### 3. Ajout de l'ingestion Knowledge Graph dans `process_pptx()` (ligne 1062)
```python
def process_pptx(pptx_path: Path, document_type: str = "default", progress_callback=None, rq_job=None):
    # ... existing code jusqu'√† la boucle de traitement des slides ...

    # üÜï NOUVEAU: Initialiser le service KG
    from knowbase.api.services.knowledge_graph import get_knowledge_graph_service
    kg_service = get_knowledge_graph_service()

    # Contexte utilisateur (pour group_id)
    user_context = {"user_id": "system", "group_id": "corporate"}  # √Ä adapter selon le contexte

    all_kg_entities = []  # Accumuler les entit√©s du deck
    all_kg_relations = []  # Accumuler les relations du deck

    for i, (idx, future) in enumerate(tasks):
        # ... existing progress tracking ...

        result = future.result()
        chunks = result.get("chunks", [])
        entities = result.get("entities", [])
        relations = result.get("relations", [])

        # Ingestion existante dans Qdrant
        ingest_chunks(chunks, metadata, pptx_path.stem, idx, summary)

        # üÜï NOUVEAU: Ingestion dans Knowledge Graph
        if entities:
            all_kg_entities.extend(entities)
            logger.info(f"Slide {idx}: {len(entities)} entit√©s extraites pour KG")

        if relations:
            all_kg_relations.extend(relations)
            logger.info(f"Slide {idx}: {len(relations)} relations extraites pour KG")

    # üÜï NOUVEAU: Ingestion batch dans Graphiti apr√®s traitement de toutes les slides
    if all_kg_entities:
        logger.info(f"üîÑ Ingestion de {len(all_kg_entities)} entit√©s dans Graphiti...")
        for entity_data in all_kg_entities:
            try:
                entity_create = EntityCreate(
                    name=entity_data["name"],
                    entity_type=EntityType[entity_data["entity_type"]],
                    description=entity_data.get("description", ""),
                    attributes=entity_data.get("attributes", {})
                )
                created_entity = await kg_service.create_entity(entity_create, user_context)
                logger.debug(f"‚úÖ Entit√© cr√©√©e: {created_entity.name}")
            except Exception as e:
                logger.error(f"‚ùå Erreur cr√©ation entit√© {entity_data['name']}: {e}")

    if all_kg_relations:
        logger.info(f"üîÑ Ingestion de {len(all_kg_relations)} relations dans Graphiti...")
        # TODO: Impl√©menter cr√©ation relations via KG service

    # ... existing finalization code ...
```

---

### Option 2: Appel LLM Additionnel Post-Analyse ‚ö†Ô∏è **NON RECOMMAND√â**

**Principe**: Apr√®s ingestion Qdrant, faire un appel LLM s√©par√© pour extraire entit√©s.

**Inconv√©nients**:
- ‚ùå **Co√ªt doubl√©** - appel LLM vision suppl√©mentaire par slide
- ‚ùå **Latence augment√©e** - +2-5s par slide
- ‚ùå **Risque incoh√©rence** - entit√©s peuvent diverger des chunks
- ‚ùå **Complexit√©** - gestion de deux workflows parall√®les

**Verdict**: Ne pas impl√©menter cette option.

---

### Option 3: Extraction Post-Ingestion depuis Qdrant ‚ö†Ô∏è **PARTIEL**

**Principe**: Utiliser les chunks d√©j√† dans Qdrant pour extraire entit√©s a posteriori.

**Avantages**:
- ‚úÖ Pas de modification du pipeline existant
- ‚úÖ Peut √™tre fait progressivement

**Inconv√©nients**:
- ‚ö†Ô∏è **Perte de contexte** - plus d'acc√®s √† l'image, seulement texte des chunks
- ‚ö†Ô∏è **Qualit√© inf√©rieure** - entit√©s moins pr√©cises sans contexte visuel
- ‚ö†Ô∏è **Appels LLM suppl√©mentaires** - co√ªt additionnel sans vision

**Usage recommand√©**: Uniquement pour migration historique des donn√©es existantes, pas pour nouveaux imports.

---

## üìã Donn√©es LLM R√©utilisables pour Graphiti

### Depuis `analyze_deck_summary()` (Deck global)

| Donn√©e LLM | Utilisation Graphiti | Type Entit√© |
|------------|----------------------|-------------|
| `metadata.main_solution` | Entit√© principale PRODUCT | `EntityType.PRODUCT` |
| `metadata.supporting_solutions[]` | Entit√©s PRODUCT + relations SUPPORTS | `EntityType.PRODUCT` |
| `metadata.mentioned_solutions[]` | Entit√©s PRODUCT + relations MENTIONS | `EntityType.PRODUCT` |
| `metadata.title` | Attribut document | M√©tadonn√©e |
| `metadata.objective` | Attribut document | M√©tadonn√©e |
| `metadata.audience[]` | Entit√©s PERSONA | `EntityType.CONCEPT` |
| `metadata.version` | Attribut version produit | Attribut |
| `metadata.deployment_model` | Attribut deployment | Attribut |
| `summary` | Description document | Contexte global |

**Exemple d'entit√© cr√©√©e**:
```python
EntityCreate(
    name="SAP S/4HANA Cloud",
    entity_type=EntityType.PRODUCT,
    description=deck_summary,  # Contexte riche du deck
    attributes={
        "version": "2024 FPS01",
        "deployment_model": "Public Cloud",
        "family": "ERP",
        "document_source": "presentation_xyz.pptx",
        "source_date": "2025-01-15"
    }
)
```

---

### Depuis `ask_gpt_slide_analysis()` (Par slide)

| Donn√©e LLM | Utilisation Graphiti | Type Entit√© |
|------------|----------------------|-------------|
| `full_explanation` | Description d√©taill√©e | Attribut/Description |
| `meta.mentioned_solutions[]` | Relations PRODUCT | Relation |
| `meta.tags[]` | Tags/cat√©gories | Attribut |
| `meta.type` | Type de contenu | Attribut |
| `meta.level` | Niveau technique | Attribut |
| `meta.scope` | Scope (solution-specific, general) | Attribut |

**Nouvelles extractions √† ajouter** (modification prompt):
- **Entit√©s nomm√©es**: Features, Modules, Technologies, Personas
- **Relations**: USES, REQUIRES, REPLACES, INTEGRATES_WITH
- **√âv√©nements temporels**: Releases, Migrations, Deadlines

---

## üéØ Recommandation Finale

### ‚úÖ Impl√©menter Option 1: Enrichissement Direct

**Justification**:
1. **Co√ªt LLM nul** - r√©utilise appels existants
2. **Qualit√© maximale** - contexte vision + texte complet
3. **Latence nulle** - extraction parall√®le
4. **Coh√©rence garantie** - entit√©s align√©es avec chunks Qdrant

**Impl√©mentation sugg√©r√©e**:

#### Phase 1: Extension minimale (2-3 heures)
1. ‚úÖ Modifier prompt slide pour ajouter section "entities" et "relations"
2. ‚úÖ Modifier retour de `ask_gpt_slide_analysis()` pour inclure entit√©s
3. ‚úÖ Ajouter ingestion KG dans `process_pptx()` apr√®s boucle slides
4. ‚úÖ Tests avec 1 PPTX simple (5-10 slides)

#### Phase 2: Optimisations (1-2 jours)
1. ‚è≥ D√©doublonnage entit√©s (m√™me entit√© sur plusieurs slides)
2. ‚è≥ Fusion intelligente des attributs
3. ‚è≥ Cr√©ation des relations entre entit√©s
4. ‚è≥ Linking entit√©s ‚Üî chunks Qdrant (via UUIDs)

#### Phase 3: Production (optionnel)
1. ‚è≥ Gestion erreurs robuste (entit√© existe d√©j√†, etc.)
2. ‚è≥ Statistiques KG dans r√©ponse ingestion
3. ‚è≥ UI pour visualiser entit√©s extraites d'un document
4. ‚è≥ Tests charge (deck 100+ slides)

---

## üìä Estimation Co√ªts/B√©n√©fices

### Co√ªts Additionnels
- **Co√ªt LLM**: 0‚Ç¨ (r√©utilise appels existants)
- **Latence**: +0s (extraction parall√®le)
- **Stockage Neo4j**: ~50-200 entit√©s par deck (n√©gligeable)
- **D√©veloppement**: 2-3 jours (estimation)

### B√©n√©fices
- ‚úÖ **Knowledge Graph automatiquement enrichi** lors de chaque import
- ‚úÖ **Qualit√© sup√©rieure** vs migration a posteriori (contexte visuel pr√©serv√©)
- ‚úÖ **Z√©ro impact performance** sur pipeline existant
- ‚úÖ **Workflow unifi√©** - 1 seul job pour Qdrant + Graphiti
- ‚úÖ **Coh√©rence parfaite** entre chunks vectoriels et entit√©s graph

---

## üîÑ Comparaison avec Strat√©gie de Migration

| Aspect | Import Direct (Option 1) | Migration Post-Ingestion |
|--------|---------------------------|--------------------------|
| **Co√ªt LLM** | $0 (r√©utilise existant) | ~$14 pour 1000 docs |
| **Temps** | +0s par document | 8-16h pour 1000 docs |
| **Qualit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (vision + texte) | ‚≠ê‚≠ê‚≠ê (texte seulement) |
| **Latence ingestion** | Identique | N/A |
| **Coh√©rence donn√©es** | Parfaite | Risque divergence |
| **Complexit√© impl√©mentation** | Moyenne | Faible |
| **Maintenance** | Simple (1 workflow) | Double (2 workflows) |

**Verdict**: L'import direct (Option 1) est **largement sup√©rieur** pour les nouveaux documents.

---

## üìù Exemple Concret

### Document: "SAP S/4HANA Cloud - Technical Overview.pptx" (50 slides)

#### Donn√©es LLM Actuelles (D√©j√† Extraites)
```json
{
  "deck_analysis": {
    "summary": "Pr√©sentation technique compl√®te de SAP S/4HANA Cloud...",
    "metadata": {
      "main_solution": "SAP S/4HANA Cloud",
      "supporting_solutions": ["SAP Fiori", "SAP HANA", "SAP BTP"],
      "mentioned_solutions": ["SAP Analytics Cloud", "SAP Integration Suite"]
    }
  },
  "slide_5_analysis": {
    "concepts": [
      {
        "full_explanation": "SAP S/4HANA Cloud utilise une architecture 3-tier...",
        "meta": {
          "tags": ["architecture", "cloud", "scalability"],
          "mentioned_solutions": ["SAP HANA", "SAP BTP"]
        }
      }
    ]
  }
}
```

#### Entit√©s Graphiti Cr√©√©es (Apr√®s Modification)
```python
# Depuis analyze_deck_summary()
Entity(
    uuid="uuid-s4hana-cloud",
    name="SAP S/4HANA Cloud",
    entity_type=EntityType.PRODUCT,
    description="Cloud ERP solution with real-time analytics",
    attributes={"family": "ERP", "deployment": "Public Cloud"}
)

# Depuis slide 5 analysis
Entity(
    uuid="uuid-fiori",
    name="SAP Fiori",
    entity_type=EntityType.PRODUCT,
    description="Modern user experience layer",
    attributes={"type": "UX Framework"}
)

Relation(
    source_uuid="uuid-s4hana-cloud",
    target_uuid="uuid-fiori",
    relation_type="USES_TECHNOLOGY",
    description="S/4HANA Cloud uses Fiori for modern UX"
)
```

---

## ‚úÖ Action Items

### Priorit√© Haute (Impl√©menter maintenant)
- [ ] Modifier prompt slide dans `config/prompts.yaml` pour ajouter extraction entit√©s/relations
- [ ] Adapter `ask_gpt_slide_analysis()` pour parser nouvelles sections
- [ ] Int√©grer ingestion KG dans `process_pptx()`
- [ ] Tester avec 1 PPTX simple

### Priorit√© Moyenne (Apr√®s validation)
- [ ] D√©doublonnage entit√©s au niveau deck
- [ ] Cr√©ation relations entre entit√©s
- [ ] Linking entit√©s ‚Üî chunks Qdrant
- [ ] Tests avec gros deck (100+ slides)

### Priorit√© Basse (Nice to have)
- [ ] UI visualisation entit√©s extraites
- [ ] Statistiques KG dans r√©ponse API
- [ ] Export graph knowledge d'un document
- [ ] Tests E2E complets

---

**Conclusion**: La modification du pipeline PPTX pour enrichir directement le Knowledge Graph est **hautement recommand√©e** car elle offre z√©ro co√ªt LLM additionnel, qualit√© maximale gr√¢ce au contexte vision, et coh√©rence parfaite avec les donn√©es vectorielles Qdrant.