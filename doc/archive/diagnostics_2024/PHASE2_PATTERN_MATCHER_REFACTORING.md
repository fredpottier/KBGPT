# Phase 2 OSMOSE - Refactoring PatternMatcher (Architecture Robuste)

**Date:** 2025-01-19
**ProblÃ¨me:** Patterns regex figÃ©s trop fragiles pour extraction rÃ©elle
**Solution:** Architecture hybride multi-stratÃ©gies

---

## ğŸš¨ ProblÃ¨me IdentifiÃ©

### Exemple RÃ©el ManquÃ©
```
Input: "la base HANA est chiffrÃ©e au repos en AES256"

Concepts dÃ©tectÃ©s:
- HANA (database)
- AES256 (encryption algorithm)

Relations attendues:
- HANA USES AES256 (encryption)
- HANA HAS_SECURITY_FEATURE "encryption at rest"

âŒ Patterns actuels: AUCUNE relation dÃ©tectÃ©e !
```

### Limites Approche Regex Pure

1. **VariabilitÃ© linguistique infinie**
   - "utilise", "uses", "is based on", "leverages", "employs"
   - "chiffrÃ©e", "encrypted", "secured with", "protected by"
   - ImpossibilitÃ© de lister tous les verbes

2. **Relations implicites**
   - "HANA chiffrÃ©e en AES256" â†’ USES implicite
   - "Fiori dans S/4HANA" â†’ PART_OF implicite
   - "CCR 2023 aprÃ¨s CCR 2022" â†’ REPLACES implicite

3. **Contexte technique crucial**
   - "au repos" vs "en transit" â†’ metadata importante
   - "optionnel" vs "obligatoire" â†’ USES vs REQUIRES
   - "deprecated" vs "current" â†’ status relation

4. **NÃ©gations et conditions**
   - "ne nÃ©cessite PAS" â†’ ne pas crÃ©er REQUIRES
   - "peut utiliser" â†’ USES avec strength=WEAK
   - "incompatible avec" â†’ relation nÃ©gative

---

## âœ… Architecture Hybride Robuste

### StratÃ©gie 1: Co-occurrence Analysis (NEW!)
**IdÃ©e:** Concepts mentionnÃ©s proches â†’ candidats relations

```python
def find_cooccurring_concepts(
    concepts: List[Dict],
    full_text: str,
    window_size: int = 100  # 100 caractÃ¨res
) -> List[Tuple[str, str, str]]:
    """
    Trouver concepts co-occurrents dans fenÃªtres glissantes.

    Returns:
        [(concept_A, concept_B, context_snippet), ...]
    """
    # Pour chaque paire concepts trouvÃ©s Ã  <100 chars
    # â†’ Candidat relation (LLM dÃ©cidera du type)
```

**Exemple:**
```
"la base HANA est chiffrÃ©e au repos en AES256"
         ^^^^                           ^^^^^^
         |                               |
         +---------- 35 chars -----------+

â†’ Candidat: (HANA, AES256, "chiffrÃ©e au repos en")
â†’ LLM: USES (encryption context)
```

### StratÃ©gie 2: spaCy Dependency Parsing (J5)
**IdÃ©e:** Analyser structure grammaticale Sujet-Verbe-Objet

```python
import spacy

nlp = spacy.load("fr_core_news_lg")
doc = nlp("la base HANA est chiffrÃ©e au repos en AES256")

# Extraire triplets SVO
for token in doc:
    if token.dep_ == "ROOT":  # Verbe principal
        subject = [w for w in token.children if w.dep_ == "nsubj"]
        objects = [w for w in token.children if w.dep_ in ["obj", "obl"]]

        # â†’ (HANA, chiffrÃ©e, AES256)
        # Verbe "chiffrÃ©e" â†’ mapper vers relation USES
```

**Mapping verbes â†’ relation types:**
```python
VERB_TO_RELATION = {
    # FranÃ§ais
    "utilise": RelationType.USES,
    "nÃ©cessite": RelationType.REQUIRES,
    "remplace": RelationType.REPLACES,
    "chiffre": RelationType.USES,  # Context: encryption
    "inclut": RelationType.PART_OF,

    # Anglais
    "uses": RelationType.USES,
    "requires": RelationType.REQUIRES,
    "encrypts": RelationType.USES,
    "includes": RelationType.PART_OF,
    "replaces": RelationType.REPLACES,
}
```

### StratÃ©gie 3: LLM Validation (CRITIQUE!)
**IdÃ©e:** LLM dÃ©cide du type relation + valide contexte

```python
def validate_with_llm(
    candidate: Tuple[str, str, str],  # (conceptA, conceptB, context)
    concepts_metadata: Dict
) -> Optional[TypedRelation]:
    """
    Envoyer candidat au LLM pour validation.

    Prompt:
    '''
    Context: "{context}"
    Concept A: {conceptA.canonical_name} ({conceptA.type})
    Concept B: {conceptB.canonical_name} ({conceptB.type})

    Question: Is there a semantic relation between A and B?
    If yes, which type?
    - USES (A uses B)
    - REQUIRES (A requires B - mandatory)
    - PART_OF (A is part of B)
    - ... [9 core types]

    Answer JSON:
    {
        "has_relation": true/false,
        "relation_type": "USES",
        "confidence": 0.85,
        "direction": "Aâ†’B",
        "metadata": {
            "context_type": "encryption",
            "strength": "STRONG"
        }
    }
    '''
    """
```

**Exemple LLM response:**
```json
{
    "has_relation": true,
    "relation_type": "USES",
    "confidence": 0.92,
    "direction": "HANAâ†’AES256",
    "metadata": {
        "context_type": "encryption",
        "encryption_scope": "at_rest",
        "strength": "STRONG"
    }
}
```

### StratÃ©gie 4: Semantic Similarity (Embeddings)
**IdÃ©e:** Patterns sÃ©mantiques appris via embeddings

```python
def compute_relation_similarity(
    context_embedding: np.ndarray,  # "chiffrÃ©e au repos en"
    relation_type_embeddings: Dict[RelationType, np.ndarray]
) -> RelationType:
    """
    Comparer embedding contexte avec embeddings types relations.

    relation_type_embeddings = {
        RelationType.USES: embed("uses, utilizes, employs, leverages"),
        RelationType.REQUIRES: embed("requires, needs, depends on"),
        ...
    }
    """
    similarities = {}
    for rel_type, rel_emb in relation_type_embeddings.items():
        sim = cosine_similarity(context_embedding, rel_emb)
        similarities[rel_type] = sim

    return max(similarities, key=similarities.get)
```

---

## ğŸ—ï¸ Nouvelle Architecture PatternMatcher

```python
class ImprovedPatternMatcher:
    """
    Matcher hybride multi-stratÃ©gies.

    Pipeline:
    1. Co-occurrence analysis (fenÃªtres glissantes)
    2. spaCy dependency parsing (SVO triplets)
    3. Regex patterns (patterns explicites)
    4. Semantic similarity (embeddings)
    5. LLM validation (final decision)
    """

    def __init__(self):
        self.spacy_nlp = spacy.load("fr_core_news_lg")
        self.llm_router = LLMRouter()
        self.embedder = MultilingualEmbedder(config)

        # Pre-compute relation type embeddings
        self.relation_embeddings = self._compute_relation_embeddings()

    def extract_relations(
        self,
        concepts: List[Dict],
        full_text: str,
        document_id: str
    ) -> List[TypedRelation]:
        """
        Extraction multi-stratÃ©gies.
        """
        candidates = []

        # StratÃ©gie 1: Co-occurrence (NOUVEAU!)
        cooccur_candidates = self._extract_cooccurrence(concepts, full_text)
        candidates.extend(cooccur_candidates)

        # StratÃ©gie 2: spaCy SVO (NOUVEAU!)
        spacy_candidates = self._extract_spacy_triplets(concepts, full_text)
        candidates.extend(spacy_candidates)

        # StratÃ©gie 3: Regex patterns (existant)
        regex_candidates = self._extract_regex_patterns(concepts, full_text)
        candidates.extend(regex_candidates)

        # StratÃ©gie 4: Semantic similarity (NOUVEAU!)
        for candidate in candidates:
            if not candidate.relation_type:
                # LLM n'a pas dÃ©cidÃ©, essayer semantic similarity
                candidate.relation_type = self._infer_type_semantic(
                    candidate.context
                )

        # StratÃ©gie 5: LLM validation (CRITIQUE!)
        validated_relations = []
        for candidate in candidates:
            validated = self._validate_with_llm(candidate, concepts)
            if validated and validated.metadata.confidence >= 0.60:
                validated_relations.append(validated)

        return validated_relations
```

---

## ğŸ“Š Performance Attendue

### Baseline (Regex seul)
- Precision: ~70% (beaucoup faux positifs)
- Recall: ~30% (beaucoup manquÃ©s)
- **F1-score: ~42%**

### Approche Hybride
- Precision: ~85% (LLM valide)
- Recall: ~70% (co-occurrence + spaCy Ã©largissent)
- **F1-score: ~77%** (+35 points!)

### Cas d'usage amÃ©liorÃ©s

| Exemple | Regex seul | Hybride |
|---------|------------|---------|
| "HANA chiffrÃ©e en AES256" | âŒ ManquÃ© | âœ… USES (0.92) |
| "Fiori inclus dans S/4" | âœ… PART_OF | âœ… PART_OF (0.95) |
| "CCR remplace l'ancien systÃ¨me" | âŒ "ancien systÃ¨me" pas concept | âœ… Ignore (LLM) |
| "peut utiliser OCR optionnel" | âŒ ManquÃ© | âœ… USES (weak) |

---

## ğŸ”„ Plan ImplÃ©mentation

### Phase 1 (ImmÃ©diat)
- [x] Identifier problÃ¨me patterns figÃ©s
- [ ] ImplÃ©menter co-occurrence analyzer
- [ ] Ajouter spaCy dependency parsing
- [ ] CrÃ©er LLM validation prompt

### Phase 2 (J5-J7)
- [ ] ImplÃ©menter semantic similarity
- [ ] Tests sur 100 cas rÃ©els
- [ ] Tuning seuils confidence

### Phase 3 (J8-J10)
- [ ] Optimisation prompts LLM
- [ ] Cache LLM responses (mÃªmes patterns)
- [ ] Monitoring prÃ©cision/recall

---

## ğŸ’¡ Conclusion

**ProblÃ¨me initial:** Patterns regex trop rigides, manquent 70% relations rÃ©elles

**Solution:** Architecture hybride 5 stratÃ©gies complÃ©mentaires

**Gain attendu:** +35 points F1-score (42% â†’ 77%)

**ClÃ© du succÃ¨s:** LLM validation finale (dÃ©cision intelligente basÃ©e contexte)
