# IDEA 001 - OpenAI Structured Outputs pour Extraction Robuste

**Date** : 2025-10-12
**Statut** : Proposition / Ã€ Ã©valuer
**Impact estimÃ©** : ğŸ”¥ Ã‰levÃ© - RÃ©duction drastique des erreurs de parsing
**PrioritÃ©** : Moyenne-Haute

---

## ğŸ“Š Contexte

Actuellement, le projet utilise `response_format={"type": "json_object"}` pour les extractions LLM (entitÃ©s, facts, mÃ©tadonnÃ©es). Cette approche ne garantit **pas** que le JSON retournÃ© respecte exactement le schÃ©ma attendu, ce qui nÃ©cessite du code de "rÃ©paration" et de transformation.

**ProblÃ¨mes rencontrÃ©s** :
- âœ— Le LLM peut retourner des champs manquants ou mal typÃ©s
- âœ— NÃ©cessitÃ© de crÃ©er `transform_fact_for_neo4j()` pour rÃ©parer les incohÃ©rences (pdf_pipeline.py:424-529)
- âœ— Parsing manual avec regex pour les facts
- âœ— Erreurs Pydantic validation possibles

---

## ğŸ¯ Qu'est-ce que Structured Outputs ?

**Structured Outputs** est une fonctionnalitÃ© d'OpenAI qui garantit que le LLM retourne **toujours** un JSON qui correspond **exactement** Ã  un schÃ©ma JSON Schema fourni.

### DiffÃ©rence avec JSON Mode Standard

| Aspect | JSON Mode Standard | Structured Outputs |
|--------|-------------------|-------------------|
| **ConformitÃ© schÃ©ma** | Non garantie | âœ… 100% garantie |
| **Parsing errors** | Possibles | âŒ Impossibles |
| **Validation Pydantic** | Peut Ã©chouer | âœ… Toujours rÃ©ussit |
| **Champs requis** | Peuvent manquer | âœ… Toujours prÃ©sents |
| **Types stricts** | Non respectÃ©s | âœ… Strictement respectÃ©s |

---

## âœ¨ Avantages pour le Projet SAP_KB

### 1. **Extraction d'EntitÃ©s PDF** (pdf_pipeline.py)

**Situation actuelle** :
- Utilise `response_format={"type": "json_object"}` (ligne ~400)
- Le LLM gÃ©nÃ¨re parfois des facts avec format incompatible FactCreate
- NÃ©cessitÃ© de `transform_fact_for_neo4j()` pour mapper les types

**Avec Structured Outputs** :
```python
class FactCreate(BaseModel):
    subject: str
    predicate: str
    object: str
    value: float
    unit: str
    fact_type: FactType  # Enum strict

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "fact_extraction",
            "strict": True,
            "schema": FactCreate.model_json_schema()
        }
    }
)

# âœ… Parsing ne peut PAS Ã©chouer, plus besoin de transform_fact_for_neo4j()
result = FactCreate.model_validate_json(response.choices[0].message.content)
```

**Impact** :
- âœ… Suppression de transform_fact_for_neo4j() (100+ lignes de code)
- âœ… Ã‰limination des erreurs Pydantic ValidationError
- âœ… Code plus simple et maintenable

### 2. **Extraction Facts** (pdf_pipeline.py)

**ProblÃ¨me actuel** :
- Parsing manuel avec regex car le format n'est pas garanti
- Mapping free-text â†’ enum `fact_type`
- Parsing de valeurs numÃ©riques + unitÃ©s

**Avec Structured Outputs** :
- Le LLM est **forcÃ©** de retourner un enum valide
- Les valeurs numÃ©riques sont dÃ©jÃ  typÃ©es correctement
- Pas besoin de parsing manuel

### 3. **Metadata Extraction** (pptx_pipeline.py)

**Avec Structured Outputs** :
- Garantie que les champs requis sont prÃ©sents
- Types strictement respectÃ©s
- Moins de code dÃ©fensif

### 4. **Ontology Generation** (ontology_worker.py)

**Avec Structured Outputs** :
- Structure d'ontologie strictement garantie
- Pas de validation manuelle nÃ©cessaire
- RÃ©duction des erreurs de format

---

## ğŸ’» Comment l'ImplÃ©menter ?

### Exemple Simple

```python
from pydantic import BaseModel
from openai import OpenAI

# SchÃ©ma Pydantic (dÃ©jÃ  existant dans le projet)
class EntityExtraction(BaseModel):
    entities: list[Entity]
    facts: list[Fact]

# Appel avec Structured Outputs
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "entity_extraction",
            "strict": True,  # â† ClÃ© importante !
            "schema": EntityExtraction.model_json_schema()
        }
    }
)

# Le parsing ne peut PAS Ã©chouer !
result = EntityExtraction.model_validate_json(response.choices[0].message.content)
```

### IntÃ©gration dans llm_router.py

Modifier `src/knowbase/common/llm_router.py` pour supporter un paramÃ¨tre `strict_schema` :

```python
def call_llm(
    prompt: str,
    model_preference: str = "openai",
    response_format: Optional[dict] = None,
    strict_schema: Optional[BaseModel] = None,  # â† Nouveau
    **kwargs
) -> str:
    if strict_schema and model_preference == "openai":
        response = client.chat.completions.create(
            model=model_config["name"],
            messages=[{"role": "user", "content": prompt}],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": strict_schema.__name__,
                    "strict": True,
                    "schema": strict_schema.model_json_schema()
                }
            },
            **kwargs
        )
    else:
        # Mode standard actuel
        ...
```

---

## ğŸ¯ Cas d'Usage Prioritaires

### ğŸ¥‡ **PrioritÃ© 1 : pdf_pipeline.py - Extraction Facts**

**Raison** : Impact le plus Ã©levÃ©, beaucoup de code de transformation Ã  supprimer

**Fichiers Ã  modifier** :
- `src/knowbase/ingestion/pipelines/pdf_pipeline.py` (lignes 400-650)
- Suppression de `transform_fact_for_neo4j()` (lignes 424-529)

**Gain estimÃ©** :
- -150 lignes de code de transformation
- -100% erreurs Pydantic ValidationError sur facts
- Temps dev Ã©conomisÃ© : ~2-3h par bug de format Ã©vitÃ©

### ğŸ¥ˆ **PrioritÃ© 2 : ontology_worker.py - GÃ©nÃ©ration Ontologie**

**Raison** : Structure critique, garantie de qualitÃ© importante

**Fichiers Ã  modifier** :
- `src/knowbase/api/workers/ontology_worker.py`

**Gain estimÃ©** :
- Validation automatique 100% fiable
- Moins de debugging

### ğŸ¥‰ **PrioritÃ© 3 : pptx_pipeline.py - MÃ©tadonnÃ©es**

**Raison** : Moins critique mais amÃ©lioration de robustesse

**Fichiers Ã  modifier** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

---

## âš–ï¸ Trade-offs

### âœ… Avantages

| Avantage | Impact |
|----------|--------|
| Ã‰limine erreurs parsing/validation | ğŸ”¥ Ã‰levÃ© |
| Code plus simple (-150 lignes) | ğŸ”¥ Ã‰levÃ© |
| Moins de code dÃ©fensif | ğŸŸ¡ Moyen |
| Meilleure robustesse | ğŸ”¥ Ã‰levÃ© |
| Maintenance facilitÃ©e | ğŸŸ¡ Moyen |

### âš ï¸ InconvÃ©nients

| InconvÃ©nient | Impact |
|--------------|--------|
| Migration nÃ©cessite tests | ğŸŸ¡ Moyen |
| LÃ©gÃ¨rement plus lent (~5-10%) | ğŸŸ¢ Faible |
| NÃ©cessite OpenAI SDK >= 1.0 | ğŸŸ¢ Faible |
| Seulement OpenAI (pas Claude) | ğŸŸ¡ Moyen |

---

## ğŸ› ï¸ Plan de Migration SuggÃ©rÃ©

### Phase 1 : PrÃ©paration (1h)
1. VÃ©rifier version OpenAI SDK actuelle
2. Upgrade si nÃ©cessaire : `pip install openai>=1.0`
3. Tester sur environnement de dev

### Phase 2 : ImplÃ©mentation PDF Pipeline (3-4h)
1. Modifier `llm_router.py` pour supporter `strict_schema`
2. Adapter `pdf_pipeline.py` pour utiliser Structured Outputs
3. Supprimer `transform_fact_for_neo4j()`
4. Tests unitaires

### Phase 3 : Validation (2h)
1. Tester sur documents rÃ©els
2. Comparer rÃ©sultats avant/aprÃ¨s
3. Monitorer logs d'erreurs

### Phase 4 : Rollout autres pipelines (2h)
1. Ontology worker
2. PPTX pipeline
3. Tests d'intÃ©gration

**Temps total estimÃ©** : 8-9 heures

---

## ğŸ“Š MÃ©triques de SuccÃ¨s

### Avant Migration
- âŒ ~5-10% erreurs Pydantic ValidationError sur facts
- âŒ 150 lignes de code de transformation
- âŒ Temps debug moyen : 30min par erreur de format

### AprÃ¨s Migration
- âœ… 0% erreurs Pydantic ValidationError attendu
- âœ… -150 lignes de code
- âœ… Temps debug : 0 (pas d'erreurs de format)

---

## ğŸ” Limitations Techniques

### ModÃ¨les SupportÃ©s
- âœ… GPT-4o
- âœ… GPT-4o-mini
- âŒ GPT-3.5-turbo (pas supportÃ©)
- âŒ Claude (OpenAI uniquement)

**Impact pour le projet** : âœ… Pas de problÃ¨me, on utilise gpt-4o-mini

### Contraintes JSON Schema

Structured Outputs supporte :
- âœ… Types simples (string, number, boolean)
- âœ… Objects et nested objects
- âœ… Arrays
- âœ… Enums
- âœ… Required fields
- âŒ `additionalProperties: true` (pas supportÃ© en mode strict)

---

## ğŸ’¡ Recommandation Finale

**Verdict** : âœ… **TrÃ¨s recommandÃ©**

**Raisons** :
1. Le projet a dÃ©jÃ  rencontrÃ© des bugs liÃ©s aux formats JSON incohÃ©rents
2. Beaucoup de code de "rÃ©paration" pourrait Ãªtre Ã©liminÃ©
3. Utilise dÃ©jÃ  gpt-4o-mini (compatible)
4. ROI Ã©levÃ© : 8-9h migration vs ~3-4h Ã©conomisÃ©es par mois en debug

**Action recommandÃ©e** :
- DÃ©marrer par une **proof of concept** sur pdf_pipeline.py (2-3h)
- Si succÃ¨s â†’ Migration progressive des autres pipelines
- Si Ã©chec â†’ Pas de rÃ©gression, code actuel conservÃ©

---

## ğŸ“š RÃ©fÃ©rences

- Documentation OpenAI : https://platform.openai.com/docs/guides/structured-outputs
- Migration Guide : https://platform.openai.com/docs/guides/structured-outputs/migrating
- JSON Schema Spec : https://json-schema.org/

---

## ğŸ“ Notes Additionnelles

**CompatibilitÃ© avec config actuelle** :
- `config/llm_models.yaml` : Pas de modification nÃ©cessaire
- `config/prompts.yaml` : Pas de modification nÃ©cessaire
- Multi-provider : Rester compatible avec Claude (fallback sur JSON mode standard)

**Risques identifiÃ©s** :
- ğŸŸ¢ Faible : Migration technique simple
- ğŸŸ¢ Faible : Rollback possible immÃ©diatement
- ğŸŸ¡ Moyen : NÃ©cessite tests approfondis pour valider Ã©quivalence

---

**CrÃ©Ã© par** : Claude Code
**DerniÃ¨re mise Ã  jour** : 2025-10-12
