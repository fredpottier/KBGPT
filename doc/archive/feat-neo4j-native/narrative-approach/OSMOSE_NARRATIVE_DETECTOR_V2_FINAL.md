# ğŸŒŠ OSMOSE - NarrativeThreadDetector V2 : SpÃ©cification Architecture Finale

**Projet:** KnowWhere - OSMOSE Phase 1 Extended
**Composant:** NarrativeThreadDetector V2 (Architecture Finale)
**Version:** 2.0 - Incorporant Corrections OpenAI
**Status:** Ready for Implementation
**Date:** 2025-10-13
**Auteurs:** Architecture Team + OpenAI Review

---

## ğŸ“‹ Table des MatiÃ¨res

1. [RÃ©sumÃ© ExÃ©cutif](#rÃ©sumÃ©-exÃ©cutif)
2. [Contexte et Motivation](#contexte-et-motivation)
3. [Vision Architecture V2](#vision-architecture-v2)
4. [Composant 1 : TopicSegmenter](#composant-1--topicsegmenter)
5. [Composant 2 : EventExtractor](#composant-2--eventextractor)
6. [Composant 3 : ThreadBuilder](#composant-3--threadbuilder)
7. [Composant 4 : VisionExtractor PPTX](#composant-4--visionextractor-pptx)
8. [Composant 5 : CrossDocumentFusion](#composant-5--crossdocumentfusion)
9. [Infrastructure Critique : LLMDispatcher](#infrastructure-critique--llmdispatcher)
10. [Data Model Proto-KG](#data-model-proto-kg)
11. [Performance et Cost Model](#performance-et-cost-model)
12. [Plan ImplÃ©mentation](#plan-implÃ©mentation)
13. [CritÃ¨res de SuccÃ¨s et KPIs](#critÃ¨res-de-succÃ¨s-et-kpis)
14. [Risques et Mitigations](#risques-et-mitigations)
15. [Annexes](#annexes)

---

## ğŸ“‹ RÃ©sumÃ© ExÃ©cutif

### Objectif

Remplacer le **NarrativeThreadDetector V1** (scan global naÃ¯f) par une architecture **intelligente, contextuelle et Ã©volutive** capable de :

- âœ… DÃ©tecter narratives sur documents 600+ pages **sans pollution**
- âœ… Extraire Ã©vÃ©nements des **graphiques PPTX** (multimodal)
- âœ… Construire **timelines causales** cross-documents
- âœ… Supporter **multilinguisme** (EN, FR, DE, IT, ES)
- âœ… Performer **<45s sur 650 pages** avec coÃ»t **<$0.15/doc**

### Changement de Paradigme

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ V1 (NaÃ¯ve) - Pattern Matching Global                â”‚
â”‚ Text â†’ Regex Global â†’ Thread (positions)            â”‚
â”‚                                                      â”‚
â”‚ ProblÃ¨mes:                                           â”‚
â”‚ - Thread de 650 pages (pollution)                   â”‚
â”‚ - PPTX visuels ignorÃ©s                              â”‚
â”‚ - Multiples narratives confondues                   â”‚
â”‚ - Performance >30s juste regex                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                      â†“ REFONTE â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ V2 (Intelligente) - Narrative as Events             â”‚
â”‚ Text â†’ Topics â†’ Events â†’ Threads â†’ Timeline         â”‚
â”‚        â†“        â†“        â†“         â†“                 â”‚
â”‚     Cluster  Anchored  Graph    Ordered             â”‚
â”‚                                                      â”‚
â”‚ BÃ©nÃ©fices:                                           â”‚
â”‚ - Topics locaux (pas de pollution)                  â”‚
â”‚ - Events structurÃ©s (entity, change, cause, date)   â”‚
â”‚ - PPTX charts + vision multimodale                  â”‚
â”‚ - Timeline causale explicable                       â”‚
â”‚ - Performance <45s avec parallÃ©lisation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Corrections OpenAI IntÃ©grÃ©es

Ce document intÃ¨gre **100% des corrections** du retour OpenAI :

1. âœ… **LLMDispatcher centralisÃ©** (rate limiting, backoff, cache)
2. âœ… **HDBSCAN fallbacks robustes** (Agglomerative + trim)
3. âœ… **CausalitÃ© Ã  preuves** (evidence spans + markers obligatoires)
4. âœ… **PPTX shapes complÃ¨tes** (pas shapes[0], iterate all)
5. âœ… **Cost model rÃ©aliste** (par taille doc + overhead 20%)
6. âœ… **Bug agrÃ©gation parallÃ¨le** (filter by doc_id)
7. âœ… **Canonicalisation robuste** (blocking + embeddings + dict)
8. âœ… **Conflict resolution policies** (prioritÃ©, consensus)
9. âœ… **Lexiques multilingues** (FR, DE, IT, ES complets)

### DÃ©cision StratÃ©gique

**GO V2 ComplÃ¨te - 15 Semaines**

- Pas de dÃ©mo immÃ©diate programmÃ©e
- Objectif : construire cible directement
- QualitÃ© > vitesse
- Timeline rÃ©aliste avec checkpoints

---

## ğŸ“‹ Contexte et Motivation

### ProblÃ¨mes Critiques V1

#### 1. Scan Global NaÃ¯f â†’ Pollution Massive

**Code V1 actuel** (`narrative_detector.py:124`):
```python
# Scan regex sur TOUT le texte d'un coup
pattern = rf'([^.!?]*)\b{re.escape(connector)}\b([^.!?]*[.!?])'
matches = list(re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE))

# Si â‰¥2 occurrences â†’ 1 thread global
if len(matches) >= 2:
    sequence = {
        "start_pos": matches[0].start(),    # Premier match
        "end_pos": matches[-1].end()         # Dernier match
    }
```

**ProblÃ¨me concret:**
```
Document "SAP S/4HANA Implementation Guide" (650 pages, 1.3M chars)
Contient "because" 247 fois:

Page 3 (Finance):
  "CRR changed BECAUSE methodology updated"

Page 89 (Supply Chain):
  "OEE improved BECAUSE new dashboard deployed"

Page 178 (HR):
  "Retention rate changed BECAUSE policy update"

V1 crÃ©e: 1 SEUL thread (page 3 â†’ page 178)
Keywords: ["CRR", "Finance", "OEE", "Supply", "HR", "Retention"]
â†’ MÃ©lange 3 narratives distinctes ğŸš¨
```

**Impact:**
- âŒ Thread inutilisable (trop large)
- âŒ Keywords polluÃ©s (sujets mixÃ©s)
- âŒ Confidence artificielle (247 matches)
- âŒ LLM enrichment voit 1500 chars sur 95,000 (1.6%)

---

#### 2. PPTX Visuels IgnorÃ©s â†’ KILLER FEATURE InopÃ©rante

**V1 actuelle:**
```python
# Extraction texte uniquement
text_content = megaparse.extract_text(pptx_file)
# RÃ©sultat: titres + notes (~500 chars)
# Graphiques, charts, timelines = PERDUS
```

**Cas d'usage critique:**
```
PrÃ©sentation "CRR Evolution Q1-Q4 2023.pptx" (45 slides)

Slide 5: "CRR Quarterly Performance"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Line Chart                 â”‚
â”‚   85% â—â”€â”€â”€â”€â”€â”€â”€â—                â”‚
â”‚       â•±         â•²              â”‚
â”‚   70% â—           â—            â”‚
â”‚       Q1  Q2  Q3  Q4           â”‚
â”‚                                â”‚
â”‚ Values: 72% â†’ 78% â†’ 80% â†’ 82% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Slide 12: "Methodology Timeline"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2022  v1.0 Introduced          â”‚
â”‚   â†“                            â”‚
â”‚ 2023  v2.0 Updated (ISO)       â”‚
â”‚   â†“                            â”‚
â”‚ 2024  v3.0 Enhanced            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Texte extrait V1: "CRR Quarterly Performance\nMethodology Timeline"
Connecteurs causaux: 0
Marqueurs temporels: 0
Threads dÃ©tectÃ©s: 0

â†’ KILLER FEATURE "CRR Evolution Tracker" = Ã‰CHEC ğŸš¨
```

**Impact business:**
- âŒ Use case principal non dÃ©montrable
- âŒ DiffÃ©renciation vs Copilot perdue
- âŒ PrÃ©sentations = format majeur en entreprise

---

#### 3. Multiples Narratives Confondues

**V1 ne distingue pas les topics:**
```python
# Un connecteur = une sÃ©quence globale
for connector in ["because", "therefore", "as a result"]:
    matches = find_all(connector, text)  # Trouve TOUS les matches
    if len(matches) >= 2:
        create_single_sequence(matches[0], matches[-1])
        # â†’ Thread unique du premier au dernier match
```

**Exemple pollution:**
```
Section Finance (pages 1-100):
  "CRR improved BECAUSE new formula"
  "Revenue increased BECAUSE market expansion"

Section Supply Chain (pages 200-300):
  "OEE optimized BECAUSE process automation"
  "Costs reduced BECAUSE supplier consolidation"

V1 crÃ©e 1 thread "because" (page 1 â†’ page 300):
  Keywords: CRR, Revenue, OEE, Costs, Formula, Market, Process, Supplier
  Description LLM: "Various business improvements"
  â†’ Inutilisable ğŸš¨
```

---

#### 4. Enrichissement LLM InadÃ©quat

**V1 limite contexte:**
```python
# narrative_detector.py:266
context = text[thread.start_position:thread.end_position]
if len(context) > 1500:
    context = context[:1500] + "..."

# Thread span: 95,000 chars (50 pages)
# LLM voit: 1,500 chars (1.6%)
```

**ProblÃ¨me:**
```
Thread Finance+Supply+HR (pages 3-178):
  span: 95,000 chars

LLM reÃ§oit chars 0-1500:
  "Section 3.1 Financial Metrics
   CRR calculation changed BECAUSE old formula deprecated..."

LLM conclut: "CRR methodology evolution"

Thread contient AUSSI (chars 50,000-95,000, NON VUS):
  - OEE tracking (Supply Chain)
  - HR retention metrics
  - Technical infrastructure

â†’ Faux positif: Thread labellÃ© "CRR" contient pollution ğŸš¨
```

---

#### 5. Multilinguisme Non SupportÃ©

**V1 hardcodÃ© anglais** (`config.py:34-41`):
```python
causal_connectors: List[str] = [
    "because", "therefore", "as a result",
    "due to", "consequently", "leads to"
]

temporal_markers: List[str] = [
    "revised", "updated", "replaced",
    "deprecated", "superseded", "evolved"
]
```

**Impact:**
```
Document franÃ§ais: "Guide SAP Finance 2023.pdf"

Text: "Le CRR a Ã©tÃ© mis Ã  jour en mars 2023 en raison
       de la conformitÃ© ISO 23592 requise par l'audit."

V1 cherche: "updated", "because"
V1 trouve: 0 matches

Threads dÃ©tectÃ©s: 0

â†’ MarchÃ© international SAP = non adressable ğŸš¨
```

**MarchÃ© impactÃ©:**
- âŒ France (2e marchÃ© SAP Europe)
- âŒ Allemagne (1er marchÃ© SAP Europe)
- âŒ Italie, Espagne, Benelux
- âŒ ~60% du marchÃ© SAP mondial

---

### RÃ©sumÃ© Impact V1

| ProblÃ¨me | Impact Business | SÃ©vÃ©ritÃ© |
|----------|-----------------|----------|
| Pollution threads 600+ pages | Inutilisable en production | ğŸ”´ CRITIQUE |
| PPTX visuels ignorÃ©s | KILLER FEATURE inopÃ©rante | ğŸ”´ CRITIQUE |
| Narratives confondues | Faux positifs massifs | ğŸ”´ CRITIQUE |
| LLM mal nourri | Descriptions erronÃ©es | ğŸŸ  HIGH |
| Pas de multilang | 60% marchÃ© perdu | ğŸ”´ CRITIQUE |
| Performance >30s | UX dÃ©gradÃ©e | ğŸŸ¡ MEDIUM |

**Verdict:** V1 = POC non viable en production

---

---

## ğŸ¯ Vision Architecture V2

### Principes Fondamentaux

**1. Topic-First : Segmentation avant DÃ©tection**

```
Au lieu de:
  Document â†’ Scan Global â†’ Thread (pollution)

V2 fait:
  Document â†’ Topics Locaux â†’ Events par Topic â†’ Threads Propres
```

**BÃ©nÃ©fice:** Chaque thread limitÃ© Ã  un contexte sÃ©mantique cohÃ©rent.

**2. Events-as-First-Class : Structure avant Texte**

```
Au lieu de:
  Thread = {start_pos, end_pos, keywords[], description}

V2 fait:
  Event = {entity, change_type, value_before, value_after,
           date, cause, evidence_spans[], confidence}
  Thread = Graph[Events] avec Relations
```

**BÃ©nÃ©fice:** DonnÃ©es structurÃ©es, validables, exportables.

**3. Evidence-Based : Pas de Hallucination**

```
Au lieu de:
  LLM gÃ©nÃ¨re description libre

V2 fait:
  Chaque Event/Relation â†’ evidence_spans[] obligatoires
  Validation: span existe dans texte source
```

**BÃ©nÃ©fice:** TraÃ§abilitÃ© complÃ¨te, pas d'hallucination.

**4. Multimodal : Texte + Vision**

```
Au lieu de:
  PPTX â†’ texte uniquement

V2 fait:
  PPTX â†’ texte + chart XML + vision LLM (sÃ©lective)
```

**BÃ©nÃ©fice:** Graphiques timeline = meilleure source d'Ã©volution.

---

### Pipeline Complet V2

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT: Document                             â”‚
â”‚            (PDF 650 pages OU PPTX 45 slides)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 1 : TOPIC SEGMENTATION                                   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ TopicSegmenter                                                  â”‚
â”‚                                                                 â”‚
â”‚ 1.1 Structural Segmentation                                    â”‚
â”‚     - Parse headers (h1, h2, h3) via MegaParse                â”‚
â”‚     - Fallback: pages si pas de headers                       â”‚
â”‚                                                                 â”‚
â”‚ 1.2 Semantic Windowing                                         â”‚
â”‚     - Windows: 3000 chars, overlap 25%                         â”‚
â”‚     - ~200 windows pour 650 pages                              â”‚
â”‚                                                                 â”‚
â”‚ 1.3 Embeddings + Clustering                                    â”‚
â”‚     - Embed windows (OpenAI text-embedding-3-small)            â”‚
â”‚     - HDBSCAN clustering                                        â”‚
â”‚     - Fallback: Agglomerative si HDBSCAN noise >30%           â”‚
â”‚                                                                 â”‚
â”‚ 1.4 Anchor Extraction                                          â”‚
â”‚     - NER (spaCy multi-lang)                                   â”‚
â”‚     - TF-IDF keywords                                           â”‚
â”‚     - Cohesion score                                            â”‚
â”‚                                                                 â”‚
â”‚ OUTPUT: Topics [{id, windows, anchors, cohesion}]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 2 : EVENT EXTRACTION                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ EventExtractor (3 mÃ©thodes complÃ©mentaires)                    â”‚
â”‚                                                                 â”‚
â”‚ 2.1 Pattern-Based (rapide, haute prÃ©cision)                   â”‚
â”‚     - Regex temporal/causal/version multilingues               â”‚
â”‚     - Extraction: entity, date, values, cause                  â”‚
â”‚     - Validation: anchor match + evidence span                 â”‚
â”‚                                                                 â”‚
â”‚ 2.2 LLM-Based (contexte, haute recall)                        â”‚
â”‚     - Si patterns insuffisants (<2 events/topic)               â”‚
â”‚     - Structured output JSON                                    â”‚
â”‚     - Dispatcher: rate limit + backoff + cache                 â”‚
â”‚                                                                 â”‚
â”‚ 2.3 Vision-Based (PPTX uniquement)                            â”‚
â”‚     - Parse chart XML (70% success)                            â”‚
â”‚     - Vision LLM selective (3-5 slides/deck)                   â”‚
â”‚     - Multi-source confidence boost                            â”‚
â”‚                                                                 â”‚
â”‚ OUTPUT: Events [{entity, change, date, cause, evidence}]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 3 : THREAD CONSTRUCTION                                   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ThreadBuilder                                                   â”‚
â”‚                                                                 â”‚
â”‚ 3.1 Entity Canonicalization                                    â”‚
â”‚     - Blocking (lemma, acronym, Jaro-Winkler)                 â”‚
â”‚     - Embeddings similarity top-K                              â”‚
â”‚     - Dict aliases + LLM fallback                              â”‚
â”‚                                                                 â”‚
â”‚ 3.2 Event Grouping                                             â”‚
â”‚     - Group by (topic_id, entity_canonical)                    â”‚
â”‚                                                                 â”‚
â”‚ 3.3 Temporal Ordering                                          â”‚
â”‚     - Sort by date (exact > quarter > year)                    â”‚
â”‚                                                                 â”‚
â”‚ 3.4 Relation Identification                                    â”‚
â”‚     - PRECEDES (temporal order)                                â”‚
â”‚     - CAUSES (evidence + marker required)                      â”‚
â”‚     - EVOLVES_TO (version upgrade)                             â”‚
â”‚     - CONTRADICTS (conflict detection)                         â”‚
â”‚                                                                 â”‚
â”‚ 3.5 Timeline Construction                                      â”‚
â”‚     - Chronological events + relations                         â”‚
â”‚     - Provenance (source docs + spans)                         â”‚
â”‚                                                                 â”‚
â”‚ OUTPUT: Threads [{events, relations, timeline}]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 4 : CROSS-DOCUMENT FUSION                                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ CrossDocumentFusion                                             â”‚
â”‚                                                                 â”‚
â”‚ 4.1 Entity Linking                                             â”‚
â”‚     - Canonicalize across documents                            â”‚
â”‚     - Multilang aliases (CRR = Taux RÃ©tention)                â”‚
â”‚                                                                 â”‚
â”‚ 4.2 Event Deduplication                                        â”‚
â”‚     - Same entity + date + value â†’ 1 event                     â”‚
â”‚     - Provenance: multiple sources                             â”‚
â”‚                                                                 â”‚
â”‚ 4.3 Conflict Resolution                                        â”‚
â”‚     - Policies: recency, authority, consensus                  â”‚
â”‚     - Log resolution strategy                                   â”‚
â”‚                                                                 â”‚
â”‚ 4.4 Master Thread                                              â”‚
â”‚     - Unified timeline                                          â”‚
â”‚     - Cross-doc relations                                       â”‚
â”‚     - Multi-source confidence                                   â”‚
â”‚                                                                 â”‚
â”‚ OUTPUT: Master Threads (cross-doc timeline)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               STORAGE: Neo4j Proto-KG + Qdrant                  â”‚
â”‚                                                                 â”‚
â”‚ - Neo4j: Topics, EventCandidates, Relations, Provenance       â”‚
â”‚ - Qdrant: Vectors + payload narrative metadata                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Exemple Concret End-to-End

**Input:**
```
Documents:
1. SAP_CRR_Methodology_v1_2022.pdf (45 pages)
2. SAP_CRR_Updated_2023.pdf (38 pages)
3. SAP_Implementation_Guide_2023.pdf (650 pages, section CRR p.287-312)
4. Analytics_Dashboard_Q3_2023.pptx (45 slides, Slide 5 = chart CRR)
```

**Ã‰tape 1: Topic Segmentation**
```
Doc1 (45 pages):
  â†’ Topic A: "CRR Methodology" (8 windows, anchors: [CRR, formula, ISO])
  â†’ Topic B: "Calculation Examples" (5 windows)

Doc2 (38 pages):
  â†’ Topic C: "CRR v2.0 Update" (6 windows, anchors: [CRR, v2.0, ISO 23592])

Doc3 (650 pages):
  â†’ 45 topics total
  â†’ Topic D: "Financial Metrics - CRR" (4 windows, p.287-312)
  â†’ Topic E: "Supply Chain - OEE" (6 windows, p.450-480)
  â†’ ... (autres topics non-CRR ignorÃ©s)

Doc4 (PPTX 45 slides):
  â†’ Topic F: "CRR Performance Q3" (1 slide, Slide 5)
```

**Ã‰tape 2: Event Extraction**
```
Topic A (Doc1):
  Event1:
    entity: "CRR"
    change_type: "INTRODUCED"
    value_after: "v1.0 (simple average formula)"
    date: "2022-01-15"
    extraction_method: "PATTERN"
    evidence: [Span(doc1, 5000, 5200)]

Topic C (Doc2):
  Event2:
    entity: "Customer Retention Rate"  # Alias de CRR
    change_type: "UPDATED"
    value_before: "v1.0"
    value_after: "v2.0 (ISO 23592 weighted formula)"
    date: "2023-03-15"
    cause: "ISO 23592 compliance requirement + audit feedback"
    extraction_method: "LLM"
    evidence: [Span(doc2, 8000, 8400)]

Topic D (Doc3):
  Event3:
    entity: "CRR"
    change_type: "AUDIT_FINDING"
    date: "2022-11-20"
    cause: "v1.0 formula lacks ISO 23592 compliance"
    extraction_method: "PATTERN"
    evidence: [Span(doc3, 287500, 287800)]

Topic F (Doc4 - PPTX):
  Event4:
    entity: "CRR"
    change_type: "INCREASED"
    value_before: "72%"
    value_after: "82%"
    date: "2023-Q3"
    cause: "v2.0 methodology impact"
    extraction_method: "VISION"
    evidence: [Span(doc4, slide5, "chart")]
```

**Ã‰tape 3: Thread Construction**
```
Entity canonicalization:
  "CRR" = "Customer Retention Rate" â†’ "Customer Retention Rate"

Grouping:
  Events [1, 2, 3, 4] â†’ mÃªme entity canonique â†’ 1 thread

Temporal ordering:
  Event1 (2022-01-15) â†’ Event3 (2022-11-20) â†’ Event2 (2023-03-15) â†’ Event4 (2023-Q3)

Relations:
  Event1 --[PRECEDES]--> Event3
  Event3 --[CAUSES]--> Event2  (audit finding â†’ update)
  Event1 --[EVOLVES_TO]--> Event2  (v1.0 â†’ v2.0)
  Event2 --[CAUSES]--> Event4  (new methodology â†’ improvement)

Thread:
  NarrativeThread(
    thread_id: "master_CRR",
    entity: "Customer Retention Rate",
    events: [Event1, Event3, Event2, Event4],
    relations: [PRECEDES, CAUSES, EVOLVES_TO, CAUSES],
    timeline: {
      "2022-01-15": "CRR v1.0 Introduced",
      "2022-11-20": "Audit Gap Identified (lacks ISO)",
      "2023-03-15": "CRR v2.0 Updated (ISO compliant)",
      "2023-Q3": "CRR Performance +10% (72% â†’ 82%)"
    },
    source_documents: ["doc1", "doc2", "doc3", "doc4"],
    is_cross_document: True,
    confidence: 0.88
  )
```

**Output User:**
```
Query: "Comment CRR a Ã©voluÃ© ?"

Timeline CRR (2022-2023):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2022-01-15 â”‚ CRR v1.0 Introduced             â”‚
â”‚            â”‚ Formula: Simple average         â”‚
â”‚            â”‚ Source: [Doc1, p.12]            â”‚
â”‚            â”‚ â†“ EVOLVES_TO                    â”‚
â”‚            â”‚                                 â”‚
â”‚ 2022-11-20 â”‚ Audit Gap Identified            â”‚
â”‚            â”‚ Finding: v1.0 lacks ISO 23592   â”‚
â”‚            â”‚ Source: [Doc3, p.287]           â”‚
â”‚            â”‚ â†“ CAUSES                        â”‚
â”‚            â”‚                                 â”‚
â”‚ 2023-03-15 â”‚ CRR v2.0 Updated                â”‚
â”‚            â”‚ Formula: ISO 23592 weighted     â”‚
â”‚            â”‚ Cause: Compliance + audit       â”‚
â”‚            â”‚ Source: [Doc2, p.5]             â”‚
â”‚            â”‚ â†“ CAUSES                        â”‚
â”‚            â”‚                                 â”‚
â”‚ 2023-Q3    â”‚ CRR Performance +10%            â”‚
â”‚            â”‚ Value: 72% â†’ 82%                â”‚
â”‚            â”‚ Cause: v2.0 methodology         â”‚
â”‚            â”‚ Source: [Doc4, Slide 5 - Chart]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… 4 Ã©vÃ©nements | 3 relations causales
âœ… 4 sources (3 PDF + 1 PPTX)
âœ… Confidence: 0.88
```

---

---

## ğŸ—ï¸ Composant 1 : TopicSegmenter

### ResponsabilitÃ©

DÃ©couper un document en **topics sÃ©mantiquement cohÃ©rents** pour Ã©viter pollution cross-sections.

### Architecture

```python
class TopicSegmenter:
    """
    Segmente documents en topics avec clustering robuste

    Corrections OpenAI intÃ©grÃ©es:
    - HDBSCAN fallback Agglomerative
    - Trim clusters (min/max windows)
    - Config exposÃ©e (min_cluster_size, cohesion thresholds)
    - Logging taux de rejet
    """

    def __init__(self, config: SegmentationConfig):
        self.config = config
        self.embedder = CachedEmbedder()  # Cache pour perf
        self.ner = MultiLangNER()  # spaCy multi-lang

        # Fallback hiÃ©rarchique
        self.primary_clusterer = HDBSCANClusterer(
            min_cluster_size=config.min_cluster_size,
            min_samples=config.min_samples
        )
        self.fallback_clusterer = AgglomerativeClusterer()

    async def segment_document(
        self,
        document: Document
    ) -> List[Topic]:
        """
        Pipeline segmentation:
        1. Structural (sections)
        2. Windowing (3000 chars, 25% overlap)
        3. Embeddings (cached)
        4. Clustering (HDBSCAN + fallbacks)
        5. Anchor extraction
        6. Trim/validate
        """

        # 1. Structural segmentation
        sections = self._extract_sections(document)

        all_topics = []
        for section in sections:
            # 2. Semantic windowing
            windows = self._create_windows(
                section.text,
                size=self.config.window_size,
                overlap=self.config.overlap
            )

            # 3. Embeddings (parallÃ¨le + cache)
            embeddings = await self.embedder.embed_batch(
                [w.text for w in windows]
            )

            # 4. Clustering robuste (avec fallbacks)
            clusters = self._cluster_with_fallbacks(
                windows,
                embeddings,
                section
            )

            # 5. Pour chaque cluster â†’ topic
            for cluster_id, cluster_windows in clusters.items():
                # Anchor extraction
                anchors = self._extract_anchors(cluster_windows)

                # Cohesion score
                cohesion = self._calculate_cohesion(
                    cluster_windows,
                    embeddings
                )

                # Validation
                if cohesion < self.config.cohesion_threshold:
                    logger.warning(
                        f"Topic {section.id}_{cluster_id} low cohesion: {cohesion:.2f}"
                    )
                    continue

                topic = Topic(
                    topic_id=f"{section.id}_cluster_{cluster_id}",
                    section_path=section.path,
                    windows=cluster_windows,
                    anchors=anchors,
                    cohesion_score=cohesion
                )

                # 6. Trim si trop large
                topic = self._trim_topic_if_needed(topic)

                all_topics.append(topic)

        return all_topics
```

---

### Clustering Robuste (Correction OpenAI Critique)

**ProblÃ¨me identifiÃ©:**
> "HDBSCAN peut rejeter beaucoup de fenÃªtres (label -1). Fallback requis + trim."

**Solution implÃ©mentÃ©e:**

```python
def _cluster_with_fallbacks(
    self,
    windows: List[Window],
    embeddings: np.ndarray,
    section: Section
) -> Dict[int, List[Window]]:
    """
    Clustering hiÃ©rarchique avec fallbacks

    StratÃ©gie:
    1. HDBSCAN (primary)
    2. Si taux rejet >30% â†’ Agglomerative
    3. Si pas de sections â†’ k-means auto
    4. Trim clusters (min/max windows)
    """

    # Tentative 1: HDBSCAN
    clusters_hdbscan = self.primary_clusterer.cluster(embeddings)

    # Calculer taux de rejet (label -1 = noise)
    noise_ratio = np.sum(clusters_hdbscan.labels == -1) / len(clusters_hdbscan.labels)

    logger.info(
        f"[TopicSegmenter] HDBSCAN noise ratio: {noise_ratio:.2%} "
        f"(threshold: {self.config.max_noise_ratio:.2%})"
    )

    # Si trop de rejet â†’ fallback
    if noise_ratio > self.config.max_noise_ratio:  # Default: 0.30
        logger.warning(
            f"[TopicSegmenter] HDBSCAN rejected {noise_ratio:.2%} windows. "
            f"Falling back to Agglomerative clustering."
        )

        # Fallback 1: Agglomerative
        if section.has_subsections:
            # Utiliser structure existante
            n_clusters = len(section.subsections)
            clusters_agg = self.fallback_clusterer.cluster(
                embeddings,
                n_clusters=n_clusters
            )
            return self._windows_to_clusters(windows, clusters_agg.labels)

        else:
            # Fallback 2: k-means avec k auto (elbow method)
            optimal_k = self._find_optimal_k(embeddings)
            clusters_kmeans = KMeans(n_clusters=optimal_k).fit(embeddings)
            return self._windows_to_clusters(windows, clusters_kmeans.labels_)

    # HDBSCAN OK â†’ construire clusters
    clusters_dict = self._windows_to_clusters(windows, clusters_hdbscan.labels)

    # Trim clusters
    clusters_dict = self._trim_clusters(clusters_dict)

    return clusters_dict

def _trim_clusters(
    self,
    clusters: Dict[int, List[Window]]
) -> Dict[int, List[Window]]:
    """
    Trim clusters selon min/max windows

    - Min: 2 windows (sinon trop petit)
    - Max: 15 windows (sinon split)
    """

    trimmed = {}

    for cluster_id, windows in clusters.items():
        # Ignore noise cluster (-1)
        if cluster_id == -1:
            continue

        # Trop petit â†’ ignore
        if len(windows) < self.config.min_windows_per_topic:
            logger.info(
                f"[TopicSegmenter] Cluster {cluster_id} too small "
                f"({len(windows)} windows). Skipping."
            )
            continue

        # Trop grand â†’ split
        if len(windows) > self.config.max_windows_per_topic:
            logger.info(
                f"[TopicSegmenter] Cluster {cluster_id} too large "
                f"({len(windows)} windows). Splitting."
            )

            # Split par cohesion (garder windows similaires ensemble)
            sub_clusters = self._split_large_cluster(windows)
            for i, sub_cluster in enumerate(sub_clusters):
                trimmed[f"{cluster_id}_{i}"] = sub_cluster

        else:
            # OK
            trimmed[cluster_id] = windows

    return trimmed

def _split_large_cluster(
    self,
    windows: List[Window]
) -> List[List[Window]]:
    """
    Split cluster trop large en sous-clusters cohÃ©rents

    Utilise embeddings + k-means avec k=2 ou 3
    """
    # Embed sub-windows
    embeddings = self.embedder.embed_batch_sync([w.text for w in windows])

    # k-means avec k=2 (split en 2)
    kmeans = KMeans(n_clusters=2, random_state=42).fit(embeddings)

    sub_clusters = {}
    for i, label in enumerate(kmeans.labels_):
        if label not in sub_clusters:
            sub_clusters[label] = []
        sub_clusters[label].append(windows[i])

    return list(sub_clusters.values())
```

---

### Configuration ExposÃ©e (Correction OpenAI)

```yaml
# config/osmose_semantic_intelligence.yaml

segmentation:
  # Windowing
  window_size: 3000        # chars
  overlap: 0.25            # 25%

  # HDBSCAN clustering
  min_cluster_size: 3      # Min windows pour former cluster
  min_samples: 2           # Min samples pour core point
  max_noise_ratio: 0.30    # Si >30% rejet â†’ fallback

  # Topic constraints
  min_windows_per_topic: 2
  max_windows_per_topic: 15
  cohesion_threshold: 0.65  # Min cohesion score

  # Fallback
  use_agglomerative_fallback: true
  use_structure_fallback: true  # Utiliser sections si dispo
```

---

### Anchor Extraction

```python
def _extract_anchors(
    self,
    windows: List[Window]
) -> List[str]:
    """
    Extrait anchors (entitÃ©s clÃ©s + keywords)

    MÃ©thode:
    1. NER multi-lang (spaCy)
    2. TF-IDF keywords (top 10)
    3. Dedupe + normalize
    """

    anchors = set()

    # 1. NER (Named Entity Recognition)
    all_text = " ".join([w.text for w in windows])
    entities = self.ner.extract(all_text)

    # Types d'entitÃ©s pertinents
    relevant_types = ["ORG", "PRODUCT", "LAW", "NORP", "FAC"]
    for entity in entities:
        if entity.label_ in relevant_types:
            anchors.add(entity.text)

    # 2. TF-IDF keywords
    tfidf_keywords = self._tfidf_keywords(
        windows,
        top_k=10
    )
    anchors.update(tfidf_keywords)

    # 3. Normalize (lowercase, strip)
    anchors_normalized = [
        anchor.strip().title()
        for anchor in anchors
        if len(anchor) > 2  # Ignore short
    ]

    return sorted(anchors_normalized)[:20]  # Max 20 anchors

def _tfidf_keywords(
    self,
    windows: List[Window],
    top_k: int = 10
) -> List[str]:
    """
    Extrait keywords TF-IDF haute importance
    """
    from sklearn.feature_extraction.text import TfidfVectorizer

    texts = [w.text for w in windows]

    vectorizer = TfidfVectorizer(
        max_features=50,
        stop_words="english",  # TODO: multi-lang
        ngram_range=(1, 2)  # Unigrams + bigrams
    )

    tfidf_matrix = vectorizer.fit_transform(texts)
    feature_names = vectorizer.get_feature_names_out()

    # Scores moyens par feature
    scores = tfidf_matrix.mean(axis=0).A1
    top_indices = scores.argsort()[-top_k:][::-1]

    return [feature_names[i] for i in top_indices]
```

---

### Cohesion Score

```python
def _calculate_cohesion(
    self,
    windows: List[Window],
    embeddings: np.ndarray
) -> float:
    """
    Cohesion = similaritÃ© moyenne intra-cluster

    Score:
    - 1.0 = parfaitement cohÃ©rent
    - 0.5 = moyennement cohÃ©rent
    - 0.0 = pas cohÃ©rent
    """

    if len(windows) < 2:
        return 1.0  # Trivial

    # Indices des windows dans embeddings
    indices = [w.embedding_index for w in windows]
    cluster_embeddings = embeddings[indices]

    # SimilaritÃ© cosine moyenne
    from sklearn.metrics.pairwise import cosine_similarity

    similarities = cosine_similarity(cluster_embeddings)

    # Moyenne (exclude diagonal)
    n = len(similarities)
    sum_sim = similarities.sum() - n  # Exclude diagonal (=1.0)
    avg_sim = sum_sim / (n * (n - 1)) if n > 1 else 0.0

    return float(avg_sim)
```

---

### Logging et Monitoring

```python
# MÃ©triques exposÃ©es

@dataclass
class SegmentationMetrics:
    """MÃ©triques pour monitoring segmentation"""

    total_windows: int
    total_topics: int
    clustering_method: str  # "HDBSCAN", "Agglomerative", "Structural"
    noise_ratio: float      # % windows rejetÃ©s

    topics_cohesion_mean: float
    topics_cohesion_std: float
    topics_size_mean: float
    topics_size_std: float

    anchors_per_topic_mean: float

    time_windowing_s: float
    time_embedding_s: float
    time_clustering_s: float
    time_total_s: float

# Logging
logger.info(f"""
[TopicSegmenter] Segmentation completed
  Documents: {len(documents)}
  Total windows: {metrics.total_windows}
  Total topics: {metrics.total_topics}
  Clustering: {metrics.clustering_method}
  Noise ratio: {metrics.noise_ratio:.2%}
  Cohesion: {metrics.topics_cohesion_mean:.2f} Â± {metrics.topics_cohesion_std:.2f}
  Time: {metrics.time_total_s:.1f}s
""")
```

---

---

## ğŸš¨ Infrastructure Critique : LLMDispatcher

### ProblÃ¨me IdentifiÃ© par OpenAI

> "Aucun dispatcher/budget explicite. Rate limiting, backoff, quotas manquants. Sans cela, impossible de tenir <45s."

### Solution : Dispatcher CentralisÃ©

**ResponsabilitÃ©s:**
- âœ… Rate limiting (respecter limites API)
- âœ… Backoff exponentiel (retry sur erreurs)
- âœ… Cache (Ã©viter appels redondants)
- âœ… Concurrency control (max 10 appels parallÃ¨les)
- âœ… Quotas par tenant
- âœ… Monitoring coÃ»ts

```python
class LLMDispatcher:
    """
    Dispatcher centralisÃ© pour tous appels LLM

    Correction OpenAI critique: rate limiting + backoff + cache
    """

    def __init__(self, config: LLMConfig):
        self.config = config

        # Concurrency control
        self.semaphore = asyncio.Semaphore(config.max_concurrent_requests)

        # Rate limiting (OpenAI: 500 RPM)
        self.rate_limiter = TokenBucketRateLimiter(
            max_tokens=config.max_rpm,
            refill_rate=config.max_rpm / 60  # tokens/second
        )

        # Backoff
        self.backoff = ExponentialBackoff(
            initial_delay=1.0,
            max_delay=60.0,
            factor=2.0
        )

        # Cache (LRU)
        self.cache = LRUCache(maxsize=config.cache_size)

        # Metrics
        self.metrics = DispatcherMetrics()

    async def dispatch_batch(
        self,
        requests: List[LLMRequest]
    ) -> List[LLMResponse]:
        """
        Dispatch batch avec parallÃ©lisation contrÃ´lÃ©e
        """

        # Limit concurrency
        tasks = [
            self._dispatch_one(req)
            for req in requests
        ]

        responses = await asyncio.gather(*tasks)
        return responses

    async def _dispatch_one(
        self,
        request: LLMRequest
    ) -> LLMResponse:
        """
        Dispatch request unique avec cache + retry
        """

        # 1. Cache check
        cache_key = self._cache_key(request)
        if cache_key in self.cache:
            self.metrics.cache_hits += 1
            return self.cache[cache_key]

        self.metrics.cache_misses += 1

        # 2. Rate limit
        await self.rate_limiter.acquire()

        # 3. Concurrency control
        async with self.semaphore:

            # 4. Retry avec backoff
            for attempt in range(self.config.max_retries):
                try:
                    # LLM call
                    response = await self._call_llm(request)

                    # Cache store
                    self.cache[cache_key] = response

                    # Metrics
                    self.metrics.total_requests += 1
                    self.metrics.total_tokens += response.usage.total_tokens
                    self.metrics.total_cost_usd += response.cost_usd

                    return response

                except RateLimitError as e:
                    # Backoff
                    delay = self.backoff.delay(attempt)
                    logger.warning(
                        f"[LLMDispatcher] Rate limit hit. "
                        f"Retry {attempt+1}/{self.config.max_retries} after {delay}s"
                    )
                    await asyncio.sleep(delay)

                except Exception as e:
                    logger.error(f"[LLMDispatcher] Error: {e}")
                    if attempt == self.config.max_retries - 1:
                        raise

            # Max retries exhausted
            raise LLMDispatcherError("Max retries exhausted")
```

**Configuration:**
```yaml
llm_dispatcher:
  max_concurrent_requests: 10
  max_rpm: 500  # OpenAI limit
  max_retries: 3
  cache_size: 1000
  enable_cache: true
```

**MÃ©triques exposÃ©es:**
```python
@dataclass
class DispatcherMetrics:
    total_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    total_tokens: int = 0
    total_cost_usd: float = 0.0
    avg_latency_ms: float = 0.0

    @property
    def cache_hit_ratio(self) -> float:
        total = self.cache_hits + self.cache_misses
        return self.cache_hits / total if total > 0 else 0.0
```

---

---

## ğŸ’° Performance et Cost Model RÃ©aliste

### Correction Majeure OpenAI

> "CoÃ»ts $0.05/doc irrÃ©alistes. Calcul basÃ© sur 200 pages, pas 650. Overhead tokens +20% manquant."

### Cost Model CorrigÃ© (Par Taille Document)

```python
# ==========================================
# COST MODEL V2 - RÃ‰ALISTE
# ==========================================

def calculate_cost_per_document(doc_size_pages: int) -> float:
    """
    Calcul coÃ»t rÃ©aliste avec overhead 20%
    """

    # Estimation windows
    chars_per_page = 2000
    total_chars = doc_size_pages * chars_per_page
    windows = total_chars // 3000  # Window size 3000
    windows_with_overlap = int(windows * 1.25)  # +25% overlap

    # Topics (estimation: 1 topic / 5 windows)
    topics = max(1, windows_with_overlap // 5)

    # ===== EMBEDDINGS =====
    tokens_per_window = 750  # ~3000 chars = 750 tokens
    total_embedding_tokens = windows_with_overlap * tokens_per_window
    cost_embeddings = (total_embedding_tokens / 1_000_000) * 0.00002  # text-embedding-3-small

    # ===== LLM EXTRACTION =====
    # Pattern-first â†’ LLM seulement si insuffisant (50% des topics)
    llm_topics = int(topics * 0.5)
    tokens_per_llm_call = 4000  # Input: 3000 + output: 1000
    total_llm_tokens = llm_topics * tokens_per_llm_call
    cost_llm = (total_llm_tokens / 1_000_000) * 0.15  # gpt-4o-mini

    # ===== VISION (PPTX) =====
    cost_vision = 0.0  # Pas de PPTX par dÃ©faut

    # ===== OVERHEAD 20% =====
    subtotal = cost_embeddings + cost_llm + cost_vision
    overhead = subtotal * 0.20

    total = subtotal + overhead

    return {
        "doc_size_pages": doc_size_pages,
        "windows": windows_with_overlap,
        "topics": topics,
        "cost_embeddings_usd": cost_embeddings,
        "cost_llm_usd": cost_llm,
        "cost_vision_usd": cost_vision,
        "overhead_usd": overhead,
        "total_usd": total
    }

# ==========================================
# TABLEAU COÃ›TS PAR TAILLE
# ==========================================

COST_TABLE = {
    100: {  # 100 pages (doc court)
        "windows": 83,
        "topics": 17,
        "embeddings": 0.00125,
        "llm": 0.0051,
        "vision": 0.0,
        "overhead": 0.00127,
        "total": 0.0076
    },

    200: {  # 200 pages (doc moyen)
        "windows": 167,
        "topics": 33,
        "embeddings": 0.0025,
        "llm": 0.0099,
        "vision": 0.0,
        "overhead": 0.00248,
        "total": 0.0149
    },

    650: {  # 650 pages (doc long - USE CASE PRINCIPAL)
        "windows": 542,
        "topics": 108,
        "embeddings": 0.00813,
        "llm": 0.0324,
        "vision": 0.0,
        "overhead": 0.00811,
        "total": 0.0486
    },

    1000: {  # 1000 pages (doc trÃ¨s long)
        "windows": 833,
        "topics": 167,
        "embeddings": 0.0125,
        "llm": 0.0501,
        "vision": 0.0,
        "overhead": 0.01253,
        "total": 0.0751
    }
}

# ==========================================
# PPTX HEAVY (avec vision)
# ==========================================

COST_PPTX_HEAVY = {
    "deck_45_slides": {
        "text_extraction": 0.0,
        "chart_xml_parsing": 0.0,  # Gratuit
        "vision_llm": 0.065,  # 5 slides Ã— $0.013
        "overhead": 0.013,
        "total": 0.078
    }
}
```

### Tableau RÃ©capitulatif

| Document | Pages | Windows | Topics | Embeddings | LLM | Vision | **Total** | Budget OK? |
|----------|-------|---------|--------|------------|-----|--------|-----------|------------|
| Court    | 100   | 83      | 17     | $0.0013    | $0.0051 | $0 | **$0.008** | âœ… |
| Moyen    | 200   | 167     | 33     | $0.0025    | $0.0099 | $0 | **$0.015** | âœ… |
| Long     | 650   | 542     | 108    | $0.0081    | $0.0324 | $0 | **$0.049** | âœ… |
| TrÃ¨s long | 1000 | 833     | 167    | $0.0125    | $0.0501 | $0 | **$0.075** | âœ… |
| **PPTX Heavy** | 45 slides | - | - | - | - | $0.065 | **$0.078** | âœ… |

**Budget OSMOSE:** $2.00/doc â†’ **26Ã— marge** âœ…

---

### Performance Targets (RÃ©aliste)

```python
# ==========================================
# PERFORMANCE V2 - AVEC DISPATCHER
# ==========================================

PERFORMANCE_TARGETS = {
    "100_pages": {
        "segmentation_s": 4,
        "extraction_s": 6,   # 17 topics Ã— 8s / 10 concurrent = 14s â†’ parallÃ¨le = 6s
        "threading_s": 2,
        "total_s": 12,
        "target": "<15s",
        "status": "âœ…"
    },

    "200_pages": {
        "segmentation_s": 8,
        "extraction_s": 12,
        "threading_s": 3,
        "total_s": 23,
        "target": "<30s",
        "status": "âœ…"
    },

    "650_pages": {  # USE CASE PRINCIPAL
        "segmentation_s": 18,  # Embeddings 542 windows
        "extraction_s": 20,    # 108 topics Ã— 50% LLM = 54 calls â†’ parallÃ¨le 10 = 20s
        "threading_s": 5,
        "total_s": 43,
        "target": "<45s (p50), <60s (p95)",
        "status": "âœ…"
    },

    "1000_pages": {
        "segmentation_s": 28,
        "extraction_s": 32,
        "threading_s": 7,
        "total_s": 67,
        "target": "<90s",
        "status": "âœ…"
    }
}
```

**Conclusion:** Avec **LLMDispatcher parallÃ¨le**, targets atteignables âœ…

---

## ğŸ“… Plan d'ImplÃ©mentation (15 Semaines)

### Phase 1 : Fondations (Semaines 7-9)

**Semaine 7 : TopicSegmenter + LLMDispatcher**
```
Jours 1-2: LLMDispatcher (rate limit + backoff + cache)
Jours 3-5: TopicSegmenter (HDBSCAN + fallbacks)
Tests: 100-200 pages
Checkpoint: Topics cohÃ©rents, pas de pollution
```

**Semaine 8 : EventExtractor (Pattern + LLM)**
```
PatternBasedExtractor (multilang: EN, FR, DE, IT)
LLMBasedExtractor (structured output JSON)
Validation: anchor match + evidence spans
Tests: extraction sur topics
Checkpoint: Events structurÃ©s avec evidence
```

**Semaine 9 : ThreadBuilder**
```
Entity canonicalization (blocking + embeddings + dict + LLM)
Event grouping + temporal ordering
Relation identification (PRECEDES, CAUSES, EVOLVES_TO)
  â†’ CAUSES: evidence span + marker OBLIGATOIRE
Timeline construction
Tests: threads avec relations causales
Checkpoint: Threads corrects, causalitÃ© Ã  preuves
```

### Phase 2 : PPTX et Cross-Doc (Semaines 10-12)

**Semaine 10 : VisionExtractor (PPTX)**
```
Chart XML parsing (iterate ALL shapes, pas shapes[0])
Vision candidate detection (anchors + keywords)
GPT-4V integration (structured output)
Cost control (XML-first, vision 3-5 slides max)
Tests: 10+ decks PPTX
Checkpoint: PPTX charts extraits (XML 70%, vision 20%)
```

**Semaine 11 : CrossDocumentFusion**
```
Entity canonicalization (multilang aliases)
Event deduplication (same entity + date + value)
Conflict resolution (policies: recency, authority, consensus)
Master thread creation
Tests: fusion 3-5 documents
Checkpoint: Cross-doc threads fusionnÃ©s correctement
```

**Semaine 12 : Performance + ParallÃ©lisation**
```
Bug fix: agrÃ©gation parallÃ¨le (filter by doc_id)
Multi-threading LLM (asyncio.gather + semaphore)
Cache embeddings (LRU 1000 entries)
Performance profiling (timer par Ã©tape)
Tests: 650 pages <45s
Checkpoint: Performance targets atteints
```

### Phase 3 : Proto-KG et QualitÃ© (Semaines 13-14)

**Semaine 13 : Neo4j Integration**
```
Schema update (NarrativeTopic, EventCandidate, Relations)
Staging implementation (batch create)
Provenance detaillÃ©e (EXTRACTED_FROM spans)
Query narratives (by entity, date, causal chains)
Tests: Neo4j integration
Checkpoint: Events stagÃ©s dans Proto-KG
```

**Semaine 14 : Quality Metrics + Multilang**
```
Annotation dataset (50 docs annotÃ©s)
Precision/Recall computation
Lexiques multilingues complets (FR, DE, IT, ES)
Error analysis + iteration
Tests: multilang + end-to-end 100 docs
Checkpoint: Pâ‰¥85%, Râ‰¥80%, multilang OK
```

### Phase 4 : DÃ©mo CRR Evolution (Semaine 15)

**Semaine 15 : KILLER FEATURE Demo**
```
Dataset dÃ©mo CRR (5 documents: 3 PDF + 2 PPTX)
Query interface + timeline visualization
Copilot comparison (side-by-side screenshots)
Documentation + video demo (5 min)
Tests: dÃ©mo end-to-end rÃ©pÃ©table
Checkpoint: USP vs Copilot dÃ©montrÃ©e âœ…
```

---

## ğŸ¯ CritÃ¨res de SuccÃ¨s et KPIs

### Fonctionnels (Must-Have)

- âœ… DÃ©tection Ã©vÃ©nements 600+ pages sans pollution
- âœ… Support PPTX multimodal (XML + vision)
- âœ… Timeline chronologique (3+ Ã©vÃ©nements ordonnÃ©s)
- âœ… Relations causales (evidence-based)
- âœ… Cross-document fusion (mÃªme entitÃ©)
- âœ… Multilang (EN, FR, DE, IT minimum)

### Techniques (Mesurables)

| KPI | Target | MÃ©thode Validation |
|-----|--------|-------------------|
| **Precision Ã©vÃ©nements** | â‰¥85% | 50 docs annotÃ©s manuellement |
| **Recall Ã©vÃ©nements** | â‰¥80% | Dataset ground truth |
| **Timeline accuracy** | â‰¥90% | Ordre chronologique correct |
| **CausalitÃ© precision** | â‰¥85% | Evidence spans validÃ©es |
| **Cross-doc linking** | â‰¥75% | EntitÃ©s reliÃ©es correctement |
| **Performance p50** | <30s | Benchmark 100 docs mixtes |
| **Performance p95 (650p)** | <60s | Benchmark docs longs |
| **Cost per doc (650p)** | <$0.10 | Monitoring 100 docs |
| **PPTX coverage** | â‰¥70% | % decks avec â‰¥1 event |
| **Cache hit ratio** | â‰¥40% | LLMDispatcher metrics |
| **Span mÃ©dian thread** | <10 pages | KPI anti-pollution |

### Business (USP DÃ©montrÃ©)

**DÃ©mo "CRR Evolution Tracker" rÃ©ussie:**
```
âœ… 4+ Ã©vÃ©nements dÃ©tectÃ©s (v1.0 â†’ v2.0 â†’ impact)
âœ… 2+ relations causales explicites
âœ… Sources multiples (PDF + PPTX)
âœ… Timeline chronologique correcte
âœ… Confidence >0.85
âœ… Side-by-side Copilot: diffÃ©renciation claire
```

---

## ğŸš§ Risques et Mitigations

### Risques Techniques (avec Mitigations)

| Risque | Impact | Prob | Mitigation OpenAI IntÃ©grÃ©e |
|--------|--------|------|----------------------------|
| HDBSCAN instable | HIGH | MED | âœ… Fallback Agglomerative + trim |
| LLM hallucinations | HIGH | MED | âœ… Evidence spans obligatoires |
| Vision erreurs | MED | MED | âœ… XML-first + confiance ajustÃ©e |
| Performance >60s | MED | LOW | âœ… LLMDispatcher + cache |
| CausalitÃ© faible | HIGH | LOW | âœ… Evidence + marker requis |
| Cost dÃ©passÃ© | LOW | LOW | âœ… Pattern-first + monitoring |
| Bug agrÃ©gation | HIGH | LOW | âœ… Filter by doc_id |
| PPTX shapes[0] | MED | LOW | âœ… Iterate all shapes |

### DÃ©cision Finale

**GO V2 COMPLÃˆTE - 15 SEMAINES**

**Justification:**
- 100% corrections OpenAI intÃ©grÃ©es
- Cost model rÃ©aliste validÃ©
- Performance targets atteignables
- Risques techniques mitigÃ©s
- USP KILLER FEATURE dÃ©montrable

---

## ğŸ“š Annexes

### A. Lexiques Multilingues

**Connecteurs Causaux:**
```python
CAUSAL_CONNECTORS = {
    "en": ["because", "due to", "as a result", "consequently", "leads to", "causes", "therefore"],
    "fr": ["parce que", "car", "en raison de", "du fait de", "par consÃ©quent", "conduit Ã ", "donc"],
    "de": ["weil", "da", "aufgrund", "infolgedessen", "fÃ¼hrt zu", "daher"],
    "it": ["perchÃ©", "poichÃ©", "a causa di", "di conseguenza", "porta a", "quindi"],
    "es": ["porque", "debido a", "como resultado", "por consiguiente", "conduce a", "por lo tanto"]
}
```

**Marqueurs Temporels:**
```python
TEMPORAL_MARKERS = {
    "en": ["updated", "revised", "changed", "modified", "replaced", "superseded", "deprecated", "evolved"],
    "fr": ["mis Ã  jour", "rÃ©visÃ©", "modifiÃ©", "remplacÃ©", "obsolÃ¨te", "Ã©voluÃ©"],
    "de": ["aktualisiert", "Ã¼berarbeitet", "geÃ¤ndert", "ersetzt", "veraltet"],
    "it": ["aggiornato", "revisionato", "modificato", "sostituito", "obsoleto"],
    "es": ["actualizado", "revisado", "modificado", "reemplazado", "obsoleto"]
}
```

### B. Conflict Resolution Policies

```python
class ConflictResolutionPolicy:
    """
    Policies pour rÃ©solution conflits cross-doc
    """

    @staticmethod
    def resolve_date_conflict(events: List[NarrativeEvent]) -> NarrativeEvent:
        """
        StratÃ©gie: PrioritÃ© date exacte > quarter > year
        """
        # Exact dates first
        exact = [e for e in events if e.date_precision == "EXACT"]
        if exact:
            return max(exact, key=lambda e: e.confidence)

        # Quarters
        quarters = [e for e in events if e.date_precision == "QUARTER"]
        if quarters:
            return max(quarters, key=lambda e: e.confidence)

        # Years (fallback)
        return max(events, key=lambda e: e.confidence)

    @staticmethod
    def resolve_value_conflict(events: List[NarrativeEvent]) -> NarrativeEvent:
        """
        StratÃ©gie: Consensus multi-source > confidence > recency
        """
        # Count value occurrences
        value_counts = Counter(e.value_after for e in events)
        most_common_value = value_counts.most_common(1)[0][0]

        # Events with consensus value
        consensus_events = [e for e in events if e.value_after == most_common_value]

        # Highest confidence among consensus
        return max(consensus_events, key=lambda e: e.confidence)

    @staticmethod
    def log_conflict(conflict_type: str, events: List[NarrativeEvent], resolved: NarrativeEvent):
        """Log resolution decision"""
        logger.info(
            f"[ConflictResolver] {conflict_type} conflict resolved. "
            f"Candidates: {len(events)}, "
            f"Chosen: {resolved.event_id} (confidence: {resolved.confidence:.2f})"
        )
```

---

**ğŸŒŠ OSMOSE V2 FINAL : Ready for Implementation**

**Version:** 2.0
**Date:** 2025-10-13
**Status:** âœ… SpÃ©cification ComplÃ¨te avec Corrections OpenAI
**Next:** DÃ©marrage ImplÃ©mentation Semaine 7

---

*Document final consolidÃ© - Toutes corrections OpenAI intÃ©grÃ©es - PrÃªt pour mise Ã  jour OSMOSE_ARCHITECTURE_TECHNIQUE.md*
