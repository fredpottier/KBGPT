# Phase 3 - Pipeline Ingestion & D√©tection Conflits - Tracking D√©taill√©

**Date d√©but** : 2025-10-05
**Date fin** : -
**Dur√©e estim√©e** : 3 jours
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ **EN COURS**
**Progression** : **0%** (0/6 t√¢ches)

---

## üéØ Objectifs Phase 3

Int√©grer l'extraction automatique de facts structur√©s dans le pipeline d'ingestion PPTX existant, avec d√©tection de conflits en temps r√©el et notifications pour les conflits critiques.

### Objectifs Sp√©cifiques

1. ‚è≥ Int√©grer extraction facts dans pipeline PPTX existant
2. ‚è≥ Impl√©menter appel LLM Vision pour extraction structur√©e (GPT-4 Vision)
3. ‚è≥ Ins√©rer facts extraits dans Neo4j (status="proposed")
4. ‚è≥ D√©clencher d√©tection conflits automatique post-ingestion
5. ‚è≥ Impl√©menter notification conflits critiques (webhook/logs)
6. ‚è≥ Tests pipeline complet (end-to-end)

---

## üìã T√¢ches D√©taill√©es

### ‚è≥ 3.1 - Analyse Pipeline PPTX Existant

**Dur√©e estim√©e** : 1h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Comprendre l'architecture actuelle du pipeline PPTX pour identifier les points d'int√©gration

**Actions** :
- [ ] Lire `src/knowbase/ingestion/pipelines/pptx_pipeline.py`
- [ ] Identifier √©tapes traitement slides (extraction texte, OCR, embeddings)
- [ ] Localiser appel LLM existant (si pr√©sent)
- [ ] D√©terminer point injection extraction facts (apr√®s OCR, avant embeddings?)
- [ ] V√©rifier m√©tadonn√©es disponibles (source_document, chunk_id, page_num)

**Fichiers √† analyser** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py`
- `src/knowbase/ingestion/pipelines/pptx_pipeline_kg.py` (si existe)
- `src/knowbase/common/llm_router.py` (LLM provider)
- `src/knowbase/config/prompts.yaml` (prompts extraction)

**Crit√®res validation** :
- ‚úÖ Architecture pipeline PPTX document√©e
- ‚úÖ Point int√©gration extraction facts identifi√©
- ‚úÖ M√©tadonn√©es tra√ßabilit√© disponibles

---

### ‚è≥ 3.2 - Prompt LLM Vision Extraction Facts

**Dur√©e estim√©e** : 2h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Cr√©er prompt optimis√© pour extraction facts structur√©s depuis slides PPTX (texte + images)

**Actions** :
- [ ] Cr√©er prompt `extract_facts_pptx_v1` dans `config/prompts.yaml`
- [ ] Sp√©cifier format JSON attendu (subject, predicate, object, value, unit, confidence)
- [ ] Inclure exemples SAP (SLA, capacit√©, pricing, features)
- [ ] D√©finir r√®gles extraction (skip facts vagues, exiger valeur num√©rique si applicable)
- [ ] Tester prompt sur 3-5 slides types (RFP, proposal, documentation technique)

**Format JSON Attendu** :
```json
{
  "facts": [
    {
      "subject": "SAP S/4HANA Cloud, Private Edition",
      "predicate": "SLA_garantie",
      "object": "99.7%",
      "value": 99.7,
      "unit": "%",
      "value_type": "numeric",
      "fact_type": "SERVICE_LEVEL",
      "confidence": 0.95,
      "valid_from": "2024-01-01",
      "source_slide_number": 12,
      "extraction_context": "Tableau SLA page 12"
    }
  ]
}
```

**Prompt Template** :
```yaml
extract_facts_pptx_v1:
  system: |
    Tu es un expert en extraction de facts m√©tier structur√©s depuis des slides SAP.

    **Objectif** : Extraire UNIQUEMENT les facts objectifs, v√©rifiables, avec valeurs num√©riques ou dates.

    **Types de facts prioritaires** :
    - SERVICE_LEVEL : SLA, uptime, performance guarantees
    - CAPACITY : Limites, quotas, tailles max (users, storage, transactions)
    - PRICING : Prix, co√ªts, tarifs (‚Ç¨, $, cr√©dits)
    - FEATURE : Fonctionnalit√©s activ√©es/d√©sactiv√©es (boolean)
    - COMPLIANCE : Certifications, normes (ISO, SOC2, GDPR)

    **R√®gles strictes** :
    1. Ignorer opinions, estimations, promesses marketing
    2. Exiger valeur num√©rique pour SERVICE_LEVEL, CAPACITY, PRICING
    3. Indiquer confidence 0.9+ si fact explicite, 0.6-0.8 si inf√©r√©
    4. Capturer valid_from si date mentionn√©e (2024, Q1 2024, etc.)
    5. R√©f√©rencer slide_number source pour tra√ßabilit√©

  user: |
    Extrait les facts structur√©s depuis ce slide PPTX :

    **Slide {slide_number}**
    Texte : {slide_text}
    Image : {image_description}

    R√©ponds en JSON strict (array de facts).

  examples:
    - input: "Slide 5 : SAP S/4HANA garantit 99.7% SLA uptime"
      output: |
        {
          "facts": [{
            "subject": "SAP S/4HANA",
            "predicate": "SLA_uptime_garantie",
            "object": "99.7%",
            "value": 99.7,
            "unit": "%",
            "value_type": "numeric",
            "fact_type": "SERVICE_LEVEL",
            "confidence": 0.95,
            "source_slide_number": 5
          }]
        }
```

**Fichiers √† modifier** :
- `config/prompts.yaml` (nouveau prompt)

**Crit√®res validation** :
- ‚úÖ Prompt cr√©√© et test√© sur 5 slides
- ‚úÖ Extraction facts JSON valide (Pydantic FactCreate)
- ‚úÖ Taux succ√®s > 80% (facts pertinents vs bruit)

---

### ‚è≥ 3.3 - Int√©gration LLM Vision dans Pipeline PPTX

**Dur√©e estim√©e** : 4h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Modifier pipeline PPTX pour appeler LLM Vision et extraire facts structur√©s

**Actions** :
- [ ] Cr√©er fonction `extract_facts_from_slide(slide_text, slide_image, slide_num, llm_client)`
- [ ] Appeler LLM Vision (GPT-4 Vision ou Claude 3.5 Sonnet) avec prompt
- [ ] Parser r√©ponse JSON ‚Üí liste `FactCreate` Pydantic
- [ ] Enrichir m√©tadonn√©es : `source_document`, `source_chunk_id`, `extraction_method="llm_vision"`
- [ ] G√©rer erreurs extraction (LLM timeout, JSON malform√©, fact invalide)
- [ ] Logger facts extraits (INFO) et erreurs (WARNING)

**Code Exemple** :
```python
# Dans pptx_pipeline.py

from knowbase.api.schemas.facts import FactCreate, FactType
from knowbase.common.llm_router import get_llm_client
from knowbase.config.prompts_loader import get_prompt

async def extract_facts_from_slide(
    slide_text: str,
    slide_image_base64: Optional[str],
    slide_number: int,
    source_document: str,
    chunk_id: str,
    llm_client
) -> List[FactCreate]:
    """Extrait facts structur√©s depuis slide PPTX via LLM Vision."""

    prompt_template = get_prompt("extract_facts_pptx_v1")

    # Construire prompt avec contexte
    user_prompt = prompt_template["user"].format(
        slide_number=slide_number,
        slide_text=slide_text,
        image_description="[image attached]" if slide_image_base64 else "[no image]"
    )

    # Appel LLM Vision
    try:
        response = await llm_client.chat_completion(
            model="gpt-4-vision-preview",
            messages=[
                {"role": "system", "content": prompt_template["system"]},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{slide_image_base64}"}}
                    ] if slide_image_base64 else user_prompt
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.0,
            max_tokens=2000,
        )

        # Parser JSON
        facts_raw = json.loads(response.choices[0].message.content)

        # Valider et enrichir facts
        facts = []
        for fact_data in facts_raw.get("facts", []):
            fact = FactCreate(
                subject=fact_data["subject"],
                predicate=fact_data["predicate"],
                object=fact_data["object"],
                value=fact_data["value"],
                unit=fact_data["unit"],
                value_type=fact_data.get("value_type", "numeric"),
                fact_type=fact_data.get("fact_type", "GENERAL"),
                confidence=fact_data.get("confidence", 0.7),
                source_chunk_id=chunk_id,
                source_document=source_document,
                extraction_method="llm_vision",
                extraction_model="gpt-4-vision-preview",
                extraction_prompt_id="extract_facts_pptx_v1",
            )
            facts.append(fact)

        logger.info(f"‚úÖ Extracted {len(facts)} facts from slide {slide_number}")
        return facts

    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è Failed to parse LLM response as JSON: {e}")
        return []
    except ValidationError as e:
        logger.warning(f"‚ö†Ô∏è Fact validation failed: {e}")
        return []
    except Exception as e:
        logger.error(f"‚ùå LLM Vision extraction failed: {e}")
        return []
```

**Fichiers √† modifier** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py` (ou cr√©er `pptx_pipeline_facts.py`)

**Crit√®res validation** :
- ‚úÖ Fonction extraction impl√©ment√©e
- ‚úÖ Appel LLM Vision fonctionnel (GPT-4 Vision)
- ‚úÖ Parser JSON ‚Üí FactCreate valid√©
- ‚úÖ M√©tadonn√©es tra√ßabilit√© compl√®tes

---

### ‚è≥ 3.4 - Insertion Facts Neo4j (status="proposed")

**Dur√©e estim√©e** : 2h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Ins√©rer facts extraits dans Neo4j avec statut "proposed" pour workflow gouvernance

**Actions** :
- [ ] Utiliser `FactsService.create_fact()` pour chaque fact extrait
- [ ] D√©finir tenant_id (client RFP si disponible, sinon "default")
- [ ] Logger insertion (fact_uuid, subject, predicate, value)
- [ ] G√©rer erreurs insertion (Neo4j indisponible, contrainte viol√©e)
- [ ] Batch insertion si > 10 facts (optimisation performance)

**Code Exemple** :
```python
# Dans pptx_pipeline.py

from knowbase.api.services.facts_service import FactsService
from knowbase.neo4j_custom import get_neo4j_client

async def insert_facts_to_neo4j(
    facts: List[FactCreate],
    tenant_id: str = "default"
) -> List[str]:
    """Ins√®re facts dans Neo4j, retourne UUIDs cr√©√©s."""

    facts_service = FactsService(tenant_id=tenant_id)
    inserted_uuids = []

    for fact in facts:
        try:
            fact_response = facts_service.create_fact(fact)
            inserted_uuids.append(fact_response.uuid)
            logger.info(
                f"‚úÖ Fact inserted: {fact_response.uuid} | "
                f"{fact.subject} {fact.predicate} {fact.value}{fact.unit}"
            )
        except Exception as e:
            logger.error(f"‚ùå Failed to insert fact: {e} | {fact.dict()}")

    logger.info(f"üìä Inserted {len(inserted_uuids)}/{len(facts)} facts to Neo4j")
    return inserted_uuids
```

**Fichiers √† modifier** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

**Crit√®res validation** :
- ‚úÖ Insertion facts Neo4j fonctionnelle
- ‚úÖ Statut "proposed" par d√©faut
- ‚úÖ M√©tadonn√©es tra√ßabilit√© compl√®tes (source_chunk_id, extraction_model)
- ‚úÖ Logs insertion (success/failure)

---

### ‚è≥ 3.5 - D√©tection Conflits Post-Ingestion

**Dur√©e estim√©e** : 3h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : D√©clencher d√©tection conflits automatique apr√®s insertion facts, identifier CONTRADICTS/OVERRIDES

**Actions** :
- [ ] Appeler `FactsService.detect_conflicts()` apr√®s insertion batch
- [ ] Filtrer conflits critiques (value_diff_pct > 5%, CONTRADICTS avec fact approved)
- [ ] Logger conflits d√©tect√©s (type, facts en conflit, diff√©rence valeur)
- [ ] Marquer facts conflictuels avec status="conflicted" (optionnel)
- [ ] Stocker conflits dans Redis cache (optimisation UI admin)

**Code Exemple** :
```python
# Dans pptx_pipeline.py

from knowbase.api.services.facts_service import FactsService

async def detect_and_log_conflicts(
    inserted_fact_uuids: List[str],
    tenant_id: str = "default"
):
    """D√©tecte conflits post-ingestion et log r√©sultats."""

    facts_service = FactsService(tenant_id=tenant_id)

    # D√©tection globale conflits
    conflicts = facts_service.detect_conflicts()

    # Filtrer conflits impliquant facts nouvellement ins√©r√©s
    relevant_conflicts = [
        c for c in conflicts
        if c.fact_proposed.uuid in inserted_fact_uuids
    ]

    if not relevant_conflicts:
        logger.info("‚úÖ No conflicts detected for new facts")
        return

    # Logger conflits critiques
    critical_conflicts = [
        c for c in relevant_conflicts
        if c.value_diff_pct > 0.05  # > 5% diff√©rence
    ]

    for conflict in critical_conflicts:
        logger.warning(
            f"‚ö†Ô∏è CONFLICT {conflict.conflict_type} | "
            f"{conflict.fact_proposed.subject} {conflict.fact_proposed.predicate} | "
            f"Proposed: {conflict.fact_proposed.value} | "
            f"Approved: {conflict.fact_approved.value} | "
            f"Diff: {conflict.value_diff_pct * 100:.1f}%"
        )

    logger.info(
        f"üìä Conflicts detected: {len(relevant_conflicts)} "
        f"({len(critical_conflicts)} critical > 5%)"
    )

    # TODO: Notification webhook si critical_conflicts
```

**Fichiers √† modifier** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

**Crit√®res validation** :
- ‚úÖ D√©tection conflits post-ingestion fonctionnelle
- ‚úÖ Filtrage conflits critiques (> 5% diff√©rence)
- ‚úÖ Logs warning pour conflits CONTRADICTS
- ‚úÖ Performance < 100ms pour d√©tection

---

### ‚è≥ 3.6 - Notification Conflits Critiques

**Dur√©e estim√©e** : 2h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Notifier √©quipe gouvernance des conflits critiques d√©tect√©s (webhook, email, Slack)

**Actions** :
- [ ] Cr√©er fonction `notify_critical_conflicts(conflicts, webhook_url)`
- [ ] Format message JSON/Slack (fact propos√© vs approuv√©, diff %, lien UI admin)
- [ ] Configurer webhook URL dans `.env` (`CONFLICT_WEBHOOK_URL`)
- [ ] Impl√©menter retry 3x si webhook √©choue
- [ ] Logger notification (success/failure)

**Code Exemple** :
```python
# Nouveau fichier: src/knowbase/ingestion/notifications.py

import httpx
from typing import List
from knowbase.api.schemas.facts import ConflictResponse

async def notify_critical_conflicts(
    conflicts: List[ConflictResponse],
    webhook_url: str,
    threshold_pct: float = 0.05
):
    """Notifie conflits critiques via webhook (Slack, Teams, email)."""

    critical = [c for c in conflicts if c.value_diff_pct > threshold_pct]

    if not critical:
        return

    # Format message Slack
    message = {
        "text": f"üö® {len(critical)} conflits critiques d√©tect√©s",
        "blocks": [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{len(critical)} conflits critiques* (diff√©rence > {threshold_pct*100}%)"
                }
            }
        ]
    }

    for conflict in critical[:5]:  # Top 5
        message["blocks"].append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": (
                    f"‚Ä¢ *{conflict.fact_proposed.subject}* - {conflict.fact_proposed.predicate}\n"
                    f"  Propos√©: `{conflict.fact_proposed.value}` | "
                    f"Approuv√©: `{conflict.fact_approved.value}` | "
                    f"Diff: *{conflict.value_diff_pct*100:.1f}%*"
                )
            }
        })

    # Envoi webhook avec retry
    async with httpx.AsyncClient() as client:
        for attempt in range(3):
            try:
                response = await client.post(
                    webhook_url,
                    json=message,
                    timeout=10.0
                )
                if response.status_code == 200:
                    logger.info(f"‚úÖ Webhook notification sent ({len(critical)} conflicts)")
                    return
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Webhook attempt {attempt+1}/3 failed: {e}")

        logger.error(f"‚ùå Failed to send webhook notification after 3 attempts")
```

**Fichiers √† cr√©er** :
- `src/knowbase/ingestion/notifications.py`

**Configuration `.env`** :
```bash
# Webhook notification conflits
CONFLICT_WEBHOOK_URL=https://hooks.slack.com/services/XXX/YYY/ZZZ
CONFLICT_THRESHOLD_PCT=0.05  # 5%
```

**Crit√®res validation** :
- ‚úÖ Webhook notification impl√©ment√©e
- ‚úÖ Format message Slack/Teams compatible
- ‚úÖ Retry 3x si √©chec
- ‚úÖ Logs notification (success/failure)

---

### ‚è≥ 3.7 - Tests Pipeline Ingestion Facts

**Dur√©e estim√©e** : 3h
**Dur√©e r√©elle** : -
**Statut** : ‚è≥ En attente
**Progression** : 0%

**Objectif** : Tests end-to-end pipeline ingestion PPTX ‚Üí extraction facts ‚Üí Neo4j ‚Üí conflits

**Actions** :
- [ ] Cr√©er `tests/ingestion/test_pptx_facts_pipeline.py`
- [ ] Test 1 : Extraction facts slide simple (texte seul)
- [ ] Test 2 : Extraction facts slide complexe (texte + image)
- [ ] Test 3 : Insertion facts Neo4j (v√©rifier tenant_id, status="proposed")
- [ ] Test 4 : D√©tection conflit CONTRADICTS
- [ ] Test 5 : Notification webhook (mock httpx)
- [ ] Test 6 : Pipeline complet (PPTX ‚Üí facts ‚Üí conflits ‚Üí webhook)

**Fichiers √† cr√©er** :
- `tests/ingestion/test_pptx_facts_pipeline.py` (300+ lignes)
- `tests/ingestion/fixtures/sample_rfp.pptx` (document test)

**Crit√®res validation** :
- ‚úÖ 6+ tests pipeline E2E pass√©s
- ‚úÖ Couverture > 80% code extraction/insertion
- ‚úÖ Performance < 5s pour pipeline complet (1 PPTX, 20 slides)

---

## üéØ Gate Phase 3 ‚Üí Phase 4

### Crit√®res Validation (4/4 requis)

- [ ] **Pipeline PPTX fonctionnel** : Extraction facts + insertion Neo4j
- [ ] **D√©tection conflits post-ingestion** : Conflits CONTRADICTS/OVERRIDES identifi√©s
- [ ] **Tests E2E pass√©s** : 6+ tests pipeline complet (100%)
- [ ] **Performance valid√©e** : < 5s pour ingestion PPTX (20 slides)

### M√©triques Attendues

| M√©trique | Cible | Moyen Mesure |
|----------|-------|--------------|
| Taux extraction facts | > 70% slides | Logs extraction LLM |
| Pr√©cision facts (confidence) | > 0.8 moyenne | Moyenne confidence extraite |
| Conflits d√©tect√©s | > 50% si pr√©sents | Logs d√©tection conflits |
| Performance ingestion | < 5s (20 slides) | Timer pipeline E2E |
| Tests pass√©s | 100% (6/6) | pytest |

---

## üìä M√©triques & KPIs

### Performance

| M√©trique | Cible | Actuel | Statut |
|----------|-------|--------|--------|
| Temps extraction 1 slide | < 2s | - | ‚è≥ |
| Temps insertion 10 facts | < 500ms | - | ‚è≥ |
| Temps d√©tection conflits | < 100ms | - | ‚è≥ |
| Pipeline complet (20 slides) | < 5s | - | ‚è≥ |

### Qualit√©

| M√©trique | Cible | Actuel | Statut |
|----------|-------|--------|--------|
| Taux extraction facts | > 70% | - | ‚è≥ |
| Confidence moyenne | > 0.8 | - | ‚è≥ |
| Facts valides (Pydantic) | 100% | - | ‚è≥ |
| Conflits d√©tect√©s | > 50% pr√©sents | - | ‚è≥ |

### Tests

| M√©trique | Cible | Actuel | Statut |
|----------|-------|--------|--------|
| Tests unitaires | 6+ | 0 | ‚è≥ |
| Couverture code | > 80% | - | ‚è≥ |
| Tests E2E pass√©s | 100% | - | ‚è≥ |

---

## üîç D√©pendances & Pr√©requis

### Code Phase 2 (Compl√©t√© ‚úÖ)
- ‚úÖ Module `neo4j_custom` (client, schemas, queries, migrations)
- ‚úÖ API `/api/facts` (CRUD complet)
- ‚úÖ `FactsService` (create_fact, detect_conflicts)
- ‚úÖ Sch√©mas Pydantic `FactCreate`, `ConflictResponse`

### Configuration
- ‚úÖ Prompts YAML (`config/prompts.yaml`)
- ‚úÖ LLM Router (`src/knowbase/common/llm_router.py`)
- ‚úÖ Neo4j connexion (`NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD`)
- ‚è≥ Webhook URL (`.env`: `CONFLICT_WEBHOOK_URL`)

### LLM Models
- ‚úÖ GPT-4 Vision (OpenAI API) ou Claude 3.5 Sonnet (Anthropic)
- ‚úÖ Token budget : ~2000 tokens/slide (estimation)
- ‚úÖ Co√ªt estim√© : $0.01/slide (GPT-4 Vision)

---

## üö® Risques & Mitigation

### Risques Techniques

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| LLM Vision timeout (> 30s) | üî¥ High | Medium | Retry 3x + timeout 60s + fallback texte seul |
| Extraction facts impr√©cise (< 70%) | üü† Medium | High | It√©ration prompt + exemples suppl√©mentaires |
| Conflits non d√©tect√©s (faux n√©gatifs) | üü† Medium | Medium | Tests regression + seuil confidence |
| Neo4j insertion lente (> 1s/fact) | üü° Low | Low | Batch insert 10 facts simultan√©s |
| Webhook notification √©choue | üü° Low | Medium | Retry 3x + fallback logs |

### Risques Fonctionnels

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| Facts extraits non pertinents (bruit) | üü† Medium | High | R√®gles strictes prompt (valeurs num√©riques requises) |
| Doublons facts (m√™me subject+predicate) | üü° Low | Medium | D√©duplication avant insertion (query Neo4j) |
| Faux conflits (variations mineures) | üü° Low | Medium | Seuil 5% diff√©rence + normalisation unit√©s |

---

## üìù Documentation Attendue

### Fichiers √† Cr√©er/Modifier

**Code** :
- `src/knowbase/ingestion/pipelines/pptx_pipeline.py` (modifi√©)
- `src/knowbase/ingestion/notifications.py` (nouveau)
- `config/prompts.yaml` (ajout prompt `extract_facts_pptx_v1`)

**Tests** :
- `tests/ingestion/test_pptx_facts_pipeline.py` (nouveau)
- `tests/ingestion/fixtures/sample_rfp.pptx` (nouveau)

**Documentation** :
- `doc/phase3/TRACKING_PHASE3.md` (ce fichier)
- `doc/phase3/PHASE3_VALIDATION.md` (√† cr√©er apr√®s tests)

---

## ‚úÖ Checklist Compl√©tude Phase 3

### Code
- [ ] Pipeline PPTX modifi√© (extraction facts)
- [ ] Prompt LLM Vision cr√©√© (`extract_facts_pptx_v1`)
- [ ] Fonction extraction facts impl√©ment√©e
- [ ] Insertion facts Neo4j (status="proposed")
- [ ] D√©tection conflits post-ingestion
- [ ] Notification webhook conflits critiques

### Tests
- [ ] Tests extraction facts (2+)
- [ ] Tests insertion Neo4j (1+)
- [ ] Tests d√©tection conflits (1+)
- [ ] Tests notification webhook (1+)
- [ ] Test E2E pipeline complet (1+)

### Documentation
- [ ] TRACKING_PHASE3.md (ce fichier)
- [ ] PHASE3_VALIDATION.md (r√©sultats tests)
- [ ] README pipeline facts (usage, config)

### Gate Validation
- [ ] 4/4 crit√®res gate pass√©s
- [ ] M√©triques performance valid√©es
- [ ] Tests E2E 100% pass√©s
- [ ] Documentation compl√®te

---

**Cr√©√© le** : 2025-10-05
**Derni√®re mise √† jour** : 2025-10-05
**Version** : 1.0
**Statut** : ‚è≥ **EN COURS**
