# Architecture LLM Canonicalizer + Adaptive Ontology

**Date** : 2025-10-17
**Phase** : 1.6 Cross-R√©f√©rence Neo4j ‚Üî Qdrant
**Statut** : D√©cision Architecturale - √Ä Impl√©menter
**Priorit√©** : P0 (Critique pour qualit√© KG)

---

## üéØ Probl√®me Identifi√©

### Sympt√¥mes Actuels

Apr√®s fix bug UNWIND, l'import fonctionne mais produit des **doublons s√©mantiques** dans Neo4j :

```cypher
// Requ√™te actuelle
MATCH (c:CanonicalConcept)
WHERE c.tenant_id = 'default' AND c.canonical_name CONTAINS 'S/4'
RETURN c.canonical_name, c.surface_form

// R√©sultats (3 concepts diff√©rents pour LE M√äME produit !)
"Sap S/4Hana Public Cloud'S", "SAP S/4HANA Public Cloud's"
"Sap S/4Hana Cloud", "SAP S/4HANA Cloud"
"S/4Hana For Group Reporting", "S/4HANA for Group Reporting"
```

### Root Cause

**Gatekeeper.py ligne 680, 690, 694** :
```python
canonical_name = concept_name.strip().title()
```

**Probl√®me** : `.title()` cr√©e des canonical_name incorrects :
- `"SAP S/4HANA Cloud's"` ‚Üí `"Sap S/4Hana Cloud'S"` ‚ùå
- Pr√©serve possessifs (`'s`, `'S`)
- Casse incorrecte pour acronymes (SAP ‚Üí Sap)
- **Ne trouve PAS le nom officiel canonique**

### Impact Business

**Sans canonicalisation stricte** :
- ‚ùå **Doublons s√©mantiques** : M√™me concept = multiples nodes Neo4j
- ‚ùå **Recherche d√©grad√©e** : `MATCH "SAP S/4HANA Cloud"` ne trouve pas `"Sap S/4Hana Cloud'S"`
- ‚ùå **KG pollu√©** : Croissance exponentielle concepts redondants
- ‚ùå **D√©duplication impossible** : Pas de cl√© canonique fiable

**Exemple concret** :
```
Recherche utilisateur : "SAP S/4HANA Cloud capabilities"
‚Üí Ne trouve PAS les documents index√©s sous "Sap S/4Hana Cloud'S"
‚Üí Perte de recall ~30-40%
```

---

## üèóÔ∏è Solution Architecturale : Adaptive Ontology (Option B Hybride)

### Vision Produit

**Zero-Config Intelligence** : Le syst√®me **apprend** les ontologies automatiquement lors de l'ingestion, sans dictionnaire pr√©-configur√©.

**Principe** :
1. **Jour 1** : Base ontologie VIDE
2. **LLM Canonicalization** : Chaque nouveau concept ‚Üí appel LLM pour trouver nom officiel canonique
3. **Apprentissage Continu** : R√©sultats LLM stock√©s dans **AdaptiveOntology** (Neo4j)
4. **Cache Intelligent** : Lookup ontologie AVANT appel LLM ‚Üí √©conomie co√ªt + latence
5. **Auto-Enrichissement** : Chaque variante rencontr√©e ‚Üí ajout√©e aux aliases

### Architecture Cible

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CANONICALIZATION WORKFLOW                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Document ing√©r√© ‚Üí Extractor trouve "S/4HANA Cloud's"
                         ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   GATEKEEPER         ‚îÇ
              ‚îÇ  Canonicalization    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ 1. Lookup Ontologie Neo4j    ‚îÇ
         ‚îÇ    (AdaptiveOntology node)   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Found in cache? ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üô              ‚Üò
            OUI                 NON
             ‚Üì                   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Return cached   ‚îÇ   ‚îÇ 2. LLM Canonicalizer ‚îÇ
   ‚îÇ canonical_name  ‚îÇ   ‚îÇ    (GPT-4o-mini)     ‚îÇ
   ‚îÇ (0ms, $0)       ‚îÇ   ‚îÇ    (~200ms, $0.0001) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ 3. Store in AdaptiveOntology ‚îÇ
                    ‚îÇ    (Neo4j node)              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ 4. Create CanonicalConcept   ‚îÇ
                    ‚îÇ    with canonical_name       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üóÑÔ∏è Sch√©ma Neo4j : AdaptiveOntology

### Node Structure

```cypher
// Nouveau type de node : AdaptiveOntology (cache canonique)
CREATE (ont:AdaptiveOntology {
    ontology_id: randomUUID(),
    tenant_id: "default",

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // CANONICAL IDENTITY
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    // Nom canonique officiel (r√©sultat LLM)
    canonical_name: "SAP S/4HANA Cloud, Public Edition",

    // Aliases/variantes reconnues (auto-enrichissement)
    aliases: [
        "S/4HANA Cloud Public",
        "S/4HANA Public Cloud",
        "S4 Cloud Public Edition",
        "SAP S/4HANA Cloud's",
        "Sap S/4Hana Public Cloud'S"
    ],

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // METADATA
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    concept_type: "ERP_Solution",
    domain: "enterprise_software",
    vendor: "SAP",

    // Description officielle (optionnel)
    official_description: "SAP's cloud-based ERP solution for public cloud deployment",

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // PROVENANCE
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    source: "llm_gpt4o_mini",
    confidence: 0.95,
    validated_by: "auto",  // "auto" | "human" | "user@example.com"

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // USAGE STATISTICS
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    usage_count: 47,  // Nombre fois rencontr√© dans documents
    first_seen: datetime("2025-10-17T10:00:00Z"),
    last_seen: datetime("2025-10-17T15:30:00Z"),

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // CONTEXT D'ORIGINE
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    first_document_id: "doc-123",
    example_context: "SAP S/4HANA Cloud's financial module provides real-time analytics...",

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // AMBIGUITY HANDLING
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    ambiguity_warning: null,  // Si ambigu√Øt√© d√©tect√©e par LLM
    possible_matches: []  // Autres canonical_names possibles
})
```

### Indexes & Constraints

```cypher
// Contrainte unicit√© canonical_name par tenant
CREATE CONSTRAINT adaptive_ontology_unique_canonical IF NOT EXISTS
FOR (o:AdaptiveOntology)
REQUIRE (o.tenant_id, o.canonical_name) IS UNIQUE;

// Index pour lookup rapide par alias
CREATE INDEX adaptive_ontology_aliases IF NOT EXISTS
FOR (o:AdaptiveOntology)
ON (o.aliases);

// Index pour lookup par tenant
CREATE INDEX adaptive_ontology_tenant IF NOT EXISTS
FOR (o:AdaptiveOntology)
ON (o.tenant_id);

// Index pour recherche par domaine
CREATE INDEX adaptive_ontology_domain IF NOT EXISTS
FOR (o:AdaptiveOntology)
ON (o.domain);

// Index full-text pour recherche fuzzy
CREATE FULLTEXT INDEX adaptive_ontology_fulltext IF NOT EXISTS
FOR (o:AdaptiveOntology)
ON EACH [o.canonical_name, o.aliases];
```

---

## üîß Composants √† Impl√©menter

### 1. LLMCanonicalizer Service

**Fichier** : `src/knowbase/ontology/llm_canonicalizer.py`

```python
"""
LLM Canonicalizer Service

Utilise LLM l√©ger (GPT-4o-mini) pour trouver le nom canonique officiel
d'un concept extrait du texte.
"""

from typing import Optional, List, Dict, Any
from pydantic import BaseModel
import json
import logging

logger = logging.getLogger(__name__)


class CanonicalizationResult(BaseModel):
    """R√©sultat de canonicalisation LLM."""

    canonical_name: str
    """Nom canonique officiel trouv√©."""

    confidence: float
    """Score confiance (0-1)."""

    reasoning: str
    """Explication d√©cision LLM."""

    aliases: List[str] = []
    """Aliases/variantes reconnues."""

    concept_type: Optional[str] = None
    """Type de concept (Product, Acronym, Organization, etc.)."""

    domain: Optional[str] = None
    """Domaine (enterprise_software, legal, medical, etc.)."""

    ambiguity_warning: Optional[str] = None
    """Avertissement si ambigu√Øt√© d√©tect√©e."""

    possible_matches: List[str] = []
    """Autres canonical_names possibles si ambigu√Øt√©."""

    metadata: Dict[str, Any] = {}
    """M√©tadonn√©es additionnelles (vendor, version, etc.)."""


class LLMCanonicalizer:
    """Service de canonicalisation via LLM l√©ger."""

    def __init__(self, llm_router):
        """
        Args:
            llm_router: Instance de LLMRouter pour appels LLM
        """
        self.llm_router = llm_router
        self.model = "gpt-4o-mini"  # Mod√®le l√©ger (~$0.0001/concept)

    async def canonicalize(
        self,
        raw_name: str,
        context: Optional[str] = None,
        domain_hint: Optional[str] = None
    ) -> CanonicalizationResult:
        """
        Canonicalise un nom via LLM.

        Args:
            raw_name: Nom brut extrait (ex: "S/4HANA Cloud's")
            context: Contexte textuel autour de la mention (optionnel)
            domain_hint: Indice domaine (ex: "enterprise_software")

        Returns:
            CanonicalizationResult avec canonical_name et m√©tadonn√©es

        Example:
            >>> result = await canonicalizer.canonicalize(
            ...     raw_name="S/4HANA Cloud's",
            ...     context="Our ERP runs on SAP S/4HANA Cloud's public edition",
            ...     domain_hint="enterprise_software"
            ... )
            >>> result.canonical_name
            "SAP S/4HANA Cloud, Public Edition"
        """

        # Construire prompt LLM
        prompt = self._build_canonicalization_prompt(
            raw_name=raw_name,
            context=context,
            domain_hint=domain_hint
        )

        # Appel LLM avec JSON structured output
        response = await self.llm_router.call_llm(
            model=self.model,
            messages=[
                {"role": "system", "content": CANONICALIZATION_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,  # D√©terministe
            response_format={"type": "json_object"}
        )

        # Parse r√©sultat JSON
        result_json = json.loads(response.content)

        return CanonicalizationResult(**result_json)

    def _build_canonicalization_prompt(
        self,
        raw_name: str,
        context: Optional[str],
        domain_hint: Optional[str]
    ) -> str:
        """Construit prompt pour LLM."""

        parts = [
            f"**Concept Name:** {raw_name}",
        ]

        if context:
            parts.append(f"**Context:** {context[:500]}")  # Limiter contexte

        if domain_hint:
            parts.append(f"**Domain Hint:** {domain_hint}")

        parts.append("\n**Task:** Find the official canonical name for this concept.")

        return "\n\n".join(parts)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SYSTEM PROMPT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CANONICALIZATION_SYSTEM_PROMPT = """You are a concept canonicalization expert.

Your task is to find the OFFICIAL CANONICAL NAME for concepts extracted from documents.

# Guidelines

1. **Official Names**: Use official product/company/standard names
   - Example: "S/4HANA Cloud's" ‚Üí "SAP S/4HANA Cloud, Public Edition"
   - Example: "iPhone 15 Pro Max's camera" ‚Üí "Apple iPhone 15 Pro Max"

2. **Acronyms**: Expand acronyms to full official names
   - Example: "SLA" ‚Üí "Service Level Agreement"
   - Example: "CEE" ‚Üí "Communaut√© √âconomique Europ√©enne" (if French context)

3. **Possessives**: Remove possessive forms ('s, 's)
   - Example: "SAP's solution" ‚Üí "SAP"

4. **Casing**: Preserve official casing
   - Acronyms: SAP, ERP, CRM (all caps)
   - Products: "SAP S/4HANA" (mixed case as official)

5. **Variants**: List common aliases/variants

6. **Ambiguity**: If uncertain, set ambiguity_warning and list possible_matches
   - Example: "S/4HANA Cloud" without context ‚Üí could be Public OR Private Edition

7. **Type Detection**: Classify concept type
   - Product, Service, Organization, Acronym, Standard, Person, Location, etc.

# Output Format (JSON)

{
  "canonical_name": "Official canonical name",
  "confidence": 0.95,
  "reasoning": "Brief explanation of decision",
  "aliases": ["variant1", "variant2"],
  "concept_type": "Product|Acronym|Organization|...",
  "domain": "enterprise_software|legal|medical|...",
  "ambiguity_warning": "Warning if ambiguous or null",
  "possible_matches": ["Alternative1", "Alternative2"] or [],
  "metadata": {
    "vendor": "SAP",
    "version": "Cloud",
    "edition": "Public"
  }
}

# Examples

## Input: "S/4HANA Cloud's"
## Context: "Our public cloud ERP solution"
## Output:
{
  "canonical_name": "SAP S/4HANA Cloud, Public Edition",
  "confidence": 0.92,
  "reasoning": "Context mentions 'public cloud', official SAP product name",
  "aliases": ["S/4HANA Cloud Public", "S4 Cloud"],
  "concept_type": "Product",
  "domain": "enterprise_software",
  "ambiguity_warning": null,
  "possible_matches": [],
  "metadata": {"vendor": "SAP", "edition": "Public"}
}

## Input: "SLA"
## Context: "99.9% SLA guarantees"
## Output:
{
  "canonical_name": "Service Level Agreement",
  "confidence": 0.98,
  "reasoning": "Standard IT acronym",
  "aliases": ["SLA", "SLAs"],
  "concept_type": "Acronym",
  "domain": "it_operations",
  "ambiguity_warning": null,
  "possible_matches": [],
  "metadata": {}
}

## Input: "S/4HANA Cloud"
## Context: "We use S/4HANA Cloud for accounting"
## Output:
{
  "canonical_name": "SAP S/4HANA Cloud",
  "confidence": 0.65,
  "reasoning": "Cannot determine Public vs Private edition from context alone",
  "aliases": ["S/4HANA Cloud", "S4 Cloud"],
  "concept_type": "Product",
  "domain": "enterprise_software",
  "ambiguity_warning": "Cannot determine Public vs Private edition",
  "possible_matches": [
    "SAP S/4HANA Cloud, Public Edition",
    "SAP S/4HANA Cloud, Private Edition"
  ],
  "metadata": {"vendor": "SAP"}
}
"""
```

---

### 2. AdaptiveOntologyManager

**Fichier** : `src/knowbase/ontology/adaptive_ontology_manager.py`

```python
"""
Adaptive Ontology Manager

G√®re le cache d'ontologie auto-apprenant dans Neo4j.
"""

from typing import Optional, List, Dict, Any
from datetime import datetime
import logging
from neo4j import Session

logger = logging.getLogger(__name__)


class AdaptiveOntologyManager:
    """Gestionnaire ontologie adaptive Neo4j."""

    def __init__(self, neo4j_client):
        """
        Args:
            neo4j_client: Instance Neo4jClient
        """
        self.neo4j = neo4j_client

    def lookup(
        self,
        raw_name: str,
        tenant_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        Cherche canonical_name dans cache ontologie.

        Args:
            raw_name: Nom brut (ex: "S/4HANA Cloud's")
            tenant_id: ID tenant

        Returns:
            Dict avec canonical_name, confidence, etc. ou None si non trouv√©

        Example:
            >>> result = manager.lookup("S/4 Cloud Public", "default")
            >>> result["canonical_name"]
            "SAP S/4HANA Cloud, Public Edition"
        """

        query = """
        MATCH (o:AdaptiveOntology)
        WHERE o.tenant_id = $tenant_id
          AND (
              o.canonical_name = $raw_name
              OR $raw_name IN o.aliases
          )
        RETURN o.canonical_name AS canonical_name,
               o.aliases AS aliases,
               o.concept_type AS concept_type,
               o.domain AS domain,
               o.confidence AS confidence,
               o.source AS source,
               o.usage_count AS usage_count,
               o.ambiguity_warning AS ambiguity_warning,
               o.possible_matches AS possible_matches,
               o.ontology_id AS ontology_id
        LIMIT 1
        """

        with self.neo4j.driver.session() as session:
            result = session.run(
                query,
                raw_name=raw_name.strip(),
                tenant_id=tenant_id
            )

            record = result.single()

            if record:
                logger.debug(
                    f"[AdaptiveOntology:Lookup] ‚úÖ Cache HIT for '{raw_name}' ‚Üí '{record['canonical_name']}'"
                )
                return dict(record)
            else:
                logger.debug(
                    f"[AdaptiveOntology:Lookup] ‚ùå Cache MISS for '{raw_name}'"
                )
                return None

    def store(
        self,
        tenant_id: str,
        canonical_name: str,
        raw_name: str,
        canonicalization_result: Dict[str, Any],
        context: Optional[str] = None,
        document_id: Optional[str] = None
    ) -> str:
        """
        Stocke r√©sultat canonicalisation dans ontologie.

        Args:
            tenant_id: ID tenant
            canonical_name: Nom canonique trouv√©
            raw_name: Nom brut d'origine
            canonicalization_result: R√©sultat LLM complet
            context: Contexte textuel (optionnel)
            document_id: ID document source (optionnel)

        Returns:
            ontology_id cr√©√©
        """

        query = """
        CREATE (o:AdaptiveOntology {
            ontology_id: randomUUID(),
            tenant_id: $tenant_id,
            canonical_name: $canonical_name,
            aliases: $aliases,
            concept_type: $concept_type,
            domain: $domain,
            source: $source,
            confidence: $confidence,
            validated_by: 'auto',
            usage_count: 1,
            first_seen: datetime(),
            last_seen: datetime(),
            first_document_id: $document_id,
            example_context: $context,
            ambiguity_warning: $ambiguity_warning,
            possible_matches: $possible_matches
        })
        RETURN o.ontology_id AS ontology_id
        """

        # Pr√©parer aliases (inclure raw_name)
        aliases = canonicalization_result.get("aliases", [])
        if raw_name not in aliases:
            aliases = [raw_name] + aliases

        with self.neo4j.driver.session() as session:
            result = session.run(
                query,
                tenant_id=tenant_id,
                canonical_name=canonical_name,
                aliases=aliases,
                concept_type=canonicalization_result.get("concept_type"),
                domain=canonicalization_result.get("domain"),
                source=canonicalization_result.get("source", "llm_gpt4o_mini"),
                confidence=canonicalization_result.get("confidence", 0.0),
                document_id=document_id,
                context=context[:500] if context else None,
                ambiguity_warning=canonicalization_result.get("ambiguity_warning"),
                possible_matches=canonicalization_result.get("possible_matches", [])
            )

            record = result.single()
            ontology_id = record["ontology_id"]

            logger.info(
                f"[AdaptiveOntology:Store] Created ontology entry '{canonical_name}' "
                f"(id={ontology_id[:8]}, aliases={len(aliases)})"
            )

            return ontology_id

    def add_alias(
        self,
        canonical_name: str,
        tenant_id: str,
        new_alias: str
    ) -> bool:
        """
        Ajoute alias √† ontologie existante (auto-enrichissement).

        Args:
            canonical_name: Nom canonique existant
            tenant_id: ID tenant
            new_alias: Nouvelle variante √† ajouter

        Returns:
            True si ajout√©, False si d√©j√† existant
        """

        query = """
        MATCH (o:AdaptiveOntology)
        WHERE o.tenant_id = $tenant_id
          AND o.canonical_name = $canonical_name
          AND NOT $new_alias IN o.aliases

        SET o.aliases = o.aliases + [$new_alias],
            o.usage_count = o.usage_count + 1,
            o.last_seen = datetime()

        RETURN o.ontology_id AS ontology_id
        """

        with self.neo4j.driver.session() as session:
            result = session.run(
                query,
                tenant_id=tenant_id,
                canonical_name=canonical_name,
                new_alias=new_alias.strip()
            )

            record = result.single()

            if record:
                logger.debug(
                    f"[AdaptiveOntology:Enrich] Added alias '{new_alias}' ‚Üí '{canonical_name}'"
                )
                return True
            else:
                logger.debug(
                    f"[AdaptiveOntology:Enrich] Alias '{new_alias}' already exists for '{canonical_name}'"
                )
                return False

    def increment_usage(
        self,
        canonical_name: str,
        tenant_id: str
    ) -> None:
        """Incr√©mente compteur usage (statistiques)."""

        query = """
        MATCH (o:AdaptiveOntology)
        WHERE o.tenant_id = $tenant_id
          AND o.canonical_name = $canonical_name

        SET o.usage_count = o.usage_count + 1,
            o.last_seen = datetime()
        """

        with self.neo4j.driver.session() as session:
            session.run(
                query,
                tenant_id=tenant_id,
                canonical_name=canonical_name
            )
```

---

### 3. Int√©gration Gatekeeper

**Fichier** : `src/knowbase/agents/gatekeeper/gatekeeper.py`

**Modifications** :

```python
class GatekeeperAgent(BaseAgent):
    """..."""

    def __init__(self, ...):
        # Existing init
        ...

        # NEW: LLM Canonicalizer
        from knowbase.ontology.llm_canonicalizer import LLMCanonicalizer
        from knowbase.ontology.adaptive_ontology_manager import AdaptiveOntologyManager
        from knowbase.common.llm_router import get_llm_router

        self.llm_router = get_llm_router()
        self.llm_canonicalizer = LLMCanonicalizer(self.llm_router)
        self.adaptive_ontology = AdaptiveOntologyManager(self.neo4j_client)

    async def _canonicalize_concept_name(
        self,
        raw_name: str,
        context: Optional[str] = None,
        tenant_id: str = "default"
    ) -> tuple[str, float]:
        """
        Canonicalise nom concept via Adaptive Ontology.

        Workflow:
        1. Lookup cache ontologie
        2. Si non trouv√© ‚Üí LLM canonicalization
        3. Store r√©sultat dans ontologie

        Returns:
            (canonical_name, confidence)
        """

        # 1. Lookup cache ontologie
        cached = self.adaptive_ontology.lookup(raw_name, tenant_id)

        if cached:
            # Cache HIT
            logger.debug(
                f"[GATEKEEPER:Canonicalization] ‚úÖ Cache HIT '{raw_name}' ‚Üí '{cached['canonical_name']}' "
                f"(confidence={cached['confidence']:.2f}, source={cached['source']})"
            )

            # Incr√©menter usage stats
            self.adaptive_ontology.increment_usage(cached["canonical_name"], tenant_id)

            return cached["canonical_name"], cached["confidence"]

        # 2. Cache MISS ‚Üí LLM canonicalization
        logger.info(
            f"[GATEKEEPER:Canonicalization] üîç Cache MISS '{raw_name}', calling LLM canonicalizer..."
        )

        llm_result = await self.llm_canonicalizer.canonicalize(
            raw_name=raw_name,
            context=context,
            domain_hint=None  # Auto-d√©tection par LLM
        )

        logger.info(
            f"[GATEKEEPER:Canonicalization] ‚úÖ LLM canonicalized '{raw_name}' ‚Üí '{llm_result.canonical_name}' "
            f"(confidence={llm_result.confidence:.2f}, type={llm_result.concept_type})"
        )

        # 3. Store dans ontologie adaptive
        self.adaptive_ontology.store(
            tenant_id=tenant_id,
            canonical_name=llm_result.canonical_name,
            raw_name=raw_name,
            canonicalization_result=llm_result.model_dump(),
            context=context
        )

        return llm_result.canonical_name, llm_result.confidence

    # Dans _promote_concepts_tool():
    async def _promote_concepts_tool(self, tool_input: PromoteConceptsInput) -> PromoteConceptsOutput:
        """..."""

        for concept in tool_input.concepts_to_promote:
            concept_name = concept.get("name", "")

            # ... existing code ...

            # REMPLACER:
            # canonical_name = concept_name.strip().title()

            # PAR:
            canonical_name, confidence = await self._canonicalize_concept_name(
                raw_name=concept_name,
                context=tool_input.full_text,  # Contexte document complet
                tenant_id=tenant_id
            )

            # ... rest of existing code ...
```

---

## üìä M√©triques & KPIs

### √âvolution Ontologie

| P√©riode | Ontology Nodes | Cache Hit Rate | Avg LLM Calls/Doc | Cost/Doc |
|---------|----------------|----------------|-------------------|----------|
| **Jour 1** | 0 | 0% | 15-30 | $0.003 |
| **Semaine 2** | 150 | 60% | 6-12 | $0.001 |
| **Mois 3** | 800 | 85% | 2-5 | $0.0003 |
| **An 1** | 2500+ | 95% | 0-2 | $0.00005 |

### Qualit√© D√©duplication

**Avant canonicalisation** :
```cypher
MATCH (c:CanonicalConcept)
WHERE c.canonical_name CONTAINS "S/4"
RETURN count(c)
// Result: 8 concepts (doublons !)
```

**Apr√®s canonicalisation** :
```cypher
MATCH (c:CanonicalConcept)
WHERE c.canonical_name = "SAP S/4HANA Cloud, Public Edition"
RETURN count(c)
// Result: 1 concept unique ‚úÖ

// Avec variantes pr√©serv√©es
RETURN c.surface_form
// Results: ["S/4HANA Cloud's", "S/4 Cloud Public", "SAP S/4HANA Cloud (Public)", ...]
```

---

## üéØ Cas d'Usage R√©els

### Cas 1 : Premier Document (Apprentissage)

**Input** :
```
Document: "SAP_S4HANA_Overview.pdf"
Extractor trouve: "S/4HANA Cloud's financial module"
```

**Workflow** :
```python
# 1. Lookup ontologie
cached = adaptive_ontology.lookup("S/4HANA Cloud's", "default")
# Result: None (premier jour)

# 2. LLM canonicalization
llm_result = await llm_canonicalizer.canonicalize(
    raw_name="S/4HANA Cloud's",
    context="SAP S/4HANA Cloud's financial module provides real-time analytics..."
)
# Result:
# {
#   "canonical_name": "SAP S/4HANA Cloud, Public Edition",
#   "confidence": 0.92,
#   "aliases": ["S/4HANA Cloud Public", "S4 Cloud"],
#   "concept_type": "Product",
#   "domain": "enterprise_software"
# }

# 3. Store dans ontologie
adaptive_ontology.store(
    canonical_name="SAP S/4HANA Cloud, Public Edition",
    raw_name="S/4HANA Cloud's",
    canonicalization_result=llm_result
)

# 4. Create CanonicalConcept
neo4j.create_canonical_concept(
    canonical_name="SAP S/4HANA Cloud, Public Edition",  # ‚úÖ Nom officiel
    surface_form="S/4HANA Cloud's",  # Variante pr√©serv√©e
    ...
)
```

**Co√ªt** : 1 appel LLM (~$0.0001)

---

### Cas 2 : Deuxi√®me Document (Cache Hit)

**Input** :
```
Document: "S4_Cloud_Benefits.pptx"
Extractor trouve: "S/4 Cloud Public"
```

**Workflow** :
```python
# 1. Lookup ontologie
cached = adaptive_ontology.lookup("S/4 Cloud Public", "default")
# Result: {
#   "canonical_name": "SAP S/4HANA Cloud, Public Edition",
#   "confidence": 0.92,
#   "source": "llm_gpt4o_mini"
# }
# ‚úÖ CACHE HIT !

# 2. PAS d'appel LLM (√©conomie)

# 3. Enrichir ontologie (add new alias)
adaptive_ontology.add_alias(
    canonical_name="SAP S/4HANA Cloud, Public Edition",
    new_alias="S/4 Cloud Public"
)
# Ontologie maintenant contient:
# aliases: ["S/4HANA Cloud's", "S/4 Cloud Public", ...]

# 4. Create CanonicalConcept
neo4j.create_canonical_concept(
    canonical_name="SAP S/4HANA Cloud, Public Edition",  # ‚úÖ M√äME canonical_name
    surface_form="S/4 Cloud Public",  # Nouvelle variante
    ...
)
```

**Co√ªt** : 0 appel LLM ($0) ‚úÖ

---

### Cas 3 : Ambigu√Øt√© D√©tect√©e

**Input** :
```
Document: "ERP_Comparison.docx"
Extractor trouve: "S/4HANA Cloud"  # Sans Public/Private
Context: "We use S/4HANA Cloud for accounting"
```

**Workflow** :
```python
# 1. Lookup ontologie ‚Üí MISS

# 2. LLM canonicalization
llm_result = await llm_canonicalizer.canonicalize(
    raw_name="S/4HANA Cloud",
    context="We use S/4HANA Cloud for accounting"
)
# Result:
# {
#   "canonical_name": "SAP S/4HANA Cloud",  # G√©n√©rique (sans √©dition)
#   "confidence": 0.65,  # ‚ö†Ô∏è Plus bas (ambigu√Øt√©)
#   "ambiguity_warning": "Cannot determine Public vs Private edition",
#   "possible_matches": [
#       "SAP S/4HANA Cloud, Public Edition",
#       "SAP S/4HANA Cloud, Private Edition"
#   ]
# }

# 3. Gatekeeper d√©cide
if llm_result.confidence < 0.7 and llm_result.ambiguity_warning:
    # Option A: Cr√©er concept g√©n√©rique
    canonical_name = "SAP S/4HANA Cloud"  # Sans √©dition sp√©cifique

    # Option B: Marquer pour validation humaine
    requires_validation = True
    logger.warning(
        f"[GATEKEEPER:Canonicalization] ‚ö†Ô∏è Ambiguity detected for '{raw_name}': "
        f"{llm_result.ambiguity_warning}"
    )
```

---

## üöÄ Plan d'Impl√©mentation

### Phase 1 : Setup Infrastructure (30 min)

1. ‚úÖ Cr√©er sch√©ma Neo4j AdaptiveOntology
2. ‚úÖ Cr√©er indexes & constraints
3. ‚úÖ Impl√©menter AdaptiveOntologyManager
4. ‚úÖ Tests unitaires manager

### Phase 2 : LLM Canonicalizer (1h)

1. ‚úÖ Impl√©menter LLMCanonicalizer service
2. ‚úÖ Cr√©er prompt system optimis√©
3. ‚úÖ Tests avec exemples r√©els (SAP, acronymes, produits)
4. ‚úÖ Gestion erreurs LLM

### Phase 3 : Int√©gration Gatekeeper (1h)

1. ‚úÖ Ajouter m√©thode `_canonicalize_concept_name()`
2. ‚úÖ Remplacer `.title()` par canonicalization
3. ‚úÖ Tests int√©gration bout-en-bout
4. ‚úÖ Monitoring logs (cache hit rate, LLM calls)

### Phase 4 : Validation & Rollout (30 min)

1. ‚úÖ Test avec document r√©el (PPTX SAP)
2. ‚úÖ V√©rifier d√©duplication Neo4j
3. ‚úÖ Mesurer cache hit rate apr√®s 2-3 documents
4. ‚úÖ Documentation finale

**Dur√©e Totale** : ~3h

---

## üîí Consid√©rations S√©curit√© & Co√ªts

### Co√ªts LLM

**Mod√®le** : GPT-4o-mini (~$0.150/1M input tokens, $0.600/1M output tokens)

**Estimation par concept** :
- Input: ~200 tokens (raw_name + context)
- Output: ~150 tokens (JSON result)
- **Co√ªt unitaire** : ~$0.0001/concept

**Projection 1000 documents** :
- Jour 1 : 1000 docs √ó 20 concepts √ó $0.0001 = **$2.00**
- Mois 3 : 1000 docs √ó 3 concepts (85% cache) √ó $0.0001 = **$0.30**
- An 1 : 1000 docs √ó 1 concept (95% cache) √ó $0.0001 = **$0.10**

**ROI** : La d√©duplication √©conomise ~30% de storage Neo4j + am√©liore recall de 40% ‚Üí **ROI positif d√®s Mois 1**.

### Privacy & Compliance

- ‚ö†Ô∏è **Pas de donn√©es sensibles** dans contexte LLM (seulement concept_name + snippet)
- ‚úÖ R√©sultats cach√©s localement (Neo4j), pas d'API externe
- ‚úÖ Tenant isolation (multi-tenant safe)

---

## üìö R√©f√©rences

### Liens Internes

- `doc/OSMOSE_ARCHITECTURE_TECHNIQUE.md` : Architecture globale OSMOSE
- `doc/phases/PHASE1_SEMANTIC_CORE.md` : Sp√©cifications Phase 1
- `doc/ongoing/SPECIFICATIONS_ARCHITECTURE_ZERO_CONFIG.md` : Zero-Config specs

### Fichiers Code

- `src/knowbase/agents/gatekeeper/gatekeeper.py` : Gatekeeper agent
- `src/knowbase/common/clients/neo4j_client.py` : Neo4j client
- `src/knowbase/common/llm_router.py` : LLM router

### Bugs R√©solus

- **Bug UNWIND liste vide** (2025-10-17) : R√©solu par REDUCE (commit `bfbf0db`)
- **Bug canonical_name .title()** (2025-10-17) : √Ä r√©soudre par LLM Canonicalizer

---

## ‚úÖ Validation & Tests

### Test Cases

#### TC1 : Cache Hit
```python
# Setup: Ontologie contient "SAP S/4HANA Cloud, Public Edition"
result = await canonicalizer.canonicalize("S/4 Cloud Public", context=None)

assert result == {
    "canonical_name": "SAP S/4HANA Cloud, Public Edition",
    "confidence": 0.92,
    "source": "cached"
}
assert llm_calls == 0  # Pas d'appel LLM
```

#### TC2 : Cache Miss ‚Üí LLM
```python
# Setup: Ontologie vide
result = await canonicalizer.canonicalize("iPhone 15 Pro Max's", context=None)

assert result.canonical_name == "Apple iPhone 15 Pro Max"
assert result.confidence > 0.9
assert llm_calls == 1  # 1 appel LLM
```

#### TC3 : Ambigu√Øt√©
```python
result = await canonicalizer.canonicalize("S/4HANA Cloud", context="We use ERP")

assert result.canonical_name == "SAP S/4HANA Cloud"  # G√©n√©rique
assert result.confidence < 0.7
assert result.ambiguity_warning is not None
assert len(result.possible_matches) == 2
```

#### TC4 : D√©duplication
```cypher
// Apr√®s ingestion 3 documents avec variantes S/4HANA
MATCH (c:CanonicalConcept {canonical_name: "SAP S/4HANA Cloud, Public Edition"})
RETURN count(c) AS count

// Expected: count = 1 (UN SEUL concept malgr√© 3 variantes)
```

---

**Derni√®re mise √† jour** : 2025-10-17
**Auteur** : Claude Code
**Statut** : Pr√™t pour impl√©mentation
**Priorit√©** : P0 (Critique - r√©sout doublons KG)
