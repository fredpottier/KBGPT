# Adaptive Ontology - Status Impl√©mentation

**Date** : 2025-10-17
**Commit** : `bdc2ccd`
**Statut** : Phases 1-2 COMPL√àTES ‚úÖ, Phase 3 EN COURS

---

## ‚úÖ COMPL√âT√â

### Phase 1: Setup Infrastructure AdaptiveOntology Neo4j

**Commit** : `bdc2ccd`

**Infrastructure Neo4j cr√©√©e** :
```bash
# V√©rifier status:
docker-compose exec app python -c "
from knowbase.common.clients.neo4j_client import get_neo4j_client
neo4j = get_neo4j_client(uri='bolt://neo4j:7687', user='neo4j', password='graphiti_neo4j_pass')
with neo4j.driver.session() as s:
    result = s.run('SHOW INDEXES')
    indexes = [r['name'] for r in result if 'adaptive_ontology' in r['name']]
    print(f'Indexes: {indexes}')
"
```

**R√©sultats attendus** :
```
Indexes: ['adaptive_ontology_domain', 'adaptive_ontology_tenant', 'adaptive_ontology_type', 'adaptive_ontology_unique_canonical']
```

**Fichiers cr√©√©s** :
- ‚úÖ `scripts/setup_adaptive_ontology.py` (150+ lignes)
- ‚úÖ Sch√©ma Neo4j (AdaptiveOntology node + indexes)

---

### Phase 2: LLMCanonicalizer + AdaptiveOntologyManager

**Commit** : `bdc2ccd`

**Fichiers cr√©√©s** :
- ‚úÖ `src/knowbase/ontology/llm_canonicalizer.py` (250 lignes)
  - Class `LLMCanonicalizer`
  - Class `CanonicalizationResult` (Pydantic)
  - Prompt syst√®me optimis√© (100+ lignes)
  - Fallback gracieux si erreur LLM

- ‚úÖ `src/knowbase/ontology/adaptive_ontology_manager.py` (200+ lignes)
  - Class `AdaptiveOntologyManager`
  - Methods: `lookup()`, `store()`, `add_alias()`, `increment_usage()`, `get_stats()`

**Test rapide** :
```bash
docker-compose exec app python -c "
from knowbase.ontology.llm_canonicalizer import LLMCanonicalizer
from knowbase.ontology.adaptive_ontology_manager import AdaptiveOntologyManager
from knowbase.common.llm_router import get_llm_router
from knowbase.common.clients.neo4j_client import get_neo4j_client

# Init
llm_router = get_llm_router()
neo4j = get_neo4j_client(uri='bolt://neo4j:7687', user='neo4j', password='graphiti_neo4j_pass')
canonicalizer = LLMCanonicalizer(llm_router)
ontology = AdaptiveOntologyManager(neo4j)

# Test canonicalization
result = canonicalizer.canonicalize(
    raw_name=\"S/4HANA Cloud's\",
    context=\"Our public cloud ERP system\"
)
print(f'Canonical: {result.canonical_name}')
print(f'Confidence: {result.confidence}')

# Test store
ontology.store(
    tenant_id='default',
    canonical_name=result.canonical_name,
    raw_name=\"S/4HANA Cloud's\",
    canonicalization_result=result.model_dump()
)
print('‚úÖ Stored in ontology')
"
```

---

## üöß EN COURS - Phase 3: Int√©gration Gatekeeper

**Status** : NON COMMENC√â (code pr√©par√© mais non int√©gr√©)

**Objectif** : Modifier Gatekeeper pour utiliser LLM Canonicalizer au lieu de `.title()`

### Fichier √† modifier

`src/knowbase/agents/gatekeeper/gatekeeper.py`

**Lignes critiques √† remplacer** :
- Ligne 680 : `canonical_name = concept_name.strip().title()`
- Ligne 690 : `canonical_name = concept_name.strip().title()`
- Ligne 694 : `canonical_name = concept_name.strip().title()`

### Code d'int√©gration pr√©par√©

```python
# Dans GatekeeperAgent.__init__()
from knowbase.ontology.llm_canonicalizer import LLMCanonicalizer
from knowbase.ontology.adaptive_ontology_manager import AdaptiveOntologyManager
from knowbase.common.llm_router import get_llm_router

self.llm_router = get_llm_router()
self.llm_canonicalizer = LLMCanonicalizer(self.llm_router)
self.adaptive_ontology = AdaptiveOntologyManager(self.neo4j_client)

# Nouvelle m√©thode √† ajouter
def _canonicalize_concept_name(
    self,
    raw_name: str,
    context: Optional[str] = None,
    tenant_id: str = "default"
) -> tuple[str, float]:
    """
    Canonicalise nom concept via Adaptive Ontology.

    Workflow:
    1. Lookup cache ontologie
    2. Si non trouv√© ‚Üí LLM canonicalization
    3. Store r√©sultat dans ontologie

    Returns:
        (canonical_name, confidence)
    """

    # 1. Lookup cache ontologie
    cached = self.adaptive_ontology.lookup(raw_name, tenant_id)

    if cached:
        # Cache HIT
        logger.debug(
            f"[GATEKEEPER:Canonicalization] ‚úÖ Cache HIT '{raw_name}' ‚Üí '{cached['canonical_name']}' "
            f"(confidence={cached['confidence']:.2f}, source={cached['source']})"
        )

        # Incr√©menter usage stats
        self.adaptive_ontology.increment_usage(cached["canonical_name"], tenant_id)

        return cached["canonical_name"], cached["confidence"]

    # 2. Cache MISS ‚Üí LLM canonicalization
    logger.info(
        f"[GATEKEEPER:Canonicalization] üîç Cache MISS '{raw_name}', calling LLM canonicalizer..."
    )

    llm_result = self.llm_canonicalizer.canonicalize(
        raw_name=raw_name,
        context=context,
        domain_hint=None  # Auto-d√©tection par LLM
    )

    logger.info(
        f"[GATEKEEPER:Canonicalization] ‚úÖ LLM canonicalized '{raw_name}' ‚Üí '{llm_result.canonical_name}' "
        f"(confidence={llm_result.confidence:.2f}, type={llm_result.concept_type})"
    )

    # 3. Store dans ontologie adaptive
    self.adaptive_ontology.store(
        tenant_id=tenant_id,
        canonical_name=llm_result.canonical_name,
        raw_name=raw_name,
        canonicalization_result=llm_result.model_dump(),
        context=context
    )

    return llm_result.canonical_name, llm_result.confidence


# Dans _promote_concepts_tool(), REMPLACER:
canonical_name = concept_name.strip().title()

# PAR:
canonical_name, confidence = self._canonicalize_concept_name(
    raw_name=concept_name,
    context=full_text,  # Passer contexte complet du document
    tenant_id=tenant_id
)
```

### Actions requises

1. **Ajouter imports** dans `gatekeeper.py`
2. **Modifier `__init__()`** pour initialiser canonicalizer + ontology
3. **Ajouter m√©thode `_canonicalize_concept_name()`**
4. **Remplacer 3 occurrences `.title()`** par appel √† `_canonicalize_concept_name()`

---

## ‚è≥ √Ä FAIRE - Phase 4: Tests Validation

**Objectif** : Valider bout-en-bout avec document r√©el

### Plan de test

1. **Rebuild worker** :
```bash
docker-compose build ingestion-worker
docker-compose restart ingestion-worker
```

2. **Purger donn√©es** :
```bash
# Purger Redis
docker-compose exec redis redis-cli FLUSHALL

# Purger Neo4j
docker exec knowbase-neo4j cypher-shell -u neo4j -p graphiti_neo4j_pass "
MATCH (n) WHERE n.tenant_id = 'default' DETACH DELETE n
"
```

3. **Import document test** :
- Via frontend : http://localhost:3000/documents/import
- Uploader PPTX SAP contenant variations : "S/4HANA Cloud's", "SAP ERP", etc.

4. **V√©rifier logs** :
```bash
docker-compose logs ingestion-worker --tail=100 | grep "LLMCanonicalizer\|AdaptiveOntology"
```

**Logs attendus** :
```
[LLMCanonicalizer] Canonicalizing 'S/4HANA Cloud's'
[LLMCanonicalizer] ‚úÖ 'S/4HANA Cloud's' ‚Üí 'SAP S/4HANA Cloud, Public Edition'
[AdaptiveOntology:Store] Created ontology entry 'SAP S/4HANA Cloud, Public Edition'
```

5. **V√©rifier Neo4j** :
```cypher
// Canonical concepts unifi√©s
MATCH (c:CanonicalConcept {tenant_id: 'default'})
WHERE c.canonical_name CONTAINS 'S/4'
RETURN c.canonical_name, c.surface_form

// Expected: UN SEUL concept canonical_name, multiples surface_forms

// Ontologie adaptive
MATCH (o:AdaptiveOntology {tenant_id: 'default'})
RETURN o.canonical_name, o.aliases, o.usage_count
ORDER BY o.usage_count DESC
```

6. **Tester 2√®me document** (cache hit) :
- Importer AUTRE document avec m√™mes concepts
- Logs attendus : `[AdaptiveOntology:Lookup] ‚úÖ Cache HIT`
- Co√ªt LLM : $0 (pas d'appel, cache utilis√©)

---

## üìä M√©triques Attendues

### Premier Document (Cache vide)
- **Concepts extraits** : ~15-30
- **Appels LLM** : 15-30 (tous nouveaux)
- **Co√ªt** : ~$0.002-$0.003
- **Cache hit rate** : 0%
- **AdaptiveOntology entries** : 15-30

### Deuxi√®me Document (Cache warm)
- **Concepts extraits** : ~20
- **Appels LLM** : ~3-8 (seulement nouveaux termes)
- **Co√ªt** : ~$0.0003-$0.0008
- **Cache hit rate** : ~60-75%
- **AdaptiveOntology entries** : 18-35 (enrichissement)

### Dixi√®me Document (Cache mature)
- **Concepts extraits** : ~20
- **Appels LLM** : ~0-2
- **Co√ªt** : ~$0.00-$0.0002
- **Cache hit rate** : ~90-95%
- **AdaptiveOntology entries** : 30-50

---

## üêõ Probl√®mes Connus

### Issue 1: Gatekeeper non modifi√©

**Status** : Lignes 680/690/694 utilisent encore `.title()`

**Impact** : Canonicalization LLM pas utilis√©e dans production

**Fix** : Appliquer int√©gration Phase 3 (voir code ci-dessus)

---

## üìù Notes Importantes

### Documentation compl√®te

`doc/ongoing/ADAPTIVE_ONTOLOGY_CANONICALIZATION.md` (1,110 lignes)
- Architecture d√©taill√©e
- Sch√©ma Neo4j complet
- Code d'int√©gration Gatekeeper
- Cas d'usage r√©els
- M√©triques et KPIs

### Commits

- `7a365a3` : docs: Architecture LLM Canonicalizer + Adaptive Ontology
- `bfbf0db` : fix(neo4j): Corriger bug UNWIND liste vide dans promote_to_published
- `bdc2ccd` : feat(ontology): Impl√©menter LLM Canonicalizer + Adaptive Ontology (Phases 1-2)

---

## üéØ Prochaine Session - Quick Start

```bash
# 1. V√©rifier infrastructure Neo4j
docker-compose exec app python -c "
from knowbase.common.clients.neo4j_client import get_neo4j_client
neo4j = get_neo4j_client(uri='bolt://neo4j:7687', user='neo4j', password='graphiti_neo4j_pass')
with neo4j.driver.session() as s:
    result = s.run('SHOW INDEXES')
    indexes = [r['name'] for r in result if 'adaptive_ontology' in r['name']]
    print('‚úÖ Indexes:', indexes)
"

# 2. Int√©grer Gatekeeper (Phase 3)
# ‚Üí Voir code ci-dessus dans section "Code d'int√©gration pr√©par√©"

# 3. Rebuild + test
docker-compose build ingestion-worker
docker-compose restart ingestion-worker

# 4. Import document test
# ‚Üí http://localhost:3000/documents/import
```

**Derni√®re mise √† jour** : 2025-10-17 12:00 UTC
