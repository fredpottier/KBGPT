# Corrections OSMOSE Pure - 2025-10-14

## üêõ Probl√®mes Identifi√©s et Corrig√©s

### Probl√®me 1: Modules manquants (CRITIQUE)

**Erreur:**
```
ModuleNotFoundError: No module named 'knowbase.semantic.narrative_detector'
```

**Cause:**
- `src/knowbase/semantic/__init__.py` importait des modules Phase 1 non encore impl√©ment√©s :
  - `narrative_detector.py`
  - `segmentation.py`
  - `extractor.py`

**Solution:** `src/knowbase/semantic/__init__.py:16-42`

Comment√© les imports manquants :
```python
from .profiler import SemanticDocumentProfiler
# Modules Phase 1 non encore impl√©ment√©s (TODO):
# from .narrative_detector import NarrativeThreadDetector
# from .segmentation import IntelligentSegmentationEngine
# from .extractor import DualStorageExtractor
```

**Status:** ‚úÖ CORRIG√â

---

### Probl√®me 2: R√©sum√©s Vision trop courts

**Observation utilisateur:**
> "la taille des retours du LLM vision pour chaque slide est plut√¥t faible. Je suis √©tonn√© qu'il ne retourne que des textes aussi courts. Il faudrait afficher le texte retourn√© dans la log"

**Causes possibles:**
1. `max_tokens=1500` trop bas pour r√©sum√©s vraiment d√©taill√©s
2. `temperature=0.3` trop conservatif pour prose cr√©ative
3. Logging affiche seulement longueur, pas contenu complet

**Solutions:** `src/knowbase/ingestion/pipelines/pptx_pipeline.py:1453-1484`

#### Changement 1: Augmentation max_tokens
```python
# AVANT
max_tokens=1500  # Suffisant pour 2-4 paragraphes riches

# APR√àS
max_tokens=2500  # Augment√© pour r√©sum√©s vraiment d√©taill√©s
```

#### Changement 2: Augmentation temperature
```python
# AVANT
temperature=0.3,  # L√©g√®rement plus cr√©atif pour prose

# APR√àS
temperature=0.5,  # Plus cr√©atif pour descriptions riches
```

#### Changement 3: Logging complet du r√©sum√©
```python
# AVANT
logger.info(f"Slide {slide_index} [VISION SUMMARY]: {len(summary)} chars generated")

# APR√àS
logger.info(f"Slide {slide_index} [VISION SUMMARY]: {len(summary)} chars generated")
logger.info(f"Slide {slide_index} [VISION SUMMARY CONTENT]:\n{summary}")
logger.info("=" * 80)
```

**R√©sultat:** Chaque r√©sum√© Vision est maintenant affich√© en entier dans les logs.

#### Changement 4: Aper√ßu texte enrichi final
**Location:** `pptx_pipeline.py:1947-1952`

```python
# Afficher aper√ßu du texte enrichi pour validation
preview_length = min(1000, len(full_text_enriched))
logger.info(f"[OSMOSE PURE] Aper√ßu texte enrichi (premiers {preview_length} chars):")
logger.info("=" * 80)
logger.info(full_text_enriched[:preview_length] + ("..." if len(full_text_enriched) > preview_length else ""))
logger.info("=" * 80)
```

**Status:** ‚úÖ CORRIG√â

---

## üìä Logs Attendus Maintenant

### 1. Logs Vision par Slide

**Format:**
```
Slide 1 [VISION SUMMARY]: 847 chars generated
Slide 1 [VISION SUMMARY CONTENT]:
This slide presents the SAP HANA architecture organized into three distinct vertical layers.
At the top, the "Application Services" layer showcases XS Advanced and HANA Studio as the
primary development tools, connected through a unified interface layer. The middle section
displays the "Processing Layer" with two prominent storage engines positioned side by side:
Column Store on the left and Row Store on the right. A bold arrow points from Column Store
to a callout box emphasizing its optimization for analytical workloads, suggesting this is
a key architectural advantage. The visual hierarchy clearly indicates that Column Store is
the primary focus for analytics, while Row Store handles transactional operations. At the
bottom, the "Persistence Layer" contains Data Volumes and Log Volumes shown as interconnected
cylinders, with bidirectional arrows indicating continuous synchronization between them...
================================================================================
```

### 2. Logs Texte Enrichi Global

**Format:**
```
[OSMOSE PURE] Texte enrichi construit: 18543 chars depuis 25 slides
[OSMOSE PURE] Aper√ßu texte enrichi (premiers 1000 chars):
================================================================================

--- Slide 1 ---
This slide presents the SAP HANA architecture organized into three distinct vertical layers...

--- Slide 2 ---
The slide shows a comparison table highlighting the differences between Column Store and Row Store...
================================================================================
```

### 3. Logs OSMOSE Processing

**Format:** (inchang√©)
```
================================================================================
[OSMOSE PURE] Lancement du traitement s√©mantique (remplace ingestion legacy)
================================================================================
[OSMOSE PURE] ‚úÖ Traitement r√©ussi:
  - 42 concepts canoniques
  - 15 connexions cross-documents
  - 8 topics segment√©s
  - Proto-KG: 42 concepts + 35 relations + 42 embeddings
  - Dur√©e: 14.2s
================================================================================
```

---

## üéØ B√©n√©fices

### Avant Corrections

‚ùå Crash au d√©marrage (modules manquants)
‚ùå R√©sum√©s Vision invisibles dans logs
‚ùå Impossible de valider qualit√© r√©sum√©s
‚ùå max_tokens=1500 limitait richesse

### Apr√®s Corrections

‚úÖ Pipeline d√©marre sans erreur
‚úÖ R√©sum√©s Vision affich√©s en entier
‚úÖ Validation qualit√© possible (observer logs)
‚úÖ max_tokens=2500 + temp=0.5 ‚Üí R√©sum√©s plus riches
‚úÖ Aper√ßu texte enrichi global visible

---

## üìù Fichiers Modifi√©s

1. **`src/knowbase/semantic/__init__.py`**
   - Lignes 16-42 : Comment√© imports modules manquants

2. **`src/knowbase/ingestion/pipelines/pptx_pipeline.py`**
   - Lignes 1459-1460 : Augmentation temperature (0.5) et max_tokens (2500)
   - Lignes 1470-1472 : Ajout logging complet r√©sum√©
   - Lignes 1947-1952 : Ajout aper√ßu texte enrichi

---

## üß™ Test Suivant

Tu peux maintenant relancer l'ingestion PPTX et observer :

1. **Logs Vision d√©taill√©s** ‚Üí Valider que r√©sum√©s sont vraiment riches
2. **Longueur r√©sum√©s** ‚Üí Devrait √™tre > 500 chars par slide en moyenne
3. **Qualit√© descriptions** ‚Üí Layouts, diagrammes, relations visuelles captur√©s
4. **Texte enrichi final** ‚Üí Aper√ßu 1000 chars permet validation rapide

**Commandes:**
```bash
# Observer logs en temps r√©el
docker-compose logs -f worker

# Relancer test PPTX
# (copier fichier dans data/docs_in/ ou via interface)
```

---

### Probl√®me 3: Import NarrativeThread manquant (CRITIQUE)

**Erreur:**
```
ImportError: cannot import name 'NarrativeThread' from 'knowbase.semantic.models'
```

**Cause:**
- `src/knowbase/semantic/__init__.py` importait `NarrativeThread` depuis `models.py`
- Ce mod√®le n'existe PAS dans `models.py`
- `NarrativeThread` √©tait pr√©vu pour Phase 1 mais non impl√©ment√©

**Solution:** `src/knowbase/semantic/__init__.py:22-52`

Supprim√© import inexistant et ajout√© les mod√®les r√©els :
```python
# AVANT
from .models import (
    SemanticProfile,
    NarrativeThread,  # ‚ùå N'existe pas
    ComplexityZone,
    CandidateEntity,
    CandidateRelation,
)

# APR√àS
from .models import (
    SemanticProfile,
    ComplexityZone,
    CandidateEntity,
    CandidateRelation,
    Concept,  # ‚úÖ Existe
    CanonicalConcept,  # ‚úÖ Existe
    Topic,  # ‚úÖ Existe
    ConceptConnection,  # ‚úÖ Existe
    ConceptType,  # ‚úÖ Enum
    DocumentRole,  # ‚úÖ Enum
)
```

**Status:** ‚úÖ CORRIG√â

---

---

### Probl√®me 4: Vision retourne JSON vide au lieu de prose (CRITIQUE)

**Erreur dans logs:**
```
WARNING: JSON invalide d√©tect√©, tentative de r√©paration: Expecting value: line 1 column 1 (char 0)
ERROR: Impossible de r√©parer le JSON, retour d'un array vide
WARNING: Slide 2 [VISION SUMMARY]: Response too short (2 chars)
```

**Cause:**
- `ask_gpt_vision_summary()` retourne de la **prose** (texte naturel)
- Mais appelle `clean_gpt_response()` qui essaie de **parser du JSON**
- Quand le parsing √©choue, retourne `"[]"` (2 chars) au lieu du texte

**Solution:** `pptx_pipeline.py:1465-1469`

Remplac√© appel √† `clean_gpt_response()` par nettoyage simple markdown :
```python
# AVANT
summary = clean_gpt_response(summary)  # ‚ùå Parse JSON et retourne "[]" si √©chec

# APR√àS
import re
summary = re.sub(r"^```(?:markdown|text)?\s*", "", summary)
summary = re.sub(r"\s*```$", "", summary)
summary = summary.strip()  # ‚úÖ Juste nettoie markdown, pas de parsing JSON
```

**Impact:** Vision peut maintenant retourner du texte prose sans qu'il soit d√©truit par le parser JSON.

**Status:** ‚úÖ CORRIG√â

---

### Probl√®me 5: Duplicate detection d√©sactiv√© (DEBUG MODE)

**Fichier:** `pptx_pipeline.py:1627-1662`

Pour faciliter les tests r√©p√©t√©s avec le m√™me fichier, la d√©tection de duplicatas par checksum a √©t√© **temporairement d√©sactiv√©e**.

**Log visible:**
```
‚ö†Ô∏è DEBUG MODE: Duplicate detection DISABLED - processing [fichier.pptx]
```

**√Ä r√©activer en production** : D√©commenter les lignes 1628-1657

**Status:** ‚ö†Ô∏è D√âSACTIV√â TEMPORAIREMENT

---

---

### Probl√®me 6: Erreur checksum duplicate en √©criture (DEBUG)

**Erreur:**
```
ValueError: Version avec checksum 72740a5ab5d81bd0eb53006fe49fe9f1b3ea01b34512f55e5a2715bd405fe062 existe d√©j√† (duplicata)
```

**Cause:**
- V√©rification duplicate en LECTURE d√©sactiv√©e (pptx_pipeline.py)
- MAIS v√©rification duplicate en √âCRITURE toujours active (document_registry_service.py)
- R√©sultat : Le document passe la lecture mais √©choue √† l'√©criture

**Solution:** `document_registry_service.py:365-371`

D√©sactiv√© la v√©rification en √©criture aussi :
```python
# AVANT
existing = self.get_version_by_checksum(version.checksum)
if existing:
    raise ValueError(f"Version avec checksum {version.checksum} existe d√©j√† (duplicata)")

# APR√àS (DEBUG MODE)
# existing = self.get_version_by_checksum(version.checksum)
# if existing:
#     raise ValueError(f"Version avec checksum {version.checksum} existe d√©j√† (duplicata)")
# DEBUG: Skip duplicate check - always create new version
pass
```

**Status:** ‚úÖ CORRIG√â

---

### Probl√®me 7: Warning Neo4j SUPERSEDES

**Warning dans logs:**
```
WARNING:neo4j.notifications: relationship type `SUPERSEDES` does not exist
```

**Cause:**
- Requ√™tes Neo4j utilisent `OPTIONAL MATCH` sur relation `SUPERSEDES`
- Cette relation n'existe pas encore dans la base (pas de versions superseded)
- Neo4j g√©n√®re un warning (pas bloquant mais polluant les logs)

**Solution:** `document_registry_service.py:482-490, 541-549`

Simplifi√© les requ√™tes pour √©viter SUPERSEDES en mode DEBUG :
```python
# AVANT
query = """
MATCH (v:DocumentVersion {checksum: $checksum})
OPTIONAL MATCH (v)-[:SUPERSEDES]->(prev:DocumentVersion)
OPTIONAL MATCH (next:DocumentVersion)-[:SUPERSEDES]->(v)
RETURN v, prev.version_id as supersedes_version_id, next.version_id as superseded_by_version_id
"""

# APR√àS (DEBUG MODE)
query = """
MATCH (v:DocumentVersion {checksum: $checksum})
RETURN v, null as supersedes_version_id, null as superseded_by_version_id
"""
```

**Fichiers modifi√©s:**
- `_get_version_by_checksum_tx()` - Ligne 480
- `_get_latest_version_tx()` - Ligne 539

**Impact:** Plus de warnings Neo4j dans les logs

**Status:** ‚úÖ CORRIG√â

---

---

### Probl√®me 8: Import qdrant_client incorrect (CRITIQUE)

**Erreur:**
```
ModuleNotFoundError: No module named 'knowbase.common.qdrant_client'
```

**Cause:**
- Import incorrect dans `osmose_integration.py`: `from knowbase.common.qdrant_client import get_qdrant_client`
- Le bon chemin est: `knowbase.common.clients.qdrant_client` (sous-r√©pertoire `clients/`)

**Solution:** `osmose_integration.py:31`

Corrig√© l'import :
```python
# AVANT
from knowbase.common.qdrant_client import get_qdrant_client

# APR√àS
from knowbase.common.clients.qdrant_client import get_qdrant_client
```

**Status:** ‚úÖ CORRIG√â

---

---

### Probl√®me 9: Settings.get() n'existe pas (CRITIQUE)

**Erreur:**
```
AttributeError: 'Settings' object has no attribute 'get'
```

**Cause:**
- `OsmoseIntegrationConfig.from_env()` utilise `settings.get("KEY", default)`
- Mais `Settings` est un objet Pydantic `BaseSettings`, pas un dict
- Pydantic n'a pas de m√©thode `.get()`

**Solution:** `osmose_integration.py:67-81`

Remplac√© `.get()` par `getattr()` :
```python
# AVANT
enable_osmose=settings.get("ENABLE_OSMOSE_PIPELINE", True)

# APR√àS
enable_osmose=getattr(settings, "enable_osmose_pipeline", True)
```

**Status:** ‚úÖ CORRIG√â

---

## üõ°Ô∏è NOUVEAU: Script de Validation (√âconomise les Appels LLM)

**Probl√®me:** Chaque test PPTX co√ªte des dizaines d'appels LLM Vision (cher !). Si une d√©pendance manque, c'est d√©couvert APR√àS les appels.

**Solution:** `src/knowbase/ingestion/validate_osmose_deps.py`

**Script de validation qui teste AVANT l'import:**
1. ‚úÖ Imports Python (semantic, osmose_integration, etc.)
2. ‚úÖ spaCy + mod√®les NER
3. ‚úÖ Connexion Neo4j
4. ‚úÖ Connexion Qdrant + collection concepts_proto
5. ‚úÖ Configuration LLM (API keys)
6. ‚úÖ Configuration OSMOSE

**Usage:**
```bash
# EX√âCUTER AVANT CHAQUE IMPORT PPTX
docker-compose exec app python -m knowbase.ingestion.validate_osmose_deps

# Si tout est OK (exit code 0):
‚úÖ Vous pouvez lancer un import PPTX en toute s√©curit√©

# Si erreur (exit code 1):
‚ùå NE PAS LANCER D'IMPORT - Corrigez d'abord
```

**B√©n√©fice:** √âconomise des appels LLM Vision en d√©tectant les erreurs AVANT de traiter les slides.

---

**Version:** 1.5
**Date:** 2025-10-14 22:10
**Status:** ‚úÖ PR√äT POUR VALIDATION PUIS TEST

**Modifications DEBUG MODE actives:**
1. ‚úÖ Duplicate detection d√©sactiv√©e (lecture + √©criture)
2. ‚úÖ Requ√™tes Neo4j simplifi√©es (pas de SUPERSEDES)
3. ‚úÖ Vision retourne prose (pas JSON)
4. ‚úÖ Logs Vision complets affich√©s
5. ‚úÖ Import qdrant_client corrig√©
6. ‚úÖ Settings.get() ‚Üí getattr()
7. ‚úÖ Script validation d√©pendances cr√©√©
8. ‚ö†Ô∏è √Ä r√©activer en production

---

### Probl√®me 10: Mod√®les spaCy non install√©s automatiquement

**Probl√®me:**
- spaCy install√© mais mod√®les NER absents apr√®s rebuild
- N√©cessitait installation manuelle: `python -m spacy download en_core_web_sm`
- √Ä refaire √† chaque rebuild

**Solution:** `app/Dockerfile:56-59`

Ajout√© installation automatique mod√®les spaCy :
```dockerfile
# T√©l√©chargement mod√®les spaCy pour OSMOSE (Phase 1 V2.1)
RUN python -m spacy download en_core_web_sm || echo "spaCy en model download failed"
RUN python -m spacy download fr_core_news_sm || echo "spaCy fr model download failed"
```

**Mod√®les install√©s:**
- `en_core_web_sm` : Anglais (12 MB)
- `fr_core_news_sm` : Fran√ßais (15 MB)

**Impact:** +27 MB image Docker, mais installation automatique permanente

**Status:** ‚úÖ CORRIG√â - N√©cessite rebuild

---

**IMPORTANT AVANT TEST PPTX:**

```bash
# 1. Rebuild Docker (si pas d√©j√† fait)
docker-compose down
docker-compose build app worker
docker-compose up -d

# 2. Valider d√©pendances (√©vite appels LLM inutiles)
docker-compose exec app python -m knowbase.ingestion.validate_osmose_deps

# Attendu: 6/6 ‚úÖ OK (y compris spaCy)

# 3. Si validation OK ‚Üí Lancer import PPTX
```

**Guide complet:** Voir `doc/ongoing/OSMOSE_PURE_REBUILD_GUIDE.md`
