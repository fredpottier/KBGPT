# Documentation Technique Exhaustive du Pipeline d'Ingestion V2

**Projet:** OSMOSE (Organic Semantic Memory Organization & Smart Extraction)
**Produit:** OSMOSIS
**Statut:** EN COURS DE R√âDACTION
**Date de cr√©ation:** 2026-01-29
**Derni√®re MAJ:** 2026-01-29
**Branche:** `pivot/stratified-pipeline-v2`

---

## 1. Introduction

### 1.1 Objet du document

Ce document constitue la **r√©f√©rence technique exhaustive** du Pipeline d'Ingestion V2 (Pipeline Stratifi√©) d'OSMOSIS. Il d√©crit, pour chaque phase du pipeline, les entrants, objectifs, m√©canismes/algorithmes retenus et sorties produites.

L'analyse croise syst√©matiquement l'impl√©mentation r√©elle avec les d√©cisions architecturales (ADR) normatives pour identifier les d√©viations et risques par phase.

### 1.2 P√©rim√®tre

Ce document couvre l'int√©gralit√© du pipeline V2, du fichier source jusqu'au graphe s√©mantique consolid√© :

- **Pass 0** ‚Äî Extraction (Docling + Vision Gating V4)
- **Pass 0 Structural** ‚Äî Construction du graphe structurel (Document ‚Üí Section ‚Üí DocItem)
- **Pass 0.5** ‚Äî R√©solution de cor√©f√©rence linguistique
- **Pass 0.9** ‚Äî Construction de la Vue Globale (meta-document)
- **Pass 1.1** ‚Äî Analyse documentaire (Subject, Structure, Themes)
- **Pass 1.2** ‚Äî Identification des concepts frugaux
- **Pass 1.3** ‚Äî Extraction d'assertions typ√©es
- **Pass 1.3b** ‚Äî R√©solution d'ancrage (chunk ‚Üí DocItem)
- **Pass 1.4** ‚Äî Promotion (Assertion ‚Üí Information) + Value Contract + ClaimKey
- **Pass 2** ‚Äî Enrichissement s√©mantique (relations inter-concepts)
- **Pass 3** ‚Äî Consolidation corpus (entity resolution cross-document)

### 1.3 Hors p√©rim√®tre

- Code du pipeline legacy (V1)
- Documentation frontend / UI V2
- Documentation des API endpoints V2
- Correction des d√©viations identifi√©es (seulement documentation)

### 1.4 Conventions

| Convention | Signification |
|------------|---------------|
| ‚úÖ | Conforme √† l'ADR/ARCH de r√©f√©rence |
| ‚ö†Ô∏è | Partiellement conforme ou d√©viation mineure |
| ‚ùå | Non conforme ou non impl√©ment√© |
| üî¥ | Risque critique |
| üü° | Risque mod√©r√© |
| üü¢ | Risque faible ou ma√Ætris√© |

---

## 2. R√©f√©rences normatives

Cette section synth√©tise les axes de v√©rification extraits des 8 documents ADR/ARCH normatifs. Ces axes sont appliqu√©s syst√©matiquement √† chaque phase du pipeline.

### 2.1 ADR North Star ‚Äî V√©rit√© Documentaire Contextualis√©e

**Document source :** `doc/ongoing/ADR_NORTH_STAR_VERITE_DOCUMENTAIRE.md`
**Statut :** ‚úÖ VALID√â COMME NORTH STAR

**Principe fondateur :**

> OSMOSIS est le Knowledge Graph documentaire de l'entreprise et l'arbitre de sa v√©rit√© documentaire : il capture, structure et expose la connaissance telle qu'elle est exprim√©e dans le corpus documentaire, sans jamais extrapoler au-del√† de ce corpus.

**10 axes de v√©rification North Star :**

| # | Axe | Description | Amendement |
|---|-----|-------------|------------|
| NS-1 | **Information-First** | L'Information est l'entit√© primaire, le Concept est optionnel. Z√©ro rejet pour `no_concept_match`. | Amdt 1 r√©vis√© |
| NS-2 | **LLM = Extracteur evidence-locked** | Le LLM extrait, il ne d√©cide pas, n'inf√®re pas, ne r√©sout pas les contradictions. | Amdt 4 |
| NS-3 | **Citation exacte obligatoire** | Toute Information doit inclure `exact_quote` (verbatim) + `span` (page, paragraphe, ligne). | Amdt 4 |
| NS-4 | **Pas de synth√®se cross-source** | Une Information = un document source. Pas de fusion multi-documents dans une Information. | Amdt 4 |
| NS-5 | **ClaimKey comme pivot** | Question factuelle canonique, ind√©pendante du wording, pour comparaison cross-doc. Inf√©rence en 2 niveaux (patterns + LLM assist√©). | Amdt 3 + 5d |
| NS-6 | **Value Contract** | Extraction de valeurs normalis√©es (`raw`, `normalized`, `unit`, `operator`) pour comparaison machine. Statut `comparable: strict\|loose\|non_comparable`. | Amdt 5 |
| NS-7 | **Addressability-First** | Toute Information PROMOTED doit avoir ‚â•1 pivot navigable (Concept, Theme, ClaimKey, SectionPath, Facet). Orphelin total interdit. | Amdt 1 r√©vis√© |
| NS-8 | **Rhetorical Role** | Distinction fait/exemple/analogie/d√©finition/instruction/claim/caution. Exemples et analogies ne g√©n√®rent pas de ClaimKey comparatif. | Amdt 6 |
| NS-9 | **Promotion Policy par type** | ALWAYS (DEFINITIONAL, PRESCRIPTIVE, CAUSAL), CONDITIONAL (FACTUAL, CONDITIONAL, PERMISSIVE), RARELY (COMPARATIVE), NEVER (PROCEDURAL). | ¬ß4 |
| NS-10 | **D√©duplication par fingerprint** | `hash(claimkey + value.normalized + context_key + span_bucket)`. M√™me fait r√©p√©t√© = merge evidence, pas 2 nodes. | Amdt 5c |

### 2.2 ADR Pass 0.9 ‚Äî Global View Construction

**Document source :** `doc/ongoing/ADR_PASS09_GLOBAL_VIEW_CONSTRUCTION.md`
**Statut :** R√©f√©renc√© dans le plan d'impl√©mentation (fichier absent du worktree actuel ‚Äî axes extraits depuis ARCH V2 et spec)

**6 axes de v√©rification Pass 0.9 :**

| # | Axe | Description |
|---|-----|-------------|
| P09-1 | **Couverture 100% sections** | Le meta-document doit couvrir toutes les sections du document source |
| P09-2 | **Compression hi√©rarchique** | Pr√©servation de la structure H1 > H2 > H3 dans la compression |
| P09-3 | **Meta-document 15-25K chars** | Taille cible pour tenir dans le contexte LLM des passes suivantes |
| P09-4 | **95% minimum sections r√©sum√©es** | Seuil de couverture minimale acceptable |
| P09-5 | **Fallback mode (Option C)** | Mode d√©grad√© op√©rationnel si r√©sum√© √©choue |
| P09-6 | **Int√©gration dans Pass 1.1 et 1.2** | Le meta-document alimente l'analyse documentaire et l'identification de concepts |

### 2.3 ARCH Stratified Pipeline V2

**Document source :** `doc/ongoing/ARCH_STRATIFIED_PIPELINE_V2.md`
**Statut :** EN CONCEPTION (valid√© par POC)

**Principes fondateurs :**
1. **Frugalit√©** ‚Äî Moins de nodes, plus de valeur par node (~195 nodes/doc vs ~4700 legacy)
2. **Top-Down** ‚Äî Structure ‚Üí Concepts ‚Üí Informations (inversion du flux V1 bottom-up)
3. **Promotion Policy** ‚Äî Seules les assertions d√©fendables deviennent Information
4. **Overlay** ‚Äî Information = pointeur vers source, pas copie
5. **Ind√©pendance** ‚Äî Pipeline V2 coexiste avec legacy jusqu'√† validation

**10 axes de v√©rification ARCH V2 :**

| # | Axe | Description |
|---|-----|-------------|
| AV2-1 | **S√©paration structure documentaire / s√©mantique** | Structure documentaire (Document, Section, DocItem) ‚â† Structure s√©mantique (Subject, Theme, Concept, Information) |
| AV2-2 | **8 types de nodes maximum** | Document, Section, DocItem, Subject, Theme, Concept, Information, AssertionLog |
| AV2-3 | **Ancrage Information sur DocItem** | Information `-[:ANCHORED_IN]->` DocItem. PAS sur chunk Qdrant. |
| AV2-4 | **DocItem atomique** | DocItem = item Docling natif (paragraph, table-row, list-item, heading, figure-caption). Pas de fusion agressive. |
| AV2-5 | **AssertionLog avec statut enum** | `PROMOTED \| ABSTAINED \| REJECTED` avec `AssertionLogReason` standardis√© (10+ raisons) |
| AV2-6 | **Frugalit√© concepts (5-15 max)** | Garde-fou max 15 concepts par document, refus termes g√©n√©riques et mentions uniques |
| AV2-7 | **Top-down** | Document Analysis (1.1) ‚Üí Concept Identification (1.2) ‚Üí Assertion Extraction (1.3) ‚Üí Linking (1.4) |
| AV2-8 | **Dual storage** | Neo4j (graphe s√©mantique navigable) + Qdrant (TypeAwareChunks retrieval vectoriel) |
| AV2-9 | **Pass 3 mode manuel + batch** | R√©solution d'entit√©s en mode batch ou incr√©mental, pas automatique inline |
| AV2-10 | **< 250 nodes/document** | Estimation ~195 nodes/doc, soit ~4% du legacy |

### 2.4 ADR compl√©mentaires

#### 2.4.1 ADR Mod√®le de Lecture Stratifi√©e

**Document source :** `doc/ongoing/ADR_STRATIFIED_READING_MODEL.md`

Formalise l'inversion du flux V1 ‚Üí V2 (bottom-up ‚Üí top-down). D√©finit les 3 structures universelles de d√©pendance des assertions :

| Structure | D√©finition | Test |
|-----------|------------|------|
| **CENTRAL** | Assertions d√©pendantes d'un artefact unique | "Sans X, ce document a-t-il un sens ?" ‚Üí NON |
| **TRANSVERSAL** | Assertions ind√©pendantes | Remplacer le nom propre ‚Üí assertion reste vraie |
| **CONTEXTUAL** | Assertions conditionnelles | Vraies uniquement sous certaines conditions |

D√©finit les crit√®res de cr√©ation de ConceptSitu√© : ‚â•3 informations distinctes, ‚â•2 types diff√©rents, ‚â•2 sections/sous-th√®mes.

#### 2.4.2 ADR Scope vs Assertion Separation

**Document source :** `doc/ongoing/ADR_SCOPE_VS_ASSERTION_SEPARATION.md`
**Statut :** ‚úÖ APPROVED ‚Äî ARCHITECTURAL FOUNDATION ‚Äî BLOCKING

S√©paration fondamentale entre :
- **Scope Layer** (dense) : Ce que le document couvre ‚Üí Navigation, non traversable
- **Assertion Layer** (sparse) : Ce que le document affirme ‚Üí Raisonnement, traversable

Le Scope mining est un filtre de candidats, pas un g√©n√©rateur d'assertions. Le contexte documentaire (titre, section) ne constitue pas une preuve locale.

#### 2.4.3 ADR Relations Discursivement D√©termin√©es

**Document source :** `doc/ongoing/ADR_DISCURSIVE_RELATIONS.md`
**Statut :** ACCEPTED

Extension pour les relations reconstructibles par un lecteur rigoureux sans connaissance externe :
- `AssertionKind` : EXPLICIT / DISCURSIVE
- `DiscursiveBasis` : ALTERNATIVE, DEFAULT, EXCEPTION, SCOPE, COREF, ENUMERATION
- Whitelist stricte des `RelationType` autoris√©s pour DISCURSIVE (V1)
- Promotion via `DefensibilityTier` : STRICT / EXTENDED

#### 2.4.4 ADR NormativeRule & SpecFact

**Document source :** `doc/ongoing/ADR_NORMATIVE_RULES_SPEC_FACTS.md`
**Statut :** ‚úÖ APPROVED ‚Äî V1

Capture des informations "high-value" non-relationnelles :
- **NormativeRule** : obligations/interdictions avec marqueur modal (MUST, SHOULD, MAY)
- **SpecFact** : valeurs structur√©es issues de tables/listes cl√©-valeur

Extraction pattern-first, preuve locale obligatoire, non-traversable, scope-only applicability.

---

## 3. Table des mati√®res d√©taill√©e

- [1. Introduction](#1-introduction)
- [2. R√©f√©rences normatives](#2-r√©f√©rences-normatives)
  - [2.1 ADR North Star](#21-adr-north-star--v√©rit√©-documentaire-contextualis√©e)
  - [2.2 ADR Pass 0.9](#22-adr-pass-09--global-view-construction)
  - [2.3 ARCH Stratified Pipeline V2](#23-arch-stratified-pipeline-v2)
  - [2.4 ADR compl√©mentaires](#24-adr-compl√©mentaires)
- [4. Vue d'ensemble du Pipeline V2](#4-vue-densemble-du-pipeline-v2)
- [5. Pass 0 ‚Äî Extraction](#5-pass-0--extraction)
  - [5.1 Docling Extraction](#51-docling-extraction)
  - [5.2 Vision Gating V4](#52-vision-gating-v4)
  - [5.3 Vision Path (GPT-4o)](#53-vision-path-gpt-4o)
  - [5.4 Structured Merge](#54-structured-merge)
  - [5.5 Lin√©arisation](#55-lin√©arisation)
  - [5.6 Extraction de Contexte Documentaire](#56-extraction-de-contexte-documentaire)
  - [5.7 Table Summarizer](#57-table-summarizer)
  - [5.8 Cache Versionn√©](#58-cache-versionn√©)
  - [5.9 Conformit√© ADR ‚Äî Pass 0 Extraction](#59-conformit√©-adr--pass-0-extraction)
  - [5.10 Risques ‚Äî Pass 0 Extraction](#510-risques--pass-0-extraction)
- [6. Pass 0 Structural ‚Äî Graphe Structurel](#6-pass-0-structural--graphe-structurel)
  - [6.1 Adapter Docling ‚Üí Schema V2](#61-adapter-docling--schema-v2)
  - [6.2 Construction du graphe (Document, Section, DocItem)](#62-construction-du-graphe-document-section-docitem)
  - [6.3 Conformit√© ADR ‚Äî Pass 0 Structural](#63-conformit√©-adr--pass-0-structural)
  - [6.4 Risques ‚Äî Pass 0 Structural](#64-risques--pass-0-structural)
- [7. Pass 0.5 ‚Äî R√©solution de Cor√©f√©rence Linguistique](#7-pass-05--r√©solution-de-cor√©f√©rence-linguistique)
  - [7.0 Vue d'ensemble Pass 0.5](#70-vue-densemble-pass-05)
  - [7.1 M√©canismes de r√©solution](#71-m√©canismes-de-r√©solution)
  - [7.2 Conformit√© ADR ‚Äî Pass 0.5](#72-conformit√©-adr--pass-05)
  - [7.3 Risques ‚Äî Pass 0.5](#73-risques--pass-05)
- [8. Pass 0.9 ‚Äî Construction de la Vue Globale](#8-pass-09--construction-de-la-vue-globale)
  - [8.1 SectionSummarizer](#81-sectionsummarizer)
  - [8.2 HierarchicalCompressor](#82-hierarchicalcompressor)
  - [8.3 GlobalView (meta-document)](#83-globalview-meta-document)
  - [8.4 Conformit√© ADR ‚Äî Pass 0.9](#84-conformit√©-adr--pass-09)
  - [8.5 Risques ‚Äî Pass 0.9](#85-risques--pass-09)
- [9. Pass 1.1 ‚Äî Analyse Documentaire](#9-pass-11--analyse-documentaire)
  - [9.1 D√©tection de structure (CENTRAL/TRANSVERSAL/CONTEXTUAL)](#91-d√©tection-de-structure)
  - [9.2 Identification Subject et Themes](#92-identification-subject-et-themes)
  - [9.3 Conformit√© ADR ‚Äî Pass 1.1](#93-conformit√©-adr--pass-11)
  - [9.4 Risques ‚Äî Pass 1.1](#94-risques--pass-11)
- [10. Pass 1.2 ‚Äî Identification des Concepts](#10-pass-12--identification-des-concepts)
  - [10.1 Extraction LLM de concepts frugaux](#101-extraction-llm-de-concepts-frugaux)
  - [10.2 Concept Refinement (Pass 1.2b)](#102-concept-refinement-pass-12b)
  - [10.3 Trigger Enrichment TF-IDF + Embedding (Pass 1.2c)](#103-trigger-enrichment-tf-idf--embedding-pass-12c)
  - [10.4 SINK Concept Injection (Pass 1.2d)](#104-sink-concept-injection-pass-12d)
  - [10.5 Conformit√© ADR ‚Äî Pass 1.2](#105-conformit√©-adr--pass-12)
  - [10.6 Risques ‚Äî Pass 1.2](#106-risques--pass-12)
- [11. Pass 1.3 ‚Äî Extraction d'Assertions](#11-pass-13--extraction-dassertions)
  - [11.1 Mode pointeur et extraction par chunk](#111-mode-pointeur-et-extraction-par-chunk)
  - [11.2 Validation verbatim](#112-validation-verbatim)
  - [11.3 Indexation des unit√©s d'assertion](#113-indexation-des-unit√©s-dassertion)
  - [11.4 Conformit√© ADR ‚Äî Pass 1.3](#114-conformit√©-adr--pass-13)
  - [11.5 Risques ‚Äî Pass 1.3](#115-risques--pass-13)
- [12. Pass 1.3b ‚Äî R√©solution d'Ancrage](#12-pass-13b--r√©solution-dancrage)
  - [12.1 Mapping chunk_id ‚Üí docitem_id](#121-mapping-chunk_id--docitem_id)
  - [12.2 Conformit√© ADR ‚Äî Pass 1.3b](#122-conformit√©-adr--pass-13b)
  - [12.3 Risques ‚Äî Pass 1.3b](#123-risques--pass-13b)
- [13. Pass 1.4 ‚Äî Promotion et Value Contract](#13-pass-14--promotion-et-value-contract)
  - [13.1 Promotion Engine (Assertion ‚Üí Information)](#131-promotion-engine-assertion--information)
  - [13.2 Promotion Policy par type d'assertion](#132-promotion-policy-par-type-dassertion)
  - [13.3 Value Extractor (Value Contract)](#133-value-extractor-value-contract)
  - [13.4 ClaimKey ‚Äî Patterns et gestion de statut](#134-claimkey--patterns-et-gestion-de-statut)
  - [13.5 AssertionLog et gouvernance](#135-assertionlog-et-gouvernance)
  - [13.6 Theme Lint (gouvernance th√©matique)](#136-theme-lint-gouvernance-th√©matique)
  - [13.7 Conformit√© ADR ‚Äî Pass 1.4](#137-conformit√©-adr--pass-14)
  - [13.8 Risques ‚Äî Pass 1.4](#138-risques--pass-14)
- [14. Pass 2 ‚Äî Enrichissement S√©mantique](#14-pass-2--enrichissement-s√©mantique)
  - [14.1 Extraction de relations inter-concepts](#141-extraction-de-relations-inter-concepts)
  - [14.2 Types de relations et garde-fous](#142-types-de-relations-et-garde-fous)
  - [14.3 Conformit√© ADR ‚Äî Pass 2](#143-conformit√©-adr--pass-2)
  - [14.4 Risques ‚Äî Pass 2](#144-risques--pass-2)
- [15. Pass 3 ‚Äî Consolidation Corpus](#15-pass-3--consolidation-corpus)
  - [15.1 Entity Resolution (embedding + clustering)](#151-entity-resolution-embedding--clustering)
  - [15.2 Theme Alignment cross-document](#152-theme-alignment-cross-document)
  - [15.3 D√©tection de contradictions](#153-d√©tection-de-contradictions)
  - [15.4 Modes batch et incr√©mental](#154-modes-batch-et-incr√©mental)
  - [15.5 Conformit√© ADR ‚Äî Pass 3](#155-conformit√©-adr--pass-3)
  - [15.6 Risques ‚Äî Pass 3](#156-risques--pass-3)
- [16. Orchestration Pipeline](#16-orchestration-pipeline)
  - [16.1 S√©quencement global (watcher ‚Üí dispatcher ‚Üí pipeline)](#161-s√©quencement-global)
  - [16.2 Feature flag routing V1/V2](#162-feature-flag-routing-v1v2)
  - [16.3 Burst Mode](#163-burst-mode)
  - [16.4 Conformit√© ADR ‚Äî Orchestration](#164-conformit√©-adr--orchestration)
- [17. Mod√®le de donn√©es complet](#17-mod√®le-de-donn√©es-complet)
  - [17.1 Hi√©rarchie des 8 types de nodes](#171-hi√©rarchie-des-8-types-de-nodes)
  - [17.2 Sch√©ma Neo4j V2](#172-sch√©ma-neo4j-v2)
  - [17.3 Dual Storage (Neo4j + Qdrant)](#173-dual-storage-neo4j--qdrant)
- [18. Synth√®se globale des risques](#18-synth√®se-globale-des-risques)
  - [18.1 Risques critiques (üî¥)](#181-risques-critiques-)
  - [18.2 Risques mod√©r√©s (üü°)](#182-risques-mod√©r√©s-)
  - [18.3 Risques faibles (üü¢)](#183-risques-faibles-)
  - [18.4 Matrice de priorisation](#184-matrice-de-priorisation)
- [19. Diagramme d'architecture global](#19-diagramme-darchitecture-global)
- [20. Conclusion](#20-conclusion)

---

## 4. Vue d'ensemble du Pipeline V2

<!-- √Ä compl√©ter : diagramme ASCII du flux global Pass 0 ‚Üí 0.5 ‚Üí 0.9 ‚Üí 1.x ‚Üí 2 ‚Üí 3 -->

---

## 5. Pass 0 ‚Äî Extraction

### 5.0 Vue d'ensemble Pass 0

**Fichier orchestrateur :** `src/knowbase/extraction_v2/pipeline.py` ‚Äî classe `ExtractionPipelineV2`

**Objectif :** Transformer un fichier source (PDF, DOCX, PPTX, XLSX, Image) en un `ExtractionResult` structur√© contenant :
- `full_text` lin√©aris√© avec marqueurs s√©mantiques (pour les passes suivantes)
- `structure` compl√®te (pages, blocs, tables, enrichissements Vision)
- `doc_context` (DocContextFrame ‚Äî marqueurs de version, scope documentaire)
- `page_index` (mapping offsets ‚Üí pages pour tra√ßabilit√©)
- `gating_decisions` et `vision_results` (audit du path Vision)

**Entrants :**

| Entrant | Type | Description |
|---------|------|-------------|
| `file_path` | `str` | Chemin vers le fichier source |
| `document_id` | `str` (optionnel) | ID unique du document (g√©n√©r√© via SHA256 si absent) |
| `tenant_id` | `str` (optionnel) | Tenant pour Domain Context (d√©faut : `"default"`) |

**S√©quence d'ex√©cution (8 √©tapes) :**

```
√âtape 1: Cache Check (VersionedCache)
  ‚Üì miss
√âtape 2: Extraction Docling ‚Üí List[VisionUnit]
  ‚Üì
√âtape 3: Vision Gating V4 ‚Üí List[GatingDecision]
  ‚Üì
√âtape 4: Vision Path GPT-4o (parall√®le, semaphore) ‚Üí Dict[int, VisionExtraction]
  ‚Üì
√âtape 4.5: Vision Semantic Reader (parall√®le) ‚Üí Dict[int, VisionSemanticResult]
  ‚Üì
√âtape 5: Structured Merge ‚Üí List[MergedPageOutput]
  ‚Üì
√âtape 5.5: Table Summaries (QW-1, batch) ‚Üí summaries attach√©es aux TableData
  ‚Üì
√âtape 6: Lin√©arisation ‚Üí (full_text, page_index)
  ‚Üì
√âtape 7: DocContext Extraction (6a: DocumentContext + 6b: DocContextFrame)
  ‚Üì
√âtape 8: Structural Graph (Option C) ‚Üí StructuralGraphBuildResult
  ‚Üì
√âtape 8.25: Enrichissement FIGURE_TEXT avec Vision Semantic
  ‚Üì
√âtape 8.5: Pass 0.5 Linguistic Coref (si non-V2)
  ‚Üì
Construction ExtractionResult + Cache Save
```

**Configuration :** `PipelineConfig` (dataclass avec ~20 param√®tres) ‚Äî tous les composants sont activables/d√©sactivables via flags bool√©ens.

**M√©triques :** `PipelineMetrics` (dataclass) ‚Äî temps par √©tape, compteurs de pages, taux de succ√®s Vision, etc.

---

### 5.1 Docling Extraction

**Fichier :** `src/knowbase/extraction_v2/extractors/docling_extractor.py` ‚Äî classe `DoclingExtractor`

**Objectif :** Convertir tout fichier source en une liste normalis√©e de `VisionUnit` (une par page/slide) via la biblioth√®que Docling (>= 2.14.0).

#### 5.1.1 Formats support√©s

| Extension | Format interne | Dimensions par d√©faut |
|-----------|---------------|----------------------|
| `.pdf` | PDF | 612 √ó 792 (Letter, en points) |
| `.docx` | DOCX | 612 √ó 792 |
| `.pptx` | PPTX | 960 √ó 540 (16:9 HD) |
| `.xlsx` | XLSX | 612 √ó 792 |
| `.html` | HTML | 612 √ó 792 |
| `.md` | Markdown | 612 √ó 792 |
| `.png`, `.jpg`, `.jpeg`, `.tiff`, `.bmp`, `.webp` | Image | 1920 √ó 1080 (HD) |

#### 5.1.2 Configuration Docling

```python
DoclingExtractor(
    ocr_enabled=True,       # OCR activ√© pour images/scans
    table_mode="accurate",  # Extraction pr√©cise des tables
    image_resolution_scale=2.0  # Facteur de r√©solution images
)
```

Le pipeline PDF utilise `PyPdfiumDocumentBackend` avec `PdfPipelineOptions(do_ocr=True, do_table_structure=True)`.

#### 5.1.3 M√©canisme d'extraction

1. **D√©tection format** : Extension ‚Üí format interne via `SUPPORTED_FORMATS`
2. **Conversion Docling** : `self._converter.convert(path)` ‚Üí `DoclingResult`
3. **It√©ration pages** : Parcours du dict `doc.pages` (cl√©s 1-indexed dans Docling ‚â• 2.66)
4. **Pour chaque page**, extraction de :

| Composant | M√©thode | Sortie |
|-----------|---------|--------|
| Blocs de texte | `_extract_text_blocks()` | `List[TextBlock]` ‚Äî type (paragraph, heading, list_item, caption), bbox, level |
| Tables | `_extract_tables()` | `List[TableData]` ‚Äî headers, cells, bbox, num_rows/cols, `is_structured=True` |
| √âl√©ments visuels | `_extract_visual_elements()` | `List[VisualElement]` ‚Äî kind="raster_image", bbox (via `doc.pictures`) |
| Titre de page | `_detect_title()` | Premier heading de level ‚â§ 2 (limit√© √† 200 chars) |

5. **Construction VisionUnit** : Chaque page produit un objet `VisionUnit(id, format, index, dimensions, blocks, tables, visual_elements, title)`

#### 5.1.4 Variante `extract_to_units_with_docling()`

Retourne aussi le `DoclingDocument` brut, n√©cessaire pour le Structural Graph Builder (Option C) qui acc√®de √† la structure native Docling sans re-parser.

#### 5.1.5 Sortie

```
List[VisionUnit] ‚Äî une VisionUnit par page/slide
  ‚îú‚îÄ‚îÄ id: "PDF_PAGE_0", "PPTX_PAGE_5"...
  ‚îú‚îÄ‚îÄ format: "PDF", "PPTX"...
  ‚îú‚îÄ‚îÄ index: 0, 1, 2... (0-based)
  ‚îú‚îÄ‚îÄ dimensions: (width, height)
  ‚îú‚îÄ‚îÄ blocks: List[TextBlock]
  ‚îú‚îÄ‚îÄ tables: List[TableData]
  ‚îú‚îÄ‚îÄ visual_elements: List[VisualElement]
  ‚îî‚îÄ‚îÄ title: Optional[str]
```

---

### 5.2 Vision Gating V4

**Fichiers :** `src/knowbase/extraction_v2/gating/engine.py`, `signals.py`, `weights.py`
**Classe principale :** `GatingEngine`
**Sp√©cification :** `VISION_GATING_V4_SPEC.md`

**Objectif :** D√©cider, pour chaque page/slide, si l'analyse Vision (GPT-4o) est n√©cessaire, recommand√©e, ou inutile. Ceci optimise les co√ªts en √©vitant les appels Vision sur des pages purement textuelles.

#### 5.2.1 Les 5 signaux

Le syst√®me calcule 5 signaux ind√©pendants, chacun entre 0.0 et 1.0 :

| Signal | Nom complet | Ce qu'il d√©tecte | Formule | Poids |
|--------|------------|-------------------|---------|-------|
| **RIS** | Raster Image Signal | Images raster significatives | `largest_image_ratio ‚â• 0.30 ‚Üí 1.0`, `‚â• 0.20 ‚Üí 0.7`, `‚â• 0.10 ‚Üí 0.4`, sinon 0.0 | **0.30** |
| **VDS** | Vector Drawing Signal | Shapes vectoriels, connecteurs | `connectors ‚â• 3 OU drawing_area ‚â• 35% ‚Üí 1.0`, `drawings ‚â• 15 ‚Üí 0.7`, `‚â• 8 ‚Üí 0.4` | **0.30** |
| **TFS** | Text Fragmentation Signal | Fragmentation texte (indicateur diagramme) | `short_ratio ‚â• 0.75 ET blocks ‚â• 12 ‚Üí 1.0`, `ratio ‚â• 0.60 ‚Üí 0.6` (short = < 200 chars) | **0.15** |
| **SDS** | Spatial Dispersion Signal | Dispersion spatiale du texte | `variance ‚â• 0.08 ‚Üí 1.0`, `‚â• 0.04 ‚Üí 0.5` (variance des centres normalis√©s x+y) | **0.15** |
| **VTS** | Visual Table Signal | Pseudo-tables non structur√©es | `H_lines ‚â• 3 ET V_lines ‚â• 2 ‚Üí 1.0`, ou text grid pattern. `0.0 si table structur√©e d√©j√† d√©tect√©e` | **0.10** |

**Calcul d√©taill√© de chaque signal :**

- **RIS** (`compute_raster_image_signal`) : Filtre les `VisualElement` de kind `"raster_image"`, calcule le ratio surface_image/surface_page pour la plus grande image. Seuils par paliers : `RIS_THRESHOLD_HIGH=0.30`, `MEDIUM=0.20`, `LOW=0.10`.

- **VDS** (`compute_vector_drawing_signal`) : Compte les connecteurs (kind in `connector, line, arrow`), les shapes (kind in `vector_shape, drawing, rectangle, oval, shape`), et le ratio de surface cumul√©e. Seuils : `VDS_CONNECTOR_THRESHOLD=3`, `VDS_AREA_THRESHOLD=0.35`, `VDS_DRAWINGS_HIGH=15`, `VDS_DRAWINGS_MEDIUM=8`.

- **TFS** (`compute_text_fragmentation_signal`) : Compte les blocs de texte < 200 caract√®res. Si ratio court ‚â• 75% avec ‚â• 12 blocs ‚Üí signal maximal (indique un diagramme avec labels). Seuils : `TFS_SHORT_CHAR_LIMIT=200`, `TFS_MIN_BLOCKS=12`, `TFS_HIGH_SHORT_RATIO=0.75`, `TFS_MEDIUM_SHORT_RATIO=0.60`.

- **SDS** (`compute_spatial_dispersion_signal`) : Calcule la variance des centres des blocs de texte (normalis√©s par les dimensions de la page). Minimum 3 blocs requis. Variance = var(x) + var(y). Seuils : `SDS_HIGH_VARIANCE=0.08`, `SDS_MEDIUM_VARIANCE=0.04`.

- **VTS** (`compute_visual_table_signal`) : Si des tables structur√©es existent d√©j√† ‚Üí `0.0` (pas besoin de Vision). Sinon, cherche un pattern de grille (lignes horizontales/verticales) ou un pattern de texte en grille (clustering de positions via `_find_aligned_clusters` avec tol√©rance 0.05).

#### 5.2.2 Calcul du VNS (Vision Need Score)

```
VNS = Œ£(weight_i √ó signal_i) = 0.30√óRIS + 0.30√óVDS + 0.15√óTFS + 0.15√óSDS + 0.10√óVTS
```

**Ajustement par Domain Context :** Si un `VisionDomainContext` est fourni, les poids peuvent √™tre ajust√©s de **¬±10% maximum**. Trois domaines pr√©d√©finis :

| Domaine | Ajustement |
|---------|------------|
| `SAP` | VDS=0.35 (‚Üë), RIS=0.25 (‚Üì) ‚Äî plus de diagrammes d'architecture |
| `pharmaceutical` | VTS=0.20 (‚Üë), TFS=0.10 (‚Üì) ‚Äî tables r√©glementaires complexes |
| `retail` | RIS=0.40 (‚Üë), VDS=0.20 (‚Üì) ‚Äî images marketing |

Les poids ajust√©s sont renormalis√©s pour que leur somme = 1.0.

#### 5.2.3 D√©cision de gating

| Condition | Action | Description |
|-----------|--------|-------------|
| `RIS == 1.0 OU VDS == 1.0` | `VISION_REQUIRED` | **R√®gle de s√©curit√©** ‚Äî bypass du VNS |
| `VNS ‚â• 0.60` | `VISION_REQUIRED` | Vision obligatoire |
| `0.40 ‚â§ VNS < 0.60` | `VISION_RECOMMENDED` | Vision recommand√©e (incluse par d√©faut) |
| `VNS < 0.40` | `NONE` | Pas de Vision n√©cessaire |

Le `GatingDecision` produit contient : `index`, `unit_id`, `action`, `vision_need_score`, `signals` (les 5 valeurs), et `reasons` (liste explicative textuelle).

#### 5.2.4 Seuils exp√©rimentaux

Le module `weights.py` d√©finit aussi des `EXPERIMENTAL_THRESHOLDS` (√† calibrer sur corpus r√©el en Phase 7) avec des seuils alternatifs plus agressifs pour les signaux individuels (ex : `RIS_HIGH=0.15`, `VDS_CONNECTOR_MIN=1`).

#### 5.2.5 Budget Vision

Le pipeline supporte un `vision_budget` optionnel (nombre max de pages avec Vision). Si le nombre de candidats d√©passe le budget, les pages `VISION_REQUIRED` sont prioritaires, puis `VISION_RECOMMENDED` tri√©es par VNS d√©croissant.

---

### 5.3 Vision Path (GPT-4o)

**Fichiers :** `src/knowbase/extraction_v2/vision/analyzer.py`, `semantic_reader.py`, `diagram_interpreter.py`

Le Vision Path se compose de **trois composants** aux r√¥les distincts :

#### 5.3.1 VisionAnalyzer ‚Äî Extraction structur√©e de diagrammes

**Classe :** `VisionAnalyzer`
**Mod√®le :** GPT-4o (temperature=0.0, max_tokens=4096)

**Objectif :** Extraire les √©l√©ments structurels (boxes, labels, arrows) et les relations visuelles depuis les diagrammes. Vision **OBSERVE et D√âCRIT**, ne raisonne pas.

**Principes directeurs :**
- Toute relation doit avoir une **evidence visuelle**
- Les ambigu√Øt√©s sont **d√©clar√©es**, jamais r√©solues implicitement
- Sortie JSON stricte conforme au sch√©ma `VisionExtraction`

**M√©canisme :**
1. Encode l'image en base64
2. Construit les messages via `get_vision_messages()` (prompt system + user avec image + domain context + snippets locaux)
3. Appel API Vision avec `response_format={"type": "json_object"}`
4. Parse la r√©ponse JSON ‚Üí `VisionExtraction`

**Sortie `VisionExtraction` :**
```
VisionExtraction
  ‚îú‚îÄ‚îÄ kind: str (type de diagramme)
  ‚îú‚îÄ‚îÄ elements: List[VisionElement] ‚Äî boxes, labels d√©tect√©s
  ‚îú‚îÄ‚îÄ relations: List[VisionRelation] ‚Äî fl√®ches, connexions
  ‚îú‚îÄ‚îÄ ambiguities: List[VisionAmbiguity] ‚Äî zones ambigu√´s
  ‚îú‚îÄ‚îÄ uncertainties: List[VisionUncertainty] ‚Äî incertitudes
  ‚îú‚îÄ‚îÄ page_index: int
  ‚îî‚îÄ‚îÄ confidence: float (0.0-1.0)
```

**Traitement parall√®le :** Les pages Vision sont trait√©es en parall√®le via `asyncio.gather()` avec un `asyncio.Semaphore(max_concurrent)`. La concurrence est configurable via `MAX_WORKERS` env var (d√©faut : 30). Pour les tr√®s gros documents (>400 pages), elle est r√©duite automatiquement √† 5.

**Gestion d'erreurs :** En cas d'√©chec d'un appel Vision, l'erreur est logg√©e mais le pipeline continue ‚Äî la page n'aura simplement pas d'enrichissement Vision.

#### 5.3.2 VisionSemanticReader ‚Äî Lecture s√©mantique textuelle

**Classe :** `VisionSemanticReader`
**Mod√®le :** GPT-4o (temperature=0.0, max_tokens=1024, timeout=30s)
**Spec :** `SPEC_VISION_SEMANTIC_INTEGRATION.md`

**Objectif :** Produire du **TEXTE exploitable** pour les passes suivantes (Pass 1) au lieu d'√©l√©ments g√©om√©triques. Ce texte enrichit les chunks `FIGURE_TEXT` du graphe structurel.

**Invariants :**
- **I1** : Jamais de texte vide en sortie
- **I4** : Tra√ßabilit√© origine obligatoire (`TextOrigin`)
- **I5** : Texte descriptif uniquement, pas d'assertions pr√©-promues

**Strat√©gie de fallback 3-tier :**

| Tier | M√©thode | TextOrigin r√©sultant |
|------|---------|---------------------|
| 1 | GPT-4o Vision ‚Üí texte s√©mantique | `VISION_SEMANTIC` |
| 2 | Retry (1x) si timeout/rate limit | `VISION_SEMANTIC` |
| 3 | OCR basique si Vision √©choue | `OCR` |
| 4 | Placeholder (jamais vide) | `PLACEHOLDER` |

**Prompt syst√®me :** D√©crit le contenu visuel de mani√®re FACTUELLE et OBSERVABLE (2-8 phrases), identifie entit√©s principales et relations visuelles. R√©ponse JSON : `{diagram_type, description, key_entities, confidence}`.

**Sortie `VisionSemanticResult` :**
```
VisionSemanticResult
  ‚îú‚îÄ‚îÄ page_no: int
  ‚îú‚îÄ‚îÄ semantic_text: str (jamais vide ‚Äî Invariant I1)
  ‚îú‚îÄ‚îÄ text_origin: TextOrigin (VISION_SEMANTIC | OCR | PLACEHOLDER)
  ‚îú‚îÄ‚îÄ diagram_type: Optional[str]
  ‚îú‚îÄ‚îÄ confidence: float
  ‚îú‚îÄ‚îÄ key_entities: List[str]
  ‚îú‚îÄ‚îÄ model: str
  ‚îú‚îÄ‚îÄ prompt_version: str ("v1.0")
  ‚îú‚îÄ‚îÄ image_hash: str (SHA256[:16] pour cache/replay)
  ‚îî‚îÄ‚îÄ candidate_hints: Optional[List[str]] (jamais promues ‚Äî I5)
```

#### 5.3.3 DiagramInterpreter ‚Äî Routing adaptatif LITE/FULL

**Classe :** `DiagramInterpreter`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` (QW-3)

**Objectif :** Optimiser les co√ªts Vision via un routing adaptatif bas√© sur le score VNS du gating.

**Routing :**

| Condition | M√©thode | Mod√®le | Co√ªt estim√© |
|-----------|---------|--------|-------------|
| `NONE` + TFS < 0.3 | `SKIP` | ‚Äî | 0 tokens |
| `NONE` + TFS ‚â• 0.3 | `TEXT_ONLY` | ‚Äî | 0 tokens (OCR existant) |
| `VISION_RECOMMENDED` | `VISION_LITE` | gpt-4o-mini | ~500 tokens |
| `VISION_REQUIRED` | `VISION_FULL` | gpt-4o | ~2000 tokens |

**Quality Gate :** Apr√®s extraction, si `confidence < 0.70` ‚Üí fallback vers `FALLBACK_PROSE` (r√©sum√© en prose au lieu d'√©l√©ments structur√©s).

---

### 5.4 Structured Merge

**Fichier :** `src/knowbase/extraction_v2/merge/merger.py` ‚Äî classe `StructuredMerger`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 9

**Objectif :** Fusionner les r√©sultats Docling (socle) et Vision (enrichissement) **sans √©crasement**.

#### 5.4.1 R√®gle d'or

> **Vision n'√©crase JAMAIS Docling.**

Docling fournit le **SOCLE** (blocs texte, tables structur√©es). Vision fournit l'**ENRICHISSEMENT** (√©l√©ments visuels, relations). L'enrichissement est **ATTACH√â** au socle, jamais fusionn√©.

#### 5.4.2 Strat√©gie d'attachement

1. Par `page_index` / `slide_index` (obligatoire)
2. Par bbox overlap (optionnel, pour pr√©cision)
3. Marquage explicite source : `"docling"` | `"vision"`

#### 5.4.3 M√©canisme

Pour chaque page (`merge_page()`), le merger :
1. Copie les blocs de base (Docling = socle intouchable)
2. Copie les tables de base
3. Attache l'enrichissement Vision (si disponible)
4. Attache la d√©cision de gating
5. Ajoute la provenance (version Docling, mod√®le Vision, score gating, timestamp)

Pour un document complet (`merge_document()`), construit un dict `{page_index ‚Üí GatingDecision}` et it√®re sur toutes les VisionUnits.

#### 5.4.4 Sortie

```
MergedPageOutput
  ‚îú‚îÄ‚îÄ page_index: int
  ‚îú‚îÄ‚îÄ base_blocks: List[TextBlock]     ‚Üê Docling (socle)
  ‚îú‚îÄ‚îÄ base_tables: List[TableData]     ‚Üê Docling (socle)
  ‚îú‚îÄ‚îÄ vision_enrichment: Optional[VisionExtraction]  ‚Üê Vision (attach√©)
  ‚îú‚îÄ‚îÄ gating_decision: Optional[GatingDecision]
  ‚îú‚îÄ‚îÄ provenance: MergeProvenance
  ‚îÇ     ‚îú‚îÄ‚îÄ docling_version: str
  ‚îÇ     ‚îú‚îÄ‚îÄ vision_model: Optional[str]
  ‚îÇ     ‚îú‚îÄ‚îÄ gating_score: Optional[float]
  ‚îÇ     ‚îî‚îÄ‚îÄ merge_timestamp: str
  ‚îú‚îÄ‚îÄ title: Optional[str]
  ‚îî‚îÄ‚îÄ format: str ("PDF", "PPTX"...)
```

---

### 5.5 Lin√©arisation

**Fichier :** `src/knowbase/extraction_v2/merge/linearizer.py` ‚Äî classe `Linearizer`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 1

**Objectif :** G√©n√©rer le `full_text` lin√©aris√© avec marqueurs s√©mantiques explicites. Ce `full_text` est la repr√©sentation canonique du document pour toutes les passes suivantes (Pass 0.9, 1.x).

#### 5.5.1 Grammaire des marqueurs (BNF)

```bnf
marker       ::= '[' marker_type attributes? ']'
marker_type  ::= 'PAGE' | 'TITLE' | 'PARAGRAPH' | 'TABLE_START' | 'TABLE_END'
               | 'TABLE_SUMMARY' | 'TABLE_RAW'
               | 'VISUAL_ENRICHMENT' | 'END_VISUAL_ENRICHMENT'
attributes   ::= (key '=' value)+
key          ::= [a-z_]+
value        ::= [a-zA-Z0-9_.-]+
```

#### 5.5.2 Marqueurs produits

| Marqueur | Signification | Exemple |
|----------|---------------|---------|
| `[PAGE n \| TYPE=xxx]` | D√©but de page | `[PAGE 6 \| TYPE=ARCHITECTURE_DIAGRAM]` |
| `[TITLE level=n]` | Titre (heading) | `[TITLE level=1] Target Architecture Overview` |
| `[PARAGRAPH]` | Paragraphe de contenu | `[PARAGRAPH]\nThis architecture enables...` |
| `[TABLE_START id=x]` | D√©but table (sans r√©sum√©) | `[TABLE_START id=tbl_1]` |
| `[TABLE_SUMMARY id=x]` | D√©but table avec r√©sum√© LLM (QW-1) | `[TABLE_SUMMARY id=tbl_1]` |
| `[TABLE_RAW]` | S√©parateur r√©sum√©/markdown brut | ‚Äî |
| `[TABLE_END]` | Fin de table | ‚Äî |
| `[VISUAL_ENRICHMENT id=x confidence=y]` | D√©but enrichissement Vision | `[VISUAL_ENRICHMENT id=vision_6_1 confidence=0.82]` |
| `[END_VISUAL_ENRICHMENT]` | Fin enrichissement Vision | ‚Äî |

#### 5.5.3 Algorithme de lin√©arisation

Pour chaque `MergedPageOutput` :
1. **Marqueur de page** : `[PAGE n | TYPE=xxx]` ‚Äî le type est d√©tect√© depuis l'enrichissement Vision (`kind`) ou `None`
2. **Titre** : `[TITLE level=1] ...` si pr√©sent
3. **Blocs de texte** : Chaque bloc format√© selon son type (heading ‚Üí `[TITLE]`, sinon ‚Üí `[PARAGRAPH]`)
4. **Tables** : Si r√©sum√© LLM disponible ‚Üí format enrichi `[TABLE_SUMMARY]...[TABLE_RAW]...[TABLE_END]` ; sinon ‚Üí format standard `[TABLE_START]...[TABLE_END]`
5. **Enrichissement Vision** : `[VISUAL_ENRICHMENT]...[END_VISUAL_ENRICHMENT]` avec `to_vision_text()`

Les pages sont jointes par `\n\n`. Un `PageIndex` (mapping offset ‚Üí page) est construit en parall√®le.

#### 5.5.4 Sortie

```
Tuple[str, List[PageIndex]]
  ‚îú‚îÄ‚îÄ full_text: str ‚Äî texte lin√©aris√© complet avec marqueurs
  ‚îî‚îÄ‚îÄ page_index: List[PageIndex]
        ‚îú‚îÄ‚îÄ page_index: int
        ‚îú‚îÄ‚îÄ start_offset: int
        ‚îî‚îÄ‚îÄ end_offset: int
```

---

### 5.6 Extraction de Contexte Documentaire

**Fichiers :** `src/knowbase/extraction_v2/context/` (13 fichiers)
**Classe orchestrateur :** `DocContextExtractor` (`doc_context_extractor.py`)
**Spec :** `ADR_ASSERTION_AWARE_KG.md` ‚Äî Section 3.1, `ADR_DOCUMENT_STRUCTURAL_AWARENESS.md`

**Objectif :** D√©terminer le **scope documentaire** (version-specific, general, mixed) et extraire les **marqueurs de contexte** (versions, √©ditions) pour qualifier les assertions en aval (Pass 1.3/1.4).

#### 5.6.1 Architecture en 3 √©tapes

```
√âtape 1: Candidate Mining (d√©terministe, sans LLM)
  ‚Üì
√âtape 2: Structural Analysis (PR6 ‚Äî analyse zones + templates)
  ‚Üì
√âtape 3: LLM Validation (PR7 ‚Äî arbitre, pas extracteur)
```

#### 5.6.2 √âtape 1 ‚Äî Candidate Mining (`candidate_mining.py`)

**Objectif :** Extraction d√©terministe (regex/patterns) de candidats marqueurs depuis :
- Nom de fichier
- Premi√®res pages (couverture/titre)
- Headers/footers
- Blocs revision/history

**Filtres universels (CandidateGate)** ‚Äî √âlimination de faux positifs AVANT scoring :

| Cat√©gorie | Patterns √©limin√©s | Exemples |
|-----------|-------------------|----------|
| Dates explicites | `MM/DD/YYYY`, `YYYY-MM-DD` | `05/23/2019` |
| Trimestres | `Q1-Q4 + ann√©e` | `Q4,2023` |
| Copyright | `¬© + ann√©e` | `¬© 2023 SAP SE` |
| Mois + ann√©e | `January 2023` | `Dec. 2025` |
| Fiscal years | `FY2023` | ‚Äî |
| R√©f√©rences temporelles | `since 2019`, `2019-present` | ‚Äî |
| Unit√©s de mesure | `nombre + unit√©` | `500 MB`, `15%` |
| Exemples | `e.g. ...` | ‚Äî |
| R√©f√©rences ID | `Note 123456`, `JIRA-1234` | ‚Äî |
| Pages/slides | `Page 23`, `Slide 5` | ‚Äî |

**Patterns positifs** (marqueurs l√©gitimes) :

| Pattern | Exemples |
|---------|----------|
| SemVer | `v1.2.3-beta`, `v1.2` |
| Entity + Numeral | `S/4HANA 2023`, `iPhone 15` |
| Release forms | `Release 3.0`, `Edition 2`, `Phase 2` |
| Structured codes | `AB12`, `XY2023` |

**Structure Numbering Gate :** D√©tection agnostique de num√©rotation de sections (ex : "PUBLIC 3:" en position de titre ‚Üí candidat rejet√©, c'est un num√©ro de section, pas un marqueur de version).

**Filtrage par DocumentContext** (`decide_marker()`) :
- Si `structure_hint.has_numbered_sections` ‚Üí rejette `WORD+SMALL_NUMBER` en position heading
- Si `entity_hints` ‚Üí booste confiance si prefix correspond √† une entit√© dominante
- **Safe-by-default** : en cas de doute, rejeter le candidat

#### 5.6.3 √âtape 2 ‚Äî Structural Analysis (`context/structural/`)

Trois composants travaillent en pipeline :

**a) ZoneSegmenter** (`zone_segmenter.py`)
- Segmente chaque page en 3 zones : **TOP** (headers, titres), **MAIN** (corps), **BOTTOM** (footers, legal)
- Bas√© sur les lignes significatives (filtrage des lignes vides/courtes)
- Confiance structurelle bas√©e sur le nombre de pages : `HIGH` (‚â•10 pages), `MEDIUM` (3-9), `LOW` (<3)

**b) TemplateDetector** (`template_detector.py`)
- Identifie les fragments de texte r√©p√©titifs (boilerplate) par clustering
- Crit√®res : appara√Æt sur ‚â•30% des pages, ‚â•2 occurrences, zone consistency ‚â•60%
- Les fragments MAIN avec haute consistance ont leur `template_likelihood` r√©duit de 50% (peut √™tre du contenu s√©mantique r√©p√©t√©)
- Produit un `StructuralAnalysis` avec fragments, couverture, statistiques

**c) LinguisticCueDetector** (`linguistic_cue_detector.py`)
- Score les patterns linguistiques autour d'un candidat :
  - **Scope language** (version, release, available in) ‚Üí indique marqueur de contexte
  - **Legal language** (¬©, confidential, trademark) ‚Üí indique boilerplate
  - **Contrast language** (vs, unlike, whereas) ‚Üí indique comparaison (scope MIXED)
- Scores normalis√©s 0.0-1.0, multilingue (EN, FR, DE)

#### 5.6.4 √âtape 3 ‚Äî LLM Validation

Le LLM agit comme **ARBITRE** (pas extracteur) :
- Input : candidats enrichis avec signaux structurels
- Output : classification CONTEXT_SETTING vs TEMPLATE_NOISE
- Le LLM ne peut pas inventer de nouveaux marqueurs

#### 5.6.5 Modules compl√©mentaires du contexte

**AnchorContextAnalyzer** (`anchor_context_analyzer.py`) ‚Äî Analyse le contexte de chaque assertion (utilis√© en Pass 1.3/1.4) :
- Strat√©gie : heuristiques d'abord, LLM si ambigu
- D√©tecte : polarit√© (positive, negative, future, deprecated, conditional), marqueurs locaux, patterns d'override

**PassageHeuristics** (`heuristics.py`) ‚Äî D√©tection d√©terministe par regex de :
- N√©gation : `not, cannot, unavailable, removed` (EN/FR/DE)
- Futur : `will be, coming soon, planned for` (EN/FR/DE)
- Deprecated : `deprecated, obsolete, legacy, end-of-life` (EN/FR/DE)
- Conditionnel : `if, when, unless, depending on` (EN/FR/DE)
- Override : `unlike, in contrast, different from` (avec type : SWITCH, RANGE, GENERALIZATION)

**InheritanceEngine** (`inheritance.py`) ‚Äî Matrice d'h√©ritage DocContext ‚Üí AnchorContext :

| DocScope | Strong markers | Weak markers | Result Scope | Source | Confiance |
|----------|---------------|--------------|--------------|--------|-----------|
| `VARIANT_SPECIFIC` | ‚úÖ | ‚Äî | `CONSTRAINED` | `INHERITED_STRONG` | 0.95 |
| `VARIANT_SPECIFIC` | ‚úÖ | ‚úÖ | `CONSTRAINED` | `INHERITED_STRONG` | 0.90 |
| `VARIANT_SPECIFIC` | ‚Äî | ‚úÖ | `CONSTRAINED` | `INHERITED_WEAK` | 0.85 |
| `VARIANT_SPECIFIC` | ‚Äî | ‚Äî | `UNKNOWN` | `NONE` | 0.70 |
| `MIXED` | any | any | `UNKNOWN` | `NONE` | 0.50 |
| `GENERAL` | ‚Äî | ‚Äî | `GENERAL` | `NONE` | 0.80 |

R√®gle cl√© : **Override local d√©tect√© ‚Üí toujours prioritaire** sur l'h√©ritage documentaire.

#### 5.6.6 Sortie

```
DocContextFrame
  ‚îú‚îÄ‚îÄ doc_scope: DocScope (VARIANT_SPECIFIC | GENERAL | MIXED)
  ‚îú‚îÄ‚îÄ strong_markers: List[str] ‚Äî marqueurs √† haute confiance
  ‚îú‚îÄ‚îÄ weak_markers: List[str] ‚Äî marqueurs √† confiance mod√©r√©e
  ‚îú‚îÄ‚îÄ evidence: List[MarkerEvidence]
  ‚îú‚îÄ‚îÄ scope_signals: ScopeSignals
  ‚îî‚îÄ‚îÄ document_context: Optional[DocumentContext] ‚Äî contraintes structurelles
```

---

### 5.7 Table Summarizer

**Fichier :** `src/knowbase/extraction_v2/tables/table_summarizer.py` ‚Äî classe `TableSummarizer`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî QW-1

**Objectif :** Transformer les tableaux structur√©s en **r√©sum√©s en langage naturel** pour am√©liorer le RAG (+50% hit-rate estim√© sur questions impliquant des tableaux).

#### 5.7.1 Principe

Un r√©sum√© s√©mantique est beaucoup plus efficace pour l'embedding qu'un Markdown brut. Le r√©sum√© (2-4 phrases) est stock√© dans `[TABLE_SUMMARY]` AVANT le Markdown brut `[TABLE_RAW]`, optimisant ainsi l'embedding.

#### 5.7.2 Configuration

| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `min_cells` | 4 | Minimum de cellules pour d√©clencher le r√©sum√© |
| `max_cells` | 500 | Maximum avant troncature |
| `skip_empty` | `True` | Ignorer les tables vides |

#### 5.7.3 M√©canisme

1. **Filtre** : `_should_summarize()` ‚Äî v√©rifie min/max cellules
2. **Troncature** : Si table > `max_cells`, garde les premi√®res lignes
3. **Conversion Markdown** : `table.to_markdown()` ‚Äî g√©n√®re le Markdown de la table
4. **Appel LLM** : Via `LLMRouter` (singleton, TaskType appropri√©) avec prompt sp√©cifique
5. **Prompt** : ¬´ Summarize this table in natural language... Be factual, concise (2-4 sentences), describe key insights. ¬ª
6. **Batch** : `summarize_batch()` traite plusieurs tables en parall√®le (max_concurrent=5)

#### 5.7.4 Sortie

```
TableSummaryResult
  ‚îú‚îÄ‚îÄ table_id: str
  ‚îú‚îÄ‚îÄ summary: str ‚Äî r√©sum√© en langage naturel
  ‚îú‚îÄ‚îÄ raw_markdown: str ‚Äî Markdown original
  ‚îú‚îÄ‚îÄ success: bool
  ‚îú‚îÄ‚îÄ error: Optional[str]
  ‚îú‚îÄ‚îÄ input_tokens: int
  ‚îî‚îÄ‚îÄ output_tokens: int
```

---

### 5.8 Cache Versionn√©

**Fichier :** `src/knowbase/extraction_v2/cache/versioned_cache.py` ‚Äî classe `VersionedCache`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 10

**Objectif :** √âviter de refaire les appels Vision co√ªteux en cachant les r√©sultats d'extraction complets.

#### 5.8.1 Version actuelle

`CURRENT_CACHE_VERSION = "v5"` ‚Äî v5 inclut les DocItems s√©rialis√©s pour Pipeline V2 Pass 1 Anchor Resolution.

#### 5.8.2 Cl√© de cache

La cl√© de cache est le **SHA256 du fichier source** (pas le document_id). Ainsi, le m√™me fichier (m√™me contenu) sera toujours retrouv√©, peu importe son nom ou chemin.

**Format de fichier cache :** `{sha256_hash}.v5cache.json`

#### 5.8.3 Invalidation

- Si `cache_version != CURRENT_CACHE_VERSION` ‚Üí invalide (migration de version)
- Le hash du fichier source assure l'invalidation automatique si le contenu change

#### 5.8.4 Enrichissement √† la vol√©e

Si le cache HIT mais que `doc_context` est `None` (ancien cache), le pipeline extrait le DocContext √† la vol√©e et met √† jour le cache ‚Äî transparent pour l'appelant.

#### 5.8.5 Structure du cache

```json
{
  "cache_version": "v5",
  "created_at": "2026-01-29T14:30:00Z",
  "source_file_hash": "abc123...",
  "document_id": "doc_xyz",
  "extraction": {
    "full_text": "...",
    "structure": { ... },
    "page_index": [ ... ],
    "gating_decisions": [ ... ],
    "vision_results": [ ... ],
    "doc_context": { ... }
  }
}
```

---

### 5.8b Confidence Scorer

**Fichier :** `src/knowbase/extraction_v2/confidence/confidence_scorer.py` ‚Äî classe `ConfidenceScorer`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî QW-2

**Objectif :** Calculer un score heuristique de `parse_confidence` (0.0-1.0) sur la qualit√© du parsing (pas de l'extraction). Un texte bien pars√© (clair, structur√©, sans artefacts OCR) a un score √©lev√©.

#### 5.8b.1 Les 5 signaux de confiance

| Signal | Poids | Ce qu'il mesure | Score bas | Score haut |
|--------|-------|-----------------|-----------|------------|
| `length` | 0.20 | Longueur suffisante | < 50 chars ‚Üí 0.0 | ‚â• 500 chars ‚Üí 1.0 |
| `structure` | 0.25 | Pr√©sence de structure (headings, listes, tables) | Aucune ‚Üí 0.3 | ‚â• 3 types ‚Üí 1.0 |
| `ocr_quality` | 0.20 | Absence de patterns OCR suspects | Beaucoup de suspects ‚Üí 0.0 | Aucun ‚Üí 1.0 |
| `coherence` | 0.20 | Ratio mots/caract√®res normaux | Mots tr√®s courts/longs ‚Üí 0.5 | Normal ‚Üí 1.0 |
| `markers` | 0.15 | Pr√©sence de marqueurs OSMOSE | Aucun ‚Üí 0.5 (neutre) | ‚â• 4 types ‚Üí 1.0 |

**Floor/Ceiling :** Score final clamp√© entre `min_score=0.1` et `max_score=1.0`.

---

### 5.8c Layout Detector

**Fichier :** `src/knowbase/extraction_v2/layout/layout_detector.py` ‚Äî classe `LayoutDetector`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî MT-1

**Objectif :** D√©tecter les r√©gions structurelles dans le `full_text` lin√©aris√© pour informer le chunker (HybridAnchorChunker) des zones atomiques **√† ne jamais couper**.

#### 5.8c.1 Types de r√©gions

| Type | Atomique | Description |
|------|----------|-------------|
| `TABLE` | ‚úÖ | Entre `[TABLE_START]`/`[TABLE_SUMMARY]` et `[TABLE_END]` |
| `VISION` | ‚úÖ | Entre `[VISUAL_ENRICHMENT]` et `[END_VISUAL_ENRICHMENT]` |
| `PAGE_MARKER` | ‚ùå | Marqueur `[PAGE n]` |
| `TITLE` | ‚ùå | Marqueur `[TITLE level=n]` |
| `PARAGRAPH` | ‚ùå | Bloc `[PARAGRAPH]` + contenu |
| `TEXT` | ‚ùå | Texte libre entre les marqueurs |

#### 5.8c.2 R√®gle non-n√©gociable

> **Ne jamais couper un tableau.**

Les r√©gions atomiques (TABLE, VISION) ne peuvent **JAMAIS** √™tre coup√©es par le chunking.

#### 5.8c.3 Algorithme de d√©tection

1. D√©tection des r√©gions atomiques (tables via regex `TABLE_START_PATTERN`/`TABLE_END_PATTERN`, vision via `VISION_START_PATTERN`/`VISION_END_PATTERN`)
2. D√©tection des r√©gions non-atomiques (pages, titres, paragraphes via regex)
3. Fusion : priorit√© aux r√©gions atomiques (les non-atomiques qui chevauchent une atomique sont exclues)
4. Remplissage des trous : les gaps entre r√©gions sont combl√©s par des r√©gions `TEXT`

**Validation :** `validate_no_cut_tables()` ‚Äî v√©rifie post-chunking qu'aucun tableau n'a √©t√© coup√© (utilis√© pour tests et monitoring).

---

### 5.9 Conformit√© ADR ‚Äî Pass 0 Extraction

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Pass 0 produit uniquement la structure documentaire (VisionUnit, MergedPageOutput). Aucune entit√© s√©mantique (Concept, Information) n'est cr√©√©e. |
| AV2-4 | DocItem atomique | ‚úÖ | Les blocs extraits par Docling correspondent aux items natifs (paragraph, heading, list-item, caption). La conversion en DocItem se fait en Pass 0 Structural. |
| AV2-8 | Dual Storage | ‚ö†Ô∏è | Pass 0 produit le `full_text` pour Qdrant et la structure pour Neo4j. Le dual storage n'est effectif qu'apr√®s Pass 0 Structural (TypeAwareChunks ‚Üí Qdrant). |
| NS-2 | LLM = Extracteur evidence-locked | ‚úÖ | Vision observe et d√©crit factuellement. Le VisionSemanticReader a l'invariant I5 (pas d'assertions pr√©-promues). Le TableSummarizer d√©crit les insights observables. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Le `PageIndex` permet de tracer chaque portion du `full_text` vers sa page d'origine. Les marqueurs `[PAGE n]` assurent la tra√ßabilit√© dans le texte. |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Pass 0 traite un seul document √† la fois. Pas de fusion multi-documents. |
| AV2-10 | < 250 nodes/document | üü¢ | Pass 0 ne cr√©e aucun node Neo4j directement (c'est Pass 0 Structural qui les cr√©e). |

---

### 5.10 Risques ‚Äî Pass 0 Extraction

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R0-1 | **Shapes vectoriels non d√©tect√©s** | üü° | `_extract_visual_elements()` n'extrait que les `pictures` (raster). Les shapes vectoriels d√©pendent de la version Docling et du format. Le commentaire dans le code mentionne ¬´ Fallback VDS sera utilis√© si n√©cessaire (Phase 2.6) ¬ª. | Le signal VDS peut √™tre sous-√©valu√© pour les PPTX avec shapes sans images raster. Signal TFS et SDS compensent partiellement. |
| R0-2 | **Concurrence Vision non born√©e** | üü¢ | Le semaphore limite la concurrence (d√©faut 30, r√©duit √† 5 pour >400 pages). Risk de rate limiting OpenAI sur tr√®s gros batches. | Le semaphore et la r√©duction automatique pour gros documents att√©nuent ce risque. Le budget Vision optionnel ajoute un contr√¥le suppl√©mentaire. |
| R0-3 | **Cache version mismatch silencieux** | üü¢ | Le passage de v4 √† v5 invalide les anciens caches automatiquement. Le pipeline r√©-extrait transparemment. | Invalidation automatique par version. L'enrichissement DocContext √† la vol√©e sur anciens caches fonctionne correctement. |
| R0-4 | **Seuils de gating non calibr√©s** | üü° | Les `EXPERIMENTAL_THRESHOLDS` sont marqu√©s ¬´ √† calibrer sur corpus r√©el (Phase 7) ¬ª. Les seuils actuels sont des valeurs par d√©faut raisonnables mais non valid√©es empiriquement. | Les seuils par d√©faut (`VISION_GATING_V4_SPEC.md`) sont conservatifs. L'ajustement par Domain Context permet une adaptation au cas par cas. |
| R0-5 | **Table Summarizer ‚Äî hallucination LLM** | üü° | Le LLM peut halluciner des insights non pr√©sents dans la table. Le prompt demande de ne d√©crire que ¬´ ce qui est explicitement pr√©sent ¬ª mais aucune validation automatique n'est effectu√©e. | Le Markdown brut est conserv√© dans `[TABLE_RAW]` pour v√©rification. Le prompt est strict (¬´ Describe ONLY what is explicitly present ¬ª). |
| R0-6 | **DocContext faux positifs r√©siduels** | üü° | Malgr√© le CandidateGate robuste (>10 cat√©gories de filtres) et le filtrage par DocumentContext (`decide_marker`), certains faux positifs de marqueurs de version pourraient passer, surtout dans des domaines inhabituels. | Le principe safe-by-default (rejeter en cas de doute) et la validation LLM r√©duisent ce risque. La matrice d'h√©ritage traite `MIXED` de fa√ßon conservatrice (pas d'h√©ritage). |
| R0-7 | **VisionSemanticReader ‚Äî placeholder texte** | üü¢ | L'invariant I1 (jamais vide) peut produire un placeholder `[VISUAL_CONTENT: Page X - interpretation unavailable]` si toutes les strat√©gies √©chouent. Ce placeholder est informationnellement pauvre. | Le fallback 3-tier minimise les cas de placeholder. Les m√©triques `vision_semantic_fallback_placeholder` permettent le monitoring. |
| R0-8 | **Pass 0.5 d√©sactiv√©e en mode V2** | ‚ö†Ô∏è | Quand `stratified_pipeline_v2` feature flag est activ√©, la cor√©f√©rence linguistique (Pass 0.5) est explicitement d√©sactiv√©e car `MentionSpan/CoreferenceChain` ne font pas partie de l'architecture V2. | D√©cision architecturale consciente document√©e dans le code. La r√©solution de cor√©f√©rence en V2 sera g√©r√©e diff√©remment (√† d√©finir). |

---

## 6. Pass 0 Structural ‚Äî Graphe Structurel

**Fichiers principaux :**
- `src/knowbase/stratified/pass0/adapter.py` ‚Äî classe `Pass0Adapter` (adapter V2)
- `src/knowbase/stratified/pass0/cache_loader.py` ‚Äî fonction `load_pass0_from_cache()` (chargement depuis cache)
- `src/knowbase/structural/graph_builder.py` ‚Äî classe `StructuralGraphBuilder` (constructeur du graphe)
- `src/knowbase/structural/models.py` ‚Äî mod√®les Pydantic (`DocItem`, `SectionInfo`, `TypeAwareChunk`, `DocumentVersion`, `PageContext`, `StructuralProfile`)
- `src/knowbase/structural/docitem_builder.py` ‚Äî classe `DocItemBuilder` (extraction des items Docling)
- `src/knowbase/structural/section_profiler.py` ‚Äî classe `SectionProfiler` (assignment sections + profils structurels)
- `src/knowbase/structural/type_aware_chunker.py` ‚Äî classe `TypeAwareChunker` (chunking par type)

**Objectif :** Transformer le `DoclingDocument` (sortie de Docling) en un **graphe structurel Document ‚Üí Section ‚Üí DocItem** conforme au sch√©ma V2, puis produire les `TypeAwareChunk` pour le retrieval vectoriel (Qdrant) et les mappings chunk‚ÜîDocItem n√©cessaires √† l'Anchor Resolution (Pass 1.3b).

### 6.0 Vue d'ensemble Pass 0 Structural

**Entrant :**

| Entrant | Type | Source |
|---------|------|--------|
| `DoclingDocument` | Objet Docling natif | Pass 0 Extraction (via `extract_to_units_with_docling()`) |
| `tenant_id` | `str` | Contexte multi-tenant |
| `doc_id` | `str` | ID unique du document |
| Ou : fichier cache `.v4cache.json`/`.v5cache.json` | JSON s√©rialis√© | `data/extraction_cache/` (bypass Docling) |

**S√©quence d'ex√©cution (4+1 √©tapes) :**

```
√âtape 1: DocItemBuilder ‚Äî Extraction des DocItems depuis DoclingDocument
  ‚îÇ  texts[], tables[], pictures[] ‚Üí DocItem[] avec reading_order + charspan
  ‚Üì
√âtape 2: SectionProfiler ‚Äî Assignment hi√©rarchique des sections
  ‚îÇ  DocItem[] ‚Üí SectionInfo[] avec structural_profile
  ‚Üì
√âtape 3: TypeAwareChunker ‚Äî Cr√©ation des chunks type-aware
  ‚îÇ  DocItem[] + SectionInfo[] ‚Üí TypeAwareChunk[]
  ‚Üì
√âtape 4: Pass0Adapter ‚Äî Adaptation au sch√©ma V2
  ‚îÇ  StructuralGraphBuildResult ‚Üí Pass0Result
  ‚îÇ  + construction chunk‚ÜîDocItem mappings
  ‚îÇ  + construction unit_index (AssertionUnitIndexer)
  ‚Üì
√âtape 4b (optionnel): Persistance Neo4j V2
  ‚îÇ  Document, Section, DocItem nodes
```

**Chemin alternatif : CacheLoader** ‚Äî Si un cache V2/V4/V5 existe, `load_pass0_from_cache()` reconstruit directement un `Pass0Result` depuis le JSON s√©rialis√©, sans re-parser le DoclingDocument. Supporte aussi le format legacy v1.0 (page-based).

---

### 6.1 Adapter Docling ‚Üí Schema V2

**Fichier :** `src/knowbase/stratified/pass0/adapter.py` ‚Äî classe `Pass0Adapter`

**Objectif :** Wrapper le `StructuralGraphBuilder` existant et l'adapter au sch√©ma V2 en g√©n√©rant les identifiants composites et les mappings inter-couches.

#### 6.1.1 Architecture Adapter

`Pass0Adapter` encapsule `StructuralGraphBuilder` (pattern Adapter) :

```python
class Pass0Adapter:
    def __init__(self, max_chunk_size=3000, persist_artifacts=False):
        self.builder = StructuralGraphBuilder(
            max_chunk_size=max_chunk_size,
            persist_artifacts=persist_artifacts,
        )
```

Le builder sous-jacent orchestre les 3 composants internes : `DocItemBuilder` ‚Üí `SectionProfiler` ‚Üí `TypeAwareChunker`.

#### 6.1.2 Identifiants composites V2 (docitem_id)

Format : `{tenant_id}:{doc_id}:{item_id}`

Exemple : `default:doc_abc123:item_0042`

Ce format assure :
- **Unicit√© globale** multi-tenant
- **Lookup rapide** par tenant + doc_id
- **Correspondance** avec l'`item_id` Docling original (= `self_ref`)

Fonctions utilitaires :
- `get_docitem_id_v2(tenant_id, doc_id, item_id) ‚Üí str`
- `parse_docitem_id_v2(docitem_id) ‚Üí (tenant_id, doc_id, item_id)`

#### 6.1.3 M√©thode `process_document()`

S√©quence :
1. Appel `self.builder.build_from_docling()` ‚Üí `StructuralGraphBuildResult`
2. Construction des mappings chunk‚ÜîDocItem via `_build_mappings()`
3. Construction de l'index des unit√©s via `_build_unit_index()` (appel `AssertionUnitIndexer`)
4. Assemblage du `Pass0Result` V2

#### 6.1.4 Construction des mappings chunk‚ÜîDocItem

La m√©thode `_build_mappings()` produit deux structures inverses :

| Structure | Type | Utilisation |
|-----------|------|-------------|
| `chunk_to_docitem_map` | `Dict[chunk_id ‚Üí ChunkToDocItemMapping]` | Anchor Resolution (Pass 1.3b) ‚Äî trouver le DocItem source d'un chunk |
| `docitem_to_chunks_map` | `Dict[docitem_id ‚Üí List[chunk_id]]` | Navigation ‚Äî trouver tous les chunks contenant un DocItem |

Chaque `ChunkToDocItemMapping` contient : `chunk_id`, `docitem_ids` (liste car un chunk peut couvrir plusieurs DocItems), `text`, `char_start`, `char_end`.

Le `TypeAwareChunk` poss√®de d√©j√† `item_ids` (liste des `DocItem.item_id` sources). L'adapter convertit ces `item_id` en `docitem_id` composites V2.

#### 6.1.5 Index des unit√©s (AssertionUnitIndexer)

La m√©thode `_build_unit_index()` segmente chaque DocItem en **unit√©s d'assertion** pour permettre au LLM (Pass 1.3) de **pointer** vers une unit√© au lieu de copier le texte verbatim.

- Import lazy : `from knowbase.stratified.pass1.assertion_unit_indexer import AssertionUnitIndexer`
- Filtre : DocItems avec texte > 30 caract√®res uniquement
- Produit : `Dict[docitem_id ‚Üí UnitIndexResult]` stock√© dans `Pass0Result.unit_index`

---

### 6.2 Construction du graphe (Document, Section, DocItem)

**Fichier :** `src/knowbase/structural/graph_builder.py` ‚Äî classe `StructuralGraphBuilder`

**Objectif :** Orchestrer les 3 composants d'extraction structurelle (DocItemBuilder, SectionProfiler, TypeAwareChunker) depuis un DoclingDocument natif.

#### 6.2.1 √âtape 1 ‚Äî DocItemBuilder

**Fichier :** `src/knowbase/structural/docitem_builder.py`

**Objectif :** Extraire les items documentaires atomiques depuis le DoclingDocument.

**Sources d'extraction :**

| Source Docling | Items extraits | Type DocItem r√©sultant |
|----------------|----------------|----------------------|
| `doc.texts[]` | Paragraphes, headings, list-items, captions, footnotes | TEXT, HEADING, LIST_ITEM, CAPTION, FOOTNOTE |
| `doc.tables[]` | Tables structur√©es (Markdown + JSON canonique) | TABLE |
| `doc.pictures[]` | Figures avec captions | FIGURE |

**Mapping DocItemLabel ‚Üí DocItemType** (`DOCLING_LABEL_MAPPING` dans `models.py`) :

| Label Docling | DocItemType | Cat√©gorie |
|---------------|-------------|-----------|
| `text`, `paragraph`, `handwritten_text` | TEXT | Relation-bearing |
| `title`, `section_header` | HEADING | Relation-bearing |
| `caption` | CAPTION | Relation-bearing |
| `footnote` | FOOTNOTE | Relation-bearing |
| `list_item` | LIST_ITEM | Contextuel (D3.3) |
| `table`, `chart` | TABLE | Structure-bearing |
| `picture` | FIGURE | Structure-bearing |
| `code` | CODE | Structure-bearing |
| `formula` | FORMULA | Structure-bearing |
| `page_header`, `page_footer` | FURNITURE | Structure-bearing |
| `reference` | REFERENCE | Structure-bearing |
| Autres (`form`, `checkbox_*`, etc.) | OTHER | Structure-bearing |

**Distinction fondamentale (ADR D3) :**

- **Relation-bearing** (TEXT, HEADING, CAPTION, FOOTNOTE) ‚Äî portent des assertions, √©ligibles √† l'extraction de relations
- **Structure-bearing** (TABLE, FIGURE, CODE, FORMULA, etc.) ‚Äî portent de la structure, trait√©s s√©par√©ment

**Traitements par type :**
- **HEADING** : Inf√©rence du `heading_level` depuis le texte (patterns `1.`, `1.1.`, `1.1.1.` ‚Üí levels 1, 2, 3) via `infer_heading_level_from_text()`
- **TABLE** : Conversion en Markdown (`table_to_text()`) et JSON canonique (`table_to_json()`)
- **FIGURE** : Extraction de la caption si disponible

**Post-traitements globaux :**
1. `compute_reading_order()` ‚Äî Tri d√©terministe par (page, position_verticale, position_horizontale) ‚Üí `reading_order_index`
2. `compute_docwide_charspans()` ‚Äî Calcul des positions de caract√®res √† l'√©chelle du document entier (`charspan_start_docwide`, `charspan_end_docwide`) avec s√©parateur `\n`

**Sortie :** `DocItemBuildResult` contenant `doc_items: List[DocItem]`, `doc_version: DocumentVersion`, `page_contexts: List[PageContext]`, `doc_dict: Dict`

#### 6.2.2 √âtape 2 ‚Äî SectionProfiler

**Fichier :** `src/knowbase/structural/section_profiler.py`

**Objectif :** Grouper les DocItems en sections hi√©rarchiques et calculer le profil structurel de chaque section.

**Deux strat√©gies :**

| Strat√©gie | Condition d'activation | M√©canisme |
|-----------|----------------------|-----------|
| **Heading-based** | ‚â•1 DocItem de type HEADING d√©tect√© | Pile de sections (heading stack) ‚Äî chaque HEADING cr√©e/met √† jour une section, les items suivants y sont assign√©s |
| **Page-based** (fallback) | Aucun HEADING d√©tect√© | 1 section par page ‚Äî `section_p{page_idx:03d}` |

**Heading-based : d√©tail**
- Chaque HEADING cr√©e une section avec `section_id` d√©riv√© du texte (slugifi√©)
- Le `section_path` est construit hi√©rarchiquement : `"1. Introduction / 1.1 Overview"`
- Le `section_level` correspond au `heading_level` du DocItem
- Les relations parent‚Üíenfant sont √©tablies via `parent_section_id`

**Profil structurel (`StructuralProfile`)** :
Apr√®s l'assignment, chaque section est analys√©e via `StructuralProfile.from_items()` :
- Calcul des ratios par type (text_ratio, table_ratio, figure_ratio, etc.)
- Classification `is_relation_bearing` si ratio relation-types > 50%
- Classification `is_structure_bearing` si ratio structure-types > 50%
- `relation_likelihood` et `relation_likelihood_tier` (HIGH/MEDIUM/LOW/VERY_LOW) via `compute_features()` depuis le module `relation_likelihood`

**Sortie :** `List[SectionInfo]` avec `section_id`, `title`, `section_path`, `section_level`, `parent_section_id`, `item_ids`, `structural_profile`

#### 6.2.3 √âtape 3 ‚Äî TypeAwareChunker

**Fichier :** `src/knowbase/structural/type_aware_chunker.py`

**Objectif :** Cr√©er des chunks s√©par√©s par type de contenu pour optimiser le retrieval vectoriel et l'extraction de relations.

**R√®gles de chunking :**

| Type DocItem | Traitement | ChunkKind | `is_relation_bearing` |
|--------------|-----------|-----------|----------------------|
| TEXT, HEADING, CAPTION, FOOTNOTE | Bufferis√©s et fusionn√©s cons√©cutivement | `NARRATIVE_TEXT` | ‚úÖ `True` |
| TABLE | 1 chunk d√©di√© par table | `TABLE_TEXT` | ‚ùå `False` |
| FIGURE | 1 chunk d√©di√© par figure | `FIGURE_TEXT` | ‚ùå `False` |
| CODE | 1 chunk d√©di√© par bloc code | `CODE_TEXT` | ‚ùå `False` |

**M√©canisme de buffering narratif :**
- Les items NARRATIVE sont accumul√©s dans un buffer
- Quand la taille du buffer d√©passe `max_chunk_size` (d√©faut : 3000 chars), le buffer est flush√© ‚Üí 1 `TypeAwareChunk(kind=NARRATIVE_TEXT)`
- Chaque chunk narratif contient la liste des `item_ids` sources (tra√ßabilit√© DocItem ‚Üí Chunk)

**Propri√©t√©s des chunks :**
- `chunk_id` : UUID g√©n√©r√© automatiquement (`chunk_{uuid4().hex[:12]}`)
- `item_ids` : Liste des DocItem.item_id sources (1-N)
- `section_id` : Section d'appartenance
- `page_no` : Page de d√©but
- `text_origin` : Tra√ßabilit√© de l'origine du texte (DOCLING, VISION_SEMANTIC, OCR, PLACEHOLDER)

**Sortie :** `List[TypeAwareChunk]` ‚Äî seuls les chunks `NARRATIVE_TEXT` sont marqu√©s `is_relation_bearing=True`

#### 6.2.4 R√©sultat global ‚Äî StructuralGraphBuildResult

```
StructuralGraphBuildResult
  ‚îú‚îÄ‚îÄ doc_items: List[DocItem]           ‚Üê items atomiques
  ‚îú‚îÄ‚îÄ sections: List[SectionInfo]        ‚Üê hi√©rarchie de sections
  ‚îú‚îÄ‚îÄ chunks: List[TypeAwareChunk]       ‚Üê chunks pour retrieval
  ‚îú‚îÄ‚îÄ doc_version: DocumentVersion       ‚Üê version avec doc_hash
  ‚îú‚îÄ‚îÄ page_contexts: List[PageContext]   ‚Üê contextes de pages
  ‚îî‚îÄ‚îÄ doc_dict: Dict                     ‚Üê DoclingDocument s√©rialis√© (D7)
```

#### 6.2.5 R√©sultat V2 ‚Äî Pass0Result

```
Pass0Result (produit par Pass0Adapter)
  ‚îú‚îÄ‚îÄ doc_items: List[DocItem]
  ‚îú‚îÄ‚îÄ sections: List[SectionInfo]
  ‚îú‚îÄ‚îÄ chunks: List[TypeAwareChunk]
  ‚îú‚îÄ‚îÄ chunk_to_docitem_map: Dict[str, ChunkToDocItemMapping]   ‚Üê pour Pass 1.3b
  ‚îú‚îÄ‚îÄ docitem_to_chunks_map: Dict[str, List[str]]              ‚Üê index invers√©
  ‚îú‚îÄ‚îÄ unit_index: Dict[str, UnitIndexResult]                   ‚Üê pour Pass 1.3 Pointer
  ‚îú‚îÄ‚îÄ doc_title: Optional[str]
  ‚îú‚îÄ‚îÄ page_count: int
  ‚îî‚îÄ‚îÄ doc_version_id: str                                      ‚Üê hash stable v1:{sha256}
```

#### 6.2.6 Cache Loader ‚Äî Reconstruction depuis le cache

**Fichier :** `src/knowbase/stratified/pass0/cache_loader.py`

**Objectif :** Reconstruire un `Pass0Result` depuis un fichier cache JSON, √©vitant de re-parser le DoclingDocument.

**Formats support√©s :**

| Format cache | Donn√©es disponibles | Limites |
|-------------|---------------------|---------|
| `v2`, `v3`, `v4` | Chunks s√©rialis√©s dans `stats.structural_graph.chunks[]` | DocItems non s√©rialis√©s |
| `v5` | Chunks + DocItems s√©rialis√©s dans `stats.structural_graph.items[]` | Sections non s√©rialis√©es |
| `v1_legacy` | Pages brutes dans `extracted_text.pages[]` | 1 chunk/DocItem/section par page (d√©grad√©) |

**Vision Observations (ADR-20260126)** :
Le CacheLoader extrait les `vision_results[]` du cache et les convertit en `VisionObservation` (hors graphe de connaissance). Le param√®tre `merge_vision` est **DEPRECATED** ‚Äî par d√©faut, les r√©sultats Vision ne sont **PAS** merg√©s dans les chunks FIGURE_TEXT mais retourn√©s comme observations s√©par√©es.

#### 6.2.7 Persistance Neo4j V2

**Mode V2 (via `Pass0Adapter.process_and_persist_v2()`)** :
- Labels : `Document`, `Section`, `DocItem` (labels V2 simplifi√©s)
- Relations : `(Document)-[:HAS_SECTION]->(Section)`, `(Section)-[:SUBSECTION_OF]->(Section)`, `(Section)-[:CONTAINS_ITEM]->(DocItem)`
- IDs composites V2 pour `section_id` et `docitem_id`

**Mode legacy (via `StructuralGraphBuilder._persist_to_neo4j()`)** :
- Labels : `DocumentVersion`, `SectionContext`, `DocItem`, `PageContext`, `TypeAwareChunk`
- Relations : `(DocumentContext)-[:HAS_VERSION]->(DocumentVersion)`, `(DocumentVersion)-[:HAS_SECTION]->(SectionContext)`, `(SectionContext)-[:CONTAINS]->(DocItem)`, `(DocItem)-[:ON_PAGE]->(PageContext)`, `(TypeAwareChunk)-[:DERIVED_FROM]->(DocItem)`
- Feature flag `stratified_pipeline_v2` : si activ√©, skip la cr√©ation de `PageContext` (fusionn√© dans Document)

**Lazy DocItem Persistence (ADR)** :
La fonction `persist_pass0_to_neo4j_sync()` impl√©mente une strat√©gie de **persistance lazy** pour les DocItems :
- Seuls `Document` et `Section` sont cr√©√©s imm√©diatement
- Les `DocItem` sont cr√©√©s **√† la demande** lors de Pass 1.3 (Anchor Resolution) quand une Information est PROMOTED et n√©cessite un lien `ANCHORED_IN`
- Raison : ~6700 DocItems/doc ‚Üí ~50-200 DocItems/doc effectivement ancr√©s (evidence-first)

#### 6.2.8 Mod√®le de donn√©es ‚Äî DocItem

**Fichier :** `src/knowbase/structural/models.py` ‚Äî classe `DocItem` (Pydantic BaseModel)

Champs principaux :

| Cat√©gorie | Champs | Description |
|-----------|--------|-------------|
| **Identifiants (D1)** | `tenant_id`, `doc_id`, `doc_version_id`, `item_id` | Identification multi-tenant + version |
| **Type et contenu (D3)** | `item_type: DocItemType`, `heading_level`, `text`, `table_json` | Type canonique + contenu |
| **Hi√©rarchie Docling (D4.6)** | `parent_item_id`, `group_id` | Conserv√©s comme metadata (non utilis√©s pour le graphe V2) |
| **Provenance (D5)** | `page_no`, `bbox_*`, `charspan_start/end`, `charspan_start_docwide/end_docwide` | Position spatiale + textuelle |
| **Ordre (D2)** | `reading_order_index` | Position dans l'ordre de lecture du document |
| **Scope Layer** | `mentioned_concepts: List[str]` | Concepts mentionn√©s (peupl√© par Pass 2) ‚Äî navigation, pas assertions |
| **Section** | `section_id` | Assign√© par SectionProfiler |

**Hash stable du document (D6)** :
- Algorithme : `compute_doc_hash()` dans `models.py`
- Format : `v1:{sha256}`
- Exclut les champs volatiles (`mtime`, `path`, `created_at`, `pipeline_version`, etc.)
- Arrondit les floats (D6.3, pr√©cision 2 d√©cimales)
- Trie les listes par `self_ref` pour le d√©terminisme (D6.4)
- JSON canonique (cl√©s tri√©es, pas d'espaces)

---

### 6.3 Conformit√© ADR ‚Äî Pass 0 Structural

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Pass 0 Structural produit **uniquement** la structure documentaire (Document, Section, DocItem). Aucune entit√© s√©mantique (Concept, Information, Subject, Theme) n'est cr√©√©e. La s√©paration est stricte. |
| AV2-2 | 8 types de nodes maximum | ‚úÖ | Pass 0 Structural cr√©e 3 des 8 types autoris√©s : Document, Section, DocItem. Pas de prolif√©ration de types interm√©diaires. |
| AV2-3 | Ancrage Information sur DocItem | ‚úÖ | Les mappings `chunk_to_docitem_map` et `docitem_to_chunks_map` sont construits pour permettre l'Anchor Resolution en Pass 1.3b. L'ancrage sera `Information -[:ANCHORED_IN]-> DocItem`, pas sur chunk Qdrant. |
| AV2-4 | DocItem atomique | ‚úÖ | Chaque DocItem correspond √† un item Docling natif (`paragraph`, `table`, `picture`, `list_item`, `heading`, `caption`, `footnote`). Pas de fusion agressive ‚Äî les items TEXT cons√©cutifs restent s√©par√©s en tant que DocItems, et ne sont fusionn√©s que dans les chunks (TypeAwareChunker). |
| AV2-8 | Dual Storage | ‚úÖ | Les `TypeAwareChunk` alimentent Qdrant (retrieval vectoriel). Les `DocItem`/`SectionInfo` alimentent Neo4j (graphe structurel navigable). La s√©paration des responsabilit√©s est respect√©e. |
| AV2-10 | < 250 nodes/document | ‚ö†Ô∏è | Pass 0 Structural cr√©e potentiellement beaucoup de DocItems (~centaines √† ~milliers par document). Cependant, la strat√©gie Lazy DocItem Persistence r√©duit les nodes **effectivement cr√©√©s** en Neo4j √† ~50-200 (ceux ancr√©s par des Informations PROMOTED). Le reste existe uniquement en m√©moire dans le `Pass0Result`. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Chaque DocItem a `charspan_start/end` (per-page) et `charspan_start_docwide/end_docwide` (document-wide), permettant la tra√ßabilit√© exacte vers le texte source. `reading_order_index` assure l'ordonnancement. |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Pass 0 Structural traite un seul document √† la fois. Le `doc_version_id` (hash stable) identifie la version exacte. |

---

### 6.4 Risques ‚Äî Pass 0 Structural

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R0S-1 | **Heading level mal inf√©r√©** | üü° | `infer_heading_level_from_text()` utilise des patterns regex pour d√©duire le niveau de heading (`1.` ‚Üí level 1, `1.1.` ‚Üí level 2). Ces patterns peuvent √©chouer sur des num√©rotations non standard ou des headings sans num√©rotation. Un heading mal classifi√© impacte la hi√©rarchie des sections. | Fallback vers page-based si aucun heading d√©tect√©. Le profil structurel de chaque section compense partiellement (les sections mal d√©coup√©es auront un profil atypique). |
| R0S-2 | **DocItems tr√®s nombreux** | üü° | Un document de 100+ pages peut produire des milliers de DocItems (>6700 observ√©s). En m√©moire, ceci est g√©rable, mais la persistance Neo4j na√Øve serait co√ªteuse. | Lazy DocItem Persistence : seuls les DocItems ancr√©s par des Informations PROMOTED sont cr√©√©s en Neo4j (~50-200/doc). Le batch de 500 items par transaction Neo4j √©vite les timeouts. |
| R0S-3 | **Chunks NARRATIVE trop longs** | üü¢ | Le `max_chunk_size` de 3000 chars est un garde-fou. Les items narratifs cons√©cutifs sont fusionn√©s jusqu'√† cette limite. Un paragraphe unique > 3000 chars sera un chunk solo. | Le seuil de 3000 chars est configurable. Les chunks trop longs sont moins performants pour l'embedding mais restent fonctionnels. |
| R0S-4 | **Cache v5 ‚Äî Sections non s√©rialis√©es** | üü° | Le CacheLoader reconstruit les chunks et DocItems depuis le cache, mais les `SectionInfo` ne sont **pas** s√©rialis√©es. Le `Pass0Result` charg√© depuis le cache a `sections=[]`. | Les sections sont recalcul√©es si n√©cessaire par les passes suivantes (Pass 0.9 Global View utilise le full_text). Pour les cas o√π les sections sont critiques, un re-build complet via `Pass0Adapter.process_document()` est requis. |
| R0S-5 | **AssertionUnitIndexer import lazy** | üü¢ | L'import de `AssertionUnitIndexer` est fait en lazy (`try/except ImportError`). Si le module n'est pas disponible, l'indexation est silencieusement ignor√©e et `unit_index` reste vide. | Log warning √©mis. Le pipeline continue sans unit_index ‚Äî Pass 1.3 utilisera un mode fallback (copie verbatim au lieu de pointage). |
| R0S-6 | **Deux sch√©mas Neo4j coexistants** | üü° | Le code maintient deux chemins de persistance : legacy (`SectionContext`, `DocumentVersion`, `PageContext`) et V2 (`Document`, `Section`, `DocItem`). Le choix d√©pend du feature flag `stratified_pipeline_v2`. | Le feature flag assure un basculement propre. Le code legacy sera retir√© apr√®s validation compl√®te du pipeline V2. |
| R0S-7 | **Hash de document non d√©terministe** | üü¢ | Le `compute_doc_hash()` utilise des mesures de d√©terminisme (exclusion champs volatiles, tri par self_ref, arrondi floats, JSON canonique). Mais si Docling change la structure de sortie entre versions, le hash changera. | Le pr√©fixe `v1:` du hash permet de versionner l'algorithme. Le `docling_version` est trac√© dans `DocumentVersion`. |

---

## 7. Pass 0.5 ‚Äî R√©solution de Cor√©f√©rence Linguistique

**Fichiers principaux :**
- `src/knowbase/ingestion/pipelines/pass05_coref.py` ‚Äî classe `Pass05CoreferencePipeline` (orchestrateur)
- `src/knowbase/linguistic/coref_engine.py` ‚Äî interface `ICorefEngine` + impl√©mentations (spaCy, FastCoref, RuleBased, Coreferee)
- `src/knowbase/linguistic/coref_models.py` ‚Äî mod√®les (`MentionSpan`, `CoreferenceChain`, `CorefDecision`, `CorefLink`)
- `src/knowbase/linguistic/coref_gating.py` ‚Äî classe `CorefGatingPolicy` (politique conservative)
- `src/knowbase/linguistic/coref_named_gating.py` ‚Äî classe `NamedNamedGatingPolicy` (filtrage Named‚ÜîNamed)
- `src/knowbase/linguistic/coref_llm_arbiter.py` ‚Äî classe `CorefLLMArbiter` (arbitrage LLM pour cas ambigus)
- `src/knowbase/linguistic/coref_cache.py` ‚Äî classe `CorefCache` (cache des d√©cisions)
- `src/knowbase/linguistic/coref_persist.py` ‚Äî classe `CorefPersistence` (persistance Neo4j)

**Objectif :** R√©soudre les cor√©f√©rences linguistiques (pronoms ‚Üí ant√©c√©dents, groupes nominaux ‚Üí entit√©s nomm√©es) dans le texte du document. La r√©solution produit une `CorefGraph` (MentionSpan, CoreferenceChain, CorefDecision) persist√©e en Neo4j.

**‚ö†Ô∏è Statut V2 :** Pass 0.5 est **d√©sactiv√©e** quand le feature flag `stratified_pipeline_v2` est activ√© (cf. risque R0-8 dans section 5.10). Les mod√®les `MentionSpan`/`CoreferenceChain` ne font pas partie de l'architecture V2 (8 types de nodes max). La cor√©f√©rence en V2 sera g√©r√©e diff√©remment (√† d√©finir).

### 7.0 Vue d'ensemble Pass 0.5

**Entrants :**

| Entrant | Type | Source |
|---------|------|--------|
| DocItems de type narratif | Nodes Neo4j (`NARRATIVE_TEXT`, `PARAGRAPH`, `TEXT`) | Pass 0 Structural (graphe Document ‚Üí Section ‚Üí DocItem) |
| TypeAwareChunks | Nodes Neo4j | Pass 0 Structural (chunking type-aware) |
| Langue du document | `str` (propri√©t√© `DocumentVersion.language`) | Pass 0 Structural (d√©tection ou d√©faut `"en"`) |
| `doc_id` | `str` | ID unique du document |
| `doc_version_id` | `str` | ID de version du document |
| `tenant_id` | `str` | Contexte multi-tenant (d√©faut : `"default"`) |

**Texte reconstitu√© :** Le pipeline charge les DocItems de type narratif depuis Neo4j, les trie par `reading_order_index`, et les concat√®ne (s√©parateur `\n`) pour obtenir le `full_text` soumis √† l'engine de cor√©f√©rence. Les chunks sont utilis√©s pour l'ancrage secondaire des MentionSpan.

**Sorties :**

| Sortie | Type | Destination |
|--------|------|-------------|
| `MentionSpan` | Nodes Neo4j (fait linguistique) | Graphe linguistique ‚Äî ancrage sur DocItem + chunk |
| `CoreferenceChain` | Nodes Neo4j (groupement) | Graphe linguistique ‚Äî relie N MentionSpan cor√©f√©rents |
| `CorefLink` | Relations Neo4j (`COREFERS_TO`) | Graphe linguistique ‚Äî liens r√©solus pronom ‚Üí ant√©c√©dent |
| `CorefDecision` | Nodes Neo4j (audit) | Trail d'audit ‚Äî d√©cisions RESOLVED / ABSTAIN / NON_REFERENTIAL |
| `MATCHES_PROTOCONCEPT` | Relations Neo4j (optionnel) | Alignements lexicaux MentionSpan ‚Üí ProtoConcept |
| `Pass05Result` | Dataclass Python | M√©triques retourn√©es √† l'orchestrateur (spans, cha√Ænes, liens, taux, timing) |

**M√©triques cl√©s (Pass05Result) :**

| M√©trique | Description |
|----------|-------------|
| `mention_spans_created` | Nombre total de MentionSpan cr√©√©s |
| `chains_created` | Nombre de CoreferenceChain (clusters) |
| `links_created` | Nombre de CorefLink (`COREFERS_TO`) r√©solus |
| `decisions_created` | Nombre de CorefDecision (audit trail) |
| `resolution_rate` | % de pronoms r√©solus / total pronoms d√©tect√©s |
| `abstention_rate` | % de pronoms abstention / total pronoms d√©tect√©s |
| `engine_used` | Nom de l'engine utilis√© (FastCoref, Coreferee, RuleBased) |
| `processing_time_ms` | Dur√©e totale du traitement |

**Configuration (Pass05Config) :**

| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `confidence_threshold` | 0.85 | Seuil de confiance engine pour accepter un lien pronom |
| `max_sentence_distance` | 2 | Distance max en phrases entre pronom et ant√©c√©dent |
| `max_char_distance` | 500 | Distance max en caract√®res |
| `enable_named_gating` | `True` | Activer le filtrage Named‚ÜîNamed (Jaro-Winkler + LLM) |
| `named_jaro_reject` | 0.55 | Seuil Jaro-Winkler pour REJECT imm√©diat |
| `named_jaro_accept` | 0.95 | Seuil Jaro-Winkler pour ACCEPT imm√©diat |
| `named_jaccard_accept` | 0.8 | Seuil Token Jaccard pour ACCEPT |
| `enable_llm_arbitration` | `True` | Activer l'arbitrage LLM pour les paires en REVIEW |
| `skip_if_exists` | `True` | Idempotence ‚Äî ne pas retraiter si CorefGraph existe |
| `create_protoconcept_links` | `True` | Cr√©er les liens MATCHES_PROTOCONCEPT |
| `persist_decisions` | `True` | Persister les CorefDecision (audit) |
| `fastcoref_batch_size` | 50 000 | Taille max d'un batch (chars) pour √©viter OOM |
| `fastcoref_batch_overlap` | 3 000 | Overlap entre batches (chars) pour contexte cor√©f√©rentiel |

---

### 7.1 M√©canismes de r√©solution

#### 7.1.1 Architecture en pipeline

```
√âtape 1: Idempotence ‚Äî V√©rifier si d√©j√† trait√©
  ‚Üì
√âtape 2: Charger DocItems + Chunks depuis Neo4j
  ‚Üì
√âtape 3: D√©tecter la langue du document
  ‚Üì
√âtape 4: S√©lectionner l'engine de cor√©f√©rence
  ‚Üì
√âtape 5: R√©soudre les cor√©f√©rences (engine + batching OOM)
  ‚Üì
√âtape 5b: Filtrer les faux positifs Named‚ÜîNamed (gating + LLM)
  ‚Üì
√âtape 6: Appliquer la politique de gating (pronoms)
  ‚Üì
√âtape 7: Persister la CorefGraph dans Neo4j
  ‚Üì
√âtape 8: Cr√©er les liens MATCHES_PROTOCONCEPT (optionnel)
```

#### 7.1.2 Engines de cor√©f√©rence (multilingue)

| Engine | Langues | Disponibilit√© | Caract√©ristiques |
|--------|---------|---------------|-----------------|
| **FastCoref** (spaCy + F-Coref) | EN | `FASTCOREF_AVAILABLE` | Meilleur pour l'anglais, ~800MB m√©moire, singleton pour √©viter double-chargement |
| **SpaCy CoreferenceResolver** | EN | `SPACY_COREF_AVAILABLE` | Alternative spaCy native |
| **Coreferee** | FR, EN, DE | `COREFEREE_AVAILABLE` | Exp√©rimental, dernier release 2022 ‚Äî marqu√© swappable |
| **RuleBasedEngine** | Toutes | Toujours | Fallback universel ‚Äî heuristiques regex simples |

S√©lection automatique via `get_engine_for_language(lang)` ‚Äî EN pr√©f√®re FastCoref, FR/DE pr√©f√®re Coreferee, fallback vers RuleBasedEngine.

#### 7.1.3 Section batching (OOM Fix)

Pour les documents > `fastcoref_batch_size` chars (d√©faut : 50 000 chars, ~12 pages), le pipeline :
1. Groupe les DocItems par sections jusqu'√† `batch_size` chars
2. Ajoute un overlap de `fastcoref_batch_overlap` chars (d√©faut : 3000) entre batches pour le contexte cor√©f√©rentiel
3. R√©sout chaque batch ind√©pendamment via l'engine
4. Ajuste les offsets des clusters au document complet
5. D√©duplique les clusters de l'overlap (par signature `(start, end)`)

#### 7.1.4 Politique de gating conservative (pronoms)

**Classe :** `CorefGatingPolicy`

**Invariants :**
- **L3** : Closed-world disambiguation ‚Äî candidats locaux uniquement
- **L4** : Abstention-first ‚Äî ambigu√Øt√© ‚Üí ABSTAIN

| Crit√®re | Seuil | Effet |
|---------|-------|-------|
| Confiance engine | ‚â• 0.85 | En-dessous ‚Üí ABSTAIN (LOW_CONFIDENCE) |
| Distance sentences | ‚â§ 2 | Au-del√† ‚Üí ABSTAIN (LONG_DISTANCE) |
| Distance chars | ‚â§ 500 | Au-del√† ‚Üí ABSTAIN (LONG_DISTANCE) |
| Candidats multiples | >1 valide | ‚Üí ABSTAIN (AMBIGUOUS) |
| Pronom non r√©f√©rentiel | D√©tect√© | ‚Üí NON_REFERENTIAL (IMPERSONAL, EXPLETIVE, GENERIC) |

**D√©cision types :** `RESOLVED` | `ABSTAIN` | `NON_REFERENTIAL`

#### 7.1.5 Gating Named‚ÜîNamed (ADR_COREF_NAMED_NAMED_VALIDATION)

**Classe :** `NamedNamedGatingPolicy`

**Objectif :** Filtrer les faux positifs quand l'engine regroupe deux noms propres diff√©rents dans un m√™me cluster (ex: "SAP S/4HANA" ‚Üî "SAP BTP").

**Strat√©gie 3-tier :**

| Condition | D√©cision | Seuils |
|-----------|----------|--------|
| Jaro-Winkler < 0.55 | `REJECT` | STRING_SIMILARITY_LOW |
| Jaro-Winkler ‚â• 0.95 OU Token Jaccard ‚â• 0.8 | `ACCEPT` | HIGH_SIMILARITY |
| Zone interm√©diaire | `REVIEW` | Envoy√© au LLM Arbiter |

**LLM Arbiter** (`CorefLLMArbiter`) : Arbitrage batch pour les paires en REVIEW. D√©cisions : `same_entity=True/False` ou `abstain=True`.

**Cache** (`CorefCache`) : Cache des d√©cisions Named‚ÜîNamed (paire ‚Üí m√™me entit√© ou non) pour √©viter les appels LLM r√©p√©t√©s.

#### 7.1.6 Types de mentions

| Type | Exemples | Traitement |
|------|----------|-----------|
| `PRONOUN` | it, they, il, elle | Gating conservative (L4) |
| `PROPER` | SAP S/4HANA, iPhone 15 | Named‚ÜîNamed gating |
| `NP` | le syst√®me, the device | Named‚ÜîNamed gating |
| `OTHER` | ‚Äî | Exclu de la r√©solution |

#### 7.1.7 Mod√®les de donn√©es CorefGraph

```
MentionSpan (fait linguistique, pas assertion)
  ‚îú‚îÄ‚îÄ tenant_id, doc_id, doc_version_id
  ‚îú‚îÄ‚îÄ docitem_id (ancrage principal ‚Üí DocItem)
  ‚îú‚îÄ‚îÄ chunk_id (ancrage secondaire ‚Üí TypeAwareChunk)
  ‚îú‚îÄ‚îÄ span_start, span_end (offsets exacts ‚Äî L1)
  ‚îú‚îÄ‚îÄ surface (texte verbatim)
  ‚îú‚îÄ‚îÄ mention_type: MentionType (PRONOUN | NP | PROPER | OTHER)
  ‚îî‚îÄ‚îÄ lang, sentence_index

CoreferenceChain
  ‚îú‚îÄ‚îÄ chain_id, tenant_id, doc_id, doc_version_id
  ‚îú‚îÄ‚îÄ method (engine utilis√©)
  ‚îú‚îÄ‚îÄ confidence
  ‚îú‚îÄ‚îÄ mention_ids: List[str]
  ‚îî‚îÄ‚îÄ representative_mention_id

CorefLink
  ‚îú‚îÄ‚îÄ source_mention_id ‚Üí target_mention_id
  ‚îú‚îÄ‚îÄ method, confidence
  ‚îú‚îÄ‚îÄ scope: CorefScope (SAME_SENTENCE | PREV_SENTENCE | PREV_CHUNK | WINDOW_K)
  ‚îî‚îÄ‚îÄ window_chars

CorefDecision (audit trail)
  ‚îú‚îÄ‚îÄ decision_type: RESOLVED | ABSTAIN | NON_REFERENTIAL
  ‚îú‚îÄ‚îÄ reason_code: ReasonCode (UNAMBIGUOUS, AMBIGUOUS, LOW_CONFIDENCE, etc.)
  ‚îî‚îÄ‚îÄ reason_detail
```

#### 7.1.8 Liens MATCHES_PROTOCONCEPT

Si `create_protoconcept_links=True`, le pipeline :
1. Charge les `ProtoConcept` du document depuis Neo4j
2. Pour chaque `MentionSpan` de type PROPER ou NP, cherche une correspondance lexicale avec un ProtoConcept
3. Cr√©e un lien `MATCHES_PROTOCONCEPT` (confidence=0.9, method="lexical_match")

**NOTE GOUVERNANCE** : Ces liens sont des **alignements lexicaux/ancr√©s**, PAS des identit√©s ontologiques.

---

### 7.2 Conformit√© ADR ‚Äî Pass 0.5

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚ö†Ô∏è | Pass 0.5 op√®re sur la couche **linguistique**, distincte de la structure documentaire ET de la s√©mantique. Cependant, les `MentionSpan` et `CoreferenceChain` ne font pas partie des 8 types de nodes V2, ce qui cr√©e un conflit avec AV2-2. |
| AV2-2 | 8 types de nodes maximum | ‚ùå | Pass 0.5 cr√©e des types de nodes suppl√©mentaires (`MentionSpan`, `CoreferenceChain`, `CorefDecision`) qui ne font pas partie du sch√©ma V2 (Document, Section, DocItem, Subject, Theme, Concept, Information, AssertionLog). C'est la raison de la d√©sactivation en mode V2. |
| NS-2 | LLM = Extracteur evidence-locked | ‚úÖ | Le LLM Arbiter est strictement un **arbitre** (m√™me entit√© ou non ?), pas un extracteur. Il n'invente pas de cor√©f√©rences ‚Äî il valide/rejette celles propos√©es par l'engine. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Les `MentionSpan` conservent les offsets exacts (`span_start`, `span_end`) et le texte verbatim (`surface`). Invariant L1 (Evidence-preserving) respect√©. |

**Invariants linguistiques :**

| Invariant | Description | Statut |
|-----------|-------------|--------|
| L1 | Evidence-preserving (spans exacts) | ‚úÖ Offsets conserv√©s |
| L2 | No generated evidence (pas de texte modifi√© persist√©) | ‚úÖ Le texte original n'est jamais alt√©r√© |
| L3 | Closed-world disambiguation | ‚úÖ Candidats locaux (fen√™tre courte) uniquement |
| L4 | Abstention-first | ‚úÖ Politique conservative, seuil 0.85, ABSTAIN sur ambigu√Øt√© |
| L5 | Linguistic-only | ‚úÖ Pas de relation conceptuelle ‚Äî fait linguistique pur |

---

### 7.3 Risques ‚Äî Pass 0.5

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R05-1 | **D√©sactiv√©e en V2** | üü° | Pass 0.5 est enti√®rement d√©sactiv√©e quand `stratified_pipeline_v2=True`. Les cor√©f√©rences ne sont pas r√©solues dans le pipeline V2, ce qui peut d√©grader la qualit√© de l'extraction d'assertions (pronoms non r√©solus dans le texte source). | D√©cision architecturale consciente. La cor√©f√©rence V2 n√©cessite une refonte pour s'int√©grer dans le sch√©ma 8-nodes (potentiellement comme metadata sur DocItem plut√¥t que nodes s√©par√©s). |
| R05-2 | **OOM FastCoref sur gros documents** | üü° | FastCoref charge ~800MB (spaCy + mod√®le). Les documents > 50K chars n√©cessitent un section batching. Le seuil a √©t√© r√©duit de 100K √† 50K apr√®s un OOM sur un document de 106K chars. | Section batching avec overlap de 3K chars. Singleton FastCoref pour √©viter double chargement. |
| R05-3 | **Coreferee obsol√®te** | üü° | Le moteur Coreferee (utilis√© pour FR/DE) a son dernier release en 2022. Il est marqu√© "swappable sans douleur" mais aucune alternative n'est identifi√©e. | Fallback vers RuleBasedEngine si Coreferee indisponible. L'interface `ICorefEngine` permet le swap transparent. |
| R05-4 | **Offset lookup simpliste** | üü° | `_find_docitem_for_offset()` et `_find_chunk_for_offset()` retournent actuellement le **premier** DocItem/chunk (TODO dans le code). L'ancrage MentionSpan ‚Üí DocItem est potentiellement incorrect pour les mentions en milieu/fin de document. | Marqu√© TODO dans le code. En mode V2 d√©sactiv√©, ce bug n'a pas d'impact. |
| R05-5 | **Named‚ÜîNamed gating ‚Äî faux rejets** | üü¢ | Le seuil Jaro-Winkler de 0.55 pour REJECT est agressif. Des variantes l√©gitimes (ex: "SAP S/4HANA 2023" vs "S/4HANA") pourraient √™tre rejet√©es √† tort. | Le LLM Arbiter traite les cas en zone grise (REVIEW). Le cache √©vite les appels LLM r√©p√©t√©s. |
| R05-6 | **Pas d'int√©gration avec Pass 1.x** | üü° | Les r√©sultats de cor√©f√©rence (CorefGraph) ne sont pas exploit√©s par les passes s√©mantiques (Pass 1.1-1.4). Le module `coref_assertion_bridge.py` existe mais l'int√©gration n'est pas document√©e. | Le pipeline V2 contournera ce probl√®me en int√©grant la cor√©f√©rence diff√©remment (√† concevoir). |

---

## 8. Pass 0.9 ‚Äî Construction de la Vue Globale

### 8.0 Vue d'ensemble Pass 0.9

**Module :** `src/knowbase/stratified/pass09/` (5 fichiers)
**Orchestrateur :** `global_view_builder.py` ‚Äî classe `GlobalViewBuilder`
**Mod√®les :** `models.py` ‚Äî `GlobalView`, `SectionSummary`, `GlobalViewCoverage`, `Pass09Config`
**Composants :** `SectionSummarizer` (r√©sum√© LLM par section), `HierarchicalCompressor` (assemblage meta-document)

**Objectif :** Construire un **meta-document** synth√©tique (15-30K chars, cible 20K) repr√©sentant l'int√©gralit√© du document source sous forme compress√©e. Ce meta-document remplace le `full_text` brut comme entr√©e pour les passes analytiques (Pass 1.1, Pass 1.2), permettant au LLM de ¬´ voir ¬ª l'ensemble du document dans une seule fen√™tre de contexte.

**Entrants :**

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `sections` | `List[Dict]` | Pass 0 Structural (graphe structurel) | Liste des sections avec `id`, `title`, `level`, `text` ou `chunk_ids` |
| `chunks` | `Dict[str, str]` | Pass 0 Structural | Mapping `chunk_id ‚Üí texte` pour r√©soudre les chunk_ids des sections |
| `full_text` | `str` | Pass 0 Extraction | Texte lin√©aris√© complet (fallback si sections sans texte direct) |
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `tenant_id` | `str` | Pipeline | Identifiant du tenant (d√©faut : `"default"`) |
| `doc_title` | `str` | Pass 0 Extraction | Titre du document (optionnel) |

**S√©quence d'ex√©cution :**

```
√âtape 1: Extraction des textes par section
  ‚Üí _extract_section_texts() : r√©solution text direct / chunk_ids / item_ids / positions
  ‚Üì
√âtape 2: R√©sum√© de chaque section (SectionSummarizer)
  ‚Üí Parall√®le async avec Semaphore(max_concurrent_summaries=10)
  ‚Üí D√©cision par section : skip / verbatim / LLM / truncated
  ‚Üì
√âtape 3: Compression en meta-document (HierarchicalCompressor)
  ‚Üí Assemblage hi√©rarchique (headings Markdown)
  ‚Üí Construction TOC enrichie
  ‚Üí Enforcement des limites de taille
  ‚Üì
√âtape 4: Construction GlobalView
  ‚Üí meta_document + section_summaries + toc_enhanced + coverage + m√©tadonn√©es
  ‚Üì
√âtape 5: Validation
  ‚Üí coverage_ratio ‚â• 95%, taille dans [5000, 30000] chars
```

**Sortie :**

```
GlobalView
  ‚îú‚îÄ‚îÄ tenant_id: str
  ‚îú‚îÄ‚îÄ doc_id: str
  ‚îú‚îÄ‚îÄ meta_document: str  ‚Üê SORTIE PRINCIPALE (15-30K chars)
  ‚îú‚îÄ‚îÄ section_summaries: Dict[str, SectionSummary]
  ‚îú‚îÄ‚îÄ toc_enhanced: str  ‚Üê TOC enrichie avec concepts et types
  ‚îú‚îÄ‚îÄ coverage: GlobalViewCoverage
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_total: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_summarized: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_verbatim: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_skipped: int
  ‚îÇ     ‚îú‚îÄ‚îÄ chars_original: int
  ‚îÇ     ‚îú‚îÄ‚îÄ chars_meta_document: int
  ‚îÇ     ‚îú‚îÄ‚îÄ coverage_ratio: float  (propri√©t√© calcul√©e)
  ‚îÇ     ‚îî‚îÄ‚îÄ compression_ratio: float  (propri√©t√© calcul√©e)
  ‚îú‚îÄ‚îÄ created_at: datetime
  ‚îú‚îÄ‚îÄ llm_model_used: str  ("gpt-4o-mini" ou "")
  ‚îú‚îÄ‚îÄ total_llm_calls: int
  ‚îú‚îÄ‚îÄ total_tokens_used: int
  ‚îú‚îÄ‚îÄ build_time_seconds: float
  ‚îú‚îÄ‚îÄ is_fallback: bool  (True si construit sans LLM)
  ‚îî‚îÄ‚îÄ errors: List[str]
```

---

### 8.1 SectionSummarizer

**Fichier :** `src/knowbase/stratified/pass09/section_summarizer.py` ‚Äî classe `SectionSummarizer`
**Mod√®le LLM :** `gpt-4o-mini` (temperature=0.3, max_tokens=500)

**Objectif :** R√©sumer chaque section du document en un r√©sum√© informatif fid√®le (max 800 chars par d√©faut), tout en identifiant les concepts, types d'assertions et valeurs cl√©s pr√©sents dans la section.

#### 8.1.1 Strat√©gie de traitement par section

Le SectionSummarizer applique une **strat√©gie adaptative** en fonction de la taille de chaque section :

| Condition | M√©thode (`method`) | Comportement |
|-----------|-------------------|-------------|
| `char_count < 200` (`section_min_chars_to_summarize`) | `"skipped"` | Copie verbatim du texte (ou `"(section vide)"`) ‚Äî section trop courte pour m√©riter un r√©sum√© |
| `200 ‚â§ char_count < 500` (`section_max_chars_for_verbatim`) | `"verbatim"` | Copie verbatim ‚Äî section suffisamment courte pour √™tre incluse telle quelle |
| `char_count ‚â• 500` | `"llm"` | R√©sum√© via appel LLM ‚Äî section n√©cessitant compression |
| Erreur LLM | `"truncated"` | Fallback : premiers 1000 chars (`fallback_chars_per_section`) + `"..."` |

#### 8.1.2 Parall√©lisation des r√©sum√©s

Les r√©sum√©s sont ex√©cut√©s en **parall√®le asynchrone** via `asyncio.gather()` avec un `asyncio.Semaphore(max_concurrent_summaries)` (d√©faut : 10 appels simultan√©s). Les erreurs individuelles sont captur√©es via `return_exceptions=True` ‚Äî un √©chec d'une section n'emp√™che pas le traitement des autres.

#### 8.1.3 Prompt LLM

**System prompt :** Directive d'expert en analyse documentaire. R√®gles :
- Maximum `{max_chars}` caract√®res (configurable, d√©faut 800)
- Identifier les **concepts cl√©s** (termes techniques, entit√©s)
- Noter les **types d'assertions** (definitional, prescriptive, factual, procedural)
- Pr√©server les **valeurs sp√©cifiques** (versions, pourcentages, limites, dur√©es)
- Ne PAS interpr√©ter, seulement r√©sumer fid√®lement
- Style neutre et factuel

**User prompt :** Fournit le titre de section, son niveau hi√©rarchique, et le contenu (tronqu√© √† 8000 chars pour respecter la fen√™tre LLM).

**Format de r√©ponse attendu :** JSON strict :
```json
{
  "summary": "R√©sum√© de la section (max {max_chars} chars)",
  "concepts": ["concept1", "concept2", "concept3"],
  "assertion_types": ["definitional", "prescriptive", "factual"],
  "key_values": ["TLS 1.2", "99.95%", "30 days"]
}
```

**Nettoyage de la r√©ponse :** Le parser g√®re les r√©ponses envelopp√©es dans des blocs markdown (\`\`\`json...\`\`\`) et, en cas d'√©chec de parsing JSON, extrait manuellement le r√©sum√© (premiers `max_chars` chars de la r√©ponse brute).

#### 8.1.4 Compatibilit√© multi-client LLM

Le SectionSummarizer supporte trois interfaces LLM :

| Interface | M√©thode de d√©tection | Appel |
|-----------|---------------------|-------|
| OpenAI-style | `hasattr(client, "chat")` | `client.chat.completions.create(model="gpt-4o-mini", ...)` |
| vLLM-style | `hasattr(client, "generate")` | `client.generate(prompt=..., max_tokens=500)` |
| Sync fallback | `hasattr(client, "complete")` | `client.complete(prompt=..., max_tokens=500)` |

#### 8.1.5 Sortie `SectionSummary`

```
SectionSummary
  ‚îú‚îÄ‚îÄ section_id: str
  ‚îú‚îÄ‚îÄ section_title: str
  ‚îú‚îÄ‚îÄ level: int  (1=H1, 2=H2, 3=H3...)
  ‚îú‚îÄ‚îÄ summary: str  (500-1000 chars max)
  ‚îú‚îÄ‚îÄ concepts_mentioned: List[str]  (termes techniques identifi√©s)
  ‚îú‚îÄ‚îÄ assertion_types: List[str]  (definitional, prescriptive, factual, procedural)
  ‚îú‚îÄ‚îÄ key_values: List[str]  (valeurs sp√©cifiques pr√©serv√©es)
  ‚îú‚îÄ‚îÄ char_count_original: int
  ‚îú‚îÄ‚îÄ char_count_summary: int
  ‚îú‚îÄ‚îÄ method: str  ("llm" | "verbatim" | "truncated" | "skipped")
  ‚îî‚îÄ‚îÄ compression_ratio: float  (propri√©t√© calcul√©e : summary/original)
```

#### 8.1.6 Statistiques de traitement

Le SectionSummarizer maintient un dictionnaire `_stats` accessible via la propri√©t√© `stats` :
- `sections_processed` : nombre de sections r√©sum√©es par LLM
- `sections_skipped` : nombre de sections trop courtes
- `sections_verbatim` : nombre de sections copi√©es verbatim
- `total_tokens_in` / `total_tokens_out` : tokens consomm√©s
- `errors` : liste des erreurs rencontr√©es

---

### 8.2 HierarchicalCompressor

**Fichier :** `src/knowbase/stratified/pass09/hierarchical_compressor.py` ‚Äî classe `HierarchicalCompressor`

**Objectif :** Assembler les `SectionSummary` individuels en un **meta-document unique** structur√© hi√©rarchiquement, respectant les contraintes de taille (5K-30K chars) et produisant une TOC enrichie.

#### 8.2.1 M√©canisme de compression

La m√©thode `compress()` ex√©cute 4 √©tapes s√©quentielles :

```
1. _calculate_coverage()     ‚Üí GlobalViewCoverage (statistiques)
2. _build_meta_document()    ‚Üí str (meta-document structur√© Markdown)
3. _build_enhanced_toc()     ‚Üí str (table des mati√®res enrichie)
4. _enforce_size_limits()    ‚Üí str (meta-document ajust√© si n√©cessaire)
```

#### 8.2.2 Calcul de couverture (`_calculate_coverage`)

It√®re sur tous les `SectionSummary` et classifie :

| M√©thode du r√©sum√© | Compteur incr√©ment√© |
|-------------------|---------------------|
| `"llm"` | `sections_summarized` |
| `"verbatim"` | `sections_verbatim` |
| `"truncated"` | `sections_summarized` (troncature = fallback de r√©sum√©) |
| `"skipped"` | `sections_skipped` |

**coverage_ratio** = `(sections_summarized + sections_verbatim) / sections_total`

> ‚ö†Ô∏è **Note :** Les sections `"skipped"` ne comptent PAS dans la couverture. Le seuil minimum configurable est `min_coverage_ratio = 0.95` (95%).

#### 8.2.3 Construction du meta-document (`_build_meta_document`)

Format Markdown structur√© hi√©rarchiquement :

```markdown
# Document: [titre]

## [Section niveau 1]
[r√©sum√©]
**Concepts:** concept1, concept2
**Types:** definitional, prescriptive
**Valeurs:** TLS 1.2, 99.95%

### [Section niveau 2]
[r√©sum√©]
...
```

**R√®gles de formatage :**
- Le niveau de heading Markdown = `min(level + 1, 4)` ‚Äî maximum `####` pour √©viter la pollution
- Les concepts sont limit√©s √† 10 par section
- Les valeurs cl√©s sont limit√©es √† 8 par section
- Les m√©tadonn√©es enrichies (Concepts, Types, Valeurs) sont ajout√©es uniquement si pr√©sentes
- Les sections sont assembl√©es dans l'**ordre original** du document (`sections_order`)

#### 8.2.4 Table des mati√®res enrichie (`_build_enhanced_toc`)

Construit une TOC avec num√©rotation hi√©rarchique automatique et m√©tadonn√©es inline :

```
# Table des Mati√®res Enrichie

1. Architecture Overview [5 concepts, definitional/prescriptive]
  1.1 Components [3 concepts, factual]
  1.2 Deployment Model [2 concepts, procedural]
2. Security Framework [4 concepts, prescriptive]
```

**M√©canisme de num√©rotation :** Compteurs par niveau (5 niveaux max), reset des niveaux inf√©rieurs √† chaque incr√©mentation d'un niveau sup√©rieur.

#### 8.2.5 Enforcement des limites de taille (`_enforce_size_limits`)

| Condition | Action |
|-----------|--------|
| `len(meta_document) > meta_document_max_chars` (30K) | Troncature intelligente via `_smart_truncate()` |
| `len(meta_document) ‚â§ meta_document_max_chars` | Aucune action |

**Troncature intelligente (`_smart_truncate`) :**
1. Les **headings** (`#...`) sont **toujours pr√©serv√©s**
2. Les lignes de contenu sont ajout√©es tant que le budget le permet (marge de s√©curit√© : 100 chars)
3. Les m√©tadonn√©es (`**Concepts:**...`) sont supprim√©es en dernier
4. Un marqueur `[... document tronqu√© pour respecter limite tokens ...]` est ajout√© en fin

#### 8.2.6 Sortie

```
Tuple[str, str, GlobalViewCoverage]
  ‚îú‚îÄ‚îÄ meta_document: str            ‚Üê Document compress√© structur√© (5K-30K chars)
  ‚îú‚îÄ‚îÄ toc_enhanced: str             ‚Üê TOC enrichie avec concepts/types
  ‚îî‚îÄ‚îÄ coverage: GlobalViewCoverage  ‚Üê Statistiques de couverture
```

---

### 8.3 GlobalViewBuilder ‚Äî Orchestration

**Fichier :** `src/knowbase/stratified/pass09/global_view_builder.py` ‚Äî classe `GlobalViewBuilder`

**Objectif :** Orchestrer la construction compl√®te de la `GlobalView` en coordonnant `SectionSummarizer` et `HierarchicalCompressor`.

#### 8.3.1 Extraction des textes par section (`_extract_section_texts`)

R√©sout le texte de chaque section selon **5 strat√©gies** en cascade :

| Priorit√© | Condition | Source du texte |
|----------|-----------|----------------|
| 1 | `section.text` existe | Texte direct de la section |
| 2 | `section.chunk_ids` non vide | Concat√©nation des chunks r√©f√©renc√©s |
| 3 | `section.item_ids` non vide | Concat√©nation des items (DocItems) depuis le mapping chunks |
| 4 | `section.start_pos / end_pos` d√©finis | D√©coupage du `full_text` par positions |
| 5 | Aucune source | Cha√Æne vide `""` |

#### 8.3.2 Mode LLM (`_build_with_llm`) ‚Äî async

1. **R√©sum√©** : `SectionSummarizer.summarize_sections()` ‚Äî parall√®le async
2. **Compression** : `HierarchicalCompressor.compress()` ‚Äî synchrone
3. **Assemblage** : `GlobalView` avec `is_fallback=False`, mod√®le `"gpt-4o-mini"`

#### 8.3.3 Mode Fallback (`_build_fallback`) ‚Äî synchrone

Activ√© quand :
- Aucun `llm_client` n'est fourni
- Appel via `build_sync()` (compatibilit√© FastAPI synchrone)

**Strat√©gie :** Pour chaque section, tronque le texte aux premiers `fallback_chars_per_section` (1000) caract√®res + `"..."`. Toutes les sections obtiennent `method="truncated"`. Pas d'extraction de concepts/types/valeurs.

#### 8.3.4 Validation de la GlobalView

La m√©thode `GlobalView.is_valid(config)` v√©rifie :
1. `coverage.coverage_ratio ‚â• config.min_coverage_ratio` (95%)
2. `len(meta_document) ‚â• config.meta_document_min_chars` (5000)
3. `len(meta_document) ‚â§ config.meta_document_max_chars` (30000)

Si la validation √©choue, l'erreur est logg√©e et ajout√©e √† `errors`, mais la `GlobalView` est tout de m√™me retourn√©e.

#### 8.3.5 Fonction utilitaire `build_global_view()`

Fonction de convenance async au niveau module pour usage simplifi√© :

```python
from knowbase.stratified.pass09 import build_global_view

global_view = await build_global_view(
    doc_id="doc_123",
    tenant_id="default",
    sections=sections,
    chunks=chunks,
    llm_client=openai_client,
)
```

---

### 8.4 Int√©gration dans le Pipeline (Orchestrateur Pass 1)

**Fichier :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî classe `Pass1OrchestratorV2`

Pass 0.9 est int√©gr√© comme **premi√®re phase** de l'orchestrateur Pass 1, avant l'analyse documentaire (Pass 1.1).

#### 8.4.1 Activation

- Flag `enable_pass09` (d√©faut : `True`) dans le constructeur de `Pass1OrchestratorV2`
- Configuration optionnelle via `pass09_config: Pass09Config`
- Le `GlobalViewBuilder` est initialis√© dans le constructeur si `enable_pass09=True`

#### 8.4.2 Flux d'ex√©cution dans `process()`

```
1. PHASE 0.9: GlobalView Construction
   ‚îú‚îÄ‚îÄ Si sections vides : cr√©ation depuis chunks (fallback)
   ‚îú‚îÄ‚îÄ Appel build_sync() (mode synchrone FastAPI)
   ‚îú‚îÄ‚îÄ Si GlobalView valide ‚Üí analysis_content = global_view.meta_document
   ‚îú‚îÄ‚îÄ Si GlobalView vide/erreur ‚Üí analysis_content = content brut (fallback)
   ‚îî‚îÄ‚îÄ Si Pass 0.9 d√©sactiv√© ‚Üí analysis_content = content brut
   ‚Üì
2. PHASE 1.1: Document Analysis
   ‚îú‚îÄ‚îÄ Utilise analysis_content (= meta-document OU content brut)
   ‚îú‚îÄ‚îÄ Si toc_enhanced disponible ‚Üí utilise pour l'analyse au lieu de la TOC brute
   ‚îî‚îÄ‚îÄ Produit Subject, Themes, DocumentStructure
   ‚Üì
3. PHASE 1.2: Concept Identification
   ‚îú‚îÄ‚îÄ Utilise analysis_content (= meta-document OU content brut)
   ‚îî‚îÄ‚îÄ Produit List[Concept]
```

#### 8.4.3 Pr√©paration des sections (router API)

**Fichier :** `src/knowbase/stratified/api/router.py`

Avant d'appeler l'orchestrateur Pass 1, le router API pr√©pare les sections pour Pass 0.9 :

```python
sections_for_pass09 = []
for section in structural_sections:
    sections_for_pass09.append({
        "id": section.id,
        "title": section.title,
        "level": section.level,
        "text": section.text,          # Texte direct si disponible
        "chunk_ids": section.chunk_ids  # IDs de chunks r√©f√©renc√©s
    })
```

Ces sections sont pass√©es via le param√®tre `sections=sections_for_pass09` √† l'orchestrateur.

---

### 8.5 Configuration Pass 0.9

**Classe :** `Pass09Config` (dataclass)

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `section_summary_max_chars` | `int` | `800` | Taille max d'un r√©sum√© de section |
| `section_summary_min_chars` | `int` | `100` | Taille min d'un r√©sum√© |
| `section_min_chars_to_summarize` | `int` | `200` | Seuil sous lequel une section est skip/verbatim |
| `section_max_chars_for_verbatim` | `int` | `500` | Seuil sous lequel une section est copi√©e verbatim |
| `meta_document_min_chars` | `int` | `5000` | Taille min du meta-document |
| `meta_document_max_chars` | `int` | `30000` | Taille max du meta-document |
| `meta_document_target_chars` | `int` | `20000` | Taille cible du meta-document |
| `min_coverage_ratio` | `float` | `0.95` | Couverture minimum requise (95%) |
| `max_concurrent_summaries` | `int` | `10` | Nombre max de r√©sum√©s LLM en parall√®le |
| `enable_fallback` | `bool` | `True` | Active le mode fallback (troncature) |
| `fallback_chars_per_section` | `int` | `1000` | Chars par section en mode fallback |

---

### 8.6 Conformit√© ADR ‚Äî Pass 0.9

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| P09-1 | **Couverture 100% sections** | ‚ö†Ô∏è | Le meta-document it√®re sur toutes les sections dans `sections_order`, mais les sections `"skipped"` (< 200 chars) ne comptent pas dans le `coverage_ratio`. | Le coverage_ratio exige 95% (`min_coverage_ratio`), pas 100%. Les sections tr√®s courtes sont incluses en verbatim ou skip mais toujours pr√©sentes dans le meta-document. |
| P09-2 | **Compression hi√©rarchique** | ‚úÖ | `HierarchicalCompressor._build_meta_document()` pr√©serve la hi√©rarchie H1 > H2 > H3 via le calcul `"#" * min(level + 1, 4)`. | Limitation √† `####` (H4) pour √©viter la pollution Markdown. La structure originale est fid√®lement reproduite. |
| P09-3 | **Meta-document 15-25K chars** | ‚ö†Ô∏è | Fourchette impl√©ment√©e : [5000, 30000] chars (config), cible 20000. | La fourchette est plus large que l'ADR (15-25K). Le `_enforce_size_limits` tronque intelligemment si > 30K. Pas de m√©canisme d'expansion si < 5K. |
| P09-4 | **95% minimum sections r√©sum√©es** | ‚úÖ | `min_coverage_ratio = 0.95` dans `Pass09Config`, v√©rifi√© par `GlobalView.is_valid()`. | Les sections `"skipped"` ne comptent pas, mais les sections vides sont rares dans un document structur√©. |
| P09-5 | **Fallback mode (Option C)** | ‚úÖ | `_build_fallback()` op√©rationnel : tronque chaque section aux premiers 1000 chars. Mode synchrone, sans appel LLM. Activ√© automatiquement si `llm_client=None` ou via `build_sync()`. | Le fallback est fonctionnel et produit une GlobalView valide avec `is_fallback=True`. |
| P09-6 | **Int√©gration dans Pass 1.1 et 1.2** | ‚úÖ | L'orchestrateur Pass 1 utilise `global_view.meta_document` comme `analysis_content` pour Pass 1.1 (DocumentAnalyzer) et Pass 1.2 (ConceptIdentifier). La `toc_enhanced` remplace la TOC brute pour l'analyse. | L'int√©gration est compl√®te avec fallback automatique sur `content` brut si GlobalView absente ou invalide. |

---

### 8.7 Risques ‚Äî Pass 0.9

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R09-1 | **Mode sync = toujours fallback** | üü° | `build_sync()` utilise syst√©matiquement le mode fallback (troncature), m√™me si un `llm_client` est disponible. Les r√©sum√©s LLM ne sont accessibles qu'en mode async. | Le router API actuel utilise `build_sync()` dans le contexte FastAPI. Pour b√©n√©ficier des r√©sum√©s LLM, il faudrait refactorer vers `build()` async. |
| R09-2 | **Pas de gestion du budget tokens** | üü° | Le texte envoy√© au LLM est tronqu√© √† 8000 chars (`text[:8000]`), mais il n'y a pas de calcul de tokens r√©el (tiktoken). Pour les sections longues en encodage non-ASCII, 8000 chars peut d√©passer la fen√™tre du mod√®le. | Ajouter un compteur de tokens r√©el ou r√©duire la limite de chars pour les langues non-latines. |
| R09-3 | **Perte d'information dans les sections skip** | üü¢ | Les sections < 200 chars sont `"skipped"` et incluses verbatim. Aucune extraction de concepts/types/valeurs n'est effectu√©e pour ces sections. | Impact mineur : les sections tr√®s courtes contiennent rarement des concepts distincts non couverts par les sections parentes. |
| R09-4 | **D√©tection de format de r√©ponse LLM fragile** | üü° | Le parser JSON nettoie les blocs markdown mais ne g√®re pas tous les cas de malformation (ex : JSON avec commentaires, trailing commas). | Le fallback vers extraction manuelle (`response[:max_chars]`) garantit qu'un r√©sum√© est toujours produit, m√™me si les m√©tadonn√©es (concepts, types) sont perdues. |
| R09-5 | **Mod√®le LLM hardcod√©** | üü¢ | Le mod√®le `"gpt-4o-mini"` est hardcod√© dans `_call_openai_style()` et dans les m√©tadonn√©es de `GlobalView`. Pas de routing via `llm_models.yaml`. | Acceptable pour V2 beta. √Ä int√©grer au `LLMRouter` pour la production. |
| R09-6 | **Pas de cache des r√©sum√©s** | üü° | Chaque ex√©cution de Pass 0.9 recalcule tous les r√©sum√©s de section, m√™me pour un document d√©j√† trait√©. Pas de persistance des `SectionSummary`. | Ajouter un cache bas√© sur `hash(section_text)` pour √©viter les appels LLM redondants lors de re-traitements. |
| R09-7 | **Fourchette de taille plus large que l'ADR** | üü¢ | L'ADR sp√©cifie 15-25K chars, l'impl√©mentation accepte 5K-30K. | La fourchette √©largie est pragmatique pour g√©rer les documents tr√®s courts (< 15K) et tr√®s longs (> 25K). Le `meta_document_target_chars = 20000` reste dans la cible ADR. |

---

## 9. Pass 1.1 ‚Äî Analyse Documentaire

**Fichier principal :** `src/knowbase/stratified/pass1/document_analyzer.py` ‚Äî classe `DocumentAnalyzerV2`
**Orchestration :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî `Pass1OrchestratorV2.process()`, lignes 227-251
**Schema Structured Output :** `src/knowbase/stratified/pass1/llm_schemas.py` ‚Äî `DocumentAnalysisResponse`

### 9.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `doc_title` | `str` | Pass 0 | Titre du document extrait |
| `content` / `analysis_content` | `str` | Pass 0.9 ou Pass 0 | **Changement cl√© V2 :** si Pass 0.9 actif, le contenu analys√© est le `meta-document` (vue globale comprim√©e 15-25K chars). Sinon, le contenu brut complet est utilis√©. |
| `toc` / `toc_for_analysis` | `Optional[str]` | Pass 0 / Pass 0.9 | Table des mati√®res. Si `global_view.toc_enhanced` disponible (depuis Pass 0.9), elle remplace la TOC brute. Sinon, extraction heuristique via `extract_toc_from_content()`. |
| `char_limit` | `int` | Config (d√©faut: 4000) | Limite de caract√®res pour le preview envoy√© au LLM |

### 9.2 Objectifs

Pass 1.1 r√©alise l'analyse structurelle de haut niveau du document selon l'approche **top-down** (AV2-7). Les trois sorties principales sont :

1. **Subject** ‚Äî R√©sum√© du sujet principal en 1 phrase, avec un nom court (5-10 mots) d√©riv√© automatiquement si non fourni par le LLM.
2. **DocumentStructure** ‚Äî Classification de la structure de d√©pendance du document selon 3 types universels issus de l'ADR Mod√®le de Lecture Stratifi√©e :
   - **CENTRAL** : assertions d√©pendantes d'un artefact unique (ex : guide produit SAP). Test : ¬´ sans X, ce document a-t-il un sens ? ¬ª ‚Üí NON.
   - **TRANSVERSAL** : assertions ind√©pendantes du contexte (ex : r√©glementation GDPR). Test : remplacer le nom propre ‚Üí assertion reste vraie.
   - **CONTEXTUAL** : assertions conditionnelles, vraies uniquement sous certaines conditions.
3. **Themes** ‚Äî Liste des th√®mes majeurs (5-10 maximum) identifi√©s dans le document.

**Sortie annexe :** d√©tection du flag `is_hostile` si le nombre de th√®mes d√©passe `HOSTILE_SUBJECT_THRESHOLD = 10`, indiquant un document multi-sujet probl√©matique.

### 9.3 M√©canismes

#### 9.3.1 Appel LLM

L'analyse est **enti√®rement d√©l√©gu√©e au LLM** (pas d'algorithme heuristique en mode production) :

1. **Pr√©paration du preview** : `content[:char_limit]` (4000 chars par d√©faut)
2. **Chargement des prompts** depuis `src/knowbase/stratified/prompts/pass1_prompts.yaml` (cl√© `document_analysis`), avec fallback sur prompts par d√©faut int√©gr√©s √† la classe
3. **G√©n√©ration** : appel `llm_client.generate(system_prompt, user_prompt, max_tokens=1500)`
4. **Parsing** : extraction du bloc JSON (````json ... ````) ou parsing direct de la r√©ponse

**Schema Structured Output (Volet B) :**

```python
class DocumentAnalysisResponse(BaseModel):
    subject_name: str    # max 50 chars ‚Äî Nom court (5-10 mots)
    subject: str         # max 200 chars ‚Äî R√©sum√© 1 phrase
    structure: StructureInfo  # chosen: CENTRAL|TRANSVERSAL|CONTEXTUAL + justification
    themes: List[str]    # max 10 th√®mes
    language: LanguageEnum  # fr|en|de
```

Ce schema est utilisable avec vLLM Structured Outputs (`response_format={"type": "json_schema"}`) pour garantir la structure JSON.

#### 9.3.2 Validation et conversion

La m√©thode `_validate_and_convert()` transforme la r√©ponse LLM en objets Pydantic V2 :

- **Subject** : cr√©ation avec `subject_id = f"subj_{doc_id}"`, structure de d√©pendance pars√©e, justification optionnelle, langue d√©tect√©e
- **Themes** : chaque th√®me re√ßoit un `theme_id = f"theme_{doc_id}_{idx}"`. Le champ `scoped_to_sections` est initialis√© vide (sera rempli ult√©rieurement).
- **D√©rivation du nom court** : si le LLM ne fournit pas `subject_name`, il est d√©riv√© du texte du sujet (premiers mots avant la premi√®re virgule ou le premier point, tronqu√© √† 80 chars)

#### 9.3.3 D√©tection de documents HOSTILE

Apr√®s l'analyse LLM, un test post-hoc v√©rifie si le document est "hostile" :

```python
is_hostile = len(themes) > HOSTILE_SUBJECT_THRESHOLD  # seuil = 10
```

Un document hostile est un document multi-sujet qui rend l'identification de concepts difficile. Le flag `is_hostile` est propag√© √† Pass 1.2 o√π il **r√©duit le budget de concepts de moiti√©**.

#### 9.3.4 Mode fallback (tests uniquement)

Si `allow_fallback=True` et aucun LLM n'est disponible, un mode heuristique est activ√© :

- **Structure** : d√©tection par mots-cl√©s dans le titre (`guide`, `product` ‚Üí CENTRAL ; `regulation`, `gdpr` ‚Üí TRANSVERSAL ; sinon ‚Üí CONTEXTUAL)
- **Langue** : d√©tection par comptage de stop-words (fr/en/de) sur les 5000 premiers caract√®res
- **Th√®mes** : 3 th√®mes g√©n√©riques (Introduction, Contenu Principal, Conclusion)

**‚ö†Ô∏è Ce mode est r√©serv√© aux tests unitaires** ‚Äî en production, l'absence de LLM provoque une `RuntimeError` explicite.

#### 9.3.5 Extraction de TOC heuristique

La m√©thode `extract_toc_from_content()` tente d'extraire une table des mati√®res du contenu brut :

- D√©tection de l'en-t√™te TOC (regex multilingue : ¬´ table of contents ¬ª, ¬´ sommaire ¬ª, ¬´ table des mati√®res ¬ª)
- Extraction des lignes de format `N.N.N Titre` apr√®s l'en-t√™te
- Arr√™t √† la premi√®re ligne vide apr√®s ‚â•3 entr√©es de TOC

### 9.4 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `subject` | `Subject` | Sujet avec `subject_id`, `name`, `text`, `structure`, `language`, `justification` | Pass 1.2 (context pour concepts), Pass1Result |
| `themes` | `List[Theme]` | Liste de th√®mes avec `theme_id`, `name`, `scoped_to_sections=[]` | Pass 1.2 (rattachement concepts), Pass1Result |
| `is_hostile` | `bool` | Flag document multi-sujet (>10 th√®mes) | Pass 1.2 (r√©duction budget concepts) |

### 9.5 Conformit√© ADR ‚Äî Pass 1.1

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| AV2-7 | **Top-down** | ‚úÖ | Pass 1.1 est la premi√®re phase s√©mantique, √©tablissant Subject et Themes avant toute identification de concepts. | Conforme √† l'inversion de flux V1 ‚Üí V2 (bottom-up ‚Üí top-down). |
| AV2-1 | **S√©paration structure/s√©mantique** | ‚úÖ | Subject et Themes sont des entit√©s purement s√©mantiques, sans lien direct avec la structure documentaire (Section, DocItem). | Les Themes ont un champ `scoped_to_sections` mais il est initialis√© vide √† ce stade. |
| NS-2 | **LLM = Extracteur** | ‚úÖ | Le LLM identifie sujet, structure et th√®mes ‚Äî il n'inf√®re pas de relations causales ni ne r√©sout de contradictions. | L'analyse est descriptive et observationnelle. |
| P09-6 | **Int√©gration Pass 0.9** | ‚úÖ | Si Pass 0.9 actif, `analysis_content = global_view.meta_document` et `toc_for_analysis = global_view.toc_enhanced`. | Fallback automatique sur contenu brut si GlobalView absente. |

### 9.6 Risques ‚Äî Pass 1.1

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R11-1 | **Preview tronqu√© √† 4000 chars** | üü° | Seuls les 4000 premiers caract√®res du contenu (ou du meta-document) sont envoy√©s au LLM. Pour des documents longs, les th√®mes en fin de document peuvent √™tre manqu√©s. | Compens√© par l'utilisation du meta-document Pass 0.9 qui comprime tout le document en 15-25K chars. La TOC (brute ou enrichie) fournit une vue d'ensemble additionnelle. |
| R11-2 | **Seuil HOSTILE fixe** | üü¢ | Le seuil de 10 th√®mes est arbitraire et non adaptatif √† la taille du document. Un document de 500 pages avec 11 th√®mes est flagg√© hostile comme un document de 10 pages. | Impact mineur : le flag hostile r√©duit le budget concepts (Pass 1.2) mais n'emp√™che pas le traitement. |
| R11-3 | **Pas de validation crois√©e structure/contenu** | üü° | La classification CENTRAL/TRANSVERSAL/CONTEXTUAL repose uniquement sur le jugement LLM. Aucune v√©rification algorithmique n'est effectu√©e. | Le champ `justification` permet un audit humain. L'impact est limit√© car la structure influence principalement le budget de concepts. |
| R11-4 | **Fallback analyse = donn√©es non fiables** | üü¢ | Le mode fallback produit 3 th√®mes g√©n√©riques et un sujet d√©riv√© du titre. | Le fallback est strictement r√©serv√© aux tests (`allow_fallback=True`). En production, une `RuntimeError` est lev√©e. |
| R11-5 | **Pas de d√©tection de langue robuste** | üü° | La d√©tection heuristique (comptage de stop-words) est utilis√©e uniquement en fallback. En mode LLM, la langue est d√©clar√©e par le mod√®le sans validation. | Risque faible : les documents sont g√©n√©ralement dans une langue connue (fr/en/de). |

---

## 10. Pass 1.2 ‚Äî Identification des Concepts

**Fichier principal :** `src/knowbase/stratified/pass1/concept_identifier.py` ‚Äî classe `ConceptIdentifierV2`
**Raffinement it√©ratif :** `src/knowbase/stratified/pass1/concept_refiner.py` ‚Äî classe `ConceptRefinerV2` (Pass 1.2b)
**Orchestration :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî `Pass1OrchestratorV2.process()`, lignes 253-275 (Pass 1.2) et 399-533 (Pass 1.2b)
**Schema Structured Output :** `src/knowbase/stratified/pass1/llm_schemas.py` ‚Äî `ConceptIdentificationResponse`
**Note :** le fichier `trigger_enricher.py` mentionn√© dans la spec n'existe pas ‚Äî la validation et l'enrichissement des triggers lexicaux sont int√©gr√©s directement dans `ConceptIdentifierV2` (m√©thodes `_validate_lexical_triggers`, `_validate_role_requirements`, `_get_top_frequent_tokens`).

### 10.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `subject_text` | `str` | Pass 1.1 | Texte du sujet identifi√© |
| `structure` | `str` | Pass 1.1 | Structure de d√©pendance (`CENTRAL`, `TRANSVERSAL`, `CONTEXTUAL`) |
| `themes` | `List[Theme]` | Pass 1.1 | Th√®mes identifi√©s pour rattachement des concepts |
| `content` / `analysis_content` | `str` | Pass 0.9 ou Pass 0 | Contenu analys√© (meta-document ou contenu brut) |
| `is_hostile` | `bool` | Pass 1.1 | Flag document multi-sujet (r√©duit le budget de moiti√©) |
| `language` | `str` | Pass 1.1 | Langue du document (`fr`, `en`, `de`) |
| `n_sections` | `Optional[int]` | Pass 0 Structural | Nombre de sections pour le calcul du budget adaptatif |

### 10.2 Objectifs

Pass 1.2 identifie les **ConceptSitu√©s** du document ‚Äî des unit√©s conceptuelles frugales, sp√©cifiques et ancr√©es dans le texte. L'objectif est conforme aux principes ARCH V2 :

1. **Frugalit√© (AV2-6)** ‚Äî Initialement 5-15 concepts par document, √©tendu √† un **budget adaptatif** (V2.2, 2026-01-27) calcul√© dynamiquement selon la taille du document.
2. **Rattachement aux th√®mes** ‚Äî Chaque concept est obligatoirement li√© √† un th√®me identifi√© en Pass 1.1.
3. **R√¥le typ√©** ‚Äî Chaque concept re√ßoit un r√¥le : `CENTRAL` (c≈ìur du document), `STANDARD` (important secondaire), `CONTEXTUAL` (contexte).
4. **Lexical triggers obligatoires (C1)** ‚Äî Chaque concept doit poss√©der 2-4 tokens discriminants pr√©sents dans le texte, v√©rifi√©s par un algorithme de validation multi-crit√®res.
5. **Anti-aspirateurs (C1b)** ‚Äî Validation que les triggers ne sont pas trop fr√©quents (top 50 tokens du document), emp√™chant les concepts "aspirateurs" qui captent trop d'assertions.

### 10.3 M√©canismes

#### 10.3.1 Budget adaptatif (V2.2)

Le budget de concepts n'est plus fixe mais calcul√© dynamiquement :

```python
def compute_concept_budget(n_sections: int, is_hostile: bool = False) -> int:
    # Formule: clamp(20, 40, 15 + sqrt(sections) * 3)
    raw_budget = 15 + math.sqrt(n_sections) * 3
    budget = max(20, min(40, round(raw_budget)))
    if is_hostile:
        budget = max(10, budget // 2)
    return budget
```

**Propri√©t√©s cl√©s :**
- Croissance **sub-lin√©aire** : 4√ó sections ‚Üí ~2√ó concepts
- Plancher 20 concepts (petits documents)
- Plafond 40 concepts (limit√© par le contexte vLLM √† 8192 tokens input+output)
- Documents hostiles : budget divis√© par 2 (minimum 10)

| Sections | Budget normal | Budget hostile |
|----------|--------------|----------------|
| 20 | 28 | 14 |
| 50 | 36 | 18 |
| 100 | 45 ‚Üí 40 (cap) | 20 |
| 200+ | 40 (cap) | 20 |

**Fallback** si `n_sections` non fourni : 30 (normal) ou 10 (hostile).

#### 10.3.2 Appel LLM ‚Äî Identification initiale

1. **Chargement des prompts** depuis `pass1_prompts.yaml` (cl√© `concept_identification`)
2. **Formatage** : sujet, structure, th√®mes format√©s, contenu tronqu√© √† 5000 chars
3. **G√©n√©ration** : `llm_client.generate(max_tokens=4000)` ‚Äî limit√© car vLLM context = 8192 tokens (input + output)
4. **Prompt syst√®me compact** (ADR: LLM Contract) : instructions minimalistes pour √©viter la g√©n√©ration verbose et les troncatures JSON

**Schema Structured Output (Volet B) :**

```python
class ConceptIdentificationResponse(BaseModel):
    concepts: List[ConceptCompact]     # max 100 (V2.2: adaptatif jusqu'√† 80)
    refused_terms: List[RefusedTerm]   # max 20
```

O√π chaque `ConceptCompact` contient : `name` (max 50 chars, 2-4 mots), `role` (CENTRAL|STANDARD|CONTEXTUAL), `theme` (rattachement).

#### 10.3.3 Parsing et validation robuste

La m√©thode `_parse_response()` int√®gre plusieurs garde-fous :

1. **D√©tection de troncature JSON** : si le JSON ne se termine pas par `}` ou `]`, une `ValueError` explicite est lev√©e avec le contexte (¬´ LLM Contract Violation: JSON tronqu√© ¬ª)
2. **Nettoyage JSON** (`_clean_json_string`) : suppression des trailing commas, commentaires `//` et `/* */`, remplacement des single quotes ‚Äî n√©cessaire pour les mod√®les locaux (Qwen) qui g√©n√®rent parfois du JSON invalide
3. **D√©duplication par nom** : √©limination des doublons (le LLM peut renvoyer le m√™me concept plusieurs fois), avec r√©indexation des `concept_id` apr√®s d√©duplication

#### 10.3.4 Validation des lexical triggers (C1, C1b, C1c)

La m√©thode `_validate_lexical_triggers()` applique un pipeline de validation multi-crit√®res pour chaque trigger :

**√âtape 1 ‚Äî Calcul des tokens fr√©quents** (`_get_top_frequent_tokens`) :
- Tokenisation simple (mots alphanum√©riques ‚â• 3 chars)
- Comptage par `Counter`, extraction du top 50

**√âtape 2 ‚Äî Validation individuelle de chaque trigger** :

| Crit√®re | Code | Description | Action si √©chec |
|---------|------|-------------|-----------------|
| **C1b: Longueur minimale** | `len(t) < 3` | Trigger trop court (< 3 chars), sauf patterns valeur (`VALUE_PATTERN`) | Rejet du trigger |
| **C1b: Anti-fr√©quent** | `t_lower in top_50_tokens` | Trigger dans le top 50 des tokens les plus fr√©quents du document | Rejet du trigger |
| **C1c: Pr√©sence dans le texte** | `re.search(pattern, doc_lower)` | Pour alphanum√©rique : matching word-boundary (`\b`). Pour valeurs : matching substring. | Rejet du trigger |
| **C1b: Raret√©** | `freq_rate < 0.01` | Fr√©quence d'apparition dans les unit√©s < 1% | Marqu√© `rare=True` |
| **C1b: Semi-raret√©** | `freq_rate < 0.02` | Fr√©quence < 2% | Marqu√© `rare='semi-rare'` |
| **C1b: Valeur discriminante** | `VALUE_PATTERN.match(t)` | Patterns num√©riques (versions, %, ¬∞C, ratios) sont consid√©r√©s discriminants | Marqu√© `rare='fallback_value'` |

Le `VALUE_PATTERN` reconna√Æt : `^\d+(\.\d+)*[%¬∞]?[CFc]?$` et `^\d+[:\-]\d+$`.

**√âtape 3 ‚Äî Verdict final** :
- **Concept accept√©** si ‚â• 2 triggers valides ET au moins 1 trigger rare OU semi-rare
- Sinon ‚Üí concept ajout√© √† la liste `refused_terms`

**√âtape 4 ‚Äî D√©gradation de r√¥le** (`_validate_role_requirements`) :

La validation des triggers influence le r√¥le du concept via des r√®gles de d√©gradation :

```
CENTRAL demand√© + pas de trigger rare ‚Üí d√©grad√© √† STANDARD
CENTRAL demand√© + pas de trigger rare ni semi-rare ‚Üí d√©grad√© √† CONTEXTUAL
STANDARD demand√© + pas de trigger discriminant ‚Üí d√©grad√© √† CONTEXTUAL
```

Cette m√©canique emp√™che les concepts "aspirateurs" (ex : ¬´ infrastructure SAP ¬ª) avec des triggers trop g√©n√©riques de recevoir un r√¥le CENTRAL.

#### 10.3.5 Garde-fou frugalit√©

Apr√®s la validation des triggers, un dernier garde-fou applique la limite du budget :

```python
if len(concepts) > max_concepts:
    concepts = self._apply_frugality(concepts, max_concepts)
```

La m√©thode `_apply_frugality()` trie par r√¥le (`CENTRAL > STANDARD > CONTEXTUAL`) et tronque au budget.

#### 10.3.6 G√©n√©ration de cl√© lexicale

Chaque concept re√ßoit une `lex_key` normalis√©e pour la d√©duplication future :

```python
def _generate_lex_key(name: str) -> str:
    lex = name.lower().strip()
    lex = re.sub(r'\s+', '_', lex)
    lex = re.sub(r'[^a-z0-9_]', '', lex)
    return lex
```

### 10.4 Pass 1.2b ‚Äî Raffinement it√©ratif des concepts (V2.1)

**Fichier :** `src/knowbase/stratified/pass1/concept_refiner.py` ‚Äî classe `ConceptRefinerV2`
**Activation :** flag `enable_pass12b=True` dans `Pass1OrchestratorV2` (d√©faut : activ√©)
**D√©clenchement :** apr√®s Pass 1.3 (extraction assertions) et Pass 1.4 (promotion), quand le taux de `NO_CONCEPT_MATCH` est trop √©lev√©

#### 10.4.1 Principe

Pass 1.2b est une **boucle de r√©troaction** qui analyse les assertions non-li√©es √† un concept (statut `ABSTAINED`, raison `no_concept_match`) pour identifier les concepts manquants. Il op√®re **sans relire le document**, uniquement √† partir du journal d'assertions.

#### 10.4.2 M√©triques de saturation

La classe `SaturationMetrics` (dataclass) calcule les indicateurs de d√©cision :

| M√©trique | Formule | Description |
|----------|---------|-------------|
| `promotion_rate` | `promoted / total_assertions` | Taux de promotion global |
| `no_concept_match_rate` | `no_concept_match / total_assertions` | **C4 : ratio stable** (vs /abstained dans V1) |
| `coverage_rate` | `promoted / (promoted + no_concept_match)` | Couverture conceptuelle |
| `quality_unlinked_count` | `prescriptive_unlinked + value_bearing_unlinked` | **C2 : assertions de qualit√© non-li√©es** |
| `should_iterate` | `rate > 10% AND count > 20` | **C4 : d√©clencheur stable** |

#### 10.4.3 Crit√®res de qualit√© (C2, C2b)

Seules les assertions "de qualit√©" sont consid√©r√©es pour justifier de nouveaux concepts :

- **C2 ‚Äî Assertions PRESCRIPTIVE** : type PRESCRIPTIVE explicite
- **C2 ‚Äî Assertions value-bearing** : contiennent une valeur quantifiable (versions, pourcentages, tailles, temp√©ratures, dur√©es, montants, ratios) d√©tect√©e par 7 patterns regex
- **C2b ‚Äî Obligations sans modal** : d√©tection de 10 patterns d'obligations implicites (juridique/contrats) comme ¬´ is required to ¬ª, ¬´ no later than ¬ª, ¬´ within N days ¬ª, ¬´ ne peut pas ¬ª

#### 10.4.4 Boucle it√©rative

L'orchestrateur ex√©cute la boucle suivante (dans `process()`, lignes 399-533) :

```
TANT QUE saturation.should_iterate:
  1. Calculer SaturationMetrics depuis assertion_log
  2. V√©rifier C4: rate > 10% ET count > 20
  3. Si rendement d√©croissant (< 15% r√©duction) ‚Üí ARR√äT
  4. Filtrer assertions de qualit√© (C2, C2b)
  5. Appeler ConceptRefinerV2.refine_concepts()
     ‚Üí LLM identifie concepts manquants depuis assertions non-li√©es
  6. Valider C2: chaque concept doit couvrir ‚â•2 assertions dont ‚â•1 PRESCRIPTIVE/value
  7. D√©duplication vs concepts existants et doublons internes
  8. Ajouter les nouveaux concepts √† la liste
  9. Re-linker les assertions non-li√©es avec tous les concepts (anciens + nouveaux)
  10. Re-r√©soudre les ancrages (AnchorResolver)
  11. Mettre √† jour assertion_log (ABSTAINED ‚Üí PROMOTED)
```

**Garde-fous de convergence :**

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `MAX_ITERATIONS` | 3 | Maximum d'it√©rations |
| `MAX_NEW_CONCEPTS_PER_ITER` | 10 | Concepts ajout√©s par it√©ration |
| `MAX_TOTAL_CONCEPTS` | 50 | Surface conceptuelle maximale |
| `MIN_NO_CONCEPT_MATCH` | 20 | Minimum de trous pour d√©clencher |
| `MIN_REDUCTION_RATE` | 0.15 | Gain minimum pour continuer (15%) |

#### 10.4.5 Validation des concepts raffin√©s (C2)

Chaque concept propos√© par le LLM est valid√© par `_validate_concept_quality()` :

1. Le concept doit avoir des `lexical_triggers` (‚â• 2)
2. Ces triggers doivent matcher ‚â• 2 assertions non-li√©es
3. Parmi ces assertions, ‚â• 1 doit √™tre de qualit√© (PRESCRIPTIVE ou value-bearing)

### 10.5 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `concepts` | `List[Concept]` | Concepts avec `concept_id`, `theme_id`, `name`, `role`, `lex_key`, `lexical_triggers`, `definition`, `variants` | Pass 1.3 (linking assertions), Pass 1.2b (base pour raffinement), Pass1Result |
| `refused_terms` | `List[Dict]` | Termes refus√©s avec raisons (triggers invalides, trop g√©n√©riques, etc.) | Audit, Pass1Result |
| `saturation` (via Pass 1.2b) | `SaturationMetrics` | M√©triques de couverture conceptuelle finales | Logs, diagnostic |

**Structure d'un Concept :**

```python
Concept(
    concept_id="concept_doc123_0",   # ID unique
    theme_id="theme_doc123_2",       # Rattachement th√®me
    name="TLS Configuration",        # Nom court (2-4 mots)
    role=ConceptRole.CENTRAL,        # CENTRAL | STANDARD | CONTEXTUAL
    definition=None,                 # Optionnel (enrichi en Pass 2)
    variants=[],                     # Optionnel (enrichi en Pass 2)
    lex_key="tls_configuration",     # Cl√© normalis√©e pour d√©dup
    lexical_triggers=["TLS", "1.3", "cipher suite"]  # 2-4 tokens discriminants
)
```

### 10.6 Conformit√© ADR ‚Äî Pass 1.2

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| AV2-6 | **Frugalit√© concepts (5-15 max)** | ‚ö†Ô∏è | Le budget adaptatif (V2.2) √©tend la fourchette √† [20, 40] pour l'identification initiale, plus jusqu'√† 50 via Pass 1.2b. | **D√©viation document√©e.** L'ADR initiale sp√©cifiait 5-15. L'extension √† 20-40 (+ 50 max avec 1.2b) est motiv√©e par la n√©cessit√© de couvrir des documents volumineux (>100 sections). La croissance sub-lin√©aire (`sqrt`) maintient l'esprit de frugalit√©. |
| AV2-7 | **Top-down** | ‚úÖ | Les concepts sont identifi√©s APR√àS le sujet et les th√®mes (Pass 1.1). Chaque concept est rattach√© √† un th√®me existant. | Conforme √† l'approche top-down. |
| NS-2 | **LLM = Extracteur** | ‚úÖ | Le LLM identifie les concepts depuis le texte. La validation (C1, C1b, C1c) est algorithmique (post-LLM). | Le LLM extrait, les algorithmes valident. |
| NS-7 | **Addressability-First** | ‚úÖ | Chaque concept est rattach√© √† au moins un th√®me (`theme_id`). Les `lexical_triggers` garantissent l'ancrage textuel. | Les concepts sans triggers valides sont rejet√©s. |
| P09-6 | **Int√©gration Pass 0.9** | ‚úÖ | L'identification utilise `analysis_content` (meta-document si Pass 0.9 actif). Le budget adaptatif utilise `n_sections` depuis Pass 0 Structural. | Double int√©gration : contenu comprim√© + budget bas√© sur la structure. |

### 10.7 Risques ‚Äî Pass 1.2

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R12-1 | **Budget √©tendu vs frugalit√© ADR** | üü° | Le budget adaptatif [20-40] + raffinement it√©ratif (‚Üí50 max) d√©passe significativement la fourchette ADR initiale de 5-15 concepts. | La croissance sub-lin√©aire (`sqrt`) et les garde-fous de convergence (max 3 it√©rations, min 15% r√©duction) limitent l'expansion. Le cap √† 50 concepts reste bien en-de√ß√† du legacy (~4700 nodes/doc). |
| R12-2 | **Troncature JSON (LLM Contract)** | üü° | Le contexte vLLM de 8192 tokens (input+output) peut √™tre insuffisant pour g√©n√©rer 40 concepts avec triggers. Le contenu est tronqu√© √† 5000 chars, les tokens de sortie limit√©s √† 4000. | D√©tection explicite de troncature (`ValueError` lev√©e). Le prompt syst√®me compact (ADR: LLM Contract) minimise la verbosit√©. Les Structured Outputs (Volet B) garantissent la structure JSON c√¥t√© vLLM. |
| R12-3 | **Triggers trop permissifs pour petits documents** | üü° | Pour les documents avec peu d'unit√©s (< 100), le seuil de raret√© < 1% devient tr√®s strict (< 1 unit√©). Cela peut rejeter des triggers l√©gitimes. | Le fallback `semi-rare` (< 2%) et le fallback `value` (patterns num√©riques) assouplissent la validation pour les petits corpus. |
| R12-4 | **Pass 1.2b : risque de concepts de faible valeur** | üü° | Le raffinement it√©ratif peut introduire des concepts de faible discriminance, car les assertions restantes (NO_CONCEPT_MATCH) sont par d√©finition les plus difficiles √† rattacher. | Le crit√®re C2 (‚â•2 assertions dont ‚â•1 PRESCRIPTIVE/value) et la validation de qualit√© limitent ce risque. Le cap √† 50 concepts max et le rendement d√©croissant (min 15%) assurent la convergence. |
| R12-5 | **Doublons entre LLM et raffinement** | üü¢ | Le LLM (Qwen notamment) peut reproposer des concepts d√©j√† existants lors du raffinement. | D√©duplication par nom normalis√© impl√©ment√©e √† la fois dans `_validate_and_convert()` (Pass 1.2) et `refine_concepts()` (Pass 1.2b). |
| R12-6 | **Pas de trigger_enricher.py s√©par√©** | üü¢ | L'enrichissement des triggers (TF-IDF, embedding) mentionn√© dans certains documents de design n'est pas impl√©ment√© comme composant s√©par√©. La validation est int√©gr√©e dans `ConceptIdentifierV2`. | L'impl√©mentation actuelle (fr√©quence, raret√©, word-boundary) est fonctionnelle. L'enrichissement par TF-IDF/embedding pourrait √™tre ajout√© en V3 comme composant s√©par√©. |
| R12-7 | **Nettoyage JSON fragile** | üü¢ | Le nettoyage des trailing commas et single quotes par regex peut √©chouer sur du JSON fortement malform√©. | Le nettoyage couvre les cas les plus fr√©quents (Qwen). Les Structured Outputs (Volet B) √©liminent ce risque quand activ√©s. |

---

## 11. Pass 1.3 ‚Äî Extraction d'Assertions

<!-- √Ä compl√©ter : analyse d√©taill√©e de assertion_extractor.py, verbatim_validator.py -->

---

## 12. Pass 1.3b ‚Äî R√©solution d'Ancrage

<!-- √Ä compl√©ter : analyse d√©taill√©e de anchor_resolver.py -->

---

## 13. Pass 1.4 ‚Äî Promotion et Value Contract

<!-- √Ä compl√©ter : analyse d√©taill√©e de promotion_engine.py, value_extractor.py, claimkey/ -->

---

## 14. Pass 2 ‚Äî Enrichissement S√©mantique

<!-- √Ä compl√©ter : analyse d√©taill√©e de pass2/ -->

---

## 15. Pass 3 ‚Äî Consolidation Corpus

<!-- √Ä compl√©ter : analyse d√©taill√©e de pass3/ -->

---

## 16. Orchestration Pipeline

<!-- √Ä compl√©ter : analyse d√©taill√©e de queue/jobs_v2.py, dispatcher.py, burst/orchestrator.py -->

---

## 17. Mod√®le de donn√©es complet

<!-- √Ä compl√©ter : synth√®se du sch√©ma Neo4j V2 et mod√®les Pydantic -->

---

## 18. Synth√®se globale des risques

<!-- √Ä compl√©ter : tableau r√©capitulatif de tous les risques identifi√©s -->

---

## 19. Diagramme d'architecture global

<!-- √Ä compl√©ter : diagramme ASCII complet -->

---

## 20. Conclusion

<!-- √Ä compl√©ter : synth√®se finale -->
