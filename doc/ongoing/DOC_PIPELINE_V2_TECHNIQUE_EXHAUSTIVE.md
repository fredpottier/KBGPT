# Documentation Technique Exhaustive du Pipeline d'Ingestion V2

**Projet:** OSMOSE (Organic Semantic Memory Organization & Smart Extraction)
**Produit:** OSMOSIS
**Statut:** EN COURS DE R√âDACTION
**Date de cr√©ation:** 2026-01-29
**Derni√®re MAJ:** 2026-02-02
**Branche:** `feat/pass1-hybrid-extract-then-structure`

---

## 1. Introduction

### 1.1 Objet du document

Ce document constitue la **r√©f√©rence technique exhaustive** du Pipeline d'Ingestion V2 (Pipeline Stratifi√©) d'OSMOSIS. Il d√©crit, pour chaque phase du pipeline, les entrants, objectifs, m√©canismes/algorithmes retenus et sorties produites.

L'analyse croise syst√©matiquement l'impl√©mentation r√©elle avec les d√©cisions architecturales (ADR) normatives pour identifier les d√©viations et risques par phase.

### 1.2 P√©rim√®tre

Ce document couvre l'int√©gralit√© du pipeline V2, du fichier source jusqu'au graphe s√©mantique consolid√© :

- **Pass 0** ‚Äî Extraction (Docling + Vision Gating V4)
- **Pass 0 Structural** ‚Äî Construction du graphe structurel (Document ‚Üí Section ‚Üí DocItem)
- **Pass 0.5** ‚Äî R√©solution de cor√©f√©rence linguistique
- **Pass 0.9** ‚Äî Construction de la Vue Globale (meta-document)
- **Pass 1.1** ‚Äî Analyse documentaire (Subject, Structure, Themes)
- **Pass 1.2** ‚Äî Identification des concepts frugaux
- **Pass 1.3** ‚Äî Extraction d'assertions typ√©es
- **Pass 1.3b** ‚Äî R√©solution d'ancrage (chunk ‚Üí DocItem)
- **Pass 1.4** ‚Äî Promotion (Assertion ‚Üí Information) + Value Contract + ClaimKey
- **Pass 2** ‚Äî Enrichissement s√©mantique (relations inter-concepts)
- **Pass 3** ‚Äî Consolidation corpus (entity resolution cross-document)

### 1.3 Hors p√©rim√®tre

- Code du pipeline legacy (V1)
- Documentation frontend / UI V2
- Documentation des API endpoints V2
- Correction des d√©viations identifi√©es (seulement documentation)

### 1.4 Conventions

| Convention | Signification |
|------------|---------------|
| ‚úÖ | Conforme √† l'ADR/ARCH de r√©f√©rence |
| ‚ö†Ô∏è | Partiellement conforme ou d√©viation mineure |
| ‚ùå | Non conforme ou non impl√©ment√© |
| üî¥ | Risque critique |
| üü° | Risque mod√©r√© |
| üü¢ | Risque faible ou ma√Ætris√© |

---

## 2. R√©f√©rences normatives

Cette section synth√©tise les axes de v√©rification extraits des 8 documents ADR/ARCH normatifs. Ces axes sont appliqu√©s syst√©matiquement √† chaque phase du pipeline.

### 2.1 ADR North Star ‚Äî V√©rit√© Documentaire Contextualis√©e

**Document source :** `doc/ongoing/ADR_NORTH_STAR_VERITE_DOCUMENTAIRE.md`
**Statut :** ‚úÖ VALID√â COMME NORTH STAR

**Principe fondateur :**

> OSMOSIS est le Knowledge Graph documentaire de l'entreprise et l'arbitre de sa v√©rit√© documentaire : il capture, structure et expose la connaissance telle qu'elle est exprim√©e dans le corpus documentaire, sans jamais extrapoler au-del√† de ce corpus.

**10 axes de v√©rification North Star :**

| # | Axe | Description | Amendement |
|---|-----|-------------|------------|
| NS-1 | **Information-First** | L'Information est l'entit√© primaire, le Concept est optionnel. Z√©ro rejet pour `no_concept_match`. | Amdt 1 r√©vis√© |
| NS-2 | **LLM = Extracteur evidence-locked** | Le LLM extrait, il ne d√©cide pas, n'inf√®re pas, ne r√©sout pas les contradictions. | Amdt 4 |
| NS-3 | **Citation exacte obligatoire** | Toute Information doit inclure `exact_quote` (verbatim) + `span` (page, paragraphe, ligne). | Amdt 4 |
| NS-4 | **Pas de synth√®se cross-source** | Une Information = un document source. Pas de fusion multi-documents dans une Information. | Amdt 4 |
| NS-5 | **ClaimKey comme pivot** | Question factuelle canonique, ind√©pendante du wording, pour comparaison cross-doc. Inf√©rence en 2 niveaux (patterns + LLM assist√©). | Amdt 3 + 5d |
| NS-6 | **Value Contract** | Extraction de valeurs normalis√©es (`raw`, `normalized`, `unit`, `operator`) pour comparaison machine. Statut `comparable: strict\|loose\|non_comparable`. | Amdt 5 |
| NS-7 | **Addressability-First** | Toute Information PROMOTED doit avoir ‚â•1 pivot navigable (Concept, Theme, ClaimKey, SectionPath, Facet). Orphelin total interdit. | Amdt 1 r√©vis√© |
| NS-8 | **Rhetorical Role** | Distinction fait/exemple/analogie/d√©finition/instruction/claim/caution. Exemples et analogies ne g√©n√®rent pas de ClaimKey comparatif. | Amdt 6 |
| NS-9 | **Promotion Policy par type** | ALWAYS (DEFINITIONAL, PRESCRIPTIVE, CAUSAL), CONDITIONAL (FACTUAL, CONDITIONAL, PERMISSIVE), RARELY (COMPARATIVE), NEVER (PROCEDURAL). | ¬ß4 |
| NS-10 | **D√©duplication par fingerprint** | `hash(claimkey + value.normalized + context_key + span_bucket)`. M√™me fait r√©p√©t√© = merge evidence, pas 2 nodes. | Amdt 5c |

### 2.2 ADR Pass 0.9 ‚Äî Global View Construction

**Document source :** `doc/ongoing/ADR_PASS09_GLOBAL_VIEW_CONSTRUCTION.md`
**Statut :** R√©f√©renc√© dans le plan d'impl√©mentation (fichier absent du worktree actuel ‚Äî axes extraits depuis ARCH V2 et spec)

**6 axes de v√©rification Pass 0.9 :**

| # | Axe | Description |
|---|-----|-------------|
| P09-1 | **Couverture 100% sections** | Le meta-document doit couvrir toutes les sections du document source |
| P09-2 | **Compression hi√©rarchique** | Pr√©servation de la structure H1 > H2 > H3 dans la compression |
| P09-3 | **Meta-document 15-25K chars** | Taille cible pour tenir dans le contexte LLM des passes suivantes |
| P09-4 | **95% minimum sections r√©sum√©es** | Seuil de couverture minimale acceptable |
| P09-5 | **Fallback mode (Option C)** | Mode d√©grad√© op√©rationnel si r√©sum√© √©choue |
| P09-6 | **Int√©gration dans Pass 1.1 et 1.2** | Le meta-document alimente l'analyse documentaire et l'identification de concepts |

### 2.3 ARCH Stratified Pipeline V2

**Document source :** `doc/ongoing/ARCH_STRATIFIED_PIPELINE_V2.md`
**Statut :** EN CONCEPTION (valid√© par POC)

**Principes fondateurs :**
1. **Frugalit√©** ‚Äî Moins de nodes, plus de valeur par node (~195 nodes/doc vs ~4700 legacy)
2. **Top-Down** ‚Äî Structure ‚Üí Concepts ‚Üí Informations (inversion du flux V1 bottom-up)
3. **Promotion Policy** ‚Äî Seules les assertions d√©fendables deviennent Information
4. **Overlay** ‚Äî Information = pointeur vers source, pas copie
5. **Ind√©pendance** ‚Äî Pipeline V2 coexiste avec legacy jusqu'√† validation

**10 axes de v√©rification ARCH V2 :**

| # | Axe | Description |
|---|-----|-------------|
| AV2-1 | **S√©paration structure documentaire / s√©mantique** | Structure documentaire (Document, Section, DocItem) ‚â† Structure s√©mantique (Subject, Theme, Concept, Information) |
| AV2-2 | **8 types de nodes maximum** | Document, Section, DocItem, Subject, Theme, Concept, Information, AssertionLog |
| AV2-3 | **Ancrage Information sur DocItem** | Information `-[:ANCHORED_IN]->` DocItem. PAS sur chunk Qdrant. |
| AV2-4 | **DocItem atomique** | DocItem = item Docling natif (paragraph, table-row, list-item, heading, figure-caption). Pas de fusion agressive. |
| AV2-5 | **AssertionLog avec statut enum** | `PROMOTED \| ABSTAINED \| REJECTED` avec `AssertionLogReason` standardis√© (10+ raisons) |
| AV2-6 | **Frugalit√© concepts (5-15 max)** | Garde-fou max 15 concepts par document, refus termes g√©n√©riques et mentions uniques |
| AV2-7 | **Top-down** | Document Analysis (1.1) ‚Üí Concept Identification (1.2) ‚Üí Assertion Extraction (1.3) ‚Üí Linking (1.4) |
| AV2-8 | **Dual storage** | Neo4j (graphe s√©mantique navigable) + Qdrant (TypeAwareChunks retrieval vectoriel) |
| AV2-9 | **Pass 3 mode manuel + batch** | R√©solution d'entit√©s en mode batch ou incr√©mental, pas automatique inline |
| AV2-10 | **< 250 nodes/document** | Estimation ~195 nodes/doc, soit ~4% du legacy |

### 2.4 ADR compl√©mentaires

#### 2.4.1 ADR Mod√®le de Lecture Stratifi√©e

**Document source :** `doc/ongoing/ADR_STRATIFIED_READING_MODEL.md`

Formalise l'inversion du flux V1 ‚Üí V2 (bottom-up ‚Üí top-down). D√©finit les 3 structures universelles de d√©pendance des assertions :

| Structure | D√©finition | Test |
|-----------|------------|------|
| **CENTRAL** | Assertions d√©pendantes d'un artefact unique | "Sans X, ce document a-t-il un sens ?" ‚Üí NON |
| **TRANSVERSAL** | Assertions ind√©pendantes | Remplacer le nom propre ‚Üí assertion reste vraie |
| **CONTEXTUAL** | Assertions conditionnelles | Vraies uniquement sous certaines conditions |

D√©finit les crit√®res de cr√©ation de ConceptSitu√© : ‚â•3 informations distinctes, ‚â•2 types diff√©rents, ‚â•2 sections/sous-th√®mes.

#### 2.4.2 ADR Scope vs Assertion Separation

**Document source :** `doc/ongoing/ADR_SCOPE_VS_ASSERTION_SEPARATION.md`
**Statut :** ‚úÖ APPROVED ‚Äî ARCHITECTURAL FOUNDATION ‚Äî BLOCKING

S√©paration fondamentale entre :
- **Scope Layer** (dense) : Ce que le document couvre ‚Üí Navigation, non traversable
- **Assertion Layer** (sparse) : Ce que le document affirme ‚Üí Raisonnement, traversable

Le Scope mining est un filtre de candidats, pas un g√©n√©rateur d'assertions. Le contexte documentaire (titre, section) ne constitue pas une preuve locale.

#### 2.4.3 ADR Relations Discursivement D√©termin√©es

**Document source :** `doc/ongoing/ADR_DISCURSIVE_RELATIONS.md`
**Statut :** ACCEPTED

Extension pour les relations reconstructibles par un lecteur rigoureux sans connaissance externe :
- `AssertionKind` : EXPLICIT / DISCURSIVE
- `DiscursiveBasis` : ALTERNATIVE, DEFAULT, EXCEPTION, SCOPE, COREF, ENUMERATION
- Whitelist stricte des `RelationType` autoris√©s pour DISCURSIVE (V1)
- Promotion via `DefensibilityTier` : STRICT / EXTENDED

#### 2.4.4 ADR NormativeRule & SpecFact

**Document source :** `doc/ongoing/ADR_NORMATIVE_RULES_SPEC_FACTS.md`
**Statut :** ‚úÖ APPROVED ‚Äî V1

Capture des informations "high-value" non-relationnelles :
- **NormativeRule** : obligations/interdictions avec marqueur modal (MUST, SHOULD, MAY)
- **SpecFact** : valeurs structur√©es issues de tables/listes cl√©-valeur

Extraction pattern-first, preuve locale obligatoire, non-traversable, scope-only applicability.

---

## 3. Table des mati√®res d√©taill√©e

- [1. Introduction](#1-introduction)
- [2. R√©f√©rences normatives](#2-r√©f√©rences-normatives)
  - [2.1 ADR North Star](#21-adr-north-star--v√©rit√©-documentaire-contextualis√©e)
  - [2.2 ADR Pass 0.9](#22-adr-pass-09--global-view-construction)
  - [2.3 ARCH Stratified Pipeline V2](#23-arch-stratified-pipeline-v2)
  - [2.4 ADR compl√©mentaires](#24-adr-compl√©mentaires)
- [4. Vue d'ensemble du Pipeline V2](#4-vue-densemble-du-pipeline-v2)
- [5. Pass 0 ‚Äî Extraction](#5-pass-0--extraction)
  - [5.1 Docling Extraction](#51-docling-extraction)
  - [5.2 Vision Gating V4](#52-vision-gating-v4)
  - [5.3 Vision Path (GPT-4o)](#53-vision-path-gpt-4o)
  - [5.4 Structured Merge](#54-structured-merge)
  - [5.5 Lin√©arisation](#55-lin√©arisation)
  - [5.6 Extraction de Contexte Documentaire](#56-extraction-de-contexte-documentaire)
  - [5.7 Table Summarizer](#57-table-summarizer)
  - [5.8 Cache Versionn√©](#58-cache-versionn√©)
  - [5.9 Conformit√© ADR ‚Äî Pass 0 Extraction](#59-conformit√©-adr--pass-0-extraction)
  - [5.10 Risques ‚Äî Pass 0 Extraction](#510-risques--pass-0-extraction)
- [6. Pass 0 Structural ‚Äî Graphe Structurel](#6-pass-0-structural--graphe-structurel)
  - [6.1 Adapter Docling ‚Üí Schema V2](#61-adapter-docling--schema-v2)
  - [6.2 Construction du graphe (Document, Section, DocItem)](#62-construction-du-graphe-document-section-docitem)
  - [6.3 Conformit√© ADR ‚Äî Pass 0 Structural](#63-conformit√©-adr--pass-0-structural)
  - [6.4 Risques ‚Äî Pass 0 Structural](#64-risques--pass-0-structural)
- [7. Pass 0.5 ‚Äî R√©solution de Cor√©f√©rence Linguistique](#7-pass-05--r√©solution-de-cor√©f√©rence-linguistique)
  - [7.0 Vue d'ensemble Pass 0.5](#70-vue-densemble-pass-05)
  - [7.1 M√©canismes de r√©solution](#71-m√©canismes-de-r√©solution)
  - [7.2 Conformit√© ADR ‚Äî Pass 0.5](#72-conformit√©-adr--pass-05)
  - [7.3 Risques ‚Äî Pass 0.5](#73-risques--pass-05)
- [8. Pass 0.9 ‚Äî Construction de la Vue Globale](#8-pass-09--construction-de-la-vue-globale)
  - [8.1 SectionSummarizer](#81-sectionsummarizer)
  - [8.2 HierarchicalCompressor](#82-hierarchicalcompressor)
  - [8.3 GlobalView (meta-document)](#83-globalview-meta-document)
  - [8.4 Conformit√© ADR ‚Äî Pass 0.9](#84-conformit√©-adr--pass-09)
  - [8.5 Risques ‚Äî Pass 0.9](#85-risques--pass-09)
- [9. Pass 1.1 ‚Äî Analyse Documentaire](#9-pass-11--analyse-documentaire)
  - [9.1 D√©tection de structure (CENTRAL/TRANSVERSAL/CONTEXTUAL)](#91-d√©tection-de-structure)
  - [9.2 Identification Subject et Themes](#92-identification-subject-et-themes)
  - [9.3 Conformit√© ADR ‚Äî Pass 1.1](#93-conformit√©-adr--pass-11)
  - [9.4 Risques ‚Äî Pass 1.1](#94-risques--pass-11)
- [10. Pass 1.2 ‚Äî Identification des Concepts](#10-pass-12--identification-des-concepts)
  - [10.1 Extraction LLM de concepts frugaux](#101-extraction-llm-de-concepts-frugaux)
  - [10.2 Concept Refinement (Pass 1.2b)](#102-concept-refinement-pass-12b)
  - [10.3 Trigger Enrichment TF-IDF + Embedding (Pass 1.2c)](#103-trigger-enrichment-tf-idf--embedding-pass-12c)
  - [10.4 SINK Concept Injection (Pass 1.2d)](#104-sink-concept-injection-pass-12d)
  - [10.5 Conformit√© ADR ‚Äî Pass 1.2](#105-conformit√©-adr--pass-12)
  - [10.6 Risques ‚Äî Pass 1.2](#106-risques--pass-12)
- [11. Pass 1.3 ‚Äî Extraction d'Assertions](#11-pass-13--extraction-dassertions)
  - [11.1 Mode pointeur et extraction par chunk](#111-mode-pointeur-et-extraction-par-chunk)
  - [11.2 Validation verbatim](#112-validation-verbatim)
  - [11.3 Indexation des unit√©s d'assertion](#113-indexation-des-unit√©s-dassertion)
  - [11.4 Conformit√© ADR ‚Äî Pass 1.3](#114-conformit√©-adr--pass-13)
  - [11.5 Risques ‚Äî Pass 1.3](#115-risques--pass-13)
- [12. Pass 1.3b ‚Äî R√©solution d'Ancrage](#12-pass-13b--r√©solution-dancrage)
  - [12.1 Mapping chunk_id ‚Üí docitem_id](#121-mapping-chunk_id--docitem_id)
  - [12.2 Conformit√© ADR ‚Äî Pass 1.3b](#122-conformit√©-adr--pass-13b)
  - [12.3 Risques ‚Äî Pass 1.3b](#123-risques--pass-13b)
- [13. Pass 1.4 ‚Äî Promotion et Value Contract](#13-pass-14--promotion-et-value-contract)
  - [13.1 Promotion Engine (Assertion ‚Üí Information)](#131-promotion-engine-assertion--information)
  - [13.2 Promotion Policy par type d'assertion](#132-promotion-policy-par-type-dassertion)
  - [13.3 Value Extractor (Value Contract)](#133-value-extractor-value-contract)
  - [13.4 ClaimKey ‚Äî Patterns et gestion de statut](#134-claimkey--patterns-et-gestion-de-statut)
  - [13.5 AssertionLog et gouvernance](#135-assertionlog-et-gouvernance)
  - [13.6 Theme Lint (gouvernance th√©matique)](#136-theme-lint-gouvernance-th√©matique)
  - [13.7 Conformit√© ADR ‚Äî Pass 1.4](#137-conformit√©-adr--pass-14)
  - [13.8 Risques ‚Äî Pass 1.4](#138-risques--pass-14)
- [14. Pass 2 ‚Äî Enrichissement S√©mantique](#14-pass-2--enrichissement-s√©mantique)
  - [14.1 Extraction de relations inter-concepts](#141-extraction-de-relations-inter-concepts)
  - [14.2 Types de relations et garde-fous](#142-types-de-relations-et-garde-fous)
  - [14.3 Conformit√© ADR ‚Äî Pass 2](#143-conformit√©-adr--pass-2)
  - [14.4 Risques ‚Äî Pass 2](#144-risques--pass-2)
- [15. Pass 3 ‚Äî Consolidation Corpus](#15-pass-3--consolidation-corpus)
  - [15.1 Entity Resolution (embedding + clustering)](#151-entity-resolution-embedding--clustering)
  - [15.2 Theme Alignment cross-document](#152-theme-alignment-cross-document)
  - [15.3 D√©tection de contradictions](#153-d√©tection-de-contradictions)
  - [15.4 Modes batch et incr√©mental](#154-modes-batch-et-incr√©mental)
  - [15.5 Conformit√© ADR ‚Äî Pass 3](#155-conformit√©-adr--pass-3)
  - [15.6 Risques ‚Äî Pass 3](#156-risques--pass-3)
- [16. Orchestration Pipeline](#16-orchestration-pipeline)
  - [16.1 S√©quencement global](#161-s√©quencement-global)
  - [16.2 Folder Watcher](#162-folder-watcher)
  - [16.3 Dispatcher](#163-dispatcher)
  - [16.4 Modes d'ex√©cution](#164-modes-dex√©cution)
  - [16.5 Feature Flags et configuration](#165-feature-flags-et-configuration)
  - [16.6 Burst Mode (EC2 Spot)](#166-burst-mode-ec2-spot)
  - [16.7 Jobs sp√©cialis√©s](#167-jobs-sp√©cialis√©s)
  - [16.8 Conformit√© ADR ‚Äî Orchestration](#168-conformit√©-adr--orchestration)
  - [16.9 Risques ‚Äî Orchestration](#169-risques--orchestration)
- [17. Mod√®le de donn√©es complet](#17-mod√®le-de-donn√©es-complet)
- [18. Synth√®se globale des risques](#18-synth√®se-globale-des-risques)
  - [18.1 Risques critiques (üî¥)](#181-risques-critiques-)
  - [18.2 Risques mod√©r√©s (üü°)](#182-risques-mod√©r√©s-)
  - [18.3 Risques faibles (üü¢)](#183-risques-faibles-)
  - [18.4 Avertissements architecturaux (‚ö†Ô∏è)](#184-avertissements-architecturaux-)
  - [18.5 Statistiques consolid√©es](#185-statistiques-consolid√©es)
- [19. Diagramme d'architecture global](#19-diagramme-darchitecture-global)
- [20. Conclusion](#20-conclusion)
  - [20.1 Synth√®se](#201-synth√®se)
  - [20.2 Maturit√© du pipeline](#202-maturit√©-du-pipeline)
  - [20.3 Points d'attention prioritaires](#203-points-dattention-prioritaires)
  - [20.4 Prochaines √©tapes](#204-prochaines-√©tapes)

---

## 4. Vue d'ensemble du Pipeline V2

<!-- √Ä compl√©ter : diagramme ASCII du flux global Pass 0 ‚Üí 0.5 ‚Üí 0.9 ‚Üí 1.x ‚Üí 2 ‚Üí 3 -->

---

## 5. Pass 0 ‚Äî Extraction

### 5.0 Vue d'ensemble Pass 0

**Fichier orchestrateur :** `src/knowbase/extraction_v2/pipeline.py` ‚Äî classe `ExtractionPipelineV2`

**Objectif :** Transformer un fichier source (PDF, DOCX, PPTX, XLSX, Image) en un `ExtractionResult` structur√© contenant :
- `full_text` lin√©aris√© avec marqueurs s√©mantiques (pour les passes suivantes)
- `structure` compl√®te (pages, blocs, tables, enrichissements Vision)
- `doc_context` (DocContextFrame ‚Äî marqueurs de version, scope documentaire)
- `page_index` (mapping offsets ‚Üí pages pour tra√ßabilit√©)
- `gating_decisions` et `vision_results` (audit du path Vision)

**Entrants :**

| Entrant | Type | Description |
|---------|------|-------------|
| `file_path` | `str` | Chemin vers le fichier source |
| `document_id` | `str` (optionnel) | ID unique du document (g√©n√©r√© via SHA256 si absent) |
| `tenant_id` | `str` (optionnel) | Tenant pour Domain Context (d√©faut : `"default"`) |

**S√©quence d'ex√©cution (8 √©tapes) :**

```
√âtape 1: Cache Check (VersionedCache)
  ‚Üì miss
√âtape 2: Extraction Docling ‚Üí List[VisionUnit]
  ‚Üì
√âtape 3: Vision Gating V4 ‚Üí List[GatingDecision]
  ‚Üì
√âtape 4: Vision Path GPT-4o (parall√®le, semaphore) ‚Üí Dict[int, VisionExtraction]
  ‚Üì
√âtape 4.5: Vision Semantic Reader (parall√®le) ‚Üí Dict[int, VisionSemanticResult]
  ‚Üì
√âtape 5: Structured Merge ‚Üí List[MergedPageOutput]
  ‚Üì
√âtape 5.5: Table Summaries (QW-1, batch) ‚Üí summaries attach√©es aux TableData
  ‚Üì
√âtape 6: Lin√©arisation ‚Üí (full_text, page_index)
  ‚Üì
√âtape 7: DocContext Extraction (6a: DocumentContext + 6b: DocContextFrame)
  ‚Üì
√âtape 8: Structural Graph (Option C) ‚Üí StructuralGraphBuildResult
  ‚Üì
√âtape 8.25: Enrichissement FIGURE_TEXT avec Vision Semantic
  ‚Üì
√âtape 8.5: Pass 0.5 Linguistic Coref (si non-V2)
  ‚Üì
Construction ExtractionResult + Cache Save
```

**Configuration :** `PipelineConfig` (dataclass avec ~20 param√®tres) ‚Äî tous les composants sont activables/d√©sactivables via flags bool√©ens.

**M√©triques :** `PipelineMetrics` (dataclass) ‚Äî temps par √©tape, compteurs de pages, taux de succ√®s Vision, etc.

---

### 5.1 Docling Extraction

**Fichier :** `src/knowbase/extraction_v2/extractors/docling_extractor.py` ‚Äî classe `DoclingExtractor`

**Objectif :** Convertir tout fichier source en une liste normalis√©e de `VisionUnit` (une par page/slide) via la biblioth√®que Docling (>= 2.14.0).

#### 5.1.1 Formats support√©s

| Extension | Format interne | Dimensions par d√©faut |
|-----------|---------------|----------------------|
| `.pdf` | PDF | 612 √ó 792 (Letter, en points) |
| `.docx` | DOCX | 612 √ó 792 |
| `.pptx` | PPTX | 960 √ó 540 (16:9 HD) |
| `.xlsx` | XLSX | 612 √ó 792 |
| `.html` | HTML | 612 √ó 792 |
| `.md` | Markdown | 612 √ó 792 |
| `.png`, `.jpg`, `.jpeg`, `.tiff`, `.bmp`, `.webp` | Image | 1920 √ó 1080 (HD) |

#### 5.1.2 Configuration Docling

```python
DoclingExtractor(
    ocr_enabled=True,       # OCR activ√© pour images/scans
    table_mode="accurate",  # Extraction pr√©cise des tables
    image_resolution_scale=2.0  # Facteur de r√©solution images
)
```

Le pipeline PDF utilise `PyPdfiumDocumentBackend` avec `PdfPipelineOptions(do_ocr=True, do_table_structure=True)`.

#### 5.1.3 M√©canisme d'extraction

1. **D√©tection format** : Extension ‚Üí format interne via `SUPPORTED_FORMATS`
2. **Conversion Docling** : `self._converter.convert(path)` ‚Üí `DoclingResult`
3. **It√©ration pages** : Parcours du dict `doc.pages` (cl√©s 1-indexed dans Docling ‚â• 2.66)
4. **Pour chaque page**, extraction de :

| Composant | M√©thode | Sortie |
|-----------|---------|--------|
| Blocs de texte | `_extract_text_blocks()` | `List[TextBlock]` ‚Äî type (paragraph, heading, list_item, caption), bbox, level |
| Tables | `_extract_tables()` | `List[TableData]` ‚Äî headers, cells, bbox, num_rows/cols, `is_structured=True` |
| √âl√©ments visuels | `_extract_visual_elements()` | `List[VisualElement]` ‚Äî kind="raster_image", bbox (via `doc.pictures`) |
| Titre de page | `_detect_title()` | Premier heading de level ‚â§ 2 (limit√© √† 200 chars) |

5. **Construction VisionUnit** : Chaque page produit un objet `VisionUnit(id, format, index, dimensions, blocks, tables, visual_elements, title)`

#### 5.1.4 Variante `extract_to_units_with_docling()`

Retourne aussi le `DoclingDocument` brut, n√©cessaire pour le Structural Graph Builder (Option C) qui acc√®de √† la structure native Docling sans re-parser.

#### 5.1.5 Sortie

```
List[VisionUnit] ‚Äî une VisionUnit par page/slide
  ‚îú‚îÄ‚îÄ id: "PDF_PAGE_0", "PPTX_PAGE_5"...
  ‚îú‚îÄ‚îÄ format: "PDF", "PPTX"...
  ‚îú‚îÄ‚îÄ index: 0, 1, 2... (0-based)
  ‚îú‚îÄ‚îÄ dimensions: (width, height)
  ‚îú‚îÄ‚îÄ blocks: List[TextBlock]
  ‚îú‚îÄ‚îÄ tables: List[TableData]
  ‚îú‚îÄ‚îÄ visual_elements: List[VisualElement]
  ‚îî‚îÄ‚îÄ title: Optional[str]
```

---

### 5.2 Vision Gating V4

**Fichiers :** `src/knowbase/extraction_v2/gating/engine.py`, `signals.py`, `weights.py`
**Classe principale :** `GatingEngine`
**Sp√©cification :** `VISION_GATING_V4_SPEC.md`

**Objectif :** D√©cider, pour chaque page/slide, si l'analyse Vision (GPT-4o) est n√©cessaire, recommand√©e, ou inutile. Ceci optimise les co√ªts en √©vitant les appels Vision sur des pages purement textuelles.

#### 5.2.1 Les 5 signaux

Le syst√®me calcule 5 signaux ind√©pendants, chacun entre 0.0 et 1.0 :

| Signal | Nom complet | Ce qu'il d√©tecte | Formule | Poids |
|--------|------------|-------------------|---------|-------|
| **RIS** | Raster Image Signal | Images raster significatives | `largest_image_ratio ‚â• 0.30 ‚Üí 1.0`, `‚â• 0.20 ‚Üí 0.7`, `‚â• 0.10 ‚Üí 0.4`, sinon 0.0 | **0.30** |
| **VDS** | Vector Drawing Signal | Shapes vectoriels, connecteurs | `connectors ‚â• 3 OU drawing_area ‚â• 35% ‚Üí 1.0`, `drawings ‚â• 15 ‚Üí 0.7`, `‚â• 8 ‚Üí 0.4` | **0.30** |
| **TFS** | Text Fragmentation Signal | Fragmentation texte (indicateur diagramme) | `short_ratio ‚â• 0.75 ET blocks ‚â• 12 ‚Üí 1.0`, `ratio ‚â• 0.60 ‚Üí 0.6` (short = < 200 chars) | **0.15** |
| **SDS** | Spatial Dispersion Signal | Dispersion spatiale du texte | `variance ‚â• 0.08 ‚Üí 1.0`, `‚â• 0.04 ‚Üí 0.5` (variance des centres normalis√©s x+y) | **0.15** |
| **VTS** | Visual Table Signal | Pseudo-tables non structur√©es | `H_lines ‚â• 3 ET V_lines ‚â• 2 ‚Üí 1.0`, ou text grid pattern. `0.0 si table structur√©e d√©j√† d√©tect√©e` | **0.10** |

**Calcul d√©taill√© de chaque signal :**

- **RIS** (`compute_raster_image_signal`) : Filtre les `VisualElement` de kind `"raster_image"`, calcule le ratio surface_image/surface_page pour la plus grande image. Seuils par paliers : `RIS_THRESHOLD_HIGH=0.30`, `MEDIUM=0.20`, `LOW=0.10`.

- **VDS** (`compute_vector_drawing_signal`) : Compte les connecteurs (kind in `connector, line, arrow`), les shapes (kind in `vector_shape, drawing, rectangle, oval, shape`), et le ratio de surface cumul√©e. Seuils : `VDS_CONNECTOR_THRESHOLD=3`, `VDS_AREA_THRESHOLD=0.35`, `VDS_DRAWINGS_HIGH=15`, `VDS_DRAWINGS_MEDIUM=8`.

- **TFS** (`compute_text_fragmentation_signal`) : Compte les blocs de texte < 200 caract√®res. Si ratio court ‚â• 75% avec ‚â• 12 blocs ‚Üí signal maximal (indique un diagramme avec labels). Seuils : `TFS_SHORT_CHAR_LIMIT=200`, `TFS_MIN_BLOCKS=12`, `TFS_HIGH_SHORT_RATIO=0.75`, `TFS_MEDIUM_SHORT_RATIO=0.60`.

- **SDS** (`compute_spatial_dispersion_signal`) : Calcule la variance des centres des blocs de texte (normalis√©s par les dimensions de la page). Minimum 3 blocs requis. Variance = var(x) + var(y). Seuils : `SDS_HIGH_VARIANCE=0.08`, `SDS_MEDIUM_VARIANCE=0.04`.

- **VTS** (`compute_visual_table_signal`) : Si des tables structur√©es existent d√©j√† ‚Üí `0.0` (pas besoin de Vision). Sinon, cherche un pattern de grille (lignes horizontales/verticales) ou un pattern de texte en grille (clustering de positions via `_find_aligned_clusters` avec tol√©rance 0.05).

#### 5.2.2 Calcul du VNS (Vision Need Score)

```
VNS = Œ£(weight_i √ó signal_i) = 0.30√óRIS + 0.30√óVDS + 0.15√óTFS + 0.15√óSDS + 0.10√óVTS
```

**Ajustement par Domain Context :** Si un `VisionDomainContext` est fourni, les poids peuvent √™tre ajust√©s de **¬±10% maximum**. Trois domaines pr√©d√©finis :

| Domaine | Ajustement |
|---------|------------|
| `SAP` | VDS=0.35 (‚Üë), RIS=0.25 (‚Üì) ‚Äî plus de diagrammes d'architecture |
| `pharmaceutical` | VTS=0.20 (‚Üë), TFS=0.10 (‚Üì) ‚Äî tables r√©glementaires complexes |
| `retail` | RIS=0.40 (‚Üë), VDS=0.20 (‚Üì) ‚Äî images marketing |

Les poids ajust√©s sont renormalis√©s pour que leur somme = 1.0.

#### 5.2.3 D√©cision de gating

| Condition | Action | Description |
|-----------|--------|-------------|
| `RIS == 1.0 OU VDS == 1.0` | `VISION_REQUIRED` | **R√®gle de s√©curit√©** ‚Äî bypass du VNS |
| `VNS ‚â• 0.60` | `VISION_REQUIRED` | Vision obligatoire |
| `0.40 ‚â§ VNS < 0.60` | `VISION_RECOMMENDED` | Vision recommand√©e (incluse par d√©faut) |
| `VNS < 0.40` | `NONE` | Pas de Vision n√©cessaire |

Le `GatingDecision` produit contient : `index`, `unit_id`, `action`, `vision_need_score`, `signals` (les 5 valeurs), et `reasons` (liste explicative textuelle).

#### 5.2.4 Seuils exp√©rimentaux

Le module `weights.py` d√©finit aussi des `EXPERIMENTAL_THRESHOLDS` (√† calibrer sur corpus r√©el en Phase 7) avec des seuils alternatifs plus agressifs pour les signaux individuels (ex : `RIS_HIGH=0.15`, `VDS_CONNECTOR_MIN=1`).

#### 5.2.5 Budget Vision

Le pipeline supporte un `vision_budget` optionnel (nombre max de pages avec Vision). Si le nombre de candidats d√©passe le budget, les pages `VISION_REQUIRED` sont prioritaires, puis `VISION_RECOMMENDED` tri√©es par VNS d√©croissant.

---

### 5.3 Vision Path (GPT-4o)

**Fichiers :** `src/knowbase/extraction_v2/vision/analyzer.py`, `semantic_reader.py`, `diagram_interpreter.py`

Le Vision Path se compose de **trois composants** aux r√¥les distincts :

#### 5.3.1 VisionAnalyzer ‚Äî Extraction structur√©e de diagrammes

**Classe :** `VisionAnalyzer`
**Mod√®le :** GPT-4o (temperature=0.0, max_tokens=4096)

**Objectif :** Extraire les √©l√©ments structurels (boxes, labels, arrows) et les relations visuelles depuis les diagrammes. Vision **OBSERVE et D√âCRIT**, ne raisonne pas.

**Principes directeurs :**
- Toute relation doit avoir une **evidence visuelle**
- Les ambigu√Øt√©s sont **d√©clar√©es**, jamais r√©solues implicitement
- Sortie JSON stricte conforme au sch√©ma `VisionExtraction`

**M√©canisme :**
1. Encode l'image en base64
2. Construit les messages via `get_vision_messages()` (prompt system + user avec image + domain context + snippets locaux)
3. Appel API Vision avec `response_format={"type": "json_object"}`
4. Parse la r√©ponse JSON ‚Üí `VisionExtraction`

**Sortie `VisionExtraction` :**
```
VisionExtraction
  ‚îú‚îÄ‚îÄ kind: str (type de diagramme)
  ‚îú‚îÄ‚îÄ elements: List[VisionElement] ‚Äî boxes, labels d√©tect√©s
  ‚îú‚îÄ‚îÄ relations: List[VisionRelation] ‚Äî fl√®ches, connexions
  ‚îú‚îÄ‚îÄ ambiguities: List[VisionAmbiguity] ‚Äî zones ambigu√´s
  ‚îú‚îÄ‚îÄ uncertainties: List[VisionUncertainty] ‚Äî incertitudes
  ‚îú‚îÄ‚îÄ page_index: int
  ‚îî‚îÄ‚îÄ confidence: float (0.0-1.0)
```

**Traitement parall√®le :** Les pages Vision sont trait√©es en parall√®le via `asyncio.gather()` avec un `asyncio.Semaphore(max_concurrent)`. La concurrence est configurable via `MAX_WORKERS` env var (d√©faut : 30). Pour les tr√®s gros documents (>400 pages), elle est r√©duite automatiquement √† 5.

**Gestion d'erreurs :** En cas d'√©chec d'un appel Vision, l'erreur est logg√©e mais le pipeline continue ‚Äî la page n'aura simplement pas d'enrichissement Vision.

#### 5.3.2 VisionSemanticReader ‚Äî Lecture s√©mantique textuelle

**Classe :** `VisionSemanticReader`
**Mod√®le :** GPT-4o (temperature=0.0, max_tokens=1024, timeout=30s)
**Spec :** `SPEC_VISION_SEMANTIC_INTEGRATION.md`

**Objectif :** Produire du **TEXTE exploitable** pour les passes suivantes (Pass 1) au lieu d'√©l√©ments g√©om√©triques. Ce texte enrichit les chunks `FIGURE_TEXT` du graphe structurel.

**Invariants :**
- **I1** : Jamais de texte vide en sortie
- **I4** : Tra√ßabilit√© origine obligatoire (`TextOrigin`)
- **I5** : Texte descriptif uniquement, pas d'assertions pr√©-promues

**Strat√©gie de fallback 3-tier :**

| Tier | M√©thode | TextOrigin r√©sultant |
|------|---------|---------------------|
| 1 | GPT-4o Vision ‚Üí texte s√©mantique | `VISION_SEMANTIC` |
| 2 | Retry (1x) si timeout/rate limit | `VISION_SEMANTIC` |
| 3 | OCR basique si Vision √©choue | `OCR` |
| 4 | Placeholder (jamais vide) | `PLACEHOLDER` |

**Prompt syst√®me :** D√©crit le contenu visuel de mani√®re FACTUELLE et OBSERVABLE (2-8 phrases), identifie entit√©s principales et relations visuelles. R√©ponse JSON : `{diagram_type, description, key_entities, confidence}`.

**Sortie `VisionSemanticResult` :**
```
VisionSemanticResult
  ‚îú‚îÄ‚îÄ page_no: int
  ‚îú‚îÄ‚îÄ semantic_text: str (jamais vide ‚Äî Invariant I1)
  ‚îú‚îÄ‚îÄ text_origin: TextOrigin (VISION_SEMANTIC | OCR | PLACEHOLDER)
  ‚îú‚îÄ‚îÄ diagram_type: Optional[str]
  ‚îú‚îÄ‚îÄ confidence: float
  ‚îú‚îÄ‚îÄ key_entities: List[str]
  ‚îú‚îÄ‚îÄ model: str
  ‚îú‚îÄ‚îÄ prompt_version: str ("v1.0")
  ‚îú‚îÄ‚îÄ image_hash: str (SHA256[:16] pour cache/replay)
  ‚îî‚îÄ‚îÄ candidate_hints: Optional[List[str]] (jamais promues ‚Äî I5)
```

#### 5.3.3 DiagramInterpreter ‚Äî Routing adaptatif LITE/FULL

**Classe :** `DiagramInterpreter`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` (QW-3)

**Objectif :** Optimiser les co√ªts Vision via un routing adaptatif bas√© sur le score VNS du gating.

**Routing :**

| Condition | M√©thode | Mod√®le | Co√ªt estim√© |
|-----------|---------|--------|-------------|
| `NONE` + TFS < 0.3 | `SKIP` | ‚Äî | 0 tokens |
| `NONE` + TFS ‚â• 0.3 | `TEXT_ONLY` | ‚Äî | 0 tokens (OCR existant) |
| `VISION_RECOMMENDED` | `VISION_LITE` | gpt-4o-mini | ~500 tokens |
| `VISION_REQUIRED` | `VISION_FULL` | gpt-4o | ~2000 tokens |

**Quality Gate :** Apr√®s extraction, si `confidence < 0.70` ‚Üí fallback vers `FALLBACK_PROSE` (r√©sum√© en prose au lieu d'√©l√©ments structur√©s).

---

### 5.4 Structured Merge

**Fichier :** `src/knowbase/extraction_v2/merge/merger.py` ‚Äî classe `StructuredMerger`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 9

**Objectif :** Fusionner les r√©sultats Docling (socle) et Vision (enrichissement) **sans √©crasement**.

#### 5.4.1 R√®gle d'or

> **Vision n'√©crase JAMAIS Docling.**

Docling fournit le **SOCLE** (blocs texte, tables structur√©es). Vision fournit l'**ENRICHISSEMENT** (√©l√©ments visuels, relations). L'enrichissement est **ATTACH√â** au socle, jamais fusionn√©.

#### 5.4.2 Strat√©gie d'attachement

1. Par `page_index` / `slide_index` (obligatoire)
2. Par bbox overlap (optionnel, pour pr√©cision)
3. Marquage explicite source : `"docling"` | `"vision"`

#### 5.4.3 M√©canisme

Pour chaque page (`merge_page()`), le merger :
1. Copie les blocs de base (Docling = socle intouchable)
2. Copie les tables de base
3. Attache l'enrichissement Vision (si disponible)
4. Attache la d√©cision de gating
5. Ajoute la provenance (version Docling, mod√®le Vision, score gating, timestamp)

Pour un document complet (`merge_document()`), construit un dict `{page_index ‚Üí GatingDecision}` et it√®re sur toutes les VisionUnits.

#### 5.4.4 Sortie

```
MergedPageOutput
  ‚îú‚îÄ‚îÄ page_index: int
  ‚îú‚îÄ‚îÄ base_blocks: List[TextBlock]     ‚Üê Docling (socle)
  ‚îú‚îÄ‚îÄ base_tables: List[TableData]     ‚Üê Docling (socle)
  ‚îú‚îÄ‚îÄ vision_enrichment: Optional[VisionExtraction]  ‚Üê Vision (attach√©)
  ‚îú‚îÄ‚îÄ gating_decision: Optional[GatingDecision]
  ‚îú‚îÄ‚îÄ provenance: MergeProvenance
  ‚îÇ     ‚îú‚îÄ‚îÄ docling_version: str
  ‚îÇ     ‚îú‚îÄ‚îÄ vision_model: Optional[str]
  ‚îÇ     ‚îú‚îÄ‚îÄ gating_score: Optional[float]
  ‚îÇ     ‚îî‚îÄ‚îÄ merge_timestamp: str
  ‚îú‚îÄ‚îÄ title: Optional[str]
  ‚îî‚îÄ‚îÄ format: str ("PDF", "PPTX"...)
```

---

### 5.5 Lin√©arisation

**Fichier :** `src/knowbase/extraction_v2/merge/linearizer.py` ‚Äî classe `Linearizer`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 1

**Objectif :** G√©n√©rer le `full_text` lin√©aris√© avec marqueurs s√©mantiques explicites. Ce `full_text` est la repr√©sentation canonique du document pour toutes les passes suivantes (Pass 0.9, 1.x).

#### 5.5.1 Grammaire des marqueurs (BNF)

```bnf
marker       ::= '[' marker_type attributes? ']'
marker_type  ::= 'PAGE' | 'TITLE' | 'PARAGRAPH' | 'TABLE_START' | 'TABLE_END'
               | 'TABLE_SUMMARY' | 'TABLE_RAW'
               | 'VISUAL_ENRICHMENT' | 'END_VISUAL_ENRICHMENT'
attributes   ::= (key '=' value)+
key          ::= [a-z_]+
value        ::= [a-zA-Z0-9_.-]+
```

#### 5.5.2 Marqueurs produits

| Marqueur | Signification | Exemple |
|----------|---------------|---------|
| `[PAGE n \| TYPE=xxx]` | D√©but de page | `[PAGE 6 \| TYPE=ARCHITECTURE_DIAGRAM]` |
| `[TITLE level=n]` | Titre (heading) | `[TITLE level=1] Target Architecture Overview` |
| `[PARAGRAPH]` | Paragraphe de contenu | `[PARAGRAPH]\nThis architecture enables...` |
| `[TABLE_START id=x]` | D√©but table (sans r√©sum√©) | `[TABLE_START id=tbl_1]` |
| `[TABLE_SUMMARY id=x]` | D√©but table avec r√©sum√© LLM (QW-1) | `[TABLE_SUMMARY id=tbl_1]` |
| `[TABLE_RAW]` | S√©parateur r√©sum√©/markdown brut | ‚Äî |
| `[TABLE_END]` | Fin de table | ‚Äî |
| `[VISUAL_ENRICHMENT id=x confidence=y]` | D√©but enrichissement Vision | `[VISUAL_ENRICHMENT id=vision_6_1 confidence=0.82]` |
| `[END_VISUAL_ENRICHMENT]` | Fin enrichissement Vision | ‚Äî |

#### 5.5.3 Algorithme de lin√©arisation

Pour chaque `MergedPageOutput` :
1. **Marqueur de page** : `[PAGE n | TYPE=xxx]` ‚Äî le type est d√©tect√© depuis l'enrichissement Vision (`kind`) ou `None`
2. **Titre** : `[TITLE level=1] ...` si pr√©sent
3. **Blocs de texte** : Chaque bloc format√© selon son type (heading ‚Üí `[TITLE]`, sinon ‚Üí `[PARAGRAPH]`)
4. **Tables** : Si r√©sum√© LLM disponible ‚Üí format enrichi `[TABLE_SUMMARY]...[TABLE_RAW]...[TABLE_END]` ; sinon ‚Üí format standard `[TABLE_START]...[TABLE_END]`
5. **Enrichissement Vision** : `[VISUAL_ENRICHMENT]...[END_VISUAL_ENRICHMENT]` avec `to_vision_text()`

Les pages sont jointes par `\n\n`. Un `PageIndex` (mapping offset ‚Üí page) est construit en parall√®le.

#### 5.5.4 Sortie

```
Tuple[str, List[PageIndex]]
  ‚îú‚îÄ‚îÄ full_text: str ‚Äî texte lin√©aris√© complet avec marqueurs
  ‚îî‚îÄ‚îÄ page_index: List[PageIndex]
        ‚îú‚îÄ‚îÄ page_index: int
        ‚îú‚îÄ‚îÄ start_offset: int
        ‚îî‚îÄ‚îÄ end_offset: int
```

---

### 5.6 Extraction de Contexte Documentaire

**Fichiers :** `src/knowbase/extraction_v2/context/` (13 fichiers)
**Classe orchestrateur :** `DocContextExtractor` (`doc_context_extractor.py`)
**Spec :** `ADR_ASSERTION_AWARE_KG.md` ‚Äî Section 3.1, `ADR_DOCUMENT_STRUCTURAL_AWARENESS.md`

**Objectif :** D√©terminer le **scope documentaire** (version-specific, general, mixed) et extraire les **marqueurs de contexte** (versions, √©ditions) pour qualifier les assertions en aval (Pass 1.3/1.4).

#### 5.6.1 Architecture en 3 √©tapes

```
√âtape 1: Candidate Mining (d√©terministe, sans LLM)
  ‚Üì
√âtape 2: Structural Analysis (PR6 ‚Äî analyse zones + templates)
  ‚Üì
√âtape 3: LLM Validation (PR7 ‚Äî arbitre, pas extracteur)
```

#### 5.6.2 √âtape 1 ‚Äî Candidate Mining (`candidate_mining.py`)

**Objectif :** Extraction d√©terministe (regex/patterns) de candidats marqueurs depuis :
- Nom de fichier
- Premi√®res pages (couverture/titre)
- Headers/footers
- Blocs revision/history

**Filtres universels (CandidateGate)** ‚Äî √âlimination de faux positifs AVANT scoring :

| Cat√©gorie | Patterns √©limin√©s | Exemples |
|-----------|-------------------|----------|
| Dates explicites | `MM/DD/YYYY`, `YYYY-MM-DD` | `05/23/2019` |
| Trimestres | `Q1-Q4 + ann√©e` | `Q4,2023` |
| Copyright | `¬© + ann√©e` | `¬© 2023 SAP SE` |
| Mois + ann√©e | `January 2023` | `Dec. 2025` |
| Fiscal years | `FY2023` | ‚Äî |
| R√©f√©rences temporelles | `since 2019`, `2019-present` | ‚Äî |
| Unit√©s de mesure | `nombre + unit√©` | `500 MB`, `15%` |
| Exemples | `e.g. ...` | ‚Äî |
| R√©f√©rences ID | `Note 123456`, `JIRA-1234` | ‚Äî |
| Pages/slides | `Page 23`, `Slide 5` | ‚Äî |

**Patterns positifs** (marqueurs l√©gitimes) :

| Pattern | Exemples |
|---------|----------|
| SemVer | `v1.2.3-beta`, `v1.2` |
| Entity + Numeral | `S/4HANA 2023`, `iPhone 15` |
| Release forms | `Release 3.0`, `Edition 2`, `Phase 2` |
| Structured codes | `AB12`, `XY2023` |

**Structure Numbering Gate :** D√©tection agnostique de num√©rotation de sections (ex : "PUBLIC 3:" en position de titre ‚Üí candidat rejet√©, c'est un num√©ro de section, pas un marqueur de version).

**Filtrage par DocumentContext** (`decide_marker()`) :
- Si `structure_hint.has_numbered_sections` ‚Üí rejette `WORD+SMALL_NUMBER` en position heading
- Si `entity_hints` ‚Üí booste confiance si prefix correspond √† une entit√© dominante
- **Safe-by-default** : en cas de doute, rejeter le candidat

#### 5.6.3 √âtape 2 ‚Äî Structural Analysis (`context/structural/`)

Trois composants travaillent en pipeline :

**a) ZoneSegmenter** (`zone_segmenter.py`)
- Segmente chaque page en 3 zones : **TOP** (headers, titres), **MAIN** (corps), **BOTTOM** (footers, legal)
- Bas√© sur les lignes significatives (filtrage des lignes vides/courtes)
- Confiance structurelle bas√©e sur le nombre de pages : `HIGH` (‚â•10 pages), `MEDIUM` (3-9), `LOW` (<3)

**b) TemplateDetector** (`template_detector.py`)
- Identifie les fragments de texte r√©p√©titifs (boilerplate) par clustering
- Crit√®res : appara√Æt sur ‚â•30% des pages, ‚â•2 occurrences, zone consistency ‚â•60%
- Les fragments MAIN avec haute consistance ont leur `template_likelihood` r√©duit de 50% (peut √™tre du contenu s√©mantique r√©p√©t√©)
- Produit un `StructuralAnalysis` avec fragments, couverture, statistiques

**c) LinguisticCueDetector** (`linguistic_cue_detector.py`)
- Score les patterns linguistiques autour d'un candidat :
  - **Scope language** (version, release, available in) ‚Üí indique marqueur de contexte
  - **Legal language** (¬©, confidential, trademark) ‚Üí indique boilerplate
  - **Contrast language** (vs, unlike, whereas) ‚Üí indique comparaison (scope MIXED)
- Scores normalis√©s 0.0-1.0, multilingue (EN, FR, DE)

#### 5.6.4 √âtape 3 ‚Äî LLM Validation

Le LLM agit comme **ARBITRE** (pas extracteur) :
- Input : candidats enrichis avec signaux structurels
- Output : classification CONTEXT_SETTING vs TEMPLATE_NOISE
- Le LLM ne peut pas inventer de nouveaux marqueurs

#### 5.6.5 Modules compl√©mentaires du contexte

**AnchorContextAnalyzer** (`anchor_context_analyzer.py`) ‚Äî Analyse le contexte de chaque assertion (utilis√© en Pass 1.3/1.4) :
- Strat√©gie : heuristiques d'abord, LLM si ambigu
- D√©tecte : polarit√© (positive, negative, future, deprecated, conditional), marqueurs locaux, patterns d'override

**PassageHeuristics** (`heuristics.py`) ‚Äî D√©tection d√©terministe par regex de :
- N√©gation : `not, cannot, unavailable, removed` (EN/FR/DE)
- Futur : `will be, coming soon, planned for` (EN/FR/DE)
- Deprecated : `deprecated, obsolete, legacy, end-of-life` (EN/FR/DE)
- Conditionnel : `if, when, unless, depending on` (EN/FR/DE)
- Override : `unlike, in contrast, different from` (avec type : SWITCH, RANGE, GENERALIZATION)

**InheritanceEngine** (`inheritance.py`) ‚Äî Matrice d'h√©ritage DocContext ‚Üí AnchorContext :

| DocScope | Strong markers | Weak markers | Result Scope | Source | Confiance |
|----------|---------------|--------------|--------------|--------|-----------|
| `VARIANT_SPECIFIC` | ‚úÖ | ‚Äî | `CONSTRAINED` | `INHERITED_STRONG` | 0.95 |
| `VARIANT_SPECIFIC` | ‚úÖ | ‚úÖ | `CONSTRAINED` | `INHERITED_STRONG` | 0.90 |
| `VARIANT_SPECIFIC` | ‚Äî | ‚úÖ | `CONSTRAINED` | `INHERITED_WEAK` | 0.85 |
| `VARIANT_SPECIFIC` | ‚Äî | ‚Äî | `UNKNOWN` | `NONE` | 0.70 |
| `MIXED` | any | any | `UNKNOWN` | `NONE` | 0.50 |
| `GENERAL` | ‚Äî | ‚Äî | `GENERAL` | `NONE` | 0.80 |

R√®gle cl√© : **Override local d√©tect√© ‚Üí toujours prioritaire** sur l'h√©ritage documentaire.

#### 5.6.6 Sortie

```
DocContextFrame
  ‚îú‚îÄ‚îÄ doc_scope: DocScope (VARIANT_SPECIFIC | GENERAL | MIXED)
  ‚îú‚îÄ‚îÄ strong_markers: List[str] ‚Äî marqueurs √† haute confiance
  ‚îú‚îÄ‚îÄ weak_markers: List[str] ‚Äî marqueurs √† confiance mod√©r√©e
  ‚îú‚îÄ‚îÄ evidence: List[MarkerEvidence]
  ‚îú‚îÄ‚îÄ scope_signals: ScopeSignals
  ‚îî‚îÄ‚îÄ document_context: Optional[DocumentContext] ‚Äî contraintes structurelles
```

---

### 5.7 Table Summarizer

**Fichier :** `src/knowbase/extraction_v2/tables/table_summarizer.py` ‚Äî classe `TableSummarizer`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî QW-1

**Objectif :** Transformer les tableaux structur√©s en **r√©sum√©s en langage naturel** pour am√©liorer le RAG (+50% hit-rate estim√© sur questions impliquant des tableaux).

#### 5.7.1 Principe

Un r√©sum√© s√©mantique est beaucoup plus efficace pour l'embedding qu'un Markdown brut. Le r√©sum√© (2-4 phrases) est stock√© dans `[TABLE_SUMMARY]` AVANT le Markdown brut `[TABLE_RAW]`, optimisant ainsi l'embedding.

#### 5.7.2 Configuration

| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `min_cells` | 4 | Minimum de cellules pour d√©clencher le r√©sum√© |
| `max_cells` | 500 | Maximum avant troncature |
| `skip_empty` | `True` | Ignorer les tables vides |

#### 5.7.3 M√©canisme

1. **Filtre** : `_should_summarize()` ‚Äî v√©rifie min/max cellules
2. **Troncature** : Si table > `max_cells`, garde les premi√®res lignes
3. **Conversion Markdown** : `table.to_markdown()` ‚Äî g√©n√®re le Markdown de la table
4. **Appel LLM** : Via `LLMRouter` (singleton, TaskType appropri√©) avec prompt sp√©cifique
5. **Prompt** : ¬´ Summarize this table in natural language... Be factual, concise (2-4 sentences), describe key insights. ¬ª
6. **Batch** : `summarize_batch()` traite plusieurs tables en parall√®le (max_concurrent=5)

#### 5.7.4 Sortie

```
TableSummaryResult
  ‚îú‚îÄ‚îÄ table_id: str
  ‚îú‚îÄ‚îÄ summary: str ‚Äî r√©sum√© en langage naturel
  ‚îú‚îÄ‚îÄ raw_markdown: str ‚Äî Markdown original
  ‚îú‚îÄ‚îÄ success: bool
  ‚îú‚îÄ‚îÄ error: Optional[str]
  ‚îú‚îÄ‚îÄ input_tokens: int
  ‚îî‚îÄ‚îÄ output_tokens: int
```

---

### 5.8 Cache Versionn√©

**Fichier :** `src/knowbase/extraction_v2/cache/versioned_cache.py` ‚Äî classe `VersionedCache`
**Sp√©cification :** `OSMOSIS_EXTRACTION_V2_DECISIONS.md` ‚Äî D√©cision 10

**Objectif :** √âviter de refaire les appels Vision co√ªteux en cachant les r√©sultats d'extraction complets.

#### 5.8.1 Version actuelle

`CURRENT_CACHE_VERSION = "v5"` ‚Äî v5 inclut les DocItems s√©rialis√©s pour Pipeline V2 Pass 1 Anchor Resolution.

#### 5.8.2 Cl√© de cache

La cl√© de cache est le **SHA256 du fichier source** (pas le document_id). Ainsi, le m√™me fichier (m√™me contenu) sera toujours retrouv√©, peu importe son nom ou chemin.

**Format de fichier cache :** `{sha256_hash}.v5cache.json`

#### 5.8.3 Invalidation

- Si `cache_version != CURRENT_CACHE_VERSION` ‚Üí invalide (migration de version)
- Le hash du fichier source assure l'invalidation automatique si le contenu change

#### 5.8.4 Enrichissement √† la vol√©e

Si le cache HIT mais que `doc_context` est `None` (ancien cache), le pipeline extrait le DocContext √† la vol√©e et met √† jour le cache ‚Äî transparent pour l'appelant.

#### 5.8.5 Structure du cache

```json
{
  "cache_version": "v5",
  "created_at": "2026-01-29T14:30:00Z",
  "source_file_hash": "abc123...",
  "document_id": "doc_xyz",
  "extraction": {
    "full_text": "...",
    "structure": { ... },
    "page_index": [ ... ],
    "gating_decisions": [ ... ],
    "vision_results": [ ... ],
    "doc_context": { ... }
  }
}
```

---

### 5.8b Confidence Scorer

**Fichier :** `src/knowbase/extraction_v2/confidence/confidence_scorer.py` ‚Äî classe `ConfidenceScorer`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî QW-2

**Objectif :** Calculer un score heuristique de `parse_confidence` (0.0-1.0) sur la qualit√© du parsing (pas de l'extraction). Un texte bien pars√© (clair, structur√©, sans artefacts OCR) a un score √©lev√©.

#### 5.8b.1 Les 5 signaux de confiance

| Signal | Poids | Ce qu'il mesure | Score bas | Score haut |
|--------|-------|-----------------|-----------|------------|
| `length` | 0.20 | Longueur suffisante | < 50 chars ‚Üí 0.0 | ‚â• 500 chars ‚Üí 1.0 |
| `structure` | 0.25 | Pr√©sence de structure (headings, listes, tables) | Aucune ‚Üí 0.3 | ‚â• 3 types ‚Üí 1.0 |
| `ocr_quality` | 0.20 | Absence de patterns OCR suspects | Beaucoup de suspects ‚Üí 0.0 | Aucun ‚Üí 1.0 |
| `coherence` | 0.20 | Ratio mots/caract√®res normaux | Mots tr√®s courts/longs ‚Üí 0.5 | Normal ‚Üí 1.0 |
| `markers` | 0.15 | Pr√©sence de marqueurs OSMOSE | Aucun ‚Üí 0.5 (neutre) | ‚â• 4 types ‚Üí 1.0 |

**Floor/Ceiling :** Score final clamp√© entre `min_score=0.1` et `max_score=1.0`.

---

### 5.8c Layout Detector

**Fichier :** `src/knowbase/extraction_v2/layout/layout_detector.py` ‚Äî classe `LayoutDetector`
**Spec :** `ADR_REDUCTO_PARSING_PRIMITIVES` ‚Äî MT-1

**Objectif :** D√©tecter les r√©gions structurelles dans le `full_text` lin√©aris√© pour informer le chunker (HybridAnchorChunker) des zones atomiques **√† ne jamais couper**.

#### 5.8c.1 Types de r√©gions

| Type | Atomique | Description |
|------|----------|-------------|
| `TABLE` | ‚úÖ | Entre `[TABLE_START]`/`[TABLE_SUMMARY]` et `[TABLE_END]` |
| `VISION` | ‚úÖ | Entre `[VISUAL_ENRICHMENT]` et `[END_VISUAL_ENRICHMENT]` |
| `PAGE_MARKER` | ‚ùå | Marqueur `[PAGE n]` |
| `TITLE` | ‚ùå | Marqueur `[TITLE level=n]` |
| `PARAGRAPH` | ‚ùå | Bloc `[PARAGRAPH]` + contenu |
| `TEXT` | ‚ùå | Texte libre entre les marqueurs |

#### 5.8c.2 R√®gle non-n√©gociable

> **Ne jamais couper un tableau.**

Les r√©gions atomiques (TABLE, VISION) ne peuvent **JAMAIS** √™tre coup√©es par le chunking.

#### 5.8c.3 Algorithme de d√©tection

1. D√©tection des r√©gions atomiques (tables via regex `TABLE_START_PATTERN`/`TABLE_END_PATTERN`, vision via `VISION_START_PATTERN`/`VISION_END_PATTERN`)
2. D√©tection des r√©gions non-atomiques (pages, titres, paragraphes via regex)
3. Fusion : priorit√© aux r√©gions atomiques (les non-atomiques qui chevauchent une atomique sont exclues)
4. Remplissage des trous : les gaps entre r√©gions sont combl√©s par des r√©gions `TEXT`

**Validation :** `validate_no_cut_tables()` ‚Äî v√©rifie post-chunking qu'aucun tableau n'a √©t√© coup√© (utilis√© pour tests et monitoring).

---

### 5.9 Conformit√© ADR ‚Äî Pass 0 Extraction

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Pass 0 produit uniquement la structure documentaire (VisionUnit, MergedPageOutput). Aucune entit√© s√©mantique (Concept, Information) n'est cr√©√©e. |
| AV2-4 | DocItem atomique | ‚úÖ | Les blocs extraits par Docling correspondent aux items natifs (paragraph, heading, list-item, caption). La conversion en DocItem se fait en Pass 0 Structural. |
| AV2-8 | Dual Storage | ‚ö†Ô∏è | Pass 0 produit le `full_text` pour Qdrant et la structure pour Neo4j. Le dual storage n'est effectif qu'apr√®s Pass 0 Structural (TypeAwareChunks ‚Üí Qdrant). |
| NS-2 | LLM = Extracteur evidence-locked | ‚úÖ | Vision observe et d√©crit factuellement. Le VisionSemanticReader a l'invariant I5 (pas d'assertions pr√©-promues). Le TableSummarizer d√©crit les insights observables. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Le `PageIndex` permet de tracer chaque portion du `full_text` vers sa page d'origine. Les marqueurs `[PAGE n]` assurent la tra√ßabilit√© dans le texte. |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Pass 0 traite un seul document √† la fois. Pas de fusion multi-documents. |
| AV2-10 | < 250 nodes/document | üü¢ | Pass 0 ne cr√©e aucun node Neo4j directement (c'est Pass 0 Structural qui les cr√©e). |

---

### 5.10 Risques ‚Äî Pass 0 Extraction

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R0-1 | **Shapes vectoriels non d√©tect√©s** | üü° | `_extract_visual_elements()` n'extrait que les `pictures` (raster). Les shapes vectoriels d√©pendent de la version Docling et du format. Le commentaire dans le code mentionne ¬´ Fallback VDS sera utilis√© si n√©cessaire (Phase 2.6) ¬ª. | Le signal VDS peut √™tre sous-√©valu√© pour les PPTX avec shapes sans images raster. Signal TFS et SDS compensent partiellement. |
| R0-2 | **Concurrence Vision non born√©e** | üü¢ | Le semaphore limite la concurrence (d√©faut 30, r√©duit √† 5 pour >400 pages). Risk de rate limiting OpenAI sur tr√®s gros batches. | Le semaphore et la r√©duction automatique pour gros documents att√©nuent ce risque. Le budget Vision optionnel ajoute un contr√¥le suppl√©mentaire. |
| R0-3 | **Cache version mismatch silencieux** | üü¢ | Le passage de v4 √† v5 invalide les anciens caches automatiquement. Le pipeline r√©-extrait transparemment. | Invalidation automatique par version. L'enrichissement DocContext √† la vol√©e sur anciens caches fonctionne correctement. |
| R0-4 | **Seuils de gating non calibr√©s** | üü° | Les `EXPERIMENTAL_THRESHOLDS` sont marqu√©s ¬´ √† calibrer sur corpus r√©el (Phase 7) ¬ª. Les seuils actuels sont des valeurs par d√©faut raisonnables mais non valid√©es empiriquement. | Les seuils par d√©faut (`VISION_GATING_V4_SPEC.md`) sont conservatifs. L'ajustement par Domain Context permet une adaptation au cas par cas. |
| R0-5 | **Table Summarizer ‚Äî hallucination LLM** | üü° | Le LLM peut halluciner des insights non pr√©sents dans la table. Le prompt demande de ne d√©crire que ¬´ ce qui est explicitement pr√©sent ¬ª mais aucune validation automatique n'est effectu√©e. | Le Markdown brut est conserv√© dans `[TABLE_RAW]` pour v√©rification. Le prompt est strict (¬´ Describe ONLY what is explicitly present ¬ª). |
| R0-6 | **DocContext faux positifs r√©siduels** | üü° | Malgr√© le CandidateGate robuste (>10 cat√©gories de filtres) et le filtrage par DocumentContext (`decide_marker`), certains faux positifs de marqueurs de version pourraient passer, surtout dans des domaines inhabituels. | Le principe safe-by-default (rejeter en cas de doute) et la validation LLM r√©duisent ce risque. La matrice d'h√©ritage traite `MIXED` de fa√ßon conservatrice (pas d'h√©ritage). |
| R0-7 | **VisionSemanticReader ‚Äî placeholder texte** | üü¢ | L'invariant I1 (jamais vide) peut produire un placeholder `[VISUAL_CONTENT: Page X - interpretation unavailable]` si toutes les strat√©gies √©chouent. Ce placeholder est informationnellement pauvre. | Le fallback 3-tier minimise les cas de placeholder. Les m√©triques `vision_semantic_fallback_placeholder` permettent le monitoring. |
| R0-8 | **Pass 0.5 d√©sactiv√©e en mode V2** | ‚ö†Ô∏è | Quand `stratified_pipeline_v2` feature flag est activ√©, la cor√©f√©rence linguistique (Pass 0.5) est explicitement d√©sactiv√©e car `MentionSpan/CoreferenceChain` ne font pas partie de l'architecture V2. | D√©cision architecturale consciente document√©e dans le code. La r√©solution de cor√©f√©rence en V2 sera g√©r√©e diff√©remment (√† d√©finir). |

---

## 6. Pass 0 Structural ‚Äî Graphe Structurel

**Fichiers principaux :**
- `src/knowbase/stratified/pass0/adapter.py` ‚Äî classe `Pass0Adapter` (adapter V2)
- `src/knowbase/stratified/pass0/cache_loader.py` ‚Äî fonction `load_pass0_from_cache()` (chargement depuis cache)
- `src/knowbase/structural/graph_builder.py` ‚Äî classe `StructuralGraphBuilder` (constructeur du graphe)
- `src/knowbase/structural/models.py` ‚Äî mod√®les Pydantic (`DocItem`, `SectionInfo`, `TypeAwareChunk`, `DocumentVersion`, `PageContext`, `StructuralProfile`)
- `src/knowbase/structural/docitem_builder.py` ‚Äî classe `DocItemBuilder` (extraction des items Docling)
- `src/knowbase/structural/section_profiler.py` ‚Äî classe `SectionProfiler` (assignment sections + profils structurels)
- `src/knowbase/structural/type_aware_chunker.py` ‚Äî classe `TypeAwareChunker` (chunking par type)

**Objectif :** Transformer le `DoclingDocument` (sortie de Docling) en un **graphe structurel Document ‚Üí Section ‚Üí DocItem** conforme au sch√©ma V2, puis produire les `TypeAwareChunk` pour le retrieval vectoriel (Qdrant) et les mappings chunk‚ÜîDocItem n√©cessaires √† l'Anchor Resolution (Pass 1.3b).

### 6.0 Vue d'ensemble Pass 0 Structural

**Entrant :**

| Entrant | Type | Source |
|---------|------|--------|
| `DoclingDocument` | Objet Docling natif | Pass 0 Extraction (via `extract_to_units_with_docling()`) |
| `tenant_id` | `str` | Contexte multi-tenant |
| `doc_id` | `str` | ID unique du document |
| Ou : fichier cache `.v4cache.json`/`.v5cache.json` | JSON s√©rialis√© | `data/extraction_cache/` (bypass Docling) |

**S√©quence d'ex√©cution (4+1 √©tapes) :**

```
√âtape 1: DocItemBuilder ‚Äî Extraction des DocItems depuis DoclingDocument
  ‚îÇ  texts[], tables[], pictures[] ‚Üí DocItem[] avec reading_order + charspan
  ‚Üì
√âtape 2: SectionProfiler ‚Äî Assignment hi√©rarchique des sections
  ‚îÇ  DocItem[] ‚Üí SectionInfo[] avec structural_profile
  ‚Üì
√âtape 3: TypeAwareChunker ‚Äî Cr√©ation des chunks type-aware
  ‚îÇ  DocItem[] + SectionInfo[] ‚Üí TypeAwareChunk[]
  ‚Üì
√âtape 4: Pass0Adapter ‚Äî Adaptation au sch√©ma V2
  ‚îÇ  StructuralGraphBuildResult ‚Üí Pass0Result
  ‚îÇ  + construction chunk‚ÜîDocItem mappings
  ‚îÇ  + construction unit_index (AssertionUnitIndexer)
  ‚Üì
√âtape 4b (optionnel): Persistance Neo4j V2
  ‚îÇ  Document, Section, DocItem nodes
```

**Chemin alternatif : CacheLoader** ‚Äî Si un cache V2/V4/V5 existe, `load_pass0_from_cache()` reconstruit directement un `Pass0Result` depuis le JSON s√©rialis√©, sans re-parser le DoclingDocument. Supporte aussi le format legacy v1.0 (page-based).

---

### 6.1 Adapter Docling ‚Üí Schema V2

**Fichier :** `src/knowbase/stratified/pass0/adapter.py` ‚Äî classe `Pass0Adapter`

**Objectif :** Wrapper le `StructuralGraphBuilder` existant et l'adapter au sch√©ma V2 en g√©n√©rant les identifiants composites et les mappings inter-couches.

#### 6.1.1 Architecture Adapter

`Pass0Adapter` encapsule `StructuralGraphBuilder` (pattern Adapter) :

```python
class Pass0Adapter:
    def __init__(self, max_chunk_size=3000, persist_artifacts=False):
        self.builder = StructuralGraphBuilder(
            max_chunk_size=max_chunk_size,
            persist_artifacts=persist_artifacts,
        )
```

Le builder sous-jacent orchestre les 3 composants internes : `DocItemBuilder` ‚Üí `SectionProfiler` ‚Üí `TypeAwareChunker`.

#### 6.1.2 Identifiants composites V2 (docitem_id)

Format : `{tenant_id}:{doc_id}:{item_id}`

Exemple : `default:doc_abc123:item_0042`

Ce format assure :
- **Unicit√© globale** multi-tenant
- **Lookup rapide** par tenant + doc_id
- **Correspondance** avec l'`item_id` Docling original (= `self_ref`)

Fonctions utilitaires :
- `get_docitem_id_v2(tenant_id, doc_id, item_id) ‚Üí str`
- `parse_docitem_id_v2(docitem_id) ‚Üí (tenant_id, doc_id, item_id)`

#### 6.1.3 M√©thode `process_document()`

S√©quence :
1. Appel `self.builder.build_from_docling()` ‚Üí `StructuralGraphBuildResult`
2. Construction des mappings chunk‚ÜîDocItem via `_build_mappings()`
3. Construction de l'index des unit√©s via `_build_unit_index()` (appel `AssertionUnitIndexer`)
4. Assemblage du `Pass0Result` V2

#### 6.1.4 Construction des mappings chunk‚ÜîDocItem

La m√©thode `_build_mappings()` produit deux structures inverses :

| Structure | Type | Utilisation |
|-----------|------|-------------|
| `chunk_to_docitem_map` | `Dict[chunk_id ‚Üí ChunkToDocItemMapping]` | Anchor Resolution (Pass 1.3b) ‚Äî trouver le DocItem source d'un chunk |
| `docitem_to_chunks_map` | `Dict[docitem_id ‚Üí List[chunk_id]]` | Navigation ‚Äî trouver tous les chunks contenant un DocItem |

Chaque `ChunkToDocItemMapping` contient : `chunk_id`, `docitem_ids` (liste car un chunk peut couvrir plusieurs DocItems), `text`, `char_start`, `char_end`.

Le `TypeAwareChunk` poss√®de d√©j√† `item_ids` (liste des `DocItem.item_id` sources). L'adapter convertit ces `item_id` en `docitem_id` composites V2.

#### 6.1.5 Index des unit√©s (AssertionUnitIndexer)

La m√©thode `_build_unit_index()` segmente chaque DocItem en **unit√©s d'assertion** pour permettre au LLM (Pass 1.3) de **pointer** vers une unit√© au lieu de copier le texte verbatim.

- Import lazy : `from knowbase.stratified.pass1.assertion_unit_indexer import AssertionUnitIndexer`
- Filtre : DocItems avec texte > 30 caract√®res uniquement
- Produit : `Dict[docitem_id ‚Üí UnitIndexResult]` stock√© dans `Pass0Result.unit_index`

---

### 6.2 Construction du graphe (Document, Section, DocItem)

**Fichier :** `src/knowbase/structural/graph_builder.py` ‚Äî classe `StructuralGraphBuilder`

**Objectif :** Orchestrer les 3 composants d'extraction structurelle (DocItemBuilder, SectionProfiler, TypeAwareChunker) depuis un DoclingDocument natif.

#### 6.2.1 √âtape 1 ‚Äî DocItemBuilder

**Fichier :** `src/knowbase/structural/docitem_builder.py`

**Objectif :** Extraire les items documentaires atomiques depuis le DoclingDocument.

**Sources d'extraction :**

| Source Docling | Items extraits | Type DocItem r√©sultant |
|----------------|----------------|----------------------|
| `doc.texts[]` | Paragraphes, headings, list-items, captions, footnotes | TEXT, HEADING, LIST_ITEM, CAPTION, FOOTNOTE |
| `doc.tables[]` | Tables structur√©es (Markdown + JSON canonique) | TABLE |
| `doc.pictures[]` | Figures avec captions | FIGURE |

**Mapping DocItemLabel ‚Üí DocItemType** (`DOCLING_LABEL_MAPPING` dans `models.py`) :

| Label Docling | DocItemType | Cat√©gorie |
|---------------|-------------|-----------|
| `text`, `paragraph`, `handwritten_text` | TEXT | Relation-bearing |
| `title`, `section_header` | HEADING | Relation-bearing |
| `caption` | CAPTION | Relation-bearing |
| `footnote` | FOOTNOTE | Relation-bearing |
| `list_item` | LIST_ITEM | Contextuel (D3.3) |
| `table`, `chart` | TABLE | Structure-bearing |
| `picture` | FIGURE | Structure-bearing |
| `code` | CODE | Structure-bearing |
| `formula` | FORMULA | Structure-bearing |
| `page_header`, `page_footer` | FURNITURE | Structure-bearing |
| `reference` | REFERENCE | Structure-bearing |
| Autres (`form`, `checkbox_*`, etc.) | OTHER | Structure-bearing |

**Distinction fondamentale (ADR D3) :**

- **Relation-bearing** (TEXT, HEADING, CAPTION, FOOTNOTE) ‚Äî portent des assertions, √©ligibles √† l'extraction de relations
- **Structure-bearing** (TABLE, FIGURE, CODE, FORMULA, etc.) ‚Äî portent de la structure, trait√©s s√©par√©ment

**Traitements par type :**
- **HEADING** : Inf√©rence du `heading_level` depuis le texte (patterns `1.`, `1.1.`, `1.1.1.` ‚Üí levels 1, 2, 3) via `infer_heading_level_from_text()`
- **TABLE** : Conversion en Markdown (`table_to_text()`) et JSON canonique (`table_to_json()`)
- **FIGURE** : Extraction de la caption si disponible

**Post-traitements globaux :**
1. `compute_reading_order()` ‚Äî Tri d√©terministe par (page, position_verticale, position_horizontale) ‚Üí `reading_order_index`
2. `compute_docwide_charspans()` ‚Äî Calcul des positions de caract√®res √† l'√©chelle du document entier (`charspan_start_docwide`, `charspan_end_docwide`) avec s√©parateur `\n`

**Sortie :** `DocItemBuildResult` contenant `doc_items: List[DocItem]`, `doc_version: DocumentVersion`, `page_contexts: List[PageContext]`, `doc_dict: Dict`

#### 6.2.2 √âtape 2 ‚Äî SectionProfiler

**Fichier :** `src/knowbase/structural/section_profiler.py`

**Objectif :** Grouper les DocItems en sections hi√©rarchiques et calculer le profil structurel de chaque section.

**Deux strat√©gies :**

| Strat√©gie | Condition d'activation | M√©canisme |
|-----------|----------------------|-----------|
| **Heading-based** | ‚â•1 DocItem de type HEADING d√©tect√© | Pile de sections (heading stack) ‚Äî chaque HEADING cr√©e/met √† jour une section, les items suivants y sont assign√©s |
| **Page-based** (fallback) | Aucun HEADING d√©tect√© | 1 section par page ‚Äî `section_p{page_idx:03d}` |

**Heading-based : d√©tail**
- Chaque HEADING cr√©e une section avec `section_id` d√©riv√© du texte (slugifi√©)
- Le `section_path` est construit hi√©rarchiquement : `"1. Introduction / 1.1 Overview"`
- Le `section_level` correspond au `heading_level` du DocItem
- Les relations parent‚Üíenfant sont √©tablies via `parent_section_id`

**Profil structurel (`StructuralProfile`)** :
Apr√®s l'assignment, chaque section est analys√©e via `StructuralProfile.from_items()` :
- Calcul des ratios par type (text_ratio, table_ratio, figure_ratio, etc.)
- Classification `is_relation_bearing` si ratio relation-types > 50%
- Classification `is_structure_bearing` si ratio structure-types > 50%
- `relation_likelihood` et `relation_likelihood_tier` (HIGH/MEDIUM/LOW/VERY_LOW) via `compute_features()` depuis le module `relation_likelihood`

**Sortie :** `List[SectionInfo]` avec `section_id`, `title`, `section_path`, `section_level`, `parent_section_id`, `item_ids`, `structural_profile`

#### 6.2.3 √âtape 3 ‚Äî TypeAwareChunker

**Fichier :** `src/knowbase/structural/type_aware_chunker.py`

**Objectif :** Cr√©er des chunks s√©par√©s par type de contenu pour optimiser le retrieval vectoriel et l'extraction de relations.

**R√®gles de chunking :**

| Type DocItem | Traitement | ChunkKind | `is_relation_bearing` |
|--------------|-----------|-----------|----------------------|
| TEXT, HEADING, CAPTION, FOOTNOTE | Bufferis√©s et fusionn√©s cons√©cutivement | `NARRATIVE_TEXT` | ‚úÖ `True` |
| TABLE | 1 chunk d√©di√© par table | `TABLE_TEXT` | ‚ùå `False` |
| FIGURE | 1 chunk d√©di√© par figure | `FIGURE_TEXT` | ‚ùå `False` |
| CODE | 1 chunk d√©di√© par bloc code | `CODE_TEXT` | ‚ùå `False` |

**M√©canisme de buffering narratif :**
- Les items NARRATIVE sont accumul√©s dans un buffer
- Quand la taille du buffer d√©passe `max_chunk_size` (d√©faut : 3000 chars), le buffer est flush√© ‚Üí 1 `TypeAwareChunk(kind=NARRATIVE_TEXT)`
- Chaque chunk narratif contient la liste des `item_ids` sources (tra√ßabilit√© DocItem ‚Üí Chunk)

**Propri√©t√©s des chunks :**
- `chunk_id` : UUID g√©n√©r√© automatiquement (`chunk_{uuid4().hex[:12]}`)
- `item_ids` : Liste des DocItem.item_id sources (1-N)
- `section_id` : Section d'appartenance
- `page_no` : Page de d√©but
- `text_origin` : Tra√ßabilit√© de l'origine du texte (DOCLING, VISION_SEMANTIC, OCR, PLACEHOLDER)

**Sortie :** `List[TypeAwareChunk]` ‚Äî seuls les chunks `NARRATIVE_TEXT` sont marqu√©s `is_relation_bearing=True`

#### 6.2.4 R√©sultat global ‚Äî StructuralGraphBuildResult

```
StructuralGraphBuildResult
  ‚îú‚îÄ‚îÄ doc_items: List[DocItem]           ‚Üê items atomiques
  ‚îú‚îÄ‚îÄ sections: List[SectionInfo]        ‚Üê hi√©rarchie de sections
  ‚îú‚îÄ‚îÄ chunks: List[TypeAwareChunk]       ‚Üê chunks pour retrieval
  ‚îú‚îÄ‚îÄ doc_version: DocumentVersion       ‚Üê version avec doc_hash
  ‚îú‚îÄ‚îÄ page_contexts: List[PageContext]   ‚Üê contextes de pages
  ‚îî‚îÄ‚îÄ doc_dict: Dict                     ‚Üê DoclingDocument s√©rialis√© (D7)
```

#### 6.2.5 R√©sultat V2 ‚Äî Pass0Result

```
Pass0Result (produit par Pass0Adapter)
  ‚îú‚îÄ‚îÄ doc_items: List[DocItem]
  ‚îú‚îÄ‚îÄ sections: List[SectionInfo]
  ‚îú‚îÄ‚îÄ chunks: List[TypeAwareChunk]
  ‚îú‚îÄ‚îÄ chunk_to_docitem_map: Dict[str, ChunkToDocItemMapping]   ‚Üê pour Pass 1.3b
  ‚îú‚îÄ‚îÄ docitem_to_chunks_map: Dict[str, List[str]]              ‚Üê index invers√©
  ‚îú‚îÄ‚îÄ unit_index: Dict[str, UnitIndexResult]                   ‚Üê pour Pass 1.3 Pointer
  ‚îú‚îÄ‚îÄ doc_title: Optional[str]
  ‚îú‚îÄ‚îÄ page_count: int
  ‚îî‚îÄ‚îÄ doc_version_id: str                                      ‚Üê hash stable v1:{sha256}
```

#### 6.2.6 Cache Loader ‚Äî Reconstruction depuis le cache

**Fichier :** `src/knowbase/stratified/pass0/cache_loader.py`

**Objectif :** Reconstruire un `Pass0Result` depuis un fichier cache JSON, √©vitant de re-parser le DoclingDocument.

**Formats support√©s :**

| Format cache | Donn√©es disponibles | Limites |
|-------------|---------------------|---------|
| `v2`, `v3`, `v4` | Chunks s√©rialis√©s dans `stats.structural_graph.chunks[]` | DocItems non s√©rialis√©s |
| `v5` | Chunks + DocItems s√©rialis√©s dans `stats.structural_graph.items[]` | Sections non s√©rialis√©es |
| `v1_legacy` | Pages brutes dans `extracted_text.pages[]` | 1 chunk/DocItem/section par page (d√©grad√©) |

**Vision Observations (ADR-20260126)** :
Le CacheLoader extrait les `vision_results[]` du cache et les convertit en `VisionObservation` (hors graphe de connaissance). Le param√®tre `merge_vision` est **DEPRECATED** ‚Äî par d√©faut, les r√©sultats Vision ne sont **PAS** merg√©s dans les chunks FIGURE_TEXT mais retourn√©s comme observations s√©par√©es.

#### 6.2.7 Persistance Neo4j V2

**Mode V2 (via `Pass0Adapter.process_and_persist_v2()`)** :
- Labels : `Document`, `Section`, `DocItem` (labels V2 simplifi√©s)
- Relations : `(Document)-[:HAS_SECTION]->(Section)`, `(Section)-[:SUBSECTION_OF]->(Section)`, `(Section)-[:CONTAINS_ITEM]->(DocItem)`
- IDs composites V2 pour `section_id` et `docitem_id`

**Mode legacy (via `StructuralGraphBuilder._persist_to_neo4j()`)** :
- Labels : `DocumentVersion`, `SectionContext`, `DocItem`, `PageContext`, `TypeAwareChunk`
- Relations : `(DocumentContext)-[:HAS_VERSION]->(DocumentVersion)`, `(DocumentVersion)-[:HAS_SECTION]->(SectionContext)`, `(SectionContext)-[:CONTAINS]->(DocItem)`, `(DocItem)-[:ON_PAGE]->(PageContext)`, `(TypeAwareChunk)-[:DERIVED_FROM]->(DocItem)`
- Feature flag `stratified_pipeline_v2` : si activ√©, skip la cr√©ation de `PageContext` (fusionn√© dans Document)

**Lazy DocItem Persistence (ADR)** :
La fonction `persist_pass0_to_neo4j_sync()` impl√©mente une strat√©gie de **persistance lazy** pour les DocItems :
- Seuls `Document` et `Section` sont cr√©√©s imm√©diatement
- Les `DocItem` sont cr√©√©s **√† la demande** lors de Pass 1.3 (Anchor Resolution) quand une Information est PROMOTED et n√©cessite un lien `ANCHORED_IN`
- Raison : ~6700 DocItems/doc ‚Üí ~50-200 DocItems/doc effectivement ancr√©s (evidence-first)

#### 6.2.8 Mod√®le de donn√©es ‚Äî DocItem

**Fichier :** `src/knowbase/structural/models.py` ‚Äî classe `DocItem` (Pydantic BaseModel)

Champs principaux :

| Cat√©gorie | Champs | Description |
|-----------|--------|-------------|
| **Identifiants (D1)** | `tenant_id`, `doc_id`, `doc_version_id`, `item_id` | Identification multi-tenant + version |
| **Type et contenu (D3)** | `item_type: DocItemType`, `heading_level`, `text`, `table_json` | Type canonique + contenu |
| **Hi√©rarchie Docling (D4.6)** | `parent_item_id`, `group_id` | Conserv√©s comme metadata (non utilis√©s pour le graphe V2) |
| **Provenance (D5)** | `page_no`, `bbox_*`, `charspan_start/end`, `charspan_start_docwide/end_docwide` | Position spatiale + textuelle |
| **Ordre (D2)** | `reading_order_index` | Position dans l'ordre de lecture du document |
| **Scope Layer** | `mentioned_concepts: List[str]` | Concepts mentionn√©s (peupl√© par Pass 2) ‚Äî navigation, pas assertions |
| **Section** | `section_id` | Assign√© par SectionProfiler |

**Hash stable du document (D6)** :
- Algorithme : `compute_doc_hash()` dans `models.py`
- Format : `v1:{sha256}`
- Exclut les champs volatiles (`mtime`, `path`, `created_at`, `pipeline_version`, etc.)
- Arrondit les floats (D6.3, pr√©cision 2 d√©cimales)
- Trie les listes par `self_ref` pour le d√©terminisme (D6.4)
- JSON canonique (cl√©s tri√©es, pas d'espaces)

---

### 6.3 Conformit√© ADR ‚Äî Pass 0 Structural

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Pass 0 Structural produit **uniquement** la structure documentaire (Document, Section, DocItem). Aucune entit√© s√©mantique (Concept, Information, Subject, Theme) n'est cr√©√©e. La s√©paration est stricte. |
| AV2-2 | 8 types de nodes maximum | ‚úÖ | Pass 0 Structural cr√©e 3 des 8 types autoris√©s : Document, Section, DocItem. Pas de prolif√©ration de types interm√©diaires. |
| AV2-3 | Ancrage Information sur DocItem | ‚úÖ | Les mappings `chunk_to_docitem_map` et `docitem_to_chunks_map` sont construits pour permettre l'Anchor Resolution en Pass 1.3b. L'ancrage sera `Information -[:ANCHORED_IN]-> DocItem`, pas sur chunk Qdrant. |
| AV2-4 | DocItem atomique | ‚úÖ | Chaque DocItem correspond √† un item Docling natif (`paragraph`, `table`, `picture`, `list_item`, `heading`, `caption`, `footnote`). Pas de fusion agressive ‚Äî les items TEXT cons√©cutifs restent s√©par√©s en tant que DocItems, et ne sont fusionn√©s que dans les chunks (TypeAwareChunker). |
| AV2-8 | Dual Storage | ‚úÖ | Les `TypeAwareChunk` alimentent Qdrant (retrieval vectoriel). Les `DocItem`/`SectionInfo` alimentent Neo4j (graphe structurel navigable). La s√©paration des responsabilit√©s est respect√©e. |
| AV2-10 | < 250 nodes/document | ‚ö†Ô∏è | Pass 0 Structural cr√©e potentiellement beaucoup de DocItems (~centaines √† ~milliers par document). Cependant, la strat√©gie Lazy DocItem Persistence r√©duit les nodes **effectivement cr√©√©s** en Neo4j √† ~50-200 (ceux ancr√©s par des Informations PROMOTED). Le reste existe uniquement en m√©moire dans le `Pass0Result`. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Chaque DocItem a `charspan_start/end` (per-page) et `charspan_start_docwide/end_docwide` (document-wide), permettant la tra√ßabilit√© exacte vers le texte source. `reading_order_index` assure l'ordonnancement. |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Pass 0 Structural traite un seul document √† la fois. Le `doc_version_id` (hash stable) identifie la version exacte. |

---

### 6.4 Risques ‚Äî Pass 0 Structural

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R0S-1 | **Heading level mal inf√©r√©** | üü° | `infer_heading_level_from_text()` utilise des patterns regex pour d√©duire le niveau de heading (`1.` ‚Üí level 1, `1.1.` ‚Üí level 2). Ces patterns peuvent √©chouer sur des num√©rotations non standard ou des headings sans num√©rotation. Un heading mal classifi√© impacte la hi√©rarchie des sections. | Fallback vers page-based si aucun heading d√©tect√©. Le profil structurel de chaque section compense partiellement (les sections mal d√©coup√©es auront un profil atypique). |
| R0S-2 | **DocItems tr√®s nombreux** | üü° | Un document de 100+ pages peut produire des milliers de DocItems (>6700 observ√©s). En m√©moire, ceci est g√©rable, mais la persistance Neo4j na√Øve serait co√ªteuse. | Lazy DocItem Persistence : seuls les DocItems ancr√©s par des Informations PROMOTED sont cr√©√©s en Neo4j (~50-200/doc). Le batch de 500 items par transaction Neo4j √©vite les timeouts. |
| R0S-3 | **Chunks NARRATIVE trop longs** | üü¢ | Le `max_chunk_size` de 3000 chars est un garde-fou. Les items narratifs cons√©cutifs sont fusionn√©s jusqu'√† cette limite. Un paragraphe unique > 3000 chars sera un chunk solo. | Le seuil de 3000 chars est configurable. Les chunks trop longs sont moins performants pour l'embedding mais restent fonctionnels. |
| R0S-4 | **Cache v5 ‚Äî Sections non s√©rialis√©es** | üü° | Le CacheLoader reconstruit les chunks et DocItems depuis le cache, mais les `SectionInfo` ne sont **pas** s√©rialis√©es. Le `Pass0Result` charg√© depuis le cache a `sections=[]`. | Les sections sont recalcul√©es si n√©cessaire par les passes suivantes (Pass 0.9 Global View utilise le full_text). Pour les cas o√π les sections sont critiques, un re-build complet via `Pass0Adapter.process_document()` est requis. |
| R0S-5 | **AssertionUnitIndexer import lazy** | üü¢ | L'import de `AssertionUnitIndexer` est fait en lazy (`try/except ImportError`). Si le module n'est pas disponible, l'indexation est silencieusement ignor√©e et `unit_index` reste vide. | Log warning √©mis. Le pipeline continue sans unit_index ‚Äî Pass 1.3 utilisera un mode fallback (copie verbatim au lieu de pointage). |
| R0S-6 | **Deux sch√©mas Neo4j coexistants** | üü° | Le code maintient deux chemins de persistance : legacy (`SectionContext`, `DocumentVersion`, `PageContext`) et V2 (`Document`, `Section`, `DocItem`). Le choix d√©pend du feature flag `stratified_pipeline_v2`. | Le feature flag assure un basculement propre. Le code legacy sera retir√© apr√®s validation compl√®te du pipeline V2. |
| R0S-7 | **Hash de document non d√©terministe** | üü¢ | Le `compute_doc_hash()` utilise des mesures de d√©terminisme (exclusion champs volatiles, tri par self_ref, arrondi floats, JSON canonique). Mais si Docling change la structure de sortie entre versions, le hash changera. | Le pr√©fixe `v1:` du hash permet de versionner l'algorithme. Le `docling_version` est trac√© dans `DocumentVersion`. |

---

## 7. Pass 0.5 ‚Äî R√©solution de Cor√©f√©rence Linguistique

**Fichiers principaux :**
- `src/knowbase/ingestion/pipelines/pass05_coref.py` ‚Äî classe `Pass05CoreferencePipeline` (orchestrateur)
- `src/knowbase/linguistic/coref_engine.py` ‚Äî interface `ICorefEngine` + impl√©mentations (spaCy, FastCoref, RuleBased, Coreferee)
- `src/knowbase/linguistic/coref_models.py` ‚Äî mod√®les (`MentionSpan`, `CoreferenceChain`, `CorefDecision`, `CorefLink`)
- `src/knowbase/linguistic/coref_gating.py` ‚Äî classe `CorefGatingPolicy` (politique conservative)
- `src/knowbase/linguistic/coref_named_gating.py` ‚Äî classe `NamedNamedGatingPolicy` (filtrage Named‚ÜîNamed)
- `src/knowbase/linguistic/coref_llm_arbiter.py` ‚Äî classe `CorefLLMArbiter` (arbitrage LLM pour cas ambigus)
- `src/knowbase/linguistic/coref_cache.py` ‚Äî classe `CorefCache` (cache des d√©cisions)
- `src/knowbase/linguistic/coref_persist.py` ‚Äî classe `CorefPersistence` (persistance Neo4j)

**Objectif :** R√©soudre les cor√©f√©rences linguistiques (pronoms ‚Üí ant√©c√©dents, groupes nominaux ‚Üí entit√©s nomm√©es) dans le texte du document. La r√©solution produit une `CorefGraph` (MentionSpan, CoreferenceChain, CorefDecision) persist√©e en Neo4j.

**‚ö†Ô∏è Statut V2 :** Pass 0.5 est **d√©sactiv√©e** quand le feature flag `stratified_pipeline_v2` est activ√© (cf. risque R0-8 dans section 5.10). Les mod√®les `MentionSpan`/`CoreferenceChain` ne font pas partie de l'architecture V2 (8 types de nodes max). La cor√©f√©rence en V2 sera g√©r√©e diff√©remment (√† d√©finir).

### 7.0 Vue d'ensemble Pass 0.5

**Entrants :**

| Entrant | Type | Source |
|---------|------|--------|
| DocItems de type narratif | Nodes Neo4j (`NARRATIVE_TEXT`, `PARAGRAPH`, `TEXT`) | Pass 0 Structural (graphe Document ‚Üí Section ‚Üí DocItem) |
| TypeAwareChunks | Nodes Neo4j | Pass 0 Structural (chunking type-aware) |
| Langue du document | `str` (propri√©t√© `DocumentVersion.language`) | Pass 0 Structural (d√©tection ou d√©faut `"en"`) |
| `doc_id` | `str` | ID unique du document |
| `doc_version_id` | `str` | ID de version du document |
| `tenant_id` | `str` | Contexte multi-tenant (d√©faut : `"default"`) |

**Texte reconstitu√© :** Le pipeline charge les DocItems de type narratif depuis Neo4j, les trie par `reading_order_index`, et les concat√®ne (s√©parateur `\n`) pour obtenir le `full_text` soumis √† l'engine de cor√©f√©rence. Les chunks sont utilis√©s pour l'ancrage secondaire des MentionSpan.

**Sorties :**

| Sortie | Type | Destination |
|--------|------|-------------|
| `MentionSpan` | Nodes Neo4j (fait linguistique) | Graphe linguistique ‚Äî ancrage sur DocItem + chunk |
| `CoreferenceChain` | Nodes Neo4j (groupement) | Graphe linguistique ‚Äî relie N MentionSpan cor√©f√©rents |
| `CorefLink` | Relations Neo4j (`COREFERS_TO`) | Graphe linguistique ‚Äî liens r√©solus pronom ‚Üí ant√©c√©dent |
| `CorefDecision` | Nodes Neo4j (audit) | Trail d'audit ‚Äî d√©cisions RESOLVED / ABSTAIN / NON_REFERENTIAL |
| `MATCHES_PROTOCONCEPT` | Relations Neo4j (optionnel) | Alignements lexicaux MentionSpan ‚Üí ProtoConcept |
| `Pass05Result` | Dataclass Python | M√©triques retourn√©es √† l'orchestrateur (spans, cha√Ænes, liens, taux, timing) |

**M√©triques cl√©s (Pass05Result) :**

| M√©trique | Description |
|----------|-------------|
| `mention_spans_created` | Nombre total de MentionSpan cr√©√©s |
| `chains_created` | Nombre de CoreferenceChain (clusters) |
| `links_created` | Nombre de CorefLink (`COREFERS_TO`) r√©solus |
| `decisions_created` | Nombre de CorefDecision (audit trail) |
| `resolution_rate` | % de pronoms r√©solus / total pronoms d√©tect√©s |
| `abstention_rate` | % de pronoms abstention / total pronoms d√©tect√©s |
| `engine_used` | Nom de l'engine utilis√© (FastCoref, Coreferee, RuleBased) |
| `processing_time_ms` | Dur√©e totale du traitement |

**Configuration (Pass05Config) :**

| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `confidence_threshold` | 0.85 | Seuil de confiance engine pour accepter un lien pronom |
| `max_sentence_distance` | 2 | Distance max en phrases entre pronom et ant√©c√©dent |
| `max_char_distance` | 500 | Distance max en caract√®res |
| `enable_named_gating` | `True` | Activer le filtrage Named‚ÜîNamed (Jaro-Winkler + LLM) |
| `named_jaro_reject` | 0.55 | Seuil Jaro-Winkler pour REJECT imm√©diat |
| `named_jaro_accept` | 0.95 | Seuil Jaro-Winkler pour ACCEPT imm√©diat |
| `named_jaccard_accept` | 0.8 | Seuil Token Jaccard pour ACCEPT |
| `enable_llm_arbitration` | `True` | Activer l'arbitrage LLM pour les paires en REVIEW |
| `skip_if_exists` | `True` | Idempotence ‚Äî ne pas retraiter si CorefGraph existe |
| `create_protoconcept_links` | `True` | Cr√©er les liens MATCHES_PROTOCONCEPT |
| `persist_decisions` | `True` | Persister les CorefDecision (audit) |
| `fastcoref_batch_size` | 50 000 | Taille max d'un batch (chars) pour √©viter OOM |
| `fastcoref_batch_overlap` | 3 000 | Overlap entre batches (chars) pour contexte cor√©f√©rentiel |

---

### 7.1 M√©canismes de r√©solution

#### 7.1.1 Architecture en pipeline

```
√âtape 1: Idempotence ‚Äî V√©rifier si d√©j√† trait√©
  ‚Üì
√âtape 2: Charger DocItems + Chunks depuis Neo4j
  ‚Üì
√âtape 3: D√©tecter la langue du document
  ‚Üì
√âtape 4: S√©lectionner l'engine de cor√©f√©rence
  ‚Üì
√âtape 5: R√©soudre les cor√©f√©rences (engine + batching OOM)
  ‚Üì
√âtape 5b: Filtrer les faux positifs Named‚ÜîNamed (gating + LLM)
  ‚Üì
√âtape 6: Appliquer la politique de gating (pronoms)
  ‚Üì
√âtape 7: Persister la CorefGraph dans Neo4j
  ‚Üì
√âtape 8: Cr√©er les liens MATCHES_PROTOCONCEPT (optionnel)
```

#### 7.1.2 Engines de cor√©f√©rence (multilingue)

| Engine | Langues | Disponibilit√© | Caract√©ristiques |
|--------|---------|---------------|-----------------|
| **FastCoref** (spaCy + F-Coref) | EN | `FASTCOREF_AVAILABLE` | Meilleur pour l'anglais, ~800MB m√©moire, singleton pour √©viter double-chargement |
| **SpaCy CoreferenceResolver** | EN | `SPACY_COREF_AVAILABLE` | Alternative spaCy native |
| **Coreferee** | FR, EN, DE | `COREFEREE_AVAILABLE` | Exp√©rimental, dernier release 2022 ‚Äî marqu√© swappable |
| **RuleBasedEngine** | Toutes | Toujours | Fallback universel ‚Äî heuristiques regex simples |

S√©lection automatique via `get_engine_for_language(lang)` ‚Äî EN pr√©f√®re FastCoref, FR/DE pr√©f√®re Coreferee, fallback vers RuleBasedEngine.

#### 7.1.3 Section batching (OOM Fix)

Pour les documents > `fastcoref_batch_size` chars (d√©faut : 50 000 chars, ~12 pages), le pipeline :
1. Groupe les DocItems par sections jusqu'√† `batch_size` chars
2. Ajoute un overlap de `fastcoref_batch_overlap` chars (d√©faut : 3000) entre batches pour le contexte cor√©f√©rentiel
3. R√©sout chaque batch ind√©pendamment via l'engine
4. Ajuste les offsets des clusters au document complet
5. D√©duplique les clusters de l'overlap (par signature `(start, end)`)

#### 7.1.4 Politique de gating conservative (pronoms)

**Classe :** `CorefGatingPolicy`

**Invariants :**
- **L3** : Closed-world disambiguation ‚Äî candidats locaux uniquement
- **L4** : Abstention-first ‚Äî ambigu√Øt√© ‚Üí ABSTAIN

| Crit√®re | Seuil | Effet |
|---------|-------|-------|
| Confiance engine | ‚â• 0.85 | En-dessous ‚Üí ABSTAIN (LOW_CONFIDENCE) |
| Distance sentences | ‚â§ 2 | Au-del√† ‚Üí ABSTAIN (LONG_DISTANCE) |
| Distance chars | ‚â§ 500 | Au-del√† ‚Üí ABSTAIN (LONG_DISTANCE) |
| Candidats multiples | >1 valide | ‚Üí ABSTAIN (AMBIGUOUS) |
| Pronom non r√©f√©rentiel | D√©tect√© | ‚Üí NON_REFERENTIAL (IMPERSONAL, EXPLETIVE, GENERIC) |

**D√©cision types :** `RESOLVED` | `ABSTAIN` | `NON_REFERENTIAL`

#### 7.1.5 Gating Named‚ÜîNamed (ADR_COREF_NAMED_NAMED_VALIDATION)

**Classe :** `NamedNamedGatingPolicy`

**Objectif :** Filtrer les faux positifs quand l'engine regroupe deux noms propres diff√©rents dans un m√™me cluster (ex: "SAP S/4HANA" ‚Üî "SAP BTP").

**Strat√©gie 3-tier :**

| Condition | D√©cision | Seuils |
|-----------|----------|--------|
| Jaro-Winkler < 0.55 | `REJECT` | STRING_SIMILARITY_LOW |
| Jaro-Winkler ‚â• 0.95 OU Token Jaccard ‚â• 0.8 | `ACCEPT` | HIGH_SIMILARITY |
| Zone interm√©diaire | `REVIEW` | Envoy√© au LLM Arbiter |

**LLM Arbiter** (`CorefLLMArbiter`) : Arbitrage batch pour les paires en REVIEW. D√©cisions : `same_entity=True/False` ou `abstain=True`.

**Cache** (`CorefCache`) : Cache des d√©cisions Named‚ÜîNamed (paire ‚Üí m√™me entit√© ou non) pour √©viter les appels LLM r√©p√©t√©s.

#### 7.1.6 Types de mentions

| Type | Exemples | Traitement |
|------|----------|-----------|
| `PRONOUN` | it, they, il, elle | Gating conservative (L4) |
| `PROPER` | SAP S/4HANA, iPhone 15 | Named‚ÜîNamed gating |
| `NP` | le syst√®me, the device | Named‚ÜîNamed gating |
| `OTHER` | ‚Äî | Exclu de la r√©solution |

#### 7.1.7 Mod√®les de donn√©es CorefGraph

```
MentionSpan (fait linguistique, pas assertion)
  ‚îú‚îÄ‚îÄ tenant_id, doc_id, doc_version_id
  ‚îú‚îÄ‚îÄ docitem_id (ancrage principal ‚Üí DocItem)
  ‚îú‚îÄ‚îÄ chunk_id (ancrage secondaire ‚Üí TypeAwareChunk)
  ‚îú‚îÄ‚îÄ span_start, span_end (offsets exacts ‚Äî L1)
  ‚îú‚îÄ‚îÄ surface (texte verbatim)
  ‚îú‚îÄ‚îÄ mention_type: MentionType (PRONOUN | NP | PROPER | OTHER)
  ‚îî‚îÄ‚îÄ lang, sentence_index

CoreferenceChain
  ‚îú‚îÄ‚îÄ chain_id, tenant_id, doc_id, doc_version_id
  ‚îú‚îÄ‚îÄ method (engine utilis√©)
  ‚îú‚îÄ‚îÄ confidence
  ‚îú‚îÄ‚îÄ mention_ids: List[str]
  ‚îî‚îÄ‚îÄ representative_mention_id

CorefLink
  ‚îú‚îÄ‚îÄ source_mention_id ‚Üí target_mention_id
  ‚îú‚îÄ‚îÄ method, confidence
  ‚îú‚îÄ‚îÄ scope: CorefScope (SAME_SENTENCE | PREV_SENTENCE | PREV_CHUNK | WINDOW_K)
  ‚îî‚îÄ‚îÄ window_chars

CorefDecision (audit trail)
  ‚îú‚îÄ‚îÄ decision_type: RESOLVED | ABSTAIN | NON_REFERENTIAL
  ‚îú‚îÄ‚îÄ reason_code: ReasonCode (UNAMBIGUOUS, AMBIGUOUS, LOW_CONFIDENCE, etc.)
  ‚îî‚îÄ‚îÄ reason_detail
```

#### 7.1.8 Liens MATCHES_PROTOCONCEPT

Si `create_protoconcept_links=True`, le pipeline :
1. Charge les `ProtoConcept` du document depuis Neo4j
2. Pour chaque `MentionSpan` de type PROPER ou NP, cherche une correspondance lexicale avec un ProtoConcept
3. Cr√©e un lien `MATCHES_PROTOCONCEPT` (confidence=0.9, method="lexical_match")

**NOTE GOUVERNANCE** : Ces liens sont des **alignements lexicaux/ancr√©s**, PAS des identit√©s ontologiques.

---

### 7.2 Conformit√© ADR ‚Äî Pass 0.5

| # | Axe ADR | Statut | Analyse |
|---|---------|--------|---------|
| AV2-1 | S√©paration structure / s√©mantique | ‚ö†Ô∏è | Pass 0.5 op√®re sur la couche **linguistique**, distincte de la structure documentaire ET de la s√©mantique. Cependant, les `MentionSpan` et `CoreferenceChain` ne font pas partie des 8 types de nodes V2, ce qui cr√©e un conflit avec AV2-2. |
| AV2-2 | 8 types de nodes maximum | ‚ùå | Pass 0.5 cr√©e des types de nodes suppl√©mentaires (`MentionSpan`, `CoreferenceChain`, `CorefDecision`) qui ne font pas partie du sch√©ma V2 (Document, Section, DocItem, Subject, Theme, Concept, Information, AssertionLog). C'est la raison de la d√©sactivation en mode V2. |
| NS-2 | LLM = Extracteur evidence-locked | ‚úÖ | Le LLM Arbiter est strictement un **arbitre** (m√™me entit√© ou non ?), pas un extracteur. Il n'invente pas de cor√©f√©rences ‚Äî il valide/rejette celles propos√©es par l'engine. |
| NS-3 | Citation exacte obligatoire | ‚úÖ | Les `MentionSpan` conservent les offsets exacts (`span_start`, `span_end`) et le texte verbatim (`surface`). Invariant L1 (Evidence-preserving) respect√©. |

**Invariants linguistiques :**

| Invariant | Description | Statut |
|-----------|-------------|--------|
| L1 | Evidence-preserving (spans exacts) | ‚úÖ Offsets conserv√©s |
| L2 | No generated evidence (pas de texte modifi√© persist√©) | ‚úÖ Le texte original n'est jamais alt√©r√© |
| L3 | Closed-world disambiguation | ‚úÖ Candidats locaux (fen√™tre courte) uniquement |
| L4 | Abstention-first | ‚úÖ Politique conservative, seuil 0.85, ABSTAIN sur ambigu√Øt√© |
| L5 | Linguistic-only | ‚úÖ Pas de relation conceptuelle ‚Äî fait linguistique pur |

---

### 7.3 Risques ‚Äî Pass 0.5

| # | Risque | Niveau | Description | Mitigation |
|---|--------|--------|-------------|------------|
| R05-1 | **D√©sactiv√©e en V2** | üü° | Pass 0.5 est enti√®rement d√©sactiv√©e quand `stratified_pipeline_v2=True`. Les cor√©f√©rences ne sont pas r√©solues dans le pipeline V2, ce qui peut d√©grader la qualit√© de l'extraction d'assertions (pronoms non r√©solus dans le texte source). | D√©cision architecturale consciente. La cor√©f√©rence V2 n√©cessite une refonte pour s'int√©grer dans le sch√©ma 8-nodes (potentiellement comme metadata sur DocItem plut√¥t que nodes s√©par√©s). |
| R05-2 | **OOM FastCoref sur gros documents** | üü° | FastCoref charge ~800MB (spaCy + mod√®le). Les documents > 50K chars n√©cessitent un section batching. Le seuil a √©t√© r√©duit de 100K √† 50K apr√®s un OOM sur un document de 106K chars. | Section batching avec overlap de 3K chars. Singleton FastCoref pour √©viter double chargement. |
| R05-3 | **Coreferee obsol√®te** | üü° | Le moteur Coreferee (utilis√© pour FR/DE) a son dernier release en 2022. Il est marqu√© "swappable sans douleur" mais aucune alternative n'est identifi√©e. | Fallback vers RuleBasedEngine si Coreferee indisponible. L'interface `ICorefEngine` permet le swap transparent. |
| R05-4 | **Offset lookup simpliste** | üü° | `_find_docitem_for_offset()` et `_find_chunk_for_offset()` retournent actuellement le **premier** DocItem/chunk (TODO dans le code). L'ancrage MentionSpan ‚Üí DocItem est potentiellement incorrect pour les mentions en milieu/fin de document. | Marqu√© TODO dans le code. En mode V2 d√©sactiv√©, ce bug n'a pas d'impact. |
| R05-5 | **Named‚ÜîNamed gating ‚Äî faux rejets** | üü¢ | Le seuil Jaro-Winkler de 0.55 pour REJECT est agressif. Des variantes l√©gitimes (ex: "SAP S/4HANA 2023" vs "S/4HANA") pourraient √™tre rejet√©es √† tort. | Le LLM Arbiter traite les cas en zone grise (REVIEW). Le cache √©vite les appels LLM r√©p√©t√©s. |
| R05-6 | **Pas d'int√©gration avec Pass 1.x** | üü° | Les r√©sultats de cor√©f√©rence (CorefGraph) ne sont pas exploit√©s par les passes s√©mantiques (Pass 1.1-1.4). Le module `coref_assertion_bridge.py` existe mais l'int√©gration n'est pas document√©e. | Le pipeline V2 contournera ce probl√®me en int√©grant la cor√©f√©rence diff√©remment (√† concevoir). |

---

## 8. Pass 0.9 ‚Äî Construction de la Vue Globale

### 8.0 Vue d'ensemble Pass 0.9

**Module :** `src/knowbase/stratified/pass09/` (5 fichiers)
**Orchestrateur :** `global_view_builder.py` ‚Äî classe `GlobalViewBuilder`
**Mod√®les :** `models.py` ‚Äî `GlobalView`, `SectionSummary`, `GlobalViewCoverage`, `Pass09Config`
**Composants :** `SectionSummarizer` (r√©sum√© LLM par section), `HierarchicalCompressor` (assemblage meta-document)

**Objectif :** Construire un **meta-document** synth√©tique (15-30K chars, cible 20K) repr√©sentant l'int√©gralit√© du document source sous forme compress√©e. Ce meta-document remplace le `full_text` brut comme entr√©e pour les passes analytiques (Pass 1.1, Pass 1.2), permettant au LLM de ¬´ voir ¬ª l'ensemble du document dans une seule fen√™tre de contexte.

**Entrants :**

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `sections` | `List[Dict]` | Pass 0 Structural (graphe structurel) | Liste des sections avec `id`, `title`, `level`, `text` ou `chunk_ids` |
| `chunks` | `Dict[str, str]` | Pass 0 Structural | Mapping `chunk_id ‚Üí texte` pour r√©soudre les chunk_ids des sections |
| `full_text` | `str` | Pass 0 Extraction | Texte lin√©aris√© complet (fallback si sections sans texte direct) |
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `tenant_id` | `str` | Pipeline | Identifiant du tenant (d√©faut : `"default"`) |
| `doc_title` | `str` | Pass 0 Extraction | Titre du document (optionnel) |

**S√©quence d'ex√©cution :**

```
√âtape 1: Extraction des textes par section
  ‚Üí _extract_section_texts() : r√©solution text direct / chunk_ids / item_ids / positions
  ‚Üì
√âtape 2: R√©sum√© de chaque section (SectionSummarizer)
  ‚Üí Parall√®le async avec Semaphore(max_concurrent_summaries=10)
  ‚Üí D√©cision par section : skip / verbatim / LLM / truncated
  ‚Üì
√âtape 3: Compression en meta-document (HierarchicalCompressor)
  ‚Üí Assemblage hi√©rarchique (headings Markdown)
  ‚Üí Construction TOC enrichie
  ‚Üí Enforcement des limites de taille
  ‚Üì
√âtape 4: Construction GlobalView
  ‚Üí meta_document + section_summaries + toc_enhanced + coverage + m√©tadonn√©es
  ‚Üì
√âtape 5: Validation
  ‚Üí coverage_ratio ‚â• 95%, taille dans [5000, 30000] chars
```

**Sortie :**

```
GlobalView
  ‚îú‚îÄ‚îÄ tenant_id: str
  ‚îú‚îÄ‚îÄ doc_id: str
  ‚îú‚îÄ‚îÄ meta_document: str  ‚Üê SORTIE PRINCIPALE (15-30K chars)
  ‚îú‚îÄ‚îÄ section_summaries: Dict[str, SectionSummary]
  ‚îú‚îÄ‚îÄ toc_enhanced: str  ‚Üê TOC enrichie avec concepts et types
  ‚îú‚îÄ‚îÄ coverage: GlobalViewCoverage
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_total: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_summarized: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_verbatim: int
  ‚îÇ     ‚îú‚îÄ‚îÄ sections_skipped: int
  ‚îÇ     ‚îú‚îÄ‚îÄ chars_original: int
  ‚îÇ     ‚îú‚îÄ‚îÄ chars_meta_document: int
  ‚îÇ     ‚îú‚îÄ‚îÄ coverage_ratio: float  (propri√©t√© calcul√©e)
  ‚îÇ     ‚îî‚îÄ‚îÄ compression_ratio: float  (propri√©t√© calcul√©e)
  ‚îú‚îÄ‚îÄ created_at: datetime
  ‚îú‚îÄ‚îÄ llm_model_used: str  ("gpt-4o-mini" ou "")
  ‚îú‚îÄ‚îÄ total_llm_calls: int
  ‚îú‚îÄ‚îÄ total_tokens_used: int
  ‚îú‚îÄ‚îÄ build_time_seconds: float
  ‚îú‚îÄ‚îÄ is_fallback: bool  (True si construit sans LLM)
  ‚îî‚îÄ‚îÄ errors: List[str]
```

---

### 8.1 SectionSummarizer

**Fichier :** `src/knowbase/stratified/pass09/section_summarizer.py` ‚Äî classe `SectionSummarizer`
**Mod√®le LLM :** `gpt-4o-mini` (temperature=0.3, max_tokens=500)

**Objectif :** R√©sumer chaque section du document en un r√©sum√© informatif fid√®le (max 800 chars par d√©faut), tout en identifiant les concepts, types d'assertions et valeurs cl√©s pr√©sents dans la section.

#### 8.1.1 Strat√©gie de traitement par section

Le SectionSummarizer applique une **strat√©gie adaptative** en fonction de la taille de chaque section :

| Condition | M√©thode (`method`) | Comportement |
|-----------|-------------------|-------------|
| `char_count < 200` (`section_min_chars_to_summarize`) | `"skipped"` | Copie verbatim du texte (ou `"(section vide)"`) ‚Äî section trop courte pour m√©riter un r√©sum√© |
| `200 ‚â§ char_count < 500` (`section_max_chars_for_verbatim`) | `"verbatim"` | Copie verbatim ‚Äî section suffisamment courte pour √™tre incluse telle quelle |
| `char_count ‚â• 500` | `"llm"` | R√©sum√© via appel LLM ‚Äî section n√©cessitant compression |
| Erreur LLM | `"truncated"` | Fallback : premiers 1000 chars (`fallback_chars_per_section`) + `"..."` |

#### 8.1.2 Parall√©lisation des r√©sum√©s

Les r√©sum√©s sont ex√©cut√©s en **parall√®le asynchrone** via `asyncio.gather()` avec un `asyncio.Semaphore(max_concurrent_summaries)` (d√©faut : 10 appels simultan√©s). Les erreurs individuelles sont captur√©es via `return_exceptions=True` ‚Äî un √©chec d'une section n'emp√™che pas le traitement des autres.

#### 8.1.3 Prompt LLM

**System prompt :** Directive d'expert en analyse documentaire. R√®gles :
- Maximum `{max_chars}` caract√®res (configurable, d√©faut 800)
- Identifier les **concepts cl√©s** (termes techniques, entit√©s)
- Noter les **types d'assertions** (definitional, prescriptive, factual, procedural)
- Pr√©server les **valeurs sp√©cifiques** (versions, pourcentages, limites, dur√©es)
- Ne PAS interpr√©ter, seulement r√©sumer fid√®lement
- Style neutre et factuel

**User prompt :** Fournit le titre de section, son niveau hi√©rarchique, et le contenu (tronqu√© √† 8000 chars pour respecter la fen√™tre LLM).

**Format de r√©ponse attendu :** JSON strict :
```json
{
  "summary": "R√©sum√© de la section (max {max_chars} chars)",
  "concepts": ["concept1", "concept2", "concept3"],
  "assertion_types": ["definitional", "prescriptive", "factual"],
  "key_values": ["TLS 1.2", "99.95%", "30 days"]
}
```

**Nettoyage de la r√©ponse :** Le parser g√®re les r√©ponses envelopp√©es dans des blocs markdown (\`\`\`json...\`\`\`) et, en cas d'√©chec de parsing JSON, extrait manuellement le r√©sum√© (premiers `max_chars` chars de la r√©ponse brute).

#### 8.1.4 Compatibilit√© multi-client LLM

Le SectionSummarizer supporte trois interfaces LLM :

| Interface | M√©thode de d√©tection | Appel |
|-----------|---------------------|-------|
| OpenAI-style | `hasattr(client, "chat")` | `client.chat.completions.create(model="gpt-4o-mini", ...)` |
| vLLM-style | `hasattr(client, "generate")` | `client.generate(prompt=..., max_tokens=500)` |
| Sync fallback | `hasattr(client, "complete")` | `client.complete(prompt=..., max_tokens=500)` |

#### 8.1.5 Sortie `SectionSummary`

```
SectionSummary
  ‚îú‚îÄ‚îÄ section_id: str
  ‚îú‚îÄ‚îÄ section_title: str
  ‚îú‚îÄ‚îÄ level: int  (1=H1, 2=H2, 3=H3...)
  ‚îú‚îÄ‚îÄ summary: str  (500-1000 chars max)
  ‚îú‚îÄ‚îÄ concepts_mentioned: List[str]  (termes techniques identifi√©s)
  ‚îú‚îÄ‚îÄ assertion_types: List[str]  (definitional, prescriptive, factual, procedural)
  ‚îú‚îÄ‚îÄ key_values: List[str]  (valeurs sp√©cifiques pr√©serv√©es)
  ‚îú‚îÄ‚îÄ char_count_original: int
  ‚îú‚îÄ‚îÄ char_count_summary: int
  ‚îú‚îÄ‚îÄ method: str  ("llm" | "verbatim" | "truncated" | "skipped")
  ‚îî‚îÄ‚îÄ compression_ratio: float  (propri√©t√© calcul√©e : summary/original)
```

#### 8.1.6 Statistiques de traitement

Le SectionSummarizer maintient un dictionnaire `_stats` accessible via la propri√©t√© `stats` :
- `sections_processed` : nombre de sections r√©sum√©es par LLM
- `sections_skipped` : nombre de sections trop courtes
- `sections_verbatim` : nombre de sections copi√©es verbatim
- `total_tokens_in` / `total_tokens_out` : tokens consomm√©s
- `errors` : liste des erreurs rencontr√©es

---

### 8.2 HierarchicalCompressor

**Fichier :** `src/knowbase/stratified/pass09/hierarchical_compressor.py` ‚Äî classe `HierarchicalCompressor`

**Objectif :** Assembler les `SectionSummary` individuels en un **meta-document unique** structur√© hi√©rarchiquement, respectant les contraintes de taille (5K-30K chars) et produisant une TOC enrichie.

#### 8.2.1 M√©canisme de compression

La m√©thode `compress()` ex√©cute 4 √©tapes s√©quentielles :

```
1. _calculate_coverage()     ‚Üí GlobalViewCoverage (statistiques)
2. _build_meta_document()    ‚Üí str (meta-document structur√© Markdown)
3. _build_enhanced_toc()     ‚Üí str (table des mati√®res enrichie)
4. _enforce_size_limits()    ‚Üí str (meta-document ajust√© si n√©cessaire)
```

#### 8.2.2 Calcul de couverture (`_calculate_coverage`)

It√®re sur tous les `SectionSummary` et classifie :

| M√©thode du r√©sum√© | Compteur incr√©ment√© |
|-------------------|---------------------|
| `"llm"` | `sections_summarized` |
| `"verbatim"` | `sections_verbatim` |
| `"truncated"` | `sections_summarized` (troncature = fallback de r√©sum√©) |
| `"skipped"` | `sections_skipped` |

**coverage_ratio** = `(sections_summarized + sections_verbatim) / sections_total`

> ‚ö†Ô∏è **Note :** Les sections `"skipped"` ne comptent PAS dans la couverture. Le seuil minimum configurable est `min_coverage_ratio = 0.95` (95%).

#### 8.2.3 Construction du meta-document (`_build_meta_document`)

Format Markdown structur√© hi√©rarchiquement :

```markdown
# Document: [titre]

## [Section niveau 1]
[r√©sum√©]
**Concepts:** concept1, concept2
**Types:** definitional, prescriptive
**Valeurs:** TLS 1.2, 99.95%

### [Section niveau 2]
[r√©sum√©]
...
```

**R√®gles de formatage :**
- Le niveau de heading Markdown = `min(level + 1, 4)` ‚Äî maximum `####` pour √©viter la pollution
- Les concepts sont limit√©s √† 10 par section
- Les valeurs cl√©s sont limit√©es √† 8 par section
- Les m√©tadonn√©es enrichies (Concepts, Types, Valeurs) sont ajout√©es uniquement si pr√©sentes
- Les sections sont assembl√©es dans l'**ordre original** du document (`sections_order`)

#### 8.2.4 Table des mati√®res enrichie (`_build_enhanced_toc`)

Construit une TOC avec num√©rotation hi√©rarchique automatique et m√©tadonn√©es inline :

```
# Table des Mati√®res Enrichie

1. Architecture Overview [5 concepts, definitional/prescriptive]
  1.1 Components [3 concepts, factual]
  1.2 Deployment Model [2 concepts, procedural]
2. Security Framework [4 concepts, prescriptive]
```

**M√©canisme de num√©rotation :** Compteurs par niveau (5 niveaux max), reset des niveaux inf√©rieurs √† chaque incr√©mentation d'un niveau sup√©rieur.

#### 8.2.5 Enforcement des limites de taille (`_enforce_size_limits`)

| Condition | Action |
|-----------|--------|
| `len(meta_document) > meta_document_max_chars` (30K) | Troncature intelligente via `_smart_truncate()` |
| `len(meta_document) ‚â§ meta_document_max_chars` | Aucune action |

**Troncature intelligente (`_smart_truncate`) :**
1. Les **headings** (`#...`) sont **toujours pr√©serv√©s**
2. Les lignes de contenu sont ajout√©es tant que le budget le permet (marge de s√©curit√© : 100 chars)
3. Les m√©tadonn√©es (`**Concepts:**...`) sont supprim√©es en dernier
4. Un marqueur `[... document tronqu√© pour respecter limite tokens ...]` est ajout√© en fin

#### 8.2.6 Sortie

```
Tuple[str, str, GlobalViewCoverage]
  ‚îú‚îÄ‚îÄ meta_document: str            ‚Üê Document compress√© structur√© (5K-30K chars)
  ‚îú‚îÄ‚îÄ toc_enhanced: str             ‚Üê TOC enrichie avec concepts/types
  ‚îî‚îÄ‚îÄ coverage: GlobalViewCoverage  ‚Üê Statistiques de couverture
```

---

### 8.3 GlobalViewBuilder ‚Äî Orchestration

**Fichier :** `src/knowbase/stratified/pass09/global_view_builder.py` ‚Äî classe `GlobalViewBuilder`

**Objectif :** Orchestrer la construction compl√®te de la `GlobalView` en coordonnant `SectionSummarizer` et `HierarchicalCompressor`.

#### 8.3.1 Extraction des textes par section (`_extract_section_texts`)

R√©sout le texte de chaque section selon **5 strat√©gies** en cascade :

| Priorit√© | Condition | Source du texte |
|----------|-----------|----------------|
| 1 | `section.text` existe | Texte direct de la section |
| 2 | `section.chunk_ids` non vide | Concat√©nation des chunks r√©f√©renc√©s |
| 3 | `section.item_ids` non vide | Concat√©nation des items (DocItems) depuis le mapping chunks |
| 4 | `section.start_pos / end_pos` d√©finis | D√©coupage du `full_text` par positions |
| 5 | Aucune source | Cha√Æne vide `""` |

#### 8.3.2 Mode LLM (`_build_with_llm`) ‚Äî async

1. **R√©sum√©** : `SectionSummarizer.summarize_sections()` ‚Äî parall√®le async
2. **Compression** : `HierarchicalCompressor.compress()` ‚Äî synchrone
3. **Assemblage** : `GlobalView` avec `is_fallback=False`, mod√®le `"gpt-4o-mini"`

#### 8.3.3 Mode Fallback (`_build_fallback`) ‚Äî synchrone

Activ√© quand :
- Aucun `llm_client` n'est fourni
- Appel via `build_sync()` (compatibilit√© FastAPI synchrone)

**Strat√©gie :** Pour chaque section, tronque le texte aux premiers `fallback_chars_per_section` (1000) caract√®res + `"..."`. Toutes les sections obtiennent `method="truncated"`. Pas d'extraction de concepts/types/valeurs.

#### 8.3.4 Validation de la GlobalView

La m√©thode `GlobalView.is_valid(config)` v√©rifie :
1. `coverage.coverage_ratio ‚â• config.min_coverage_ratio` (95%)
2. `len(meta_document) ‚â• config.meta_document_min_chars` (5000)
3. `len(meta_document) ‚â§ config.meta_document_max_chars` (30000)

Si la validation √©choue, l'erreur est logg√©e et ajout√©e √† `errors`, mais la `GlobalView` est tout de m√™me retourn√©e.

#### 8.3.5 Fonction utilitaire `build_global_view()`

Fonction de convenance async au niveau module pour usage simplifi√© :

```python
from knowbase.stratified.pass09 import build_global_view

global_view = await build_global_view(
    doc_id="doc_123",
    tenant_id="default",
    sections=sections,
    chunks=chunks,
    llm_client=openai_client,
)
```

---

### 8.4 Int√©gration dans le Pipeline (Orchestrateur Pass 1)

**Fichier :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî classe `Pass1OrchestratorV2`

Pass 0.9 est int√©gr√© comme **premi√®re phase** de l'orchestrateur Pass 1, avant l'analyse documentaire (Pass 1.1).

#### 8.4.1 Activation

- Flag `enable_pass09` (d√©faut : `True`) dans le constructeur de `Pass1OrchestratorV2`
- Configuration optionnelle via `pass09_config: Pass09Config`
- Le `GlobalViewBuilder` est initialis√© dans le constructeur si `enable_pass09=True`

#### 8.4.2 Flux d'ex√©cution dans `process()`

```
1. PHASE 0.9: GlobalView Construction
   ‚îú‚îÄ‚îÄ Si sections vides : cr√©ation depuis chunks (fallback)
   ‚îú‚îÄ‚îÄ Appel build_sync() (mode synchrone FastAPI)
   ‚îú‚îÄ‚îÄ Si GlobalView valide ‚Üí analysis_content = global_view.meta_document
   ‚îú‚îÄ‚îÄ Si GlobalView vide/erreur ‚Üí analysis_content = content brut (fallback)
   ‚îî‚îÄ‚îÄ Si Pass 0.9 d√©sactiv√© ‚Üí analysis_content = content brut
   ‚Üì
2. PHASE 1.1: Document Analysis
   ‚îú‚îÄ‚îÄ Utilise analysis_content (= meta-document OU content brut)
   ‚îú‚îÄ‚îÄ Si toc_enhanced disponible ‚Üí utilise pour l'analyse au lieu de la TOC brute
   ‚îî‚îÄ‚îÄ Produit Subject, Themes, DocumentStructure
   ‚Üì
3. PHASE 1.2: Concept Identification
   ‚îú‚îÄ‚îÄ Utilise analysis_content (= meta-document OU content brut)
   ‚îî‚îÄ‚îÄ Produit List[Concept]
```

#### 8.4.3 Pr√©paration des sections (router API)

**Fichier :** `src/knowbase/stratified/api/router.py`

Avant d'appeler l'orchestrateur Pass 1, le router API pr√©pare les sections pour Pass 0.9 :

```python
sections_for_pass09 = []
for section in structural_sections:
    sections_for_pass09.append({
        "id": section.id,
        "title": section.title,
        "level": section.level,
        "text": section.text,          # Texte direct si disponible
        "chunk_ids": section.chunk_ids  # IDs de chunks r√©f√©renc√©s
    })
```

Ces sections sont pass√©es via le param√®tre `sections=sections_for_pass09` √† l'orchestrateur.

---

### 8.5 Configuration Pass 0.9

**Classe :** `Pass09Config` (dataclass)

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `section_summary_max_chars` | `int` | `800` | Taille max d'un r√©sum√© de section |
| `section_summary_min_chars` | `int` | `100` | Taille min d'un r√©sum√© |
| `section_min_chars_to_summarize` | `int` | `200` | Seuil sous lequel une section est skip/verbatim |
| `section_max_chars_for_verbatim` | `int` | `500` | Seuil sous lequel une section est copi√©e verbatim |
| `meta_document_min_chars` | `int` | `5000` | Taille min du meta-document |
| `meta_document_max_chars` | `int` | `30000` | Taille max du meta-document |
| `meta_document_target_chars` | `int` | `20000` | Taille cible du meta-document |
| `min_coverage_ratio` | `float` | `0.95` | Couverture minimum requise (95%) |
| `max_concurrent_summaries` | `int` | `10` | Nombre max de r√©sum√©s LLM en parall√®le |
| `enable_fallback` | `bool` | `True` | Active le mode fallback (troncature) |
| `fallback_chars_per_section` | `int` | `1000` | Chars par section en mode fallback |

---

### 8.6 Conformit√© ADR ‚Äî Pass 0.9

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| P09-1 | **Couverture 100% sections** | ‚ö†Ô∏è | Le meta-document it√®re sur toutes les sections dans `sections_order`, mais les sections `"skipped"` (< 200 chars) ne comptent pas dans le `coverage_ratio`. | Le coverage_ratio exige 95% (`min_coverage_ratio`), pas 100%. Les sections tr√®s courtes sont incluses en verbatim ou skip mais toujours pr√©sentes dans le meta-document. |
| P09-2 | **Compression hi√©rarchique** | ‚úÖ | `HierarchicalCompressor._build_meta_document()` pr√©serve la hi√©rarchie H1 > H2 > H3 via le calcul `"#" * min(level + 1, 4)`. | Limitation √† `####` (H4) pour √©viter la pollution Markdown. La structure originale est fid√®lement reproduite. |
| P09-3 | **Meta-document 15-25K chars** | ‚ö†Ô∏è | Fourchette impl√©ment√©e : [5000, 30000] chars (config), cible 20000. | La fourchette est plus large que l'ADR (15-25K). Le `_enforce_size_limits` tronque intelligemment si > 30K. Pas de m√©canisme d'expansion si < 5K. |
| P09-4 | **95% minimum sections r√©sum√©es** | ‚úÖ | `min_coverage_ratio = 0.95` dans `Pass09Config`, v√©rifi√© par `GlobalView.is_valid()`. | Les sections `"skipped"` ne comptent pas, mais les sections vides sont rares dans un document structur√©. |
| P09-5 | **Fallback mode (Option C)** | ‚úÖ | `_build_fallback()` op√©rationnel : tronque chaque section aux premiers 1000 chars. Mode synchrone, sans appel LLM. Activ√© automatiquement si `llm_client=None` ou via `build_sync()`. | Le fallback est fonctionnel et produit une GlobalView valide avec `is_fallback=True`. |
| P09-6 | **Int√©gration dans Pass 1.1 et 1.2** | ‚úÖ | L'orchestrateur Pass 1 utilise `global_view.meta_document` comme `analysis_content` pour Pass 1.1 (DocumentAnalyzer) et Pass 1.2 (ConceptIdentifier). La `toc_enhanced` remplace la TOC brute pour l'analyse. | L'int√©gration est compl√®te avec fallback automatique sur `content` brut si GlobalView absente ou invalide. |

---

### 8.7 Risques ‚Äî Pass 0.9

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R09-1 | **Mode sync = toujours fallback** | üü° | `build_sync()` utilise syst√©matiquement le mode fallback (troncature), m√™me si un `llm_client` est disponible. Les r√©sum√©s LLM ne sont accessibles qu'en mode async. | Le router API actuel utilise `build_sync()` dans le contexte FastAPI. Pour b√©n√©ficier des r√©sum√©s LLM, il faudrait refactorer vers `build()` async. |
| R09-2 | **Pas de gestion du budget tokens** | üü° | Le texte envoy√© au LLM est tronqu√© √† 8000 chars (`text[:8000]`), mais il n'y a pas de calcul de tokens r√©el (tiktoken). Pour les sections longues en encodage non-ASCII, 8000 chars peut d√©passer la fen√™tre du mod√®le. | Ajouter un compteur de tokens r√©el ou r√©duire la limite de chars pour les langues non-latines. |
| R09-3 | **Perte d'information dans les sections skip** | üü¢ | Les sections < 200 chars sont `"skipped"` et incluses verbatim. Aucune extraction de concepts/types/valeurs n'est effectu√©e pour ces sections. | Impact mineur : les sections tr√®s courtes contiennent rarement des concepts distincts non couverts par les sections parentes. |
| R09-4 | **D√©tection de format de r√©ponse LLM fragile** | üü° | Le parser JSON nettoie les blocs markdown mais ne g√®re pas tous les cas de malformation (ex : JSON avec commentaires, trailing commas). | Le fallback vers extraction manuelle (`response[:max_chars]`) garantit qu'un r√©sum√© est toujours produit, m√™me si les m√©tadonn√©es (concepts, types) sont perdues. |
| R09-5 | **Mod√®le LLM hardcod√©** | üü¢ | Le mod√®le `"gpt-4o-mini"` est hardcod√© dans `_call_openai_style()` et dans les m√©tadonn√©es de `GlobalView`. Pas de routing via `llm_models.yaml`. | Acceptable pour V2 beta. √Ä int√©grer au `LLMRouter` pour la production. |
| R09-6 | **Pas de cache des r√©sum√©s** | üü° | Chaque ex√©cution de Pass 0.9 recalcule tous les r√©sum√©s de section, m√™me pour un document d√©j√† trait√©. Pas de persistance des `SectionSummary`. | Ajouter un cache bas√© sur `hash(section_text)` pour √©viter les appels LLM redondants lors de re-traitements. |
| R09-7 | **Fourchette de taille plus large que l'ADR** | üü¢ | L'ADR sp√©cifie 15-25K chars, l'impl√©mentation accepte 5K-30K. | La fourchette √©largie est pragmatique pour g√©rer les documents tr√®s courts (< 15K) et tr√®s longs (> 25K). Le `meta_document_target_chars = 20000` reste dans la cible ADR. |

### 8.8 Pipeline V2.2 ‚Äî Extract-then-Structure (2026-02-02)

**ADR de r√©f√©rence :** `doc/ongoing/ADR_PASS1_V22_HYBRID_EXTRACT_THEN_STRUCTURE.md`
**Feature flag :** `stratified_pipeline_v2.pass1_v22` (d√©faut: `false`)

Le pipeline V2.2 introduit une approche **Extract-then-Structure** qui s'appuie sur les zones de la GlobalView construite en Pass 0.9. Au lieu du flux V2.1 (analyse documentaire ‚Üí concepts ‚Üí assertions lin√©aire), le V2.2 :

1. **Construit la GlobalView avec zones** ‚Äî La GlobalView identifie des zones th√©matiques coh√©rentes dans le document
2. **Extrait par zone** ‚Äî Chaque zone est trait√©e ind√©pendamment par un orchestrateur `Pass1OrchestratorV22`
3. **Structure a posteriori** ‚Äî Les concepts et informations sont structur√©s apr√®s extraction, pas avant

**Fichiers cl√©s :**

| Fichier | R√¥le |
|---------|------|
| `src/knowbase/stratified/pass1_v22/orchestrator.py` | `Pass1OrchestratorV22` ‚Äî orchestrateur zone-aware |
| `src/knowbase/stratified/pass09/global_view_builder.py` | `GlobalViewBuilder.build_sync()` ‚Äî construction GlobalView avec zones |
| `src/knowbase/stratified/pass09/models.py` | Mod√®le `GlobalView` avec `zones: List[Zone]` |

**Fallback :** Si la GlobalView ne produit pas de zones, le pipeline retombe sur V2.1 automatiquement.

**Activation dans le reprocess :**

```python
use_v22 = get_stratified_v2_config("pass1_v22", tenant_id)
if use_v22:
    gv_builder = GlobalViewBuilder(llm_client=llm_client)
    global_view = gv_builder.build_sync(...)
    orchestrator_v22 = Pass1OrchestratorV22(...)
    pass1_result = orchestrator_v22.process(global_view=global_view, ...)
```

---

## 9. Pass 1.1 ‚Äî Analyse Documentaire

**Fichier principal :** `src/knowbase/stratified/pass1/document_analyzer.py` ‚Äî classe `DocumentAnalyzerV2`
**Orchestration :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî `Pass1OrchestratorV2.process()`, lignes 227-251
**Schema Structured Output :** `src/knowbase/stratified/pass1/llm_schemas.py` ‚Äî `DocumentAnalysisResponse`

### 9.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `doc_title` | `str` | Pass 0 | Titre du document extrait |
| `content` / `analysis_content` | `str` | Pass 0.9 ou Pass 0 | **Changement cl√© V2 :** si Pass 0.9 actif, le contenu analys√© est le `meta-document` (vue globale comprim√©e 15-25K chars). Sinon, le contenu brut complet est utilis√©. |
| `toc` / `toc_for_analysis` | `Optional[str]` | Pass 0 / Pass 0.9 | Table des mati√®res. Si `global_view.toc_enhanced` disponible (depuis Pass 0.9), elle remplace la TOC brute. Sinon, extraction heuristique via `extract_toc_from_content()`. |
| `char_limit` | `int` | Config (d√©faut: 4000) | Limite de caract√®res pour le preview envoy√© au LLM |

### 9.2 Objectifs

Pass 1.1 r√©alise l'analyse structurelle de haut niveau du document selon l'approche **top-down** (AV2-7). Les trois sorties principales sont :

1. **Subject** ‚Äî R√©sum√© du sujet principal en 1 phrase, avec un nom court (5-10 mots) d√©riv√© automatiquement si non fourni par le LLM.
2. **DocumentStructure** ‚Äî Classification de la structure de d√©pendance du document selon 3 types universels issus de l'ADR Mod√®le de Lecture Stratifi√©e :
   - **CENTRAL** : assertions d√©pendantes d'un artefact unique (ex : guide produit SAP). Test : ¬´ sans X, ce document a-t-il un sens ? ¬ª ‚Üí NON.
   - **TRANSVERSAL** : assertions ind√©pendantes du contexte (ex : r√©glementation GDPR). Test : remplacer le nom propre ‚Üí assertion reste vraie.
   - **CONTEXTUAL** : assertions conditionnelles, vraies uniquement sous certaines conditions.
3. **Themes** ‚Äî Liste des th√®mes majeurs (5-10 maximum) identifi√©s dans le document.

**Sortie annexe :** d√©tection du flag `is_hostile` si le nombre de th√®mes d√©passe `HOSTILE_SUBJECT_THRESHOLD = 10`, indiquant un document multi-sujet probl√©matique.

### 9.3 M√©canismes

#### 9.3.1 Appel LLM

L'analyse est **enti√®rement d√©l√©gu√©e au LLM** (pas d'algorithme heuristique en mode production) :

1. **Pr√©paration du preview** : `content[:char_limit]` (4000 chars par d√©faut)
2. **Chargement des prompts** depuis `src/knowbase/stratified/prompts/pass1_prompts.yaml` (cl√© `document_analysis`), avec fallback sur prompts par d√©faut int√©gr√©s √† la classe
3. **G√©n√©ration** : appel `llm_client.generate(system_prompt, user_prompt, max_tokens=1500)`
4. **Parsing** : extraction du bloc JSON (````json ... ````) ou parsing direct de la r√©ponse

**Schema Structured Output (Volet B) :**

```python
class DocumentAnalysisResponse(BaseModel):
    subject_name: str    # max 50 chars ‚Äî Nom court (5-10 mots)
    subject: str         # max 200 chars ‚Äî R√©sum√© 1 phrase
    structure: StructureInfo  # chosen: CENTRAL|TRANSVERSAL|CONTEXTUAL + justification
    themes: List[str]    # max 10 th√®mes
    language: LanguageEnum  # fr|en|de
```

Ce schema est utilisable avec vLLM Structured Outputs (`response_format={"type": "json_schema"}`) pour garantir la structure JSON.

#### 9.3.2 Validation et conversion

La m√©thode `_validate_and_convert()` transforme la r√©ponse LLM en objets Pydantic V2 :

- **Subject** : cr√©ation avec `subject_id = f"subj_{doc_id}"`, structure de d√©pendance pars√©e, justification optionnelle, langue d√©tect√©e
- **Themes** : chaque th√®me re√ßoit un `theme_id = f"theme_{doc_id}_{idx}"`. Le champ `scoped_to_sections` est initialis√© vide (sera rempli ult√©rieurement).
- **D√©rivation du nom court** : si le LLM ne fournit pas `subject_name`, il est d√©riv√© du texte du sujet (premiers mots avant la premi√®re virgule ou le premier point, tronqu√© √† 80 chars)

#### 9.3.3 D√©tection de documents HOSTILE

Apr√®s l'analyse LLM, un test post-hoc v√©rifie si le document est "hostile" :

```python
is_hostile = len(themes) > HOSTILE_SUBJECT_THRESHOLD  # seuil = 10
```

Un document hostile est un document multi-sujet qui rend l'identification de concepts difficile. Le flag `is_hostile` est propag√© √† Pass 1.2 o√π il **r√©duit le budget de concepts de moiti√©**.

#### 9.3.4 Mode fallback (tests uniquement)

Si `allow_fallback=True` et aucun LLM n'est disponible, un mode heuristique est activ√© :

- **Structure** : d√©tection par mots-cl√©s dans le titre (`guide`, `product` ‚Üí CENTRAL ; `regulation`, `gdpr` ‚Üí TRANSVERSAL ; sinon ‚Üí CONTEXTUAL)
- **Langue** : d√©tection par comptage de stop-words (fr/en/de) sur les 5000 premiers caract√®res
- **Th√®mes** : 3 th√®mes g√©n√©riques (Introduction, Contenu Principal, Conclusion)

**‚ö†Ô∏è Ce mode est r√©serv√© aux tests unitaires** ‚Äî en production, l'absence de LLM provoque une `RuntimeError` explicite.

#### 9.3.5 Extraction de TOC heuristique

La m√©thode `extract_toc_from_content()` tente d'extraire une table des mati√®res du contenu brut :

- D√©tection de l'en-t√™te TOC (regex multilingue : ¬´ table of contents ¬ª, ¬´ sommaire ¬ª, ¬´ table des mati√®res ¬ª)
- Extraction des lignes de format `N.N.N Titre` apr√®s l'en-t√™te
- Arr√™t √† la premi√®re ligne vide apr√®s ‚â•3 entr√©es de TOC

### 9.4 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `subject` | `Subject` | Sujet avec `subject_id`, `name`, `text`, `structure`, `language`, `justification` | Pass 1.2 (context pour concepts), Pass1Result |
| `themes` | `List[Theme]` | Liste de th√®mes avec `theme_id`, `name`, `scoped_to_sections=[]` | Pass 1.2 (rattachement concepts), Pass1Result |
| `is_hostile` | `bool` | Flag document multi-sujet (>10 th√®mes) | Pass 1.2 (r√©duction budget concepts) |

### 9.5 Conformit√© ADR ‚Äî Pass 1.1

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| AV2-7 | **Top-down** | ‚úÖ | Pass 1.1 est la premi√®re phase s√©mantique, √©tablissant Subject et Themes avant toute identification de concepts. | Conforme √† l'inversion de flux V1 ‚Üí V2 (bottom-up ‚Üí top-down). |
| AV2-1 | **S√©paration structure/s√©mantique** | ‚úÖ | Subject et Themes sont des entit√©s purement s√©mantiques, sans lien direct avec la structure documentaire (Section, DocItem). | Les Themes ont un champ `scoped_to_sections` mais il est initialis√© vide √† ce stade. |
| NS-2 | **LLM = Extracteur** | ‚úÖ | Le LLM identifie sujet, structure et th√®mes ‚Äî il n'inf√®re pas de relations causales ni ne r√©sout de contradictions. | L'analyse est descriptive et observationnelle. |
| P09-6 | **Int√©gration Pass 0.9** | ‚úÖ | Si Pass 0.9 actif, `analysis_content = global_view.meta_document` et `toc_for_analysis = global_view.toc_enhanced`. | Fallback automatique sur contenu brut si GlobalView absente. |

### 9.6 Risques ‚Äî Pass 1.1

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R11-1 | **Preview tronqu√© √† 4000 chars** | üü° | Seuls les 4000 premiers caract√®res du contenu (ou du meta-document) sont envoy√©s au LLM. Pour des documents longs, les th√®mes en fin de document peuvent √™tre manqu√©s. | Compens√© par l'utilisation du meta-document Pass 0.9 qui comprime tout le document en 15-25K chars. La TOC (brute ou enrichie) fournit une vue d'ensemble additionnelle. |
| R11-2 | **Seuil HOSTILE fixe** | üü¢ | Le seuil de 10 th√®mes est arbitraire et non adaptatif √† la taille du document. Un document de 500 pages avec 11 th√®mes est flagg√© hostile comme un document de 10 pages. | Impact mineur : le flag hostile r√©duit le budget concepts (Pass 1.2) mais n'emp√™che pas le traitement. |
| R11-3 | **Pas de validation crois√©e structure/contenu** | üü° | La classification CENTRAL/TRANSVERSAL/CONTEXTUAL repose uniquement sur le jugement LLM. Aucune v√©rification algorithmique n'est effectu√©e. | Le champ `justification` permet un audit humain. L'impact est limit√© car la structure influence principalement le budget de concepts. |
| R11-4 | **Fallback analyse = donn√©es non fiables** | üü¢ | Le mode fallback produit 3 th√®mes g√©n√©riques et un sujet d√©riv√© du titre. | Le fallback est strictement r√©serv√© aux tests (`allow_fallback=True`). En production, une `RuntimeError` est lev√©e. |
| R11-5 | **Pas de d√©tection de langue robuste** | üü° | La d√©tection heuristique (comptage de stop-words) est utilis√©e uniquement en fallback. En mode LLM, la langue est d√©clar√©e par le mod√®le sans validation. | Risque faible : les documents sont g√©n√©ralement dans une langue connue (fr/en/de). |

---

## 10. Pass 1.2 ‚Äî Identification des Concepts

**Fichier principal :** `src/knowbase/stratified/pass1/concept_identifier.py` ‚Äî classe `ConceptIdentifierV2`
**Raffinement it√©ratif :** `src/knowbase/stratified/pass1/concept_refiner.py` ‚Äî classe `ConceptRefinerV2` (Pass 1.2b)
**Orchestration :** `src/knowbase/stratified/pass1/orchestrator.py` ‚Äî `Pass1OrchestratorV2.process()`, lignes 253-275 (Pass 1.2) et 399-533 (Pass 1.2b)
**Schema Structured Output :** `src/knowbase/stratified/pass1/llm_schemas.py` ‚Äî `ConceptIdentificationResponse`
**Note :** le fichier `trigger_enricher.py` mentionn√© dans la spec n'existe pas ‚Äî la validation et l'enrichissement des triggers lexicaux sont int√©gr√©s directement dans `ConceptIdentifierV2` (m√©thodes `_validate_lexical_triggers`, `_validate_role_requirements`, `_get_top_frequent_tokens`).

### 10.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `doc_id` | `str` | Pipeline | Identifiant unique du document |
| `subject_text` | `str` | Pass 1.1 | Texte du sujet identifi√© |
| `structure` | `str` | Pass 1.1 | Structure de d√©pendance (`CENTRAL`, `TRANSVERSAL`, `CONTEXTUAL`) |
| `themes` | `List[Theme]` | Pass 1.1 | Th√®mes identifi√©s pour rattachement des concepts |
| `content` / `analysis_content` | `str` | Pass 0.9 ou Pass 0 | Contenu analys√© (meta-document ou contenu brut) |
| `is_hostile` | `bool` | Pass 1.1 | Flag document multi-sujet (r√©duit le budget de moiti√©) |
| `language` | `str` | Pass 1.1 | Langue du document (`fr`, `en`, `de`) |
| `n_sections` | `Optional[int]` | Pass 0 Structural | Nombre de sections pour le calcul du budget adaptatif |

### 10.2 Objectifs

Pass 1.2 identifie les **ConceptSitu√©s** du document ‚Äî des unit√©s conceptuelles frugales, sp√©cifiques et ancr√©es dans le texte. L'objectif est conforme aux principes ARCH V2 :

1. **Frugalit√© (AV2-6)** ‚Äî Initialement 5-15 concepts par document, √©tendu √† un **budget adaptatif** (V2.2, 2026-01-27) calcul√© dynamiquement selon la taille du document.
2. **Rattachement aux th√®mes** ‚Äî Chaque concept est obligatoirement li√© √† un th√®me identifi√© en Pass 1.1.
3. **R√¥le typ√©** ‚Äî Chaque concept re√ßoit un r√¥le : `CENTRAL` (c≈ìur du document), `STANDARD` (important secondaire), `CONTEXTUAL` (contexte).
4. **Lexical triggers obligatoires (C1)** ‚Äî Chaque concept doit poss√©der 2-4 tokens discriminants pr√©sents dans le texte, v√©rifi√©s par un algorithme de validation multi-crit√®res.
5. **Anti-aspirateurs (C1b)** ‚Äî Validation que les triggers ne sont pas trop fr√©quents (top 50 tokens du document), emp√™chant les concepts "aspirateurs" qui captent trop d'assertions.

### 10.3 M√©canismes

#### 10.3.1 Budget adaptatif (V2.2)

Le budget de concepts n'est plus fixe mais calcul√© dynamiquement :

```python
def compute_concept_budget(n_sections: int, is_hostile: bool = False) -> int:
    # Formule: clamp(20, 40, 15 + sqrt(sections) * 3)
    raw_budget = 15 + math.sqrt(n_sections) * 3
    budget = max(20, min(40, round(raw_budget)))
    if is_hostile:
        budget = max(10, budget // 2)
    return budget
```

**Propri√©t√©s cl√©s :**
- Croissance **sub-lin√©aire** : 4√ó sections ‚Üí ~2√ó concepts
- Plancher 20 concepts (petits documents)
- Plafond 40 concepts (limit√© par le contexte vLLM √† 8192 tokens input+output)
- Documents hostiles : budget divis√© par 2 (minimum 10)

| Sections | Budget normal | Budget hostile |
|----------|--------------|----------------|
| 20 | 28 | 14 |
| 50 | 36 | 18 |
| 100 | 45 ‚Üí 40 (cap) | 20 |
| 200+ | 40 (cap) | 20 |

**Fallback** si `n_sections` non fourni : 30 (normal) ou 10 (hostile).

#### 10.3.2 Appel LLM ‚Äî Identification initiale

1. **Chargement des prompts** depuis `pass1_prompts.yaml` (cl√© `concept_identification`)
2. **Formatage** : sujet, structure, th√®mes format√©s, contenu tronqu√© √† 5000 chars
3. **G√©n√©ration** : `llm_client.generate(max_tokens=4000)` ‚Äî limit√© car vLLM context = 8192 tokens (input + output)
4. **Prompt syst√®me compact** (ADR: LLM Contract) : instructions minimalistes pour √©viter la g√©n√©ration verbose et les troncatures JSON

**Schema Structured Output (Volet B) :**

```python
class ConceptIdentificationResponse(BaseModel):
    concepts: List[ConceptCompact]     # max 100 (V2.2: adaptatif jusqu'√† 80)
    refused_terms: List[RefusedTerm]   # max 20
```

O√π chaque `ConceptCompact` contient : `name` (max 50 chars, 2-4 mots), `role` (CENTRAL|STANDARD|CONTEXTUAL), `theme` (rattachement).

#### 10.3.3 Parsing et validation robuste

La m√©thode `_parse_response()` int√®gre plusieurs garde-fous :

1. **D√©tection de troncature JSON** : si le JSON ne se termine pas par `}` ou `]`, une `ValueError` explicite est lev√©e avec le contexte (¬´ LLM Contract Violation: JSON tronqu√© ¬ª)
2. **Nettoyage JSON** (`_clean_json_string`) : suppression des trailing commas, commentaires `//` et `/* */`, remplacement des single quotes ‚Äî n√©cessaire pour les mod√®les locaux (Qwen) qui g√©n√®rent parfois du JSON invalide
3. **D√©duplication par nom** : √©limination des doublons (le LLM peut renvoyer le m√™me concept plusieurs fois), avec r√©indexation des `concept_id` apr√®s d√©duplication

#### 10.3.4 Validation des lexical triggers (C1, C1b, C1c)

La m√©thode `_validate_lexical_triggers()` applique un pipeline de validation multi-crit√®res pour chaque trigger :

**√âtape 1 ‚Äî Calcul des tokens fr√©quents** (`_get_top_frequent_tokens`) :
- Tokenisation simple (mots alphanum√©riques ‚â• 3 chars)
- Comptage par `Counter`, extraction du top 50

**√âtape 2 ‚Äî Validation individuelle de chaque trigger** :

| Crit√®re | Code | Description | Action si √©chec |
|---------|------|-------------|-----------------|
| **C1b: Longueur minimale** | `len(t) < 3` | Trigger trop court (< 3 chars), sauf patterns valeur (`VALUE_PATTERN`) | Rejet du trigger |
| **C1b: Anti-fr√©quent** | `t_lower in top_50_tokens` | Trigger dans le top 50 des tokens les plus fr√©quents du document | Rejet du trigger |
| **C1c: Pr√©sence dans le texte** | `re.search(pattern, doc_lower)` | Pour alphanum√©rique : matching word-boundary (`\b`). Pour valeurs : matching substring. | Rejet du trigger |
| **C1b: Raret√©** | `freq_rate < 0.01` | Fr√©quence d'apparition dans les unit√©s < 1% | Marqu√© `rare=True` |
| **C1b: Semi-raret√©** | `freq_rate < 0.02` | Fr√©quence < 2% | Marqu√© `rare='semi-rare'` |
| **C1b: Valeur discriminante** | `VALUE_PATTERN.match(t)` | Patterns num√©riques (versions, %, ¬∞C, ratios) sont consid√©r√©s discriminants | Marqu√© `rare='fallback_value'` |

Le `VALUE_PATTERN` reconna√Æt : `^\d+(\.\d+)*[%¬∞]?[CFc]?$` et `^\d+[:\-]\d+$`.

**√âtape 3 ‚Äî Verdict final** :
- **Concept accept√©** si ‚â• 2 triggers valides ET au moins 1 trigger rare OU semi-rare
- Sinon ‚Üí concept ajout√© √† la liste `refused_terms`

**√âtape 4 ‚Äî D√©gradation de r√¥le** (`_validate_role_requirements`) :

La validation des triggers influence le r√¥le du concept via des r√®gles de d√©gradation :

```
CENTRAL demand√© + pas de trigger rare ‚Üí d√©grad√© √† STANDARD
CENTRAL demand√© + pas de trigger rare ni semi-rare ‚Üí d√©grad√© √† CONTEXTUAL
STANDARD demand√© + pas de trigger discriminant ‚Üí d√©grad√© √† CONTEXTUAL
```

Cette m√©canique emp√™che les concepts "aspirateurs" (ex : ¬´ infrastructure SAP ¬ª) avec des triggers trop g√©n√©riques de recevoir un r√¥le CENTRAL.

#### 10.3.5 Garde-fou frugalit√©

Apr√®s la validation des triggers, un dernier garde-fou applique la limite du budget :

```python
if len(concepts) > max_concepts:
    concepts = self._apply_frugality(concepts, max_concepts)
```

La m√©thode `_apply_frugality()` trie par r√¥le (`CENTRAL > STANDARD > CONTEXTUAL`) et tronque au budget.

#### 10.3.6 G√©n√©ration de cl√© lexicale

Chaque concept re√ßoit une `lex_key` normalis√©e pour la d√©duplication future :

```python
def _generate_lex_key(name: str) -> str:
    lex = name.lower().strip()
    lex = re.sub(r'\s+', '_', lex)
    lex = re.sub(r'[^a-z0-9_]', '', lex)
    return lex
```

### 10.4 Pass 1.2b ‚Äî Raffinement it√©ratif des concepts (V2.1)

**Fichier :** `src/knowbase/stratified/pass1/concept_refiner.py` ‚Äî classe `ConceptRefinerV2`
**Activation :** flag `enable_pass12b=True` dans `Pass1OrchestratorV2` (d√©faut : activ√©)
**D√©clenchement :** apr√®s Pass 1.3 (extraction assertions) et Pass 1.4 (promotion), quand le taux de `NO_CONCEPT_MATCH` est trop √©lev√©

#### 10.4.1 Principe

Pass 1.2b est une **boucle de r√©troaction** qui analyse les assertions non-li√©es √† un concept (statut `ABSTAINED`, raison `no_concept_match`) pour identifier les concepts manquants. Il op√®re **sans relire le document**, uniquement √† partir du journal d'assertions.

#### 10.4.2 M√©triques de saturation

La classe `SaturationMetrics` (dataclass) calcule les indicateurs de d√©cision :

| M√©trique | Formule | Description |
|----------|---------|-------------|
| `promotion_rate` | `promoted / total_assertions` | Taux de promotion global |
| `no_concept_match_rate` | `no_concept_match / total_assertions` | **C4 : ratio stable** (vs /abstained dans V1) |
| `coverage_rate` | `promoted / (promoted + no_concept_match)` | Couverture conceptuelle |
| `quality_unlinked_count` | `prescriptive_unlinked + value_bearing_unlinked` | **C2 : assertions de qualit√© non-li√©es** |
| `should_iterate` | `rate > 10% AND count > 20` | **C4 : d√©clencheur stable** |

#### 10.4.3 Crit√®res de qualit√© (C2, C2b)

Seules les assertions "de qualit√©" sont consid√©r√©es pour justifier de nouveaux concepts :

- **C2 ‚Äî Assertions PRESCRIPTIVE** : type PRESCRIPTIVE explicite
- **C2 ‚Äî Assertions value-bearing** : contiennent une valeur quantifiable (versions, pourcentages, tailles, temp√©ratures, dur√©es, montants, ratios) d√©tect√©e par 7 patterns regex
- **C2b ‚Äî Obligations sans modal** : d√©tection de 10 patterns d'obligations implicites (juridique/contrats) comme ¬´ is required to ¬ª, ¬´ no later than ¬ª, ¬´ within N days ¬ª, ¬´ ne peut pas ¬ª

#### 10.4.4 Boucle it√©rative

L'orchestrateur ex√©cute la boucle suivante (dans `process()`, lignes 399-533) :

```
TANT QUE saturation.should_iterate:
  1. Calculer SaturationMetrics depuis assertion_log
  2. V√©rifier C4: rate > 10% ET count > 20
  3. Si rendement d√©croissant (< 15% r√©duction) ‚Üí ARR√äT
  4. Filtrer assertions de qualit√© (C2, C2b)
  5. Appeler ConceptRefinerV2.refine_concepts()
     ‚Üí LLM identifie concepts manquants depuis assertions non-li√©es
  6. Valider C2: chaque concept doit couvrir ‚â•2 assertions dont ‚â•1 PRESCRIPTIVE/value
  7. D√©duplication vs concepts existants et doublons internes
  8. Ajouter les nouveaux concepts √† la liste
  9. Re-linker les assertions non-li√©es avec tous les concepts (anciens + nouveaux)
  10. Re-r√©soudre les ancrages (AnchorResolver)
  11. Mettre √† jour assertion_log (ABSTAINED ‚Üí PROMOTED)
```

**Garde-fous de convergence :**

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `MAX_ITERATIONS` | 3 | Maximum d'it√©rations |
| `MAX_NEW_CONCEPTS_PER_ITER` | 10 | Concepts ajout√©s par it√©ration |
| `MAX_TOTAL_CONCEPTS` | 50 | Surface conceptuelle maximale |
| `MIN_NO_CONCEPT_MATCH` | 20 | Minimum de trous pour d√©clencher |
| `MIN_REDUCTION_RATE` | 0.15 | Gain minimum pour continuer (15%) |

#### 10.4.5 Validation des concepts raffin√©s (C2)

Chaque concept propos√© par le LLM est valid√© par `_validate_concept_quality()` :

1. Le concept doit avoir des `lexical_triggers` (‚â• 2)
2. Ces triggers doivent matcher ‚â• 2 assertions non-li√©es
3. Parmi ces assertions, ‚â• 1 doit √™tre de qualit√© (PRESCRIPTIVE ou value-bearing)

### 10.5 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `concepts` | `List[Concept]` | Concepts avec `concept_id`, `theme_id`, `name`, `role`, `lex_key`, `lexical_triggers`, `definition`, `variants` | Pass 1.3 (linking assertions), Pass 1.2b (base pour raffinement), Pass1Result |
| `refused_terms` | `List[Dict]` | Termes refus√©s avec raisons (triggers invalides, trop g√©n√©riques, etc.) | Audit, Pass1Result |
| `saturation` (via Pass 1.2b) | `SaturationMetrics` | M√©triques de couverture conceptuelle finales | Logs, diagnostic |

**Structure d'un Concept :**

```python
Concept(
    concept_id="concept_doc123_0",   # ID unique
    theme_id="theme_doc123_2",       # Rattachement th√®me
    name="TLS Configuration",        # Nom court (2-4 mots)
    role=ConceptRole.CENTRAL,        # CENTRAL | STANDARD | CONTEXTUAL
    definition=None,                 # Optionnel (enrichi en Pass 2)
    variants=[],                     # Optionnel (enrichi en Pass 2)
    lex_key="tls_configuration",     # Cl√© normalis√©e pour d√©dup
    lexical_triggers=["TLS", "1.3", "cipher suite"]  # 2-4 tokens discriminants
)
```

### 10.6 Conformit√© ADR ‚Äî Pass 1.2

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| AV2-6 | **Frugalit√© concepts (5-15 max)** | ‚ö†Ô∏è | Le budget adaptatif (V2.2) √©tend la fourchette √† [20, 40] pour l'identification initiale, plus jusqu'√† 50 via Pass 1.2b. | **D√©viation document√©e.** L'ADR initiale sp√©cifiait 5-15. L'extension √† 20-40 (+ 50 max avec 1.2b) est motiv√©e par la n√©cessit√© de couvrir des documents volumineux (>100 sections). La croissance sub-lin√©aire (`sqrt`) maintient l'esprit de frugalit√©. |
| AV2-7 | **Top-down** | ‚úÖ | Les concepts sont identifi√©s APR√àS le sujet et les th√®mes (Pass 1.1). Chaque concept est rattach√© √† un th√®me existant. | Conforme √† l'approche top-down. |
| NS-2 | **LLM = Extracteur** | ‚úÖ | Le LLM identifie les concepts depuis le texte. La validation (C1, C1b, C1c) est algorithmique (post-LLM). | Le LLM extrait, les algorithmes valident. |
| NS-7 | **Addressability-First** | ‚úÖ | Chaque concept est rattach√© √† au moins un th√®me (`theme_id`). Les `lexical_triggers` garantissent l'ancrage textuel. | Les concepts sans triggers valides sont rejet√©s. |
| P09-6 | **Int√©gration Pass 0.9** | ‚úÖ | L'identification utilise `analysis_content` (meta-document si Pass 0.9 actif). Le budget adaptatif utilise `n_sections` depuis Pass 0 Structural. | Double int√©gration : contenu comprim√© + budget bas√© sur la structure. |

### 10.7 Risques ‚Äî Pass 1.2

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R12-1 | **Budget √©tendu vs frugalit√© ADR** | üü° | Le budget adaptatif [20-40] + raffinement it√©ratif (‚Üí50 max) d√©passe significativement la fourchette ADR initiale de 5-15 concepts. | La croissance sub-lin√©aire (`sqrt`) et les garde-fous de convergence (max 3 it√©rations, min 15% r√©duction) limitent l'expansion. Le cap √† 50 concepts reste bien en-de√ß√† du legacy (~4700 nodes/doc). |
| R12-2 | **Troncature JSON (LLM Contract)** | üü° | Le contexte vLLM de 8192 tokens (input+output) peut √™tre insuffisant pour g√©n√©rer 40 concepts avec triggers. Le contenu est tronqu√© √† 5000 chars, les tokens de sortie limit√©s √† 4000. | D√©tection explicite de troncature (`ValueError` lev√©e). Le prompt syst√®me compact (ADR: LLM Contract) minimise la verbosit√©. Les Structured Outputs (Volet B) garantissent la structure JSON c√¥t√© vLLM. |
| R12-3 | **Triggers trop permissifs pour petits documents** | üü° | Pour les documents avec peu d'unit√©s (< 100), le seuil de raret√© < 1% devient tr√®s strict (< 1 unit√©). Cela peut rejeter des triggers l√©gitimes. | Le fallback `semi-rare` (< 2%) et le fallback `value` (patterns num√©riques) assouplissent la validation pour les petits corpus. |
| R12-4 | **Pass 1.2b : risque de concepts de faible valeur** | üü° | Le raffinement it√©ratif peut introduire des concepts de faible discriminance, car les assertions restantes (NO_CONCEPT_MATCH) sont par d√©finition les plus difficiles √† rattacher. | Le crit√®re C2 (‚â•2 assertions dont ‚â•1 PRESCRIPTIVE/value) et la validation de qualit√© limitent ce risque. Le cap √† 50 concepts max et le rendement d√©croissant (min 15%) assurent la convergence. |
| R12-5 | **Doublons entre LLM et raffinement** | üü¢ | Le LLM (Qwen notamment) peut reproposer des concepts d√©j√† existants lors du raffinement. | D√©duplication par nom normalis√© impl√©ment√©e √† la fois dans `_validate_and_convert()` (Pass 1.2) et `refine_concepts()` (Pass 1.2b). |
| R12-6 | **Pas de trigger_enricher.py s√©par√©** | üü¢ | L'enrichissement des triggers (TF-IDF, embedding) mentionn√© dans certains documents de design n'est pas impl√©ment√© comme composant s√©par√©. La validation est int√©gr√©e dans `ConceptIdentifierV2`. | L'impl√©mentation actuelle (fr√©quence, raret√©, word-boundary) est fonctionnelle. L'enrichissement par TF-IDF/embedding pourrait √™tre ajout√© en V3 comme composant s√©par√©. |
| R12-7 | **Nettoyage JSON fragile** | üü¢ | Le nettoyage des trailing commas et single quotes par regex peut √©chouer sur du JSON fortement malform√©. | Le nettoyage couvre les cas les plus fr√©quents (Qwen). Les Structured Outputs (Volet B) √©liminent ce risque quand activ√©s. |

---

## 11. Pass 1.3 ‚Äî Extraction d'Assertions

**Fichier principal :** `src/knowbase/stratified/pass1/assertion_extractor.py` ‚Äî classe `AssertionExtractorV2`
**Validation verbatim :** `src/knowbase/stratified/pass1/verbatim_validator.py` ‚Äî fonctions `validate_raw_assertions`, `BatchValidationStats`
**Indexation unitaire (mode pointer) :** `src/knowbase/stratified/pass1/assertion_unit_indexer.py` ‚Äî classe `AssertionUnitIndexer`
**Sch√©mas pointer :** `src/knowbase/stratified/pass1/pointer_schemas.py` ‚Äî mod√®les Pydantic `PointerConcept`, `PointerExtractionResponse`
**Validation pointer :** `src/knowbase/stratified/pass1/pointer_validator.py` ‚Äî classe `PointerValidator`

### 11.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `chunks` | `Dict[str, str]` | Pass 0 / Qdrant | Dictionnaire `chunk_id ‚Üí texte`, segments issus de la segmentation documentaire |
| `concepts` | `List[Concept]` | Pass 1.2 | Concepts identifi√©s pour le linking s√©mantique (avec `lexical_triggers`) |
| `doc_language` | `Optional[str]` | Pass 1.1 | Langue du document (`fr`, `en`, etc.) |
| `docitems` | `Dict[str, DocItem]` | Pass 0 Structural | DocItems pour le mode pointer (segmentation en unit√©s) |
| `global_view` (indirect) | `str` | Pass 0.9 | Le meta-document influence les concepts fournis en entr√©e |

### 11.2 Objectifs

Pass 1.3 extrait les **assertions s√©mantiques typ√©es** du texte et les lie aux concepts identifi√©s en Pass 1.2. L'objectif est triple :

1. **Extraction** ‚Äî Identifier les assertions (phrases porteuses de connaissance) dans chaque chunk, les classifier par type (`DEFINITIONAL`, `PRESCRIPTIVE`, `FACTUAL`, `PERMISSIVE`, `CONDITIONAL`, `CAUSAL`, `COMPARATIVE`, `PROCEDURAL`).
2. **Filtrage par Promotion Policy** ‚Äî Appliquer une politique de promotion par type pour s√©parer les assertions promotionnables de celles qui seront ABSTAINED. Filtrer les m√©ta-descriptions et fragments.
3. **Liaison s√©mantique** ‚Äî Relier chaque assertion aux concepts par raisonnement s√©mantique (pas matching lexical).

**Sortie principale :** `List[RawAssertion]` ‚Äî assertions brutes typ√©es avec `chunk_id` (avant r√©solution d'ancrage en 1.3b).

### 11.3 M√©canismes

#### 11.3.1 Deux modes d'extraction

L'extracteur supporte deux modes fondamentalement diff√©rents :

**Mode classique** (`extract_assertions`) :
- Le LLM extrait les assertions en **copiant** le texte source
- Vuln√©rable √† la reformulation (le LLM peut r√©√©crire le texte au lieu de le citer)
- N√©cessite la validation verbatim (Volet A) en post-traitement

**Mode pointer** (`extract_assertions_pointer_mode`) :
- Les DocItems sont pr√©-segment√©s en **unit√©s num√©rot√©es** (U1, U2, U3...) par `AssertionUnitIndexer`
- Le LLM **pointe** vers une unit√© au lieu de copier ‚Üí √©limine structurellement la reformulation
- Le texte verbatim est reconstruit c√¥t√© code depuis l'index des unit√©s ‚Üí **garanti exact**

Le mode pointer est le mode cible pour la conformit√© North Star NS-3 (citation exacte obligatoire).

#### 11.3.2 Extraction parall√®le (mode classique)

L'extraction op√®re en parall√®le via `ThreadPoolExecutor` :

```python
# Configuration
max_workers = int(os.environ.get("OSMOSE_LLM_WORKERS", 8))
# Filtrage: chunks < 50 chars ignor√©s
# Texte tronqu√© √† 2000 chars par chunk pour le prompt LLM
```

**Pipeline par chunk :**
1. Envoi du chunk au LLM avec prompt d'extraction (`pass1_prompts.yaml`, cl√© `assertion_extraction`)
2. Parse de la r√©ponse JSON ‚Üí liste de `RawAssertion`
3. Fallback heuristique si le LLM √©choue (`_extract_heuristic`)

**Structure de `RawAssertion` :**

```python
RawAssertion(
    assertion_id="assert_a1b2c3d4",   # UUID tronqu√©
    text="TLS 1.2 is required...",     # Texte extrait (copie ou verbatim)
    assertion_type=AssertionType.PRESCRIPTIVE,
    chunk_id="chunk_42",               # R√©f√©rence chunk source (PAS docitem_id)
    start_char=145,                    # Position dans le chunk
    end_char=287,
    confidence=0.9,                    # Confiance LLM (debug uniquement)
    language="en"
)
```

#### 11.3.3 Extraction heuristique (fallback)

Si le LLM est indisponible et `allow_fallback=True` (tests uniquement) :

1. D√©coupage par regex `(?<=[.!?])\s+` (fin de phrase)
2. Phrases < 20 chars ignor√©es
3. D√©tection du type par patterns lexicaux :
   - `must/shall/required/doit/obligatoire` ‚Üí PRESCRIPTIVE
   - `is defined as/refers to/est d√©fini` ‚Üí DEFINITIONAL
   - `may/can/possible/peut` ‚Üí PERMISSIVE
   - `if/when/unless/si/lorsque` ‚Üí CONDITIONAL
   - `because/therefore/car/donc` ‚Üí CAUSAL
   - `step/first/then/√©tape` ‚Üí PROCEDURAL
   - Par d√©faut ‚Üí FACTUAL
4. D√©tection de la langue par comptage de mots-cl√©s FR vs EN

#### 11.3.4 Validation verbatim (Volet A ‚Äî mode classique)

La m√©thode `extract_and_validate_assertions()` combine extraction + validation :

1. Extraction classique des assertions via LLM
2. Appel √† `validate_raw_assertions()` (module `verbatim_validator`)
3. V√©rification que chaque assertion est une **copie exacte** du texte source (substring match dans le chunk)
4. Les assertions reformul√©es par le LLM sont rejet√©es avec raison `ABSTAIN(reformulation)`
5. **Alerte** si taux de reformulation > 10% : le LLM ne respecte pas l'instruction ¬´ texte EXACT ¬ª

Cette validation est conforme √† NS-2 (LLM = extracteur evidence-locked) et NS-3 (citation exacte).

#### 11.3.5 Assertion Unit Indexer (mode pointer)

**Fichier :** `assertion_unit_indexer.py` ‚Äî classe `AssertionUnitIndexer`

Segmente les DocItems en **unit√©s d'assertion** atomiques pour le mode pointer :

**Strat√©gie de segmentation :**

| Cas | Entr√©e | Comportement |
|-----|--------|--------------|
| Type atomique | `list_item`, `bullet`, `table_cell` | ‚Üí une seule unit√© U1 |
| Paragraphe/autre | Texte libre | ‚Üí segmentation intelligente (phrases + clauses) |
| Segment trop long | > `max_unit_length` (500 chars) | ‚Üí re-d√©coupage sur virgules |
| Segment trop court | < `min_unit_length` (30 chars) | ‚Üí ignor√© |

**Segmentation intelligente :**

1. **D√©coupage en phrases** (`_split_sentences`) avec protection des abr√©viations :
   - Points pr√©c√©d√©s d'un mot court (1-3 lettres) ‚Üí probablement abr√©viation (sauf si suivi de majuscule)
   - Points internes √† un token (i.e., e.g.) ‚Üí abr√©viation
   - Versions (1.2, 2.0.1) ‚Üí pas de coupure
   - Acronymes point√©s (U.S.) ‚Üí pas de coupure

2. **D√©coupage en clauses** (`_split_clauses`) ‚Äî conditionnel :
   - Split sur `;` uniquement en contexte prescriptif (marqueurs : must, shall, doit, obligatoire...)
   - Split sur `:` uniquement si suivi d'une liste (bullets ou ‚â•2 virgules), PAS si suivi d'une valeur courte (version, taille, protocole)

3. **Re-d√©coupage** des segments > 500 chars sur virgules

**Structure de `AssertionUnit` :**

```python
AssertionUnit(
    unit_local_id="U1",                    # ID local au DocItem
    docitem_id="tenant:doc:item_42",       # R√©f√©rence DocItem parent
    text="TLS 1.2 is required...",         # Texte verbatim (readonly)
    char_start=0,                          # Position dans DocItem.text
    char_end=42,
    unit_type="sentence"                   # sentence | clause | bullet | segment | table_row
)
# unit_global_id ‚Üí "tenant:doc:item_42#U1" (calcul√©, jamais stock√©)
```

**Indexation des tables** (`index_table_rows`) : chaque row devient une unit√© avec format canonique tri√© alphab√©tiquement : `"Header1: Cell1 | Header2: Cell2 | ..."`.

**Helpers :**
- `format_units_for_llm(units)` ‚Üí formate en `"U1: text\nU2: text\n..."` pour le prompt LLM
- `lookup_unit_text(index, docitem_id, unit_local_id)` ‚Üí retrouve le texte verbatim depuis l'index

#### 11.3.6 Sch√©mas Pointer (Pydantic)

**Fichier :** `pointer_schemas.py`

Mod√®les Pydantic pour structurer l'output LLM en mode pointer :

**`PointerConcept`** ‚Äî Concept point√© par le LLM :

```python
class PointerConcept(BaseModel):
    label: str       # max 100 chars, "2-5 mots"
    type: Literal["PRESCRIPTIVE", "DEFINITIONAL", "FACTUAL", "PERMISSIVE"]
    unit_id: str     # Valid√© par regex "^U\d+$"
    confidence: float  # [0.0, 1.0] ‚Äî IGNOR√âE pour la promotion, debug uniquement
    value_kind: Optional[str]  # version, percentage, size, number, duration, etc.
```

**`PointerExtractionResponse`** ‚Äî R√©ponse compl√®te : `{ "concepts": [PointerConcept, ...] }`

**Progression du mod√®le de donn√©es :**

```
ConceptCandidate (top-down, sans preuve)
    ‚Üì extraction pointer + validation 3 niveaux
ConceptAnchored (avec preuve valid√©e, exploitable dans le KG)
    ‚îú‚îÄ‚îÄ exact_quote: str          # Texte verbatim GARANTI (depuis index)
    ‚îú‚îÄ‚îÄ anchor: Anchor            # docitem_id + unit_id + char_start/end
    ‚îú‚îÄ‚îÄ validation_status: str    # "VALID" ou "DOWNGRADED"
    ‚îî‚îÄ‚îÄ validation_score: float   # Score lexical
```

**Fonctions helpers :**
- `get_pointer_extraction_schema()` ‚Üí JSON Schema pour vLLM structured outputs
- `parse_pointer_response(json_str)` ‚Üí Validation Pydantic de la r√©ponse
- `pointer_to_anchored(pointer, unit_text, anchor, ...)` ‚Üí Conversion PointerConcept ‚Üí ConceptAnchored

#### 11.3.7 Pointer Validator ‚Äî Validation 3 niveaux

**Fichier :** `pointer_validator.py` ‚Äî classe `PointerValidator`

Valide chaque concept point√© par le LLM avec 3 niveaux de v√©rification **d√©terministes** (la confidence LLM n'est JAMAIS utilis√©e pour la d√©cision) :

**Niveau 1 ‚Äî Support Lexical (score pond√©r√© ‚â• 1.5) :**

| Composante | Score | Condition |
|------------|-------|-----------|
| Token exact du label (word boundary) | +1.0 par token | Matching `\b{token}\b`, ignorer tokens < 3 chars, max 2 tokens scor√©s |
| Motif valeur dans l'unit√© | +1.0 | Si `value_kind` sp√©cifi√© : v√©rifier le pattern exact. Sinon : v√©rifier pattern g√©n√©rique (`\d+(\.\d+)*\s*(%|GB|...)?`) |

‚Üí Si score < 1.5 ‚Üí **ABSTAIN** (raison : `no_lexical_support`)

**Niveau 2 ‚Äî Type Markers (coh√©rence type/contenu) :**

- Si type = `PRESCRIPTIVE` mais absence de marqueurs prescriptifs (must, shall, required, doit, obligatoire...) ‚Üí **DOWNGRADE** vers `DEFINITIONAL`
- Configurable via `strict_type_markers` (d√©faut : activ√©)

**Niveau 3 ‚Äî Value Patterns (si kind sp√©cifi√©) :**

| Kind | Pattern regex | Exemples |
|------|---------------|----------|
| `version` | `\d+(\.\d+)+` | 1.2, 3.0.1 |
| `percentage` | `\d+\s*%` | 99.9% |
| `size` | `\d+\s*(GB\|TB\|MB\|TiB\|GiB\|KB\|KiB)` | 256 GB |
| `number` | `\d+` | 42 |
| `boolean` | `\b(true\|false\|yes\|no\|enabled\|disabled)\b` | enabled |
| `duration` | `\d+\s*(ms\|s\|sec\|min\|hour\|h\|day\|d\|week\|month\|year)` | 30 min |

‚Üí Si kind sp√©cifi√© mais pattern absent ‚Üí **ABSTAIN** (raison : `value_pattern_mismatch`)

**R√©sultat final :**

| Statut | Signification |
|--------|---------------|
| `VALID` | Concept valid√©, peut √™tre promu |
| `DOWNGRADE` | Type modifi√© (ex: PRESCRIPTIVE ‚Üí DEFINITIONAL), concept conserv√© |
| `ABSTAIN` | Concept rejet√© ‚Äî ne sera pas promu |

**Reconstruction du texte verbatim :**

La fonction `reconstruct_exact_quote(unit_index, docitem_id, unit_id)` est LA garantie anti-reformulation : le texte vient TOUJOURS de l'index, JAMAIS du LLM. C'est le m√©canisme central de conformit√© NS-3.

#### 11.3.8 Filtrage par Promotion Policy

La m√©thode `filter_by_promotion_policy()` filtre les assertions **avant** le linking :

**Pr√©-filtres :**
1. **M√©ta-descriptions** : d√©tection via `promotion_engine.is_meta_pattern()` ‚Äî filtre les assertions qui d√©crivent la page au lieu d'informer (ex: ¬´ La page pr√©sente un mod√®le de d√©ploiement ¬ª)
2. **Fragments** : d√©tection via `promotion_engine.is_fragment()` ‚Äî filtre les non-assertions (noms seuls, texte sans verbe)

**Politique de promotion par type :**

| Type d'assertion | Tier | Condition de promotion |
|-----------------|------|----------------------|
| `DEFINITIONAL` | ALWAYS | Toujours promu si li√© √† un concept |
| `PRESCRIPTIVE` | ALWAYS | Toujours promu si li√© √† un concept |
| `CAUSAL` | ALWAYS | Toujours promu si li√© √† un concept |
| `FACTUAL` | CONDITIONAL | Promu si `strict_promotion=False` ET `confidence ‚â• 0.7` |
| `CONDITIONAL` | CONDITIONAL | Promu si `strict_promotion=False` ET `confidence ‚â• 0.7` |
| `PERMISSIVE` | CONDITIONAL | Promu si `strict_promotion=False` ET `confidence ‚â• 0.7` |
| `COMPARATIVE` | RARELY | Promu si `strict_promotion=False` ET `confidence ‚â• 0.9` |
| `PROCEDURAL` | NEVER | Jamais promu en Information |

Cette politique est conforme √† NS-9 (Promotion Policy par type).

#### 11.3.9 Liaison s√©mantique assertions ‚Üî concepts

La m√©thode `link_to_concepts()` √©tablit les liens entre assertions et concepts :

**Par LLM** (`_link_via_llm`) :
- Batching parall√®le : si > 30 assertions, d√©coupage en batches de 30
- Chaque batch trait√© en parall√®le via `ThreadPoolExecutor`
- Le LLM raisonne **s√©mantiquement** (pas matching lexical) ‚Äî une assertion peut concerner un concept sans le mentionner, cross-langue FR/EN
- Types de liens : `defines`, `describes`, `constrains`, `enables`, `conditions`, `causes`

**Format multi-concept (V2.1)** :
- Une assertion peut √™tre li√©e √† 1-5 concepts via `MultiConceptLink`
- Filtrage C3 v2 anti "spray & pray" avec soft gate + hard gate :
  - **Soft gate** : pas de trigger lexical dans l'assertion ‚Üí `confidence -= 0.20`
  - **Hard gate** : pas de trigger ET pas de token du nom du concept ET `confidence_adj < 0.55` ‚Üí rejet
  - Seuils : `MIN_LINK_CONFIDENCE = 0.70`, `MAX_LINKS_PER_ASSERTION = 5`
  - R√®gle top-k : si √©cart entre top-1 et top-2 ‚â§ 0.10, garder les deux

**Par heuristique** (fallback) :
- Matching lexical des variantes du concept (nom, variants, acronyme) dans le texte de l'assertion
- G√©n√©ration d'acronymes √† partir du nom multi-mots
- Confiance fix√©e √† 0.6

#### 11.3.10 Enrichissement MVP V1 (Information-First)

La m√©thode `enrich_with_mvp_v1()` enrichit les assertions avec les capacit√©s Information-First :

1. **Extraction de valeurs** via `ValueExtractor` : percent, version, number, boolean, enum
2. **Inf√©rence ClaimKey Level A** via `ClaimKeyPatterns` : patterns sans LLM
3. **√âvaluation promotion MVP V1** via `PromotionPolicy` : statuts `PROMOTED_LINKED`, `PROMOTED_UNLINKED`, rejet

**Invariant 1 :** alerte si assertions UNLINKED > 10% du total (indicateur de patterns ClaimKey insuffisants).

### 11.4 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `assertions` | `List[RawAssertion]` | Assertions brutes avec `chunk_id`, type, positions | Pass 1.3b (ancrage), Pass 1.4 (promotion) |
| `links` | `List[ConceptLink]` | Liens assertion ‚Üí concept avec type, justification, confiance | Pass 1.3b (ancrage), Pass 1.4 (promotion) |
| `promotion_result` | `PromotionResult` | Assertions promotionnables + abstenues avec raisons | Pass 1.4 |
| `verbatim_stats` | `BatchValidationStats` | Statistiques de validation verbatim (mode classique) | Diagnostic, logs |
| `unit_index` (mode pointer) | `Dict[str, UnitIndexResult]` | Index des unit√©s par DocItem | Pointer Validator, reconstruction verbatim |
| `enriched` (MVP V1) | `List[EnrichedAssertion]` | Assertions avec valeurs, ClaimKey, statut promotion | Pass 1.4 (Value Contract) |

### 11.5 Conformit√© ADR ‚Äî Pass 1.3

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| NS-2 | **LLM = Extracteur evidence-locked** | ‚úÖ | Le LLM extrait les assertions, la validation (verbatim, pointer, promotion policy) est algorithmique post-LLM. La confidence LLM est explicitement ignor√©e pour les d√©cisions de promotion dans le mode pointer. | Conforme. La s√©paration extraction/validation est claire et impl√©ment√©e. |
| NS-3 | **Citation exacte obligatoire** | ‚úÖ | Deux m√©canismes compl√©mentaires : (1) validation verbatim post-extraction (mode classique), (2) reconstruction depuis index (mode pointer). Le mode pointer **garantit structurellement** le verbatim. | Le mode pointer est la solution cible. Le mode classique reste vuln√©rable si la validation est contourn√©e. |
| NS-9 | **Promotion Policy par type** | ‚úÖ | Politique `ALWAYS/CONDITIONAL/RARELY/NEVER` conforme √† la sp√©cification NS-9. Les types ALWAYS sont : DEFINITIONAL, PRESCRIPTIVE, CAUSAL. PROCEDURAL est NEVER. | Impl√©mentation fid√®le √† l'ADR. |
| AV2-7 | **Top-down** | ‚úÖ | L'extraction d'assertions (1.3) arrive APR√àS l'identification des concepts (1.2). Le linking est guid√© par les concepts existants. | S√©quence top-down respect√©e. |
| NS-7 | **Addressability-First** | ‚ö†Ô∏è | Les assertions sont li√©es aux concepts, mais le linking multi-concept V2.1 peut cr√©er des liens de faible confiance. Le filtrage C3 v2 (soft/hard gate) mitigue ce risque mais n'est pas parfait. | Le hard gate √† 0.55 pourrait laisser passer des liens faibles. |
| NS-1 | **Information-First** | ‚ö†Ô∏è | L'enrichissement MVP V1 (`enrich_with_mvp_v1`) permet la promotion UNLINKED (sans concept). Cependant, la m√©thode `filter_by_promotion_policy()` rejette les assertions PROCEDURAL inconditionnellement. | La promotion UNLINKED adresse NS-1 mais n'est pas syst√©matiquement activ√©e (d√©pend du flag `strict_promotion`). |

### 11.6 Risques ‚Äî Pass 1.3

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R13-1 | **Reformulation LLM (mode classique)** | üü° | Le LLM (Qwen notamment) reformule au lieu de citer verbatim. La validation verbatim rejette ces assertions, ce qui r√©duit le yield. | Le mode pointer √©limine structurellement ce risque. La validation verbatim d√©tecte et rejette les reformulations avec alerte si taux > 10%. |
| R13-2 | **Coexistence de deux modes d'extraction** | üü° | Le mode classique et le mode pointer coexistent, cr√©ant une dette architecturale. Les outputs ne sont pas strictement identiques (RawAssertion vs PointerConcept). | Convergence progressive vers le mode pointer uniquement. Les deux modes partagent la m√™me Promotion Policy. |
| R13-3 | **Seuil lexical du Pointer Validator** | üü° | Le seuil de 1.5 pour le score lexical peut √™tre trop strict pour des concepts avec des labels courts (2 tokens significatifs = score max 2.0 + value pattern). Un concept pertinent mais avec un label peu discriminant pourrait √™tre rejet√©. | Le score value pattern (+1.0) compense pour les assertions avec des valeurs num√©riques. Les labels de 2-5 mots (contrainte PointerConcept) donnent g√©n√©ralement 2 tokens significatifs. |
| R13-4 | **Spray & Pray malgr√© le filtre C3 v2** | üü¢ | Le LLM peut proposer des liens multiples de faible qualit√© pour une assertion. Le hard gate (pas de signal lexical + conf_adj < 0.55) peut laisser passer des faux positifs. | Le soft gate (-0.20 sans trigger) + le cap √† 5 liens max + le seuil 0.70 sur confidence ajust√©e limitent l'inflation. Le filtrage est document√© et ajustable. |
| R13-5 | **Troncature du texte √† 2000 chars** | üü¢ | Les chunks > 2000 chars sont tronqu√©s pour le prompt LLM, ce qui peut couper des assertions en fin de chunk. | La segmentation en chunks devrait produire des segments < 2000 chars en g√©n√©ral. Les assertions tronqu√©es seraient d√©tect√©es par la validation verbatim (position incorrecte). |
| R13-6 | **Fallback heuristique en production** | üî¥ | Si `allow_fallback=True` est activ√© en production, les assertions heuristiques (confiance fixe 0.5, types approximatifs) polluent le graphe. | Le flag `allow_fallback` est document√© comme ¬´ test only ¬ª. Un garde-fou `RuntimeError` bloque l'extraction sans LLM si fallback d√©sactiv√©. |
| R13-7 | **Pr√©-filtres m√©ta-descriptions et fragments** | üü¢ | Les pr√©-filtres (`is_meta_pattern`, `is_fragment`) d√©pendent du module `promotion_engine` qui est import√© dynamiquement. Si les patterns sont incomplets, des m√©ta-descriptions passent le filtre. | Les patterns couvrent EN + FR. L'import dynamique permet de mettre √† jour les patterns sans modifier l'extracteur. |

---

## 12. Pass 1.3b ‚Äî R√©solution d'Ancrage

**Fichier principal :** `src/knowbase/stratified/pass1/anchor_resolver.py` ‚Äî classe `AnchorResolverV2`
**Utilitaire :** `anchor_resolver.py` ‚Äî fonction `build_chunk_to_docitem_mapping()`
**Mod√®les :** `src/knowbase/stratified/models/` ‚Äî `Anchor`, `DocItem`, `AssertionLogReason`

### 12.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `assertions` | `List[RawAssertion]` | Pass 1.3 | Assertions brutes avec `chunk_id` |
| `links` | `List[ConceptLink]` | Pass 1.3 | Liens assertion ‚Üí concept (seules les assertions li√©es sont ancr√©es) |
| `chunk_to_docitem_map` | `Dict[str, List[str]]` | Construit dynamiquement | Mapping `chunk_id ‚Üí [docitem_ids]` |
| `docitems` | `Dict[str, DocItem]` | Pass 0 Structural | Dictionnaire des DocItems avec leur texte |
| `chunks` | `Dict[str, str]` | Pass 0 | Dictionnaire `chunk_id ‚Üí texte du chunk` |

### 12.2 Objectifs

Pass 1.3b est une **phase critique** qui convertit les ancrages `chunk_id ‚Üí docitem_id`. Cette conversion est n√©cessaire car :

1. **Les assertions sont extraites depuis des chunks** (segments Qdrant, compatibilit√© vectorielle)
2. **Le graphe s√©mantique ancre sur des DocItems** (surface de preuve atomique, grain Docling natif)
3. **L'invariant V2-001** impose : ¬´ Chaque Information DOIT avoir `ANCHORED_IN ‚Üí DocItem` ¬ª
4. **L'invariant V2-002** impose : ¬´ `ANCHORED_IN` ne doit JAMAIS viser autre chose que `DocItem` ¬ª

**Sortie principale :** Pour chaque assertion li√©e √† un concept, un `Anchor` contenant `docitem_id`, `span_start`, `span_end`, ou un √©chec typ√© (`NO_DOCITEM_ANCHOR`, `CROSS_DOCITEM`, `AMBIGUOUS_SPAN`).

### 12.3 M√©canismes

#### 12.3.1 Construction du mapping chunk ‚Üí DocItem

La fonction `build_chunk_to_docitem_mapping()` construit le mapping initial :

**Strat√©gie 1 ‚Äî Convention de nommage :**
- Si `chunk_id` contient un `docitem_id` (ex: `"chunk_docitem_123_0"`) ‚Üí mapping direct

**Strat√©gie 2 ‚Äî Matching par texte :**
- Si le texte du chunk est contenu dans un DocItem (ou vice versa) ‚Üí mapping par inclusion
- Si le ratio de similarit√© (`SequenceMatcher`) > 0.8 ‚Üí mapping par fuzzy

Un chunk peut correspondre √† **plusieurs** DocItems (cas de chunks agr√©g√©s).

#### 12.3.2 R√©solution par assertion

La m√©thode `resolve_all()` traite toutes les assertions :

1. **Filtrage** : seules les assertions **li√©es √† un concept** (pr√©sentes dans `links`) sont trait√©es
2. **Assertions non li√©es** ‚Üí √©chec avec raison `NO_CONCEPT_MATCH` (utilis√© par Pass 1.2b pour le raffinement it√©ratif)
3. Pour chaque assertion li√©e ‚Üí `resolve_single()`

#### 12.3.3 Strat√©gies de r√©solution (resolve_single)

La r√©solution proc√®de par escalade :

```
Strat√©gie 1: Mapping direct chunk ‚Üí DocItem
    ‚Üí Si mapping existe ET 1 seul DocItem ‚Üí r√©solution directe
    ‚Üí Si mapping existe ET plusieurs DocItems ‚Üí resolve_in_multiple_docitems

Strat√©gie 2: Si pas de mapping ‚Üí recherche texte dans TOUS les DocItems
    ‚Üí resolve_by_text_search
```

**R√©solution dans un DocItem unique** (`_resolve_in_single_docitem`) :

1. Recherche **exacte** du texte de l'assertion dans le texte du DocItem (`str.find()`)
2. Si √©chec ‚Üí recherche avec **normalisation des espaces** (collapse whitespace)
3. Si √©chec ‚Üí v√©rification de l'**overlap** (similarit√© ‚â• 0.5) avec positions approximatives
4. Si √©chec ‚Üí `AMBIGUOUS_SPAN`

**R√©solution dans plusieurs DocItems** (`_resolve_in_multiple_docitems`) :

1. Pour chaque DocItem candidat ‚Üí recherche exacte du span
2. Si match exact trouv√© ‚Üí r√©solution imm√©diate
3. Si aucun match exact ‚Üí calcul de similarit√© fuzzy (`SequenceMatcher`) pour chaque candidat
4. Si meilleur score ‚â• `FUZZY_THRESHOLD` (0.85) ‚Üí r√©solution avec span approximatif
5. Si score > 0.3 mais < 0.85 ‚Üí `CROSS_DOCITEM` (l'assertion chevauche plusieurs DocItems)
6. Sinon ‚Üí `NO_DOCITEM_ANCHOR`

**Recherche globale** (`_resolve_by_text_search`) :

- Parcours de TOUS les DocItems
- Match exact prioritaire
- Fallback fuzzy si seuil ‚â• 0.85
- Derni√®re option ‚Üí `NO_DOCITEM_ANCHOR` avec d√©tail du meilleur score

#### 12.3.4 Mapping de position normalis√©e

La m√©thode `_map_normalized_position()` convertit les positions du texte normalis√© (espaces collaps√©s) vers le texte original par **ratio lin√©aire** :

```python
ratio_start = norm_start / len(normalized)
orig_start = int(ratio_start * len(original))
```

‚ö†Ô∏è **Approximation** : cette heuristique est impr√©cise pour les textes avec des s√©quences d'espaces variables. Le span r√©sultant est indicatif.

### 12.4 Outputs

| Sortie | Type | Description | Consommateur |
|--------|------|-------------|--------------|
| `resolved` | `List[Tuple[RawAssertion, Anchor, concept_id]]` | Assertions ancr√©es avec succ√®s | Pass 1.4 (promotion ‚Üí Information) |
| `failed` | `List[Tuple[RawAssertion, AssertionLogReason, details]]` | Assertions en √©chec d'ancrage | AssertionLog (audit), Pass 1.2b (raffinement) |
| `stats` | `AnchorResolverStats` | Statistiques : total, resolved, no_docitem, cross_docitem, ambiguous_span | Diagnostic, logs |

**Structure de `Anchor` :**

```python
Anchor(
    docitem_id="tenant:doc:item_42",  # ID composite du DocItem
    span_start=145,                    # Position d√©but dans DocItem.text
    span_end=287                       # Position fin dans DocItem.text
)
```

**Raisons d'√©chec :**

| Raison | Description | Cons√©quence |
|--------|-------------|-------------|
| `NO_DOCITEM_ANCHOR` | Aucun DocItem correspondant trouv√© | L'assertion ne peut pas devenir Information (pas de preuve) |
| `CROSS_DOCITEM` | L'assertion chevauche plusieurs DocItems | Violation potentielle d'AV2-4 (DocItem atomique) |
| `AMBIGUOUS_SPAN` | DocItem trouv√© mais position exacte ind√©termin√©e | Span approximatif, preuve faible |
| `NO_CONCEPT_MATCH` | Assertion non li√©e √† aucun concept | Non trait√©e par l'ancrage (filtr√©e en amont) |

### 12.5 Conformit√© ADR ‚Äî Pass 1.3b

| Axe | Exigence | Statut | Impl√©mentation | Commentaire |
|-----|----------|--------|----------------|-------------|
| AV2-3 | **Ancrage Information sur DocItem** | ‚úÖ | L'invariant V2-001 est le c≈ìur de cette phase. Chaque assertion r√©solue obtient un `Anchor` avec `docitem_id`. Les √©checs sont loggu√©s mais jamais contourn√©s (pas de fallback sur chunk). | Conforme. Aucune Information ne peut exister sans ancrage DocItem. |
| AV2-4 | **DocItem atomique** | ‚ö†Ô∏è | Les cas `CROSS_DOCITEM` sont d√©tect√©s et rejet√©s. Cependant, le fuzzy matching (seuil 0.85) peut cr√©er des ancrages approximatifs sur un DocItem qui ne contient pas exactement l'assertion. | Le seuil fuzzy est un compromis pragmatique. Les assertions reformul√©es (qui ne matchent pas exactement) sont les plus vuln√©rables. |
| NS-3 | **Citation exacte obligatoire** | ‚ö†Ô∏è | La recherche exacte (`str.find`) garantit la citation verbatim. Mais le fallback fuzzy (SequenceMatcher ‚â• 0.85) et le mapping par ratio lin√©aire (`_map_normalized_position`) cr√©ent des spans approximatifs. | Le span exact n'est garanti que pour les matchs `str.find()`. Les r√©solutions fuzzy produisent un span indicatif. |
| AV2-5 | **AssertionLog avec statut enum** | ‚úÖ | Les √©checs utilisent `AssertionLogReason` standardis√© (`NO_DOCITEM_ANCHOR`, `CROSS_DOCITEM`, `NO_CONCEPT_MATCH`). | Conforme. Les raisons sont des enum typ√©s avec description d√©taill√©e. |
| NS-2 | **LLM = Extracteur, pas arbitre** | ‚úÖ | La r√©solution d'ancrage est **100% algorithmique** ‚Äî aucun appel LLM. Le LLM a extrait en 1.3, le code r√©sout les ancrages en 1.3b. | S√©paration parfaite extraction/r√©solution. |

### 12.6 Risques ‚Äî Pass 1.3b

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R13b-1 | **Mapping chunk ‚Üí DocItem fragile** | üü° | Le mapping repose sur la convention de nommage (`docitem_id in chunk_id`) ou sur le matching texte. Si les chunks sont segment√©s diff√©remment des DocItems (ce qui est courant), le mapping est incomplet. | Le fuzzy matching (seuil 0.8 pour le mapping, 0.85 pour la r√©solution) couvre les cas approximatifs. Mais l'absence de mapping d√©terministe est une dette technique. |
| R13b-2 | **Perte d'assertions au CROSS_DOCITEM** | üü° | Les assertions qui chevauchent plusieurs DocItems sont rejet√©es (`CROSS_DOCITEM`). Cela peut repr√©senter une perte significative pour les chunks agr√©g√©s (plusieurs paragraphes dans un chunk). | Le grain DocItem (Docling natif = paragraph, table-row, list-item) devrait minimiser les cas de chevauchement. Pass 1.2b peut r√©cup√©rer ces assertions via raffinement. |
| R13b-3 | **Span approximatif via ratio lin√©aire** | üü° | La m√©thode `_map_normalized_position()` utilise un ratio lin√©aire pour mapper les positions, ce qui est impr√©cis pour les textes avec des distributions irr√©guli√®res d'espaces. | La recherche exacte (`str.find`) est prioritaire. Le ratio n'est utilis√© qu'en fallback pour les matchs normalis√©s. |
| R13b-4 | **Performance O(n√óm) sur le text search** | üü¢ | La recherche globale (`_resolve_by_text_search`) parcourt TOUS les DocItems pour chaque assertion sans mapping. Avec des documents volumineux (>1000 DocItems), cela peut √™tre lent. | Le mapping chunk ‚Üí DocItem r√©duit le p√©rim√®tre de recherche dans la majorit√© des cas. La recherche globale est un fallback de dernier recours. |
| R13b-5 | **Assertions non li√©es exclues de l'ancrage** | üü¢ | Les assertions sans `ConceptLink` sont marqu√©es `NO_CONCEPT_MATCH` et non ancr√©es. Cela est coh√©rent avec le flux top-down mais signifie que Pass 1.2b est n√©cessaire pour les r√©cup√©rer. | Conforme au design : l'ancrage ne sert que pour la promotion en Information. Les assertions orphelines sont trait√©es par le raffinement it√©ratif. |
| R13b-6 | **Mode pointer rend 1.3b moins critique** | üü¢ | En mode pointer, l'ancrage est int√©gr√© √† l'extraction (le LLM pointe directement vers un DocItem/unit√©). Pass 1.3b n'est alors n√©cessaire que pour le mode classique. | La convergence vers le mode pointer uniquement r√©duira progressivement le r√¥le de 1.3b. |

---

## 13. Pass 1.4 ‚Äî Promotion et Value Contract

### 13.0 Vue d'ensemble Pass 1.4

**Fichiers source :**

| Fichier | R√¥le |
|---------|------|
| `src/knowbase/stratified/pass1/promotion_engine.py` | Moteur de d√©cision PROMOTE / ABSTAIN / REJECT |
| `src/knowbase/stratified/pass1/promotion_policy.py` | Politique Information-First MVP V1 (PromotionPolicy) |
| `src/knowbase/stratified/pass1/value_extractor.py` | Extracteur de valeurs born√©es (Value Contract) |
| `src/knowbase/stratified/claimkey/patterns.py` | Patterns ClaimKey Niveau A (inf√©rence d√©terministe) |
| `src/knowbase/stratified/claimkey/status_manager.py` | Gestion du cycle de vie ClaimKey dans Neo4j |
| `src/knowbase/stratified/models/information.py` | Mod√®le `InformationMVP` (assertion promue) |
| `src/knowbase/stratified/models/claimkey.py` | Mod√®le `ClaimKey` (question factuelle canonique) |
| `src/knowbase/stratified/models/schemas.py` | Sch√©mas Pydantic V2 (`Information`, `AssertionLogEntry`) |
| `config/meta_patterns/structural_patterns.yaml` | Patterns META structurels externalis√©s (2026-01-27) |
| `config/meta_patterns/domain_extensions.yaml` | Extensions domaine optionnelles |

**R√©f√©rence spec :** ChatGPT "Two-pass Vision Evidence Contract" (2026-01-26)

**Fonction dans le pipeline :**

Pass 1.4 est la **phase de promotion** : elle transforme les `ResolvedAssertionV1` (assertions ancr√©es sur DocItem, issues de Pass 1.3b) en `Information[]` navigables dans le graphe s√©mantique. C'est le **garde-fou central** du pipeline ‚Äî elle d√©cide ce qui m√©rite d'√™tre stock√© comme connaissance structur√©e et ce qui est rejet√© ou abstenu.

```
Pass 1.3b (ResolvedAssertionV1[])
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               PASS 1.4 ‚Äî PROMOTION ENGINE                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Meta-Pattern  ‚îÇ  ‚îÇ  Fragment    ‚îÇ  ‚îÇ  Promotion    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Filter      ‚îÇ‚Üí‚îÇ  Detector    ‚îÇ‚Üí‚îÇ  Policy       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (YAML+regex)  ‚îÇ  ‚îÇ (verbs,len) ‚îÇ  ‚îÇ (Tier-based)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                               ‚îÇ          ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ         ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Value       ‚îÇ  ‚îÇ  ClaimKey    ‚îÇ  ‚îÇ  ClaimKey     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Extractor    ‚îÇ  ‚îÇ  Patterns   ‚îÇ  ‚îÇ  Status Mgr   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (%, ver, nb)  ‚îÇ  ‚îÇ (Level A)   ‚îÇ  ‚îÇ (Neo4j CRUD)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   InformationMVP + AssertionLogEntry (audit)     ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    Information[] + AssertionLog[] (Neo4j)
```

### 13.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `AssertionBatchV1` | Batch | Pass 1.3b | Lot d'assertions r√©solues avec ancrage DocItem |
| `ResolvedAssertionV1[]` | Liste | Pass 1.3b | Assertions typ√©es avec `PromotionDecision`, `AnchorV1`, `PivotsV1` |
| `chunk_to_docitem_map` | Dict | Pass 1.3b | Mapping chunk_id ‚Üí docitem_id pour r√©solution d'ancrage |
| `concept_ids` | List[str] | Pass 1.2 | IDs des concepts identifi√©s (pour v√©rification addressability) |
| `theme_ids` | List[str] | Pass 1.1 | IDs des th√®mes identifi√©s (pour v√©rification addressability) |
| Meta-patterns YAML | Config | `config/meta_patterns/` | Patterns structurels et domaine pour le filtrage META |

**Structure des entrants cl√©s :**

```python
# ResolvedAssertionV1 (issue de Pass 1.3b)
@dataclass
class ResolvedAssertionV1:
    assertion_id: str
    text: str
    type: AssertionTypeV1           # DEFINITIONAL, PRESCRIPTIVE, CAUSAL, etc.
    confidence: float               # 0.0 ‚Üí 1.0
    support_tier: SupportTier       # ALWAYS, CONDITIONAL, RARELY, NEVER
    chunk_id: str
    span: dict                      # {page, paragraph, line}
    anchor: Optional[AnchorV1]      # Ancrage DocItem r√©solu
    pivots: PivotsV1                # concept_ids, theme_ids, section_path
    promotion: PromotionDecision    # statut, raison, rule_used
```

### 13.2 Objectifs

1. **Filtrer les assertions non-exploitables** ‚Äî Rejeter les patterns META (navigation, copyright, TOC), les fragments sans pr√©dicat, les textes trop courts
2. **Appliquer la Promotion Policy par tier** ‚Äî D√©cider PROMOTE / ABSTAIN / REJECT selon le type d'assertion et le seuil de confiance
3. **V√©rifier l'addressability** ‚Äî Garantir que toute assertion promue a ‚â•1 pivot navigable (Concept, Theme, ClaimKey, SectionPath)
4. **Extraire les valeurs born√©es (Value Contract)** ‚Äî Identifier et normaliser les valeurs (`raw`, `normalized`, `unit`, `operator`, `comparable`) pour comparaison machine
5. **Inf√©rer les ClaimKeys (Niveau A)** ‚Äî G√©n√©rer des questions factuelles canoniques par patterns d√©terministes (sans LLM)
6. **G√©rer le cycle de vie ClaimKey** ‚Äî Cr√©er/mettre √† jour les ClaimKeys dans Neo4j avec statuts (EMERGENT ‚Üí COMPARABLE)
7. **Produire le journal d'audit** ‚Äî G√©n√©rer un `AssertionLogEntry` pour chaque assertion (PROMOTED / ABSTAINED / REJECTED) avec la raison standardis√©e
8. **Calculer le fingerprint de d√©duplication** ‚Äî `SHA256(claimkey_id + value.normalized + context_key + span_bucket)` pour √©viter les doublons

### 13.3 M√©canismes

#### 13.3.1 Promotion Engine ‚Äî Moteur de d√©cision principal

**Classe :** `PromotionEngine` (`promotion_engine.py`)

**Initialisation :**

```python
class PromotionEngine:
    def __init__(self, strict_promotion: bool = True, tenant_id: str = "default"):
        self.strict_promotion = strict_promotion  # Mode strict ou permissif
        self.tenant_id = tenant_id
```

**Workflow principal ‚Äî `process_batch()`:**

Le moteur traite chaque assertion en s√©quence selon un pipeline de 5 √©tapes :

```
Pour chaque AssertionV0 dans le batch :
‚îÇ
‚îú‚îÄ √âtape 1 : Filtre META-PATTERN
‚îÇ   ‚îú‚îÄ _is_meta_pattern(text) ‚Üí regex compil√©s depuis YAML
‚îÇ   ‚îî‚îÄ Si match ‚Üí REJECTED (rule: "meta_pattern")
‚îÇ
‚îú‚îÄ √âtape 1b : D√©tection FRAGMENT
‚îÇ   ‚îú‚îÄ is_fragment(text) ‚Üí v√©rifie longueur, pr√©sence de verbes
‚îÇ   ‚îî‚îÄ Si fragment ‚Üí REJECTED (rule: "fragment_no_predicate")
‚îÇ
‚îú‚îÄ √âtape 2 : V√©rification longueur minimale
‚îÇ   ‚îú‚îÄ len(text) < MIN_TEXT_LENGTH (15 chars)
‚îÇ   ‚îî‚îÄ Si trop court ‚Üí REJECTED (rule: "text_too_short")
‚îÇ
‚îú‚îÄ √âtape 3 : R√©solution d'ancrage DocItem
‚îÇ   ‚îú‚îÄ _resolve_anchor(chunk_id, span, chunk_to_docitem_map)
‚îÇ   ‚îî‚îÄ Si √©chec ancrage ‚Üí ABSTAINED (rule: "no_docitem_anchor")
‚îÇ
‚îú‚îÄ √âtape 4 : Application Promotion Policy (par tier)
‚îÇ   ‚îú‚îÄ TYPE_TO_TIER[assertion_type] ‚Üí SupportTier
‚îÇ   ‚îú‚îÄ ALWAYS ‚Üí PROMOTED (confiance quelconque)
‚îÇ   ‚îú‚îÄ CONDITIONAL ‚Üí PROMOTED si confidence ‚â• 0.7
‚îÇ   ‚îú‚îÄ RARELY ‚Üí PROMOTED si confidence ‚â• 0.9
‚îÇ   ‚îî‚îÄ NEVER ‚Üí REJECTED
‚îÇ
‚îú‚îÄ √âtape 5 : V√©rification Addressability
‚îÇ   ‚îú‚îÄ Au moins 1 pivot parmi : concept_id, theme_id, section_path
‚îÇ   ‚îî‚îÄ Si aucun pivot ‚Üí statut PROMOTED_UNLINKED (pas de rejet)
‚îÇ
‚îú‚îÄ G√©n√©ration ResolvedAssertionV1 avec PromotionDecision
‚îî‚îÄ G√©n√©ration AssertionLogEntry (journal d'audit)
```

**Point cl√© ‚Äî Philosophie ¬´ Information-First ¬ª :** Le syst√®me ne rejette JAMAIS silencieusement une assertion. Chaque d√©cision est audit√©e dans l'`AssertionLog` avec une raison standardis√©e (`AssertionLogReason` enum : 10+ raisons possibles).

#### 13.3.2 Meta-Pattern Filter ‚Äî Chargement YAML externalis√©

**Architecture patterns META (2026-01-27) :**

Les patterns de rejet sont externalis√©s dans des fichiers YAML pour √™tre agnostiques au domaine :

```
config/meta_patterns/
‚îú‚îÄ‚îÄ structural_patterns.yaml   # Patterns structurels par langue (toujours charg√©s)
‚îî‚îÄ‚îÄ domain_extensions.yaml     # Extensions domaine (optionnelles, d√©sactiv√©es par d√©faut)
```

**Chargement au d√©marrage du module (`_load_meta_patterns()`) :**

1. **Charger `structural_patterns.yaml`** (obligatoire) ‚Äî Patterns organis√©s par langue et cat√©gorie
2. **Charger `domain_extensions.yaml`** (optionnel) ‚Äî Si `active_domain` est d√©fini, ajouter les patterns du domaine
3. **Compiler en regex** ‚Äî Chaque pattern est compil√© avec `re.IGNORECASE`, les patterns invalides sont compt√©s et ignor√©s

**Fallback si YAML absent :**

```python
META_REJECT_PATTERNS_FALLBACK = [
    r"^this\s+(page|section)\s+(describes|shows)",
    r"^see\s+also\b",
    r"^refer\s+to\b",
    r"^copyright\b",
    r"^disclaimer\s*:",
    r"^note\s*:",
    r"^\d+\.\s*$",
]
```

Les patterns sont compil√©s une seule fois au chargement du module (`_COMPILED_META_PATTERNS`), ce qui √©vite la recompilation √† chaque assertion.

#### 13.3.3 D√©tection de fragments (non-assertions)

**Fonction :** `is_fragment(text)` dans `promotion_engine.py`

Un fragment est un texte qui ne constitue pas une assertion factuelle exploitable :

| Crit√®re | Patterns | Exemples rejet√©s |
|---------|----------|------------------|
| Acronyme seul | `^[A-Z]{2,6}$` | "VPC", "ISO" |
| Nom propre seul | `^[A-Z][A-Za-z0-9\s\-]{0,20}$` | "ISO 27001" |
| Glossaire/d√©finition | `^[A-Z]...{0,30}\.$` | "VPC Peering." |
| Titre/header | `^(section|chapter)...` | "Section 3" |
| Num√©rotation seule | `^\d+(\.\d+)*\s*$` | "3.2.1" |
| Puce incompl√®te | `^[-‚Ä¢]\s*\w+$` | "- Item" |

**V√©rification de pr√©sence de verbe :** Si aucun pattern fragment ne matche, le syst√®me v√©rifie que le texte contient au moins un verbe (EN ou FR) parmi une liste de ~40 patterns verbaux (`ASSERTION_VERB_PATTERNS`). Un texte sans verbe d√©tect√© et de moins de 3 mots est un fragment.

#### 13.3.4 Promotion Policy ‚Äî Politique par tier

**Deux impl√©mentations coexistent :**

| Classe | Fichier | Usage |
|--------|---------|-------|
| `PromotionEngine._apply_promotion_policy()` | `promotion_engine.py` | Pipeline V2 principal (tier-based) |
| `PromotionPolicy.evaluate()` | `promotion_policy.py` | MVP V1 autonome (role-based, Information-First) |

**Promotion Engine ‚Äî Mapping TYPE_TO_TIER :**

| Tier | Types d'assertion | Seuil confiance | D√©cision |
|------|-------------------|-----------------|----------|
| **ALWAYS** | DEFINITIONAL, PRESCRIPTIVE | Aucun | Toujours PROMOTED |
| **CONDITIONAL** | FACTUAL, CONDITIONAL, PERMISSIVE | ‚â• 0.7 | PROMOTED si seuil atteint |
| **RARELY** | COMPARATIVE | ‚â• 0.9 | PROMOTED si seuil √©lev√© |
| **NEVER** | PROCEDURAL | N/A | Toujours REJECTED |

**PromotionPolicy MVP V1 ‚Äî Logique en 6 √©tapes :**

L'√©valuateur MVP V1 suit une logique Information-First avec priorit√© au r√¥le rh√©torique :

1. **Rejet par meta-pattern** ‚Äî Patterns internes (navigation, copyright, TOC)
2. **Rejet si texte < 15 chars** ‚Äî `REJECTED` / `"text_too_short"`
3. **Promotion par type** ‚Äî `PRESCRIPTIVE` ou `DEFINITIONAL` ‚Üí `PROMOTED_LINKED`
4. **Promotion par r√¥le rh√©torique** :
   - `FACT`, `DEFINITION`, `INSTRUCTION` ‚Üí `PROMOTED_LINKED` (avec ClaimKey)
   - `EXAMPLE`, `CAUTION` ‚Üí `PROMOTED_UNLINKED` (sans ClaimKey)
5. **Promotion si valeur pr√©sente** ‚Äî `has_value = True` ‚Üí `PROMOTED_LINKED`
6. **D√©faut** ‚Äî `PROMOTED_UNLINKED` / `"no_clear_category"` (jamais de rejet silencieux)

**Point cl√© :** La PromotionPolicy MVP V1 est plus permissive que le Promotion Engine V2 ‚Äî elle ne rejette quasiment jamais (sauf meta-patterns et texte trop court). Cela refl√®te la philosophie Information-First de l'ADR North Star (NS-1).

#### 13.3.5 Value Extractor ‚Äî Value Contract

**Classe :** `ValueExtractor` (`value_extractor.py`)

**Objectif :** Extraire et normaliser les valeurs born√©es depuis le texte des assertions, conform√©ment au Value Contract de l'ADR North Star (NS-6).

**Cha√Æne d'extraction (ordre de sp√©cificit√© d√©croissante) :**

| # | Extracteur | Types d√©tect√©s | Exemples | Normalisation |
|---|-----------|---------------|----------|---------------|
| 1 | `_extract_percent()` | `PERCENT` | "99.95%", "95 percent" | `float / 100.0` ‚Üí `0.9995` |
| 2 | `_extract_version()` | `VERSION` | "TLS 1.2", "v3.14.1" | Tronqu√© √† 3 niveaux max |
| 3 | `_extract_number_with_unit()` | `NUMBER` | "30 days", "100 GB", "5 TiB" | `float √ó multiplier` |
| 4 | `_extract_boolean()` | `BOOLEAN` | "enabled", "not required" | `True` / `False` |
| 5 | `_extract_enum()` | `ENUM` | "daily", "customer", "critical" | `str.lower()` |

**Structure de sortie ‚Äî `ValueInfo` :**

```python
@dataclass
class ValueInfo:
    kind: Optional[ValueKind]          # NUMBER, PERCENT, VERSION, ENUM, BOOLEAN, STRING
    raw: Optional[str]                 # Texte source : "99.95%"
    normalized: Optional[float|str|bool]  # Valeur normalis√©e : 0.9995
    unit: Optional[str]                # Unit√© : "%", "days", "GB", "version"
    operator: str = "="               # Op√©rateur : =, >=, <=, >, <, approx, in
    comparable: ValueComparable = NON_COMPARABLE  # STRICT, LOOSE, NON_COMPARABLE
```

**D√©tection d'op√©rateur (`_detect_operator()`) :**

| Pattern | Op√©rateur r√©sultant |
|---------|--------------------|
| `at least`, `minimum`, `‚â•` | `>=` |
| `at most`, `maximum`, `‚â§` | `<=` |
| `more than`, `above`, `>` | `>` |
| `less than`, `below`, `<` | `<` |
| `approximately`, `around`, `~` | `approx` |
| (d√©faut) | `=` |

**Point important ‚Äî Ordre des bool√©ens :** Les patterns n√©gatifs (`not required`, `not supported`, `disabled`) sont v√©rifi√©s EN PREMIER pour √©viter que "not required" ne matche d'abord "required" avec `True`.

**Familles d'enum support√©es :**

| Famille | Valeurs |
|---------|---------|
| `frequency` | daily, weekly, monthly, hourly, yearly, continuous, quarterly |
| `responsibility` | customer, sap, vendor, shared, third-party |
| `severity` | critical, high, medium, low |
| `edition` | private, public, enterprise, standard |
| `environment` | production, development, staging, test |

**Singleton :** `get_value_extractor()` retourne une instance unique r√©utilisable.

#### 13.3.6 ClaimKey ‚Äî Patterns Niveau A (inf√©rence d√©terministe)

**Classe :** `ClaimKeyPatterns` (`claimkey/patterns.py`)

**Objectif :** Inf√©rer un ClaimKey (question factuelle canonique) depuis le texte d'une assertion, sans LLM, par patterns regex d√©terministes. Conforme √† l'ADR North Star (NS-5) ‚Äî Niveau A d'inf√©rence.

**Couverture des 15+ patterns :**

| Domaine | Pattern | ClaimKey g√©n√©r√© | Type valeur |
|---------|---------|-----------------|-------------|
| SLA / Availability | `(\d+\.?\d*)%\s*(sla\|availability\|uptime)` | `sla_{context}_availability` | percent |
| Security / TLS | `tls\s*(\d+\.?\d*)` | `tls_min_version` | version |
| Security / Encryption | `(encryption\|encrypted)\s*(at\s*rest)` | `encryption_at_rest` | boolean |
| Security / Encryption | `(encryption\|encrypted)\s*(in\s*transit)` | `encryption_in_transit` | boolean |
| Backup | `backup.*?(daily\|weekly\|hourly)` | `backup_frequency` | enum |
| Retention | `retention.*?(\d+)\s*(days?\|months?)` | `data_retention_period` | number |
| Data Residency | `data.*?(remain\|stay\|stored?).*?(\w+)` | `data_residency_{country}` | boolean |
| Sizing | `(above\|over\|exceeds?).*?(\d+)\s*(tib\|tb\|gb)` | `{context}_size_threshold` | number |
| Responsibility | `(customer\|sap\|vendor).*?(responsible)` | `{topic}_responsibility` | enum |
| Compatibility | `(minimum\|required).*?version.*?(\d+\.?\d*)` | `{product}_min_version` | version |
| Patching | `(patch\|update).*?(daily\|weekly\|monthly)` | `patch_frequency` | enum |
| Recovery / RTO | `rto.*?(\d+)\s*(hours?\|minutes?)` | `rto_target` | number |
| Recovery / RPO | `rpo.*?(\d+)\s*(hours?\|minutes?)` | `rpo_target` | number |

**R√©solution de templates :**

Les cl√©s de ClaimKey utilisent des templates avec placeholders :
- `{context}` ‚Üí contexte documentaire (product, topic)
- `{country}` ‚Üí pays d√©tect√© dans le texte
- `{topic}` ‚Üí sujet du document
- `{product}` ‚Üí produit mentionn√©

**Structure de sortie ‚Äî `PatternMatch` :**

```python
@dataclass
class PatternMatch:
    claimkey_id: str             # "ck_tls_min_version"
    key: str                     # "tls_min_version"
    domain: str                  # "security.encryption"
    canonical_question: str      # "What is the minimum TLS version required?"
    value_kind: str              # "version"
    match_text: str              # Texte match√©
    inference_method: str = "pattern_level_a"
```

**Questions canoniques pr√©d√©finies :** Le syst√®me maintient un dictionnaire `CANONICAL_QUESTIONS` de 10+ questions factuelles pr√©d√©finies pour les ClaimKeys les plus courants (TLS, SLA, backup, retention, RTO/RPO, encryption).

**Singleton :** `get_claimkey_patterns()` retourne une instance unique.

#### 13.3.7 ClaimKey Status Manager ‚Äî Gestion du cycle de vie

**Classe :** `ClaimKeyStatusManager` (`claimkey/status_manager.py`)

**Objectif :** G√©rer la persistance et le cycle de vie des ClaimKeys dans Neo4j.

**Op√©rations CRUD :**

| M√©thode | Op√©ration Neo4j | Description |
|---------|-----------------|-------------|
| `get_or_create()` | `MATCH` ou `CREATE` | R√©cup√®re un ClaimKey existant ou en cr√©e un nouveau |
| `link_information()` | `MERGE (i)-[:ANSWERS]->(ck)` | Cr√©e la relation ANSWERS entre Information et ClaimKey |
| `update_metrics()` | `MATCH + COUNT + SET` | Recalcule info_count, doc_count et statut |
| `get_claimkey()` | `MATCH` | R√©cup√®re par ID |
| `find_by_key()` | `MATCH` | Recherche par cl√© machine |

**Cycle de vie ClaimKey ‚Äî Statuts :**

```
Cr√©ation ‚Üí EMERGENT (< 2 docs)
                ‚îÇ
         (‚â• 2 docs avec valeurs)
                ‚îÇ
                ‚ñº
          COMPARABLE (comparaison cross-doc possible)
                ‚îÇ
         (remplacement)
                ‚îÇ
                ‚ñº
          DEPRECATED

         (aucune info r√©cente)
                ‚îÇ
                ‚ñº
            ORPHAN
```

| Statut | Condition | Signification |
|--------|-----------|---------------|
| `EMERGENT` | `doc_count < 2` | Pas encore assez de sources pour comparaison |
| `COMPARABLE` | `doc_count ‚â• 2` | Comparaison cross-document activ√©e |
| `DEPRECATED` | Manuellement marqu√© | Remplac√© par un autre ClaimKey |
| `ORPHAN` | `info_count = 0` | Aucune Information li√©e |

**Logique `update_metrics()` :**

```cypher
MATCH (ck:ClaimKey {claimkey_id: $ck_id})
OPTIONAL MATCH (i:InformationMVP)-[:ANSWERS]->(ck)
  WHERE i.promotion_status = 'PROMOTED_LINKED'
OPTIONAL MATCH (i)-[:EXTRACTED_FROM]->(d:Document)
WITH ck, count(DISTINCT i) as info_count, count(DISTINCT d) as doc_count
-- Recalcul statut: ORPHAN si 0, EMERGENT si < 2 docs, COMPARABLE sinon
```

**Multi-tenancy :** Toutes les op√©rations sont filtr√©es par `tenant_id` pour garantir l'isolation des donn√©es.

#### 13.3.8 Mod√®le Information MVP ‚Äî Assertion promue

**Classe :** `InformationMVP` (`models/information.py`)

**Objectif :** Repr√©senter une assertion factuelle promue, stock√©e dans Neo4j comme noeud `InformationMVP`.

**Champs obligatoires :**

| Champ | Type | Conformit√© NS | Description |
|-------|------|---------------|-------------|
| `information_id` | str | ‚Äî | Identifiant unique |
| `tenant_id` | str | ‚Äî | Multi-tenancy |
| `document_id` | str | NS-4 | Source unique (pas de fusion cross-doc) |
| `text` | str | ‚Äî | Texte normalis√© de l'assertion |
| `exact_quote` | str | NS-3 | **OBLIGATOIRE** ‚Äî Verbatim du texte source |
| `type` | InformationType | NS-9 | PRESCRIPTIVE, DEFINITIONAL, CAUSAL, COMPARATIVE |
| `rhetorical_role` | RhetoricalRole | NS-8 | FACT, EXAMPLE, DEFINITION, INSTRUCTION, CLAIM, CAUTION |
| `span` | SpanInfo | NS-3 | Position : page, paragraphe, ligne |

**Champs de promotion et liaison :**

| Champ | Type | Conformit√© NS | Description |
|-------|------|---------------|-------------|
| `promotion_status` | PromotionStatus | NS-9 | PROMOTED_LINKED, PROMOTED_UNLINKED, REJECTED |
| `promotion_reason` | str | ‚Äî | Raison textuelle de la d√©cision |
| `claimkey_id` | Optional[str] | NS-5 | Lien vers ClaimKey (si inf√©r√©) |
| `theme_id` | Optional[str] | NS-7 | Lien vers Theme (addressability) |
| `value` | ValueInfo | NS-6 | Valeur extraite (Value Contract) |
| `context` | ContextInfo | ‚Äî | Contexte documentaire (edition, region, version, product) |
| `confidence` | float | ‚Äî | Score de confiance 0.0 ‚Üí 1.0 |
| `fingerprint` | str | NS-10 | Hash de d√©duplication |

**Fingerprint de d√©duplication (NS-10) :**

```python
def compute_fingerprint(self) -> str:
    """SHA256(claimkey_id:value_normalized:context_key:span_bucket)"""
    ck = self.claimkey_id or "no_claimkey"
    val = str(self.value.normalized) if self.value.normalized is not None else "no_value"
    ctx = self.context.to_context_key()  # "edition:version:region"
    page = str(self.span.page)  # Page, pas ligne exacte
    raw = f"{ck}:{val}:{ctx}:{page}"
    return hashlib.sha256(raw.encode()).hexdigest()[:32]
```

**Point cl√© :** Le fingerprint utilise la PAGE et non la ligne exacte comme granularit√© de d√©duplication, ce qui permet de fusionner les reformulations d'un m√™me fait sur la m√™me page.

**Aplatissement Neo4j (`to_neo4j_properties()`) :**

Les objets imbriqu√©s sont aplatis avec des pr√©fixes pour le stockage Neo4j :
- `span.page` ‚Üí `span_page`, `span_paragraph`, `span_line`
- `value.kind` ‚Üí `value_kind`, `value_raw`, `value_normalized`, `value_unit`, `value_operator`, `value_comparable`
- `context.edition` ‚Üí `context_edition`, `context_region`, `context_version`, `context_product`, `context_deployment`, `context_inheritance_mode`

**H√©ritage de contexte (`InheritanceMode`) :**

| Mode | Signification |
|------|---------------|
| `INHERITED` | Contexte h√©rit√© du titre/section parent |
| `ASSERTED` | Contexte explicitement mentionn√© dans le texte |
| `MIXED` | Partiellement h√©rit√©, partiellement assert√© |
| `UNKNOWN` | Contexte non d√©termin√© |

#### 13.3.9 Journal d'audit ‚Äî AssertionLog

Chaque assertion trait√©e par le Promotion Engine g√©n√®re un `AssertionLogEntry` dans le journal d'audit :

**Sch√©ma V2 (`schemas.py`) :**

```python
class AssertionLogEntry(BaseModel):
    assertion_id: str
    text: str
    type: AssertionType
    confidence: Optional[float]
    status: AssertionStatus           # PROMOTED | ABSTAINED | REJECTED
    reason: AssertionLogReason        # 10+ raisons standardis√©es
    concept_id: Optional[str]
    anchor: Optional[Anchor]
    created_at: datetime
```

**Raisons standardis√©es (`AssertionLogReason`) :**

| Raison | Cat√©gorie | Description |
|--------|-----------|-------------|
| `PROMOTED` | Promotion r√©ussie | Assertion transform√©e en Information |
| `LOW_CONFIDENCE` | Promotion Policy | Confiance en dessous du seuil du tier |
| `POLICY_REJECTED` | Promotion Policy | Rejet√© par la politique (tier NEVER, meta-pattern) |
| `NO_CONCEPT_MATCH` | Concept Linking | Aucun concept ne correspond |
| `AMBIGUOUS_LINKING` | Concept Linking | Lien concept ambigu |
| `NO_DOCITEM_ANCHOR` | Anchor Resolution | Ancrage DocItem impossible |
| `AMBIGUOUS_SPAN` | Anchor Resolution | Span ambigu (multiples DocItems candidats) |
| `CROSS_DOCITEM` | Anchor Resolution | Assertion chevauche plusieurs DocItems |
| `GENERIC_TERM` | Qualit√© | Terme trop g√©n√©rique |
| `SINGLE_MENTION` | Qualit√© | Mention unique dans le document |
| `CONTRADICTS_EXISTING` | Cross-doc (Pass 3) | Contradiction avec assertion existante |

#### 13.3.10 Theme Lint ‚Äî Gouvernance th√©matique

**Statut :** ‚ùå **NON IMPL√âMENT√â** ‚Äî Le fichier `governance/theme_lint.py` est r√©f√©renc√© dans la spec mais n'existe pas encore dans le code source.

**Objectif pr√©vu :** V√©rifier la coh√©rence entre les th√®mes inf√©r√©s par Pass 1.1 et les th√®mes r√©f√©renc√©s dans les assertions promues. D√©tecter les th√®mes orphelins (aucune Information li√©e) et les assertions avec des th√®mes non reconnus.

### 13.4 Outputs

| Output | Type | Destination | Description |
|--------|------|-------------|-------------|
| `Information[]` | Liste de n≈ìuds | Neo4j (`:InformationMVP`) | Assertions promues avec valeur, contexte, span, fingerprint |
| `AssertionLogEntry[]` | Liste d'entr√©es | Neo4j (`:AssertionLog`) | Journal d'audit de chaque d√©cision |
| `ClaimKey[]` | N≈ìuds cr√©√©s/mis √† jour | Neo4j (`:ClaimKey`) | Questions factuelles canoniques |
| Relations `[:ANSWERS]` | Relations | Neo4j | Information ‚Üí ClaimKey |
| Relations `[:EXTRACTED_FROM]` | Relations | Neo4j | Information ‚Üí Document |

**Relations Neo4j g√©n√©r√©es :**

```
(:InformationMVP)-[:ANSWERS]->(:ClaimKey)          # Si ClaimKey inf√©r√©
(:InformationMVP)-[:EXTRACTED_FROM]->(:Document)    # Toujours
(:InformationMVP)-[:ANCHORED_IN]->(:DocItem)        # Via anchor_docitem_ids
(:InformationMVP)-[:BELONGS_TO]->(:Theme)           # Si theme_id disponible
```

**M√©triques de sortie attendues :**

| M√©trique | Cible |
|----------|-------|
| Taux de promotion LINKED | > 40% des assertions |
| Taux de promotion UNLINKED | 20-40% des assertions |
| Taux de rejet META + fragment | 10-30% des assertions |
| Taux d'abstention (confidence) | 5-15% des assertions |
| ClaimKeys inf√©r√©s Niveau A | ~10-30% des assertions promues |

### 13.5 Conformit√© ADR ‚Äî Pass 1.4

| Axe | Statut | D√©tail |
|-----|--------|--------|
| **NS-1 Information-First** | ‚úÖ | L'Information est l'entit√© primaire. Z√©ro rejet pour `no_concept_match` ‚Äî les assertions sans concept restent `PROMOTED_UNLINKED`. La PromotionPolicy MVP V1 ne rejette quasiment jamais. |
| **NS-3 Citation exacte obligatoire** | ‚úÖ | `exact_quote` est un champ OBLIGATOIRE de `InformationMVP`. `SpanInfo` capture page/paragraphe/ligne. |
| **NS-4 Pas de synth√®se cross-source** | ‚úÖ | Chaque `InformationMVP` est li√©e √† un seul `document_id`. Pas de fusion multi-documents. |
| **NS-5 ClaimKey comme pivot** | ‚ö†Ô∏è | ClaimKey Niveau A (patterns) impl√©ment√©. **Niveau B (LLM assist√©) non impl√©ment√©** ‚Äî seule l'inf√©rence d√©terministe est op√©rationnelle. |
| **NS-6 Value Contract** | ‚úÖ | `ValueExtractor` produit `ValueInfo` avec `raw`, `normalized`, `unit`, `operator`, `comparable`. 5 types support√©s (NUMBER, PERCENT, VERSION, ENUM, BOOLEAN). |
| **NS-7 Addressability-First** | ‚ö†Ô∏è | Le syst√®me v√©rifie la pr√©sence de pivots mais **ne force pas le rejet** des orphelins totaux. Les assertions sans aucun pivot sont marqu√©es `PROMOTED_UNLINKED` plut√¥t que rejet√©es. |
| **NS-8 Rhetorical Role** | ‚úÖ | `RhetoricalRole` enum avec 6 r√¥les (FACT, EXAMPLE, DEFINITION, INSTRUCTION, CLAIM, CAUTION). La PromotionPolicy diff√©rencie : EXAMPLE/CAUTION ‚Üí pas de ClaimKey. |
| **NS-9 Promotion Policy par type** | ‚úÖ | `TYPE_TO_TIER` mapping impl√©ment√© : ALWAYS (DEFINITIONAL, PRESCRIPTIVE), CONDITIONAL (FACTUAL, CONDITIONAL, PERMISSIVE), RARELY (COMPARATIVE), NEVER (PROCEDURAL). |
| **NS-10 D√©duplication fingerprint** | ‚úÖ | `compute_fingerprint()` = `SHA256(claimkey_id:value_normalized:context_key:page)`. Granularit√© page pour fusionner les reformulations. |
| **AV2-3 Ancrage sur DocItem** | ‚úÖ | `anchor_docitem_ids` stocke les IDs DocItem. Pas d'ancrage sur chunk Qdrant. |
| **AV2-5 AssertionLog** | ‚úÖ | `AssertionLogEntry` avec `AssertionStatus` (PROMOTED/ABSTAINED/REJECTED) et `AssertionLogReason` (10+ raisons standardis√©es). |

### 13.6 Risques ‚Äî Pass 1.4

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R14-1 | **ClaimKey Niveau B (LLM) absent** | üü° | L'inf√©rence ClaimKey est limit√©e aux 15 patterns regex d√©terministes. Les assertions sans pattern reconnu n'ont pas de ClaimKey, ce qui r√©duit la comparabilit√© cross-doc. Le Niveau B (LLM assist√©, NS-5) n'est pas impl√©ment√©. | Les patterns couvrent les domaines les plus fr√©quents (SLA, s√©curit√©, backup, compliance). L'ajout de nouveaux patterns est simple (YAML). Le Niveau B est pr√©vu dans une it√©ration future. |
| R14-2 | **Coexistence PromotionEngine V2 / PromotionPolicy MVP V1** | üü° | Deux syst√®mes de promotion coexistent avec des logiques diff√©rentes. Le Pipeline V2 utilise `PromotionEngine` (tier-based), le MVP V1 utilise `PromotionPolicy` (role-based). Les r√©sultats peuvent diverger pour les m√™mes assertions. | La `PromotionPolicy` est un singleton stateless utilis√© par le MVP V1 uniquement. La convergence vers le `PromotionEngine` V2 est planifi√©e √† la fin du MVP. |
| R14-3 | **Addressability non stricte** | üü° | L'ADR NS-7 prescrit "orphelin total interdit" mais l'impl√©mentation ne rejette pas les assertions sans pivot. Elles sont marqu√©es `PROMOTED_UNLINKED`. Cela peut cr√©er des n≈ìuds Information inaccessibles dans le graphe. | La philosophie Information-First (NS-1) prime : mieux vaut une Information sans pivot qu'une perte. Pass 1.2b (raffinement it√©ratif des concepts) peut r√©cup√©rer ces orphelins a posteriori. |
| R14-4 | **Theme Lint non impl√©ment√©** | üü¢ | Le fichier `governance/theme_lint.py` n'existe pas. Aucune v√©rification de coh√©rence th√©matique entre les assertions promues et les th√®mes identifi√©s en Pass 1.1. | La gouvernance th√©matique est une fonctionnalit√© de qualit√©, pas critique pour le fonctionnement du pipeline. Elle est planifi√©e comme am√©lioration post-MVP. |
| R14-5 | **Fingerprint sensible au claimkey_id** | üü° | Le fingerprint de d√©duplication inclut `claimkey_id`. Si le m√™me fait est formul√© diff√©remment et matche un pattern diff√©rent (ou aucun pattern), il produira un fingerprint diff√©rent. Risque de doublons non d√©tect√©s. | Le fingerprint est un m√©canisme de d√©duplication de premier niveau. La r√©solution d'entit√©s cross-doc (Pass 3) est le m√©canisme de d√©duplication de second niveau. |
| R14-6 | **D√©tection de fragments limit√© aux verbes connus** | üü¢ | La d√©tection de fragments repose sur ~40 patterns verbaux EN/FR. Les assertions dans d'autres langues ou avec des verbes rares peuvent √™tre faussement rejet√©es comme fragments. | Le `language` du document est disponible dans le contexte. Une extension multilingue des patterns verbaux est possible. |
| R14-7 | **Value Extractor limit√© √† 5 types** | üü¢ | MVP V1 supporte NUMBER, PERCENT, VERSION, ENUM, BOOLEAN. Les valeurs complexes (plages, listes, expressions temporelles composites) ne sont pas extraites. | Les 5 types couvrent les cas les plus fr√©quents en documentation technique. Le type `STRING` est d√©fini dans l'enum mais pas extrait automatiquement. Extension pr√©vue post-MVP. |
| R14-8 | **Patterns META externalis√©s en YAML ‚Äî risque de d√©synchronisation** | üü¢ | Si les fichiers YAML de patterns sont absents ou corrompus, le syst√®me tombe sur un fallback minimal de 7 patterns. Le d√©ploiement doit garantir la pr√©sence des fichiers de configuration. | Le syst√®me log un warning explicite si le fallback est utilis√©. Les patterns invalides sont compt√©s et ignor√©s individuellement sans crash. |

---

## 14. Pass 2 ‚Äî Enrichissement S√©mantique

**Fichier principal :** `src/knowbase/stratified/pass2/relation_extractor.py` ‚Äî classe `RelationExtractorV2`
**Orchestration :** `src/knowbase/stratified/pass2/orchestrator.py` ‚Äî classe `Pass2OrchestratorV2`
**Persistence :** `src/knowbase/stratified/pass2/persister.py` ‚Äî classe `Pass2PersisterV2`
**Prompts :** `src/knowbase/stratified/prompts/pass2_prompts.yaml` (si pr√©sent)
**ADR de r√©f√©rence :** `doc/ongoing/ADR_DISCURSIVE_RELATIONS.md`, `doc/ongoing/ADR_SCOPE_VS_ASSERTION_SEPARATION.md`

### 14.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| `pass1_result` | `Pass1Result` | Pass 1 | R√©sultat complet de Pass 1 contenant `doc`, `concepts`, `informations` |
| `pass1_result.concepts` | `List[Concept]` | Pass 1.2 | Concepts identifi√©s avec `concept_id`, `name`, `role`, `variants`, `lex_key`, `theme_id` |
| `pass1_result.informations` | `List[Information]` | Pass 1.4 | Informations promues avec `info_id`, `concept_id`, `text`, `type`, `confidence`, `anchor` |
| `doc_id` | `str` | Pass 1 | Identifiant du document (extrait de `pass1_result.doc.doc_id`) |

**Mode alternatif ‚Äî chargement depuis Neo4j :** `Pass2OrchestratorV2.process_from_neo4j(doc_id)` charge les concepts et informations directement depuis le graphe Neo4j via des requ√™tes Cypher (utile pour retraiter un document d√©j√† persist√© en Pass 1).

### 14.2 Objectifs

Pass 2 enrichit le graphe s√©mantique cr√©√© par Pass 1 en ajoutant les **relations inter-concepts**. Il s'agit de la phase de densification du graphe :

1. **Extraction de relations typ√©es** ‚Äî Identifier les liens s√©mantiques entre les concepts du document (ex: A REQUIRES B, A ENABLES B).
2. **Evidence-based** ‚Äî Chaque relation est justifi√©e par au moins une Information du Pass 1 (`evidence_info_ids`).
3. **Frugalit√© relationnelle** ‚Äî Garde-fou strict : maximum 3 relations par concept source pour √©viter l'explosion combinatoire.
4. **Persistence dans le graphe** ‚Äî Cr√©er les ar√™tes `CONCEPT_RELATION` dans Neo4j entre les n≈ìuds `Concept` existants.

### 14.3 M√©canismes

#### 14.3.1 Orchestration (`Pass2OrchestratorV2`)

L'orchestrateur encha√Æne deux √©tapes principales :

```
Pass1Result ‚Üí RelationExtractorV2.extract_relations() ‚Üí Pass2Result
                                                            ‚Üì
                                                   Pass2PersisterV2.persist()
                                                            ‚Üì
                                                      Neo4j (ar√™tes)
```

**Deux points d'entr√©e :**

| M√©thode | Usage | Source des donn√©es |
|---------|-------|--------------------|
| `process(pass1_result)` | Pipeline inline | `Pass1Result` en m√©moire |
| `process_from_neo4j(doc_id)` | Retraitement | Chargement depuis Neo4j via Cypher |

Le flag `persist: bool = True` contr√¥le la persistence dans Neo4j (d√©sactivable pour tests ou dry-run).

**Chargement depuis Neo4j (`_load_from_neo4j`) :**

Les requ√™tes Cypher traversent le graphe structurel complet :

```cypher
-- Concepts
MATCH (d:Document {doc_id, tenant_id})
      -[:HAS_SUBJECT]->(:Subject)
      -[:HAS_THEME]->(t:Theme)
      -[:HAS_CONCEPT]->(c:Concept)
RETURN c.concept_id, c.name, c.role, c.variants, c.lex_key, t.theme_id

-- Informations
MATCH (d:Document {doc_id, tenant_id})
      -[:HAS_SUBJECT]->(:Subject)
      -[:HAS_THEME]->(:Theme)
      -[:HAS_CONCEPT]->(c:Concept)
      -[:HAS_INFORMATION]->(i:Information)
      -[a:ANCHORED_IN]->(di:DocItem)
RETURN i.info_id, i.text, i.type, i.confidence, c.concept_id,
       di.docitem_id, a.span_start, a.span_end
```

#### 14.3.2 Types de relations (`RelationType`)

Pass 2 d√©finit 8 types de relations entre concepts :

| Type | S√©mantique | Exemple |
|------|-----------|---------|
| `REQUIRES` | A n√©cessite B | "S/4HANA requires SAP BTP" |
| `ENABLES` | A permet/rend possible B | "ABAP Cloud enables extension development" |
| `CONSTRAINS` | A limite/contraint B | "License constrains module usage" |
| `DEPENDS_ON` | A d√©pend de B | "Fiori depends on Gateway" |
| `RELATED_TO` | Relation g√©n√©rique | Lien s√©mantique non classifiable |
| `SPECIALIZES` | A est une sp√©cialisation de B | "SAP BTP ABAP Environment specializes ABAP" |
| `PART_OF` | A fait partie de B | "Module A is part of Suite B" |
| `CONTRADICTS` | A contredit B | Assertions contradictoires entre concepts |

La liste `VALID_RELATION_TYPES` est utilis√©e pour valider les r√©ponses LLM. Tout type invalide est r√©trograd√© en `RELATED_TO`.

#### 14.3.3 Extraction via LLM (`_extract_via_llm`)

**Flux d'extraction LLM :**

1. **Construction de l'index** `concept_id ‚Üí List[Information]` via `_build_concept_info_index()` ‚Äî rattache chaque information √† son concept parent.
2. **Formatage du prompt** ‚Äî Chaque concept est pr√©sent√© avec son ID, nom, r√¥le, variantes et les 3 premi√®res informations associ√©es (tronqu√©es √† 150 caract√®res).
3. **Appel LLM** ‚Äî `llm_client.generate()` avec `max_tokens=3000`.
4. **Parsing JSON** ‚Äî Extraction du bloc ````json ... ````, d√©s√©rialisation et validation.

**Prompts (configurables via YAML ou d√©fauts int√©gr√©s) :**

- **System prompt** : r√¥le d'expert en extraction de relations, liste des types valides, r√®gles (justification obligatoire, seuils de confiance, maximum 3 relations/concept).
- **User prompt** : template `{concepts}` + `{relation_types}`, r√©ponse attendue en JSON structur√©.

**Seuils de confiance dans le prompt :**

| Cat√©gorie | Confiance |
|-----------|-----------|
| Relation explicite | ‚â• 0.7 |
| Relation implicite | 0.5 ‚Äì 0.7 |

**Validation de la r√©ponse LLM (`_parse_relations_response`) :**

- Validation que `source_concept_id` et `target_concept_id` existent dans la liste des concepts
- Validation que `relation_type` est dans `VALID_RELATION_TYPES` (sinon fallback `RELATED_TO`)
- Filtrage des `evidence_info_ids` : seuls les IDs d'informations existantes sont conserv√©s

**Fallback automatique :** si l'appel LLM √©choue (exception), le syst√®me bascule sur l'extraction heuristique.

#### 14.3.4 Extraction heuristique (`_extract_heuristic`)

Mode d√©grad√© activable via `allow_fallback=True` ou en cas d'√©chec LLM :

1. **Pour chaque concept** ‚Üí pour chaque information associ√©e ‚Üí pour chaque autre concept :
   - V√©rifier si l'autre concept est **mentionn√© dans le texte** de l'information (nom ou variantes, case-insensitive)
   - Si oui, **inf√©rer le type de relation** par pattern matching sur des mots-cl√©s textuels

2. **Patterns d'inf√©rence de type (`_infer_relation_type`) :**

| Type inf√©r√© | Mots-cl√©s d√©tect√©s |
|-------------|-------------------|
| `REQUIRES` | `requires`, `n√©cessite`, `need`, `must have` |
| `ENABLES` | `enables`, `permet`, `allows`, `makes possible` |
| `CONSTRAINS` | `constrains`, `limits`, `restricts`, `contraint` |
| `DEPENDS_ON` | `depends on`, `relies on`, `d√©pend de` |
| `PART_OF` | `part of`, `component of`, `partie de` |
| `SPECIALIZES` | `type of`, `kind of`, `specialization`, `sp√©cialisation` |
| `CONTRADICTS` | `contradicts`, `conflicts with`, `contredit` |
| `RELATED_TO` | Aucun pattern match√© (d√©faut) |

3. **Confiance fixe** : toutes les relations heuristiques re√ßoivent `confidence=0.6`.
4. **Justification** : co-occurrence avec extrait de texte (100 premiers caract√®res).

#### 14.3.5 Garde-fou frugalit√© ‚Äî Limite de relations (`_apply_relation_limit`)

M√©canisme anti-explosion combinatoire, constante de classe :

```python
MAX_RELATIONS_PER_CONCEPT = 3
```

**Algorithme :**
1. Grouper les relations par `source_concept_id`
2. Trier chaque groupe par `confidence` d√©croissante
3. Conserver les 3 premi√®res relations (plus haute confiance)
4. Comptabiliser les relations rejet√©es dans `Pass2Stats.relations_filtered`

Ce garde-fou s'applique uniform√©ment sur les r√©sultats LLM et heuristiques.

#### 14.3.6 Persistence Neo4j (`Pass2PersisterV2`)

**Mod√®le de relation Neo4j :**

```cypher
MATCH (source:Concept {concept_id: $source_id, tenant_id: $tenant_id})
MATCH (target:Concept {concept_id: $target_id, tenant_id: $tenant_id})
MERGE (source)-[r:CONCEPT_RELATION {relation_id: $relation_id}]->(target)
SET r.type = $relation_type,
    r.confidence = $confidence,
    r.evidence_info_ids = $evidence,
    r.justification = $justification,
    r.created_at = datetime()
```

**Points notables :**

- Le label de relation est **g√©n√©rique** (`CONCEPT_RELATION`) avec le type s√©mantique stock√© en **propri√©t√©** (`r.type`). Pas de labels dynamiques (pas d'APOC requis).
- `MERGE` sur `relation_id` : idempotent, re-ex√©cuter Pass 2 met √† jour sans dupliquer.
- `evidence_info_ids` est stock√© comme liste de strings ‚Äî r√©f√©rence les `info_id` des informations-preuves.
- Multi-tenant via `tenant_id` sur les n≈ìuds source et cible.

**Suppression des donn√©es Pass 2 (`delete_pass2_data`) :**

Traverse le graphe `Document ‚Üí Subject ‚Üí Theme ‚Üí Concept` puis supprime toutes les relations `CONCEPT_RELATION` sortantes. Utilis√© pour retraitement.

**Fonction utilitaire :** `persist_pass2_result(result, neo4j_driver, tenant_id)` ‚Äî wrapper stateless pour usage ponctuel.

### 14.4 Outputs

**Dataclass principale :**

```python
@dataclass
class Pass2Result:
    doc_id: str
    relations: List[ConceptRelation]  # Relations extraites et filtr√©es
    stats: Pass2Stats                 # M√©triques d'ex√©cution
```

**Structure d'une relation (`ConceptRelation`) :**

```python
@dataclass
class ConceptRelation:
    relation_id: str           # Identifiant unique (format "rel_{uuid8}")
    source_concept_id: str     # ID du concept source
    target_concept_id: str     # ID du concept cible
    relation_type: str         # Un des 8 types RelationType
    confidence: float          # Score de confiance [0.0, 1.0]
    evidence_info_ids: List[str]  # IDs des informations-preuves
    justification: str         # Explication textuelle de la relation
```

**Statistiques (`Pass2Stats`) :**

```python
@dataclass
class Pass2Stats:
    concepts_processed: int        # Nombre de concepts analys√©s
    relations_extracted: int       # Relations conserv√©es apr√®s garde-fou
    relations_filtered: int        # Relations rejet√©es par le garde-fou
    avg_relations_per_concept: float  # Ratio relations / concepts
```

**Sortie Neo4j :**

| √âl√©ment | D√©tail |
|---------|--------|
| Ar√™tes cr√©√©es | `(Concept)-[:CONCEPT_RELATION]->(Concept)` |
| Propri√©t√©s | `relation_id`, `type`, `confidence`, `evidence_info_ids`, `justification`, `created_at` |
| Compteur retourn√© | `{"relations_created": N}` |

### 14.5 Conformit√© ADR ‚Äî Pass 2

| # | Axe ADR | Statut | D√©tail |
|---|---------|--------|--------|
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Les relations sont entre n≈ìuds `Concept` (couche s√©mantique), pas entre `DocItem` (couche structurelle) |
| AV2-2 | 8 types de nodes maximum | ‚úÖ | Pass 2 ne cr√©e aucun nouveau type de n≈ìud ‚Äî uniquement des ar√™tes entre n≈ìuds existants |
| AV2-8 | Dual storage (Neo4j + Qdrant) | ‚ö†Ô∏è | Pass 2 ne persiste que dans Neo4j. Pas de mise √† jour Qdrant (les relations ne sont pas vectoris√©es). Conforme √† l'esprit (relations = graphe navigable) |
| NS-2 | LLM = Extracteur evidence-locked | ‚úÖ | Le LLM extrait des relations, il ne d√©cide pas du type final (validation post-extraction). Chaque relation doit avoir `evidence_info_ids` |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Les relations sont intra-document : entre concepts d'un m√™me document. Pas de relations cross-doc en Pass 2 |
| NS-7 | Addressability-First | ‚úÖ | Les relations sont navigables via les concepts, eux-m√™mes rattach√©s aux th√®mes et au sujet |
| SCOPE | Scope vs Assertion separation | ‚ö†Ô∏è | L'impl√©mentation actuelle ne distingue pas explicitement les relations de scope (dense) vs. les relations d'assertion (sparse). Toutes les relations sont trait√©es uniform√©ment comme `CONCEPT_RELATION`. Voir ¬ß 14.6 R2-4 |
| DR-C1 | Pas de nouvelle couche (ADR Discursive) | ‚úÖ | Pass 2 ne cr√©e pas de nouvelle couche ‚Äî les relations sont des ar√™tes, pas des n≈ìuds |
| DR-C2 | Evidence-first (ADR Discursive) | ‚ö†Ô∏è | Les relations ont `evidence_info_ids` mais pas de `EvidenceBundle` formel. La justification est un texte libre, pas un span multi-source structur√© |
| DR-C3 | Pas de contamination par inf√©rence | ‚ö†Ô∏è | Le mode heuristique inf√®re des relations par co-occurrence de noms. C'est une heuristique lexicale, pas une inf√©rence s√©mantique profonde, mais le risque de faux positifs existe |
| DR-C3bis | ExtractionMethod autoris√© | ‚ùå | L'impl√©mentation ne trace pas la m√©thode d'extraction (`PATTERN`, `LLM`, `HYBRID`). Impossible de distinguer assertions EXPLICIT vs DISCURSIVE |
| DR-C4 | Whitelist RelationType par AssertionKind | ‚ùå | Les 8 types de relations sont utilis√©s uniform√©ment. Pas de distinction EXPLICIT/DISCURSIVE ni de whitelist restrictive pour les relations discursives |

### 14.6 Risques ‚Äî Pass 2

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R2-1 | **Label g√©n√©rique `CONCEPT_RELATION`** | üü° | Toutes les relations utilisent un label unique (`CONCEPT_RELATION`) avec le type en propri√©t√©. Cela emp√™che les travers√©es Cypher typ√©es (ex: `MATCH -[:REQUIRES]->`) et oblige un filtre `WHERE r.type = ...` sur chaque requ√™te. | Acceptable en MVP. Migration possible vers labels dynamiques via APOC si les performances de travers√©e deviennent un probl√®me. Le commentaire dans le code mentionne cette √©volution. |
| R2-2 | **Garde-fou √† 3 relations arbitraire** | üü° | La limite de 3 relations par concept source est un choix pragmatique. Pour des documents tr√®s denses, cela pourrait masquer des relations significatives. Le tri par confiance att√©nue le risque mais ne l'√©limine pas. | Constante de classe `MAX_RELATIONS_PER_CONCEPT` facilement ajustable. Monitoring via `Pass2Stats.relations_filtered` pour d√©tecter les cas de filtrage excessif. |
| R2-3 | **Heuristique de fallback peu fiable** | üü° | Le mode heuristique repose sur la co-occurrence lexicale simple (pr√©sence du nom/variante dans le texte). Cela g√©n√®re des faux positifs (deux concepts mentionn√©s dans la m√™me phrase ne sont pas n√©cessairement en relation). Confiance fixe √† 0.6 sans discrimination. | Le mode heuristique est explicitement marqu√© comme non fiable (`logger.warning`). Flag `allow_fallback` d√©sactiv√© par d√©faut. |
| R2-4 | **Pas de distinction Scope vs Assertion pour les relations** | üü° | L'ADR Scope vs Assertion Separation √©tablit que le Scope Layer (ce que le document couvre) est distinct de l'Assertion Layer (ce que le document affirme). Les relations Pass 2 ne portent pas cette distinction ‚Äî une relation `RELATED_TO` par co-occurrence est fondamentalement un lien de scope, pas d'assertion. | √âvolution n√©cessaire pour taguer `assertion_kind` (EXPLICIT/DISCURSIVE) sur les relations. Non bloquant en MVP mais requis pour la conformit√© ADR Discursive Relations. |
| R2-5 | **Absence de `DefensibilityTier` et `EvidenceBundle`** | üü° | L'ADR Relations Discursivement D√©termin√©es pr√©voit un pipeline `RawAssertion ‚Üí CanonicalRelation ‚Üí SemanticRelation` avec `DefensibilityTier` (STRICT/EXTENDED). L'impl√©mentation actuelle cr√©e directement des `CONCEPT_RELATION` sans passer par ce pipeline √† trois couches. | L'ADR est un objectif architectural. L'impl√©mentation actuelle est un MVP fonctionnel. La migration vers le mod√®le ADR complet est une t√¢che d√©di√©e. |
| R2-6 | **Pas de d√©duplication des relations** | üü¢ | Le `MERGE` Neo4j sur `relation_id` pr√©vient les doublons exacts. Cependant, si Pass 2 est ex√©cut√© plusieurs fois avec des UUID diff√©rents, des relations s√©mantiquement identiques mais avec des `relation_id` distincts pourraient coexister. | `delete_pass2_data()` permet de purger avant retraitement. L'idempotence est garantie au niveau du `relation_id`, pas au niveau s√©mantique. |
| R2-7 | **Persistance relation par relation (pas de batch)** | üü¢ | Le persister it√®re sur les relations et ex√©cute une transaction par relation. Pour des documents avec beaucoup de relations, cela pourrait √™tre lent. | Optimisation possible via `UNWIND` Cypher pour batch insert. Non critique en MVP vu le garde-fou √† 3 relations/concept (max ~45 relations pour 15 concepts). |

---

## 15. Pass 3 ‚Äî Consolidation Corpus (Entity Resolution Cross-Document)

**Fichier principal :** `src/knowbase/stratified/pass3/entity_resolver.py` ‚Äî classe `EntityResolverV2`
**Orchestration :** `src/knowbase/stratified/pass3/orchestrator.py` ‚Äî classe `Pass3OrchestratorV2`
**Persistence :** `src/knowbase/stratified/pass3/persister.py` ‚Äî classe `Pass3PersisterV2`
**Mod√®le transverse :** `src/knowbase/stratified/models/contradiction.py` ‚Äî classe `Contradiction`
**ADR de r√©f√©rence :** `doc/ongoing/ARCH_STRATIFIED_PIPELINE_V2.md` (AV2-9), `doc/ongoing/ADR_NORTH_STAR_VERITE_DOCUMENTAIRE.md` (NS-4, NS-5, NS-10)

> **Positionnement dans le pipeline :** Pass 3 est la seule phase op√©rant au **niveau corpus** (multi-documents). Toutes les passes pr√©c√©dentes (0 ‚Üí 2) traitent un document unique. Pass 3 consolide le graphe s√©mantique en r√©solvant les entit√©s identiques provenant de documents diff√©rents.

### 15.1 Entrants

| Entrant | Type | Source | Description |
|---------|------|--------|-------------|
| Concepts du corpus | `List[Concept]` | Neo4j (mode batch) | Tous les concepts persist√©s dans le graphe, charg√©s via requ√™te Cypher sur `tenant_id` |
| Th√®mes du corpus | `List[Theme]` | Neo4j (mode batch) | Tous les th√®mes persist√©s dans le graphe |
| Nouveaux concepts | `List[Concept]` | Pass 1 (mode incr√©mental) | Concepts d'un nouveau document √† int√©grer |
| CanonicalConcept existants | `List[CanonicalConcept]` | Neo4j (mode incr√©mental) | Concepts canoniques d√©j√† cr√©√©s par des ex√©cutions pr√©c√©dentes |

**Chargement depuis Neo4j (`_load_all_from_neo4j`) :**

```cypher
-- Concepts
MATCH (c:Concept {tenant_id: $tenant_id})
OPTIONAL MATCH (t:Theme)-[:HAS_CONCEPT]->(c)
RETURN c.concept_id, c.name, c.role, c.variants, c.lex_key,
       t.theme_id

-- Th√®mes
MATCH (t:Theme {tenant_id: $tenant_id})
RETURN t.theme_id, t.name

-- CanonicalConcept existants (mode incr√©mental)
MATCH (cc:CanonicalConcept {tenant_id: $tenant_id})
OPTIONAL MATCH (cc)-[:SAME_AS]->(c:Concept)
RETURN cc.canonical_id, cc.name, collect(c.concept_id) AS merged_from
```

### 15.2 Objectifs

Pass 3 r√©alise la **consolidation au niveau corpus** du graphe s√©mantique en :

1. **R√©solution d'entit√©s cross-documents** ‚Äî Identifier les concepts identiques provenant de documents diff√©rents et les fusionner en `CanonicalConcept`.
2. **Alignement de th√®mes cross-documents** ‚Äî Regrouper les th√®mes similaires provenant de documents diff√©rents en `CanonicalTheme`.
3. **Cr√©ation de la couche canonique** ‚Äî √âtablir les relations `SAME_AS` (concepts) et `ALIGNED_TO` (th√®mes) entre entit√©s canoniques et entit√©s sources.
4. **Support dual mode** ‚Äî Fonctionner en mode **batch** (traitement complet du corpus) ou **incr√©mental** (int√©gration d'un nouveau document).

### 15.3 M√©canismes

#### 15.3.1 Orchestration (`Pass3OrchestratorV2`)

L'orchestrateur expose deux modes d'ex√©cution d√©finis par l'enum `Pass3Mode` :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Mode BATCH                                               ‚îÇ
‚îÇ   Neo4j (all Concepts+Themes)                            ‚îÇ
‚îÇ     ‚Üí EntityResolverV2.resolve()                         ‚îÇ
‚îÇ       ‚Üí _cluster_concepts() ‚Üí _create_canonical_concepts ‚îÇ
‚îÇ       ‚Üí _cluster_themes()   ‚Üí _create_canonical_themes   ‚îÇ
‚îÇ     ‚Üí Pass3PersisterV2.persist()                         ‚îÇ
‚îÇ       ‚Üí Neo4j (CanonicalConcept, CanonicalTheme)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Mode INCREMENTAL                                         ‚îÇ
‚îÇ   new_concepts (Pass 1) + existing_canonical (Neo4j)     ‚îÇ
‚îÇ     ‚Üí EntityResolverV2.resolve_incremental()             ‚îÇ
‚îÇ       ‚Üí Matching par nom/variantes                       ‚îÇ
‚îÇ       ‚Üí Fusion ou cr√©ation de nouveaux canoniques        ‚îÇ
‚îÇ     ‚Üí Pass3PersisterV2.persist() (si nouveaux canoniques)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Points d'entr√©e :**

| M√©thode | Mode | Source des donn√©es | Usage |
|---------|------|--------------------|-------|
| `process_batch(persist=True)` | BATCH | Neo4j (tout le corpus) | Reconsolidation compl√®te |
| `process_incremental(new_concepts, persist=True)` | INCREMENTAL | `List[Concept]` en m√©moire + Neo4j | Ajout d'un document |
| `run_pass3_batch(neo4j_driver, ...)` | BATCH | Wrapper utilitaire stateless | Script / CLI |
| `run_pass3_incremental(new_concepts, ...)` | INCREMENTAL | Wrapper utilitaire stateless | Script / CLI |

**Pr√©conditions :**

- Mode batch : `neo4j_driver` obligatoire (sinon `RuntimeError`)
- Mode incr√©mental : les CanonicalConcept existants sont charg√©s via `_load_canonical_concepts()`
- D√©pendances inject√©es : `llm_client`, `embedding_client`, `neo4j_driver` (tous optionnels sauf Neo4j en batch)

#### 15.3.2 Clustering de concepts (`EntityResolverV2`)

Le c≈ìur de Pass 3 est le **clustering de concepts** similaires provenant de documents diff√©rents. L'algorithme utilise une strat√©gie en 3 niveaux de priorit√© d√©croissante :

**Strat√©gie 1 ‚Äî Matching exact par `lex_key` :**

```python
# Index par lex_key
by_lex_key: Dict[str, List[Concept]] = {}
for concept in concepts:
    if concept.lex_key:
        by_lex_key[concept.lex_key].append(concept)
```

Tous les concepts partageant la m√™me `lex_key` (cl√© lexicale normalis√©e) sont regroup√©s dans un m√™me `ConceptCluster`. Cette strat√©gie produit des clusters de haute confiance car la `lex_key` est une forme canonique calcul√©e en Pass 1.2.

**Strat√©gie 2 ‚Äî Matching par variantes :**

Pour les concepts non assign√©s par la strat√©gie 1, le syst√®me cherche une intersection entre les ensembles `{name, variants}` de chaque concept et ceux des concepts d√©j√† clusteris√©s :

```python
concept_names = {concept.name.lower()} | {v.lower() for v in concept.variants}
other_names = {other.name.lower()} | {v.lower() for v in other.variants}
if concept_names & other_names:  # Intersection non vide
    ‚Üí merge dans le cluster existant
```

**Strat√©gie 3 ‚Äî Similarit√© par embeddings (pr√©vue, non impl√©ment√©e) :**

Le param√®tre `embedding_client` est accept√© par le constructeur mais la strat√©gie de clustering par similarit√© s√©mantique (cosine similarity sur embeddings) n'est **pas encore impl√©ment√©e**. Le seuil `SIMILARITY_THRESHOLD = 0.85` est d√©fini comme constante de classe mais non utilis√© dans le code actuel.

**Concepts orphelins :** Les concepts qui ne matchent aucun cluster existant sont plac√©s dans des **clusters singletons** (un concept = un cluster). Ces singletons ne g√©n√®rent pas de `CanonicalConcept` (voir ¬ß15.3.3).

#### 15.3.3 Cr√©ation des CanonicalConcept

Un `CanonicalConcept` est cr√©√© **uniquement si le cluster contient ‚â• 2 concepts** (fusion effective) :

```python
for cluster in clusters:
    if len(cluster.concept_ids) > 1:  # Seulement si fusion
        cc = CanonicalConcept(
            canonical_id=f"canonical_{cluster.cluster_id}",
            name=cluster.representative_name,    # Nom du premier concept
            merged_from=cluster.concept_ids       # IDs de tous les concepts fusionn√©s
        )
```

Le nom repr√©sentatif est celui du **premier concept du cluster** (ordre d'insertion). Pas de s√©lection heuristique du meilleur nom.

#### 15.3.4 Clustering de th√®mes (`_cluster_themes`)

Les th√®mes sont clusteris√©s par **nom normalis√© exact** (lowercase + strip) :

```python
norm_name = theme.name.lower().strip()
by_name[norm_name].append(theme)
```

Cr√©ation de `CanonicalTheme` uniquement si ‚â• 2 th√®mes partagent le m√™me nom normalis√©.

**‚ö†Ô∏è D√©viation notable :** Contrairement au clustering de concepts (qui utilise `lex_key` + variantes), le clustering de th√®mes ne dispose d'aucun m√©canisme de matching s√©mantique. Seule la correspondance exacte de noms (apr√®s normalisation) est utilis√©e.

#### 15.3.5 R√©solution incr√©mentale (`resolve_incremental`)

Le mode incr√©mental traite un nouvel ensemble de concepts par rapport aux `CanonicalConcept` existants :

1. **Construction d'un index** `nom_normalis√© ‚Üí CanonicalConcept` √† partir des canoniques existants.
2. **Pour chaque nouveau concept :**
   - Match par nom exact (`concept.name.lower()` dans l'index)
   - Match par variantes (`variant.lower()` dans l'index)
   - Si match : fusion (`concept_id` ajout√© √† `merged_from` du canonique existant)
   - Si pas de match : **aucune action** (pas de cr√©ation de singleton en mode incr√©mental ‚Äî attente du prochain batch)
3. **Retour** : `(updated_canonical, mapping)` o√π `mapping` associe chaque `concept_id` au `canonical_id` correspondant.

**Point notable :** Le mode incr√©mental est **conservateur** ‚Äî il ne cr√©e jamais de nouveau `CanonicalConcept`. Les concepts sans match restent isol√©s jusqu'au prochain batch. Cette strat√©gie √©vite la prolif√©ration de canoniques singletons.

#### 15.3.6 Persistence Neo4j (`Pass3PersisterV2`)

**Mod√®le de persistance :**

```
CanonicalConcept -[:SAME_AS]-> Concept     (pour chaque concept fusionn√©)
CanonicalTheme   -[:ALIGNED_TO]-> Theme    (pour chaque th√®me align√©)
```

**Transaction CanonicalConcept (`_create_canonical_concept_tx`) :**

```cypher
-- Cr√©er/mettre √† jour le n≈ìud CanonicalConcept
MERGE (cc:CanonicalConcept {canonical_id: $canonical_id, tenant_id: $tenant_id})
SET cc.name = $name, cc.created_at = datetime()

-- Pour chaque concept fusionn√©, cr√©er la relation SAME_AS
MATCH (cc:CanonicalConcept {canonical_id: $canonical_id, tenant_id: $tenant_id})
MATCH (c:Concept {concept_id: $concept_id, tenant_id: $tenant_id})
MERGE (cc)-[:SAME_AS]->(c)
```

**Transaction CanonicalTheme (`_create_canonical_theme_tx`) :**

```cypher
MERGE (ct:CanonicalTheme {canonical_id: $canonical_id, tenant_id: $tenant_id})
SET ct.name = $name, ct.created_at = datetime()

MATCH (ct:CanonicalTheme {canonical_id: $canonical_id, tenant_id: $tenant_id})
MATCH (t:Theme {theme_id: $theme_id, tenant_id: $tenant_id})
MERGE (ct)-[:ALIGNED_TO]->(t)
```

**Points notables :**

- `MERGE` sur `canonical_id + tenant_id` : idempotent, re-ex√©cuter Pass 3 met √† jour sans dupliquer.
- Multi-tenant int√©gr√© via `tenant_id` sur tous les n≈ìuds et MATCH.
- Les relations `SAME_AS` et `ALIGNED_TO` sont cr√©√©es **une par une** (it√©ration, pas de batch `UNWIND`).
- Aucun m√©canisme de suppression des donn√©es Pass 3 existantes avant retraitement (contrairement √† Pass 2 qui dispose de `delete_pass2_data()`).

**Fonction utilitaire :** `persist_pass3_result(result, neo4j_driver, tenant_id)` ‚Äî wrapper stateless pour usage ponctuel.

**Compteurs retourn√©s (`persist`) :**

```python
stats = {
    "canonical_concepts": int,      # Nombre de CanonicalConcept cr√©√©s
    "canonical_themes": int,        # Nombre de CanonicalTheme cr√©√©s
    "same_as_relations": int,       # Nombre de relations SAME_AS
    "aligned_to_relations": int,    # Nombre de relations ALIGNED_TO
}
```

### 15.4 Mod√®le de donn√©es transverse ‚Äî Contradiction

**Fichier :** `src/knowbase/stratified/models/contradiction.py`
**Usage :** OSMOSE MVP V1 ‚Äî Usage B (Challenge de Texte)
**R√©f√©rence :** `SPEC_IMPLEMENTATION_CLASSES_MVP_V1.md`

Le mod√®le `Contradiction` repr√©sente une **tension d√©tect√©e entre deux Informations** partageant le m√™me `ClaimKey`. Il op√®re au niveau cross-document et constitue un des r√©sultats attendus de la consolidation corpus.

#### 15.4.1 Structure de donn√©es

```python
@dataclass
class Contradiction:
    # Identifiants
    contradiction_id: str        # Identifiant unique
    claimkey_id: str             # ClaimKey partag√©e (pivot de comparaison)

    # Information A
    info_a_id: str               # ID de la premi√®re Information
    info_a_document: str         # Document source de A
    info_a_value_raw: Optional[str]   # Valeur brute de A
    info_a_context: dict         # Contexte de A

    # Information B
    info_b_id: str               # ID de la seconde Information
    info_b_document: str         # Document source de B
    info_b_value_raw: Optional[str]   # Valeur brute de B
    info_b_context: dict         # Contexte de B

    # Classification
    nature: ContradictionNature  # Type de contradiction
    tension_level: TensionLevel  # Niveau de tension
    explanation: str             # Explication textuelle

    # M√©tadonn√©es
    detected_at: datetime        # Horodatage de d√©tection (UTC)
    detection_method: str        # M√©thode de d√©tection (d√©faut: "value_normalized_comparison")
```

#### 15.4.2 Taxonomie des contradictions (`ContradictionNature`)

| Valeur | S√©mantique | Type |
|--------|-----------|------|
| `VALUE_CONFLICT` | Conflit de valeurs (A affirme X, B affirme Y pour la m√™me ClaimKey) | Hard |
| `VALUE_EXCEEDS_MINIMUM` | Valeur au-dessus d'un minimum d√©clar√© | Soft |
| `VALUE_BELOW_MAXIMUM` | Valeur en dessous d'un maximum d√©clar√© | Soft |
| `SCOPE_CONFLICT` | Conflit de p√©rim√®tre (applicable dans des contextes diff√©rents) | Variable |
| `TEMPORAL_CONFLICT` | Conflit temporel (vrai √† des moments diff√©rents) | Variable |
| `MISSING_CLAIM` | Absence d'affirmation attendue (un document ne mentionne pas ce que l'autre affirme) | Soft |

#### 15.4.3 Niveaux de tension (`TensionLevel`)

| Niveau | Signification |
|--------|---------------|
| `NONE` | Pas de tension r√©elle (faux positif r√©solu) |
| `SOFT` | Compatible mais diff√©rent ‚Äî les deux valeurs peuvent coexister |
| `HARD` | Incompatible ‚Äî les deux valeurs sont mutuellement exclusives |
| `UNKNOWN` | Tension non classifiable |

#### 15.4.4 S√©rialisation Neo4j

La classe fournit deux m√©thodes de s√©rialisation/d√©s√©rialisation Neo4j :

- `to_neo4j_properties()` ‚Üí `dict` : convertit toutes les propri√©t√©s en types Neo4j-compatibles (enums ‚Üí `.value`, datetime ‚Üí `.isoformat()`)
- `from_neo4j_record(record)` ‚Üí `Contradiction` : reconstruit depuis un record Cypher, avec gestion des champs optionnels et valeurs par d√©faut

**‚ö†Ô∏è Statut d'impl√©mentation :** Le mod√®le `Contradiction` est d√©fini et pr√™t √† l'emploi, mais le **d√©tecteur de contradictions** (composant qui comparerait les Informations via ClaimKey + Value Contract pour cr√©er des instances `Contradiction`) n'est **pas encore impl√©ment√©** dans le pipeline. La d√©tection de contradictions est un objectif du MVP V1 Usage B.

### 15.5 Outputs

**Dataclass principale :**

```python
@dataclass
class Pass3Result:
    canonical_concepts: List[CanonicalConcept]   # Concepts canoniques cr√©√©s
    canonical_themes: List[CanonicalTheme]        # Th√®mes canoniques cr√©√©s
    concept_clusters: List[ConceptCluster]        # Clusters de concepts
    theme_clusters: List[ThemeCluster]            # Clusters de th√®mes
    stats: Pass3Stats                             # M√©triques d'ex√©cution
```

**Structure d'un cluster de concepts (`ConceptCluster`) :**

```python
@dataclass
class ConceptCluster:
    cluster_id: str                          # Identifiant unique (format "cluster_{uuid8}")
    concept_ids: List[str]                   # IDs des concepts regroup√©s
    representative_name: str                 # Nom repr√©sentatif du cluster
    similarity_scores: Dict[str, float]      # Scores de similarit√© (non utilis√© actuellement)
```

**Structure d'un cluster de th√®mes (`ThemeCluster`) :**

```python
@dataclass
class ThemeCluster:
    cluster_id: str                          # Identifiant unique (format "theme_cluster_{uuid8}")
    theme_ids: List[str]                     # IDs des th√®mes regroup√©s
    representative_name: str                 # Nom repr√©sentatif du cluster
```

**Statistiques (`Pass3Stats`) :**

```python
@dataclass
class Pass3Stats:
    concepts_processed: int            # Nombre de concepts analys√©s
    themes_processed: int              # Nombre de th√®mes analys√©s
    concept_clusters: int              # Nombre de clusters de concepts form√©s
    theme_clusters: int                # Nombre de clusters de th√®mes form√©s
    canonical_concepts_created: int    # Nombre de CanonicalConcept cr√©√©s
    canonical_themes_created: int      # Nombre de CanonicalTheme cr√©√©s
```

**Sortie Neo4j :**

| √âl√©ment | D√©tail |
|---------|--------|
| N≈ìuds cr√©√©s | `CanonicalConcept` avec `canonical_id`, `name`, `tenant_id`, `created_at` |
| N≈ìuds cr√©√©s | `CanonicalTheme` avec `canonical_id`, `name`, `tenant_id`, `created_at` |
| Relations cr√©√©es | `(CanonicalConcept)-[:SAME_AS]->(Concept)` |
| Relations cr√©√©es | `(CanonicalTheme)-[:ALIGNED_TO]->(Theme)` |
| Compteurs retourn√©s | `canonical_concepts`, `canonical_themes`, `same_as_relations`, `aligned_to_relations` |

### 15.6 Conformit√© ADR ‚Äî Pass 3

| # | Axe ADR | Statut | D√©tail |
|---|---------|--------|--------|
| AV2-2 | 8 types de nodes maximum | ‚ö†Ô∏è | Pass 3 cr√©e deux nouveaux types de n≈ìuds (`CanonicalConcept`, `CanonicalTheme`) qui s'ajoutent aux 8 types V2 de base. Cela porte le total √† 10 types. Acceptable car ces n≈ìuds sont des **superpositions** (couche canonique au-dessus de la couche document), mais d√©passe la r√®gle stricte des 8 types |
| AV2-9 | Pass 3 mode manuel + batch | ‚úÖ | L'impl√©mentation supporte les deux modes pr√©vus : **BATCH** (reconsolidation compl√®te) et **INCREMENTAL** (ajout d'un document). Pas d'ex√©cution automatique inline ‚Äî Pass 3 est explicitement d√©clench√© |
| AV2-10 | < 250 nodes/document | ‚úÖ | Pass 3 ne cr√©e pas de n≈ìuds par document ‚Äî les `CanonicalConcept` et `CanonicalTheme` sont des n≈ìuds corpus-level. Le budget node/document n'est pas impact√© |
| NS-4 | Pas de synth√®se cross-source | ‚úÖ | Les `CanonicalConcept` sont des **pointeurs de regroupement** (`SAME_AS`), pas des synth√®ses. Chaque Information conserve son document source unique. La fusion ne cr√©e pas de nouvelle information |
| NS-5 | ClaimKey comme pivot | ‚ö†Ô∏è | Le mod√®le `Contradiction` est con√ßu autour du `ClaimKey` comme pivot de comparaison cross-doc. Cependant, le d√©tecteur de contradictions n'est pas encore impl√©ment√© |
| NS-10 | D√©duplication par fingerprint | ‚ö†Ô∏è | La r√©solution d'entit√©s par `lex_key` + variantes est une forme de d√©duplication, mais ne suit pas le m√©canisme de fingerprint `hash(claimkey + value.normalized + context_key + span_bucket)` pr√©vu par NS-10. La d√©duplication actuelle op√®re au niveau concept, pas au niveau Information |
| AV2-1 | S√©paration structure / s√©mantique | ‚úÖ | Les entit√©s canoniques appartiennent √† la couche s√©mantique. Aucune interaction avec la couche structurelle (Document, Section, DocItem) |
| AV2-8 | Dual storage (Neo4j + Qdrant) | ‚ö†Ô∏è | Pass 3 persiste uniquement dans Neo4j. Pas de mise √† jour des embeddings Qdrant pour refl√©ter la fusion de concepts. Les recherches vectorielles retourneront les concepts individuels, pas les canoniques |

### 15.7 Risques ‚Äî Pass 3

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| R3-1 | **Clustering par `lex_key` uniquement ‚Äî pas d'embeddings** | üü° | Le param√®tre `embedding_client` est accept√© mais jamais utilis√©. Le seuil `SIMILARITY_THRESHOLD = 0.85` est d√©fini mais non exploit√©. Le clustering repose exclusivement sur le matching lexical (`lex_key` exact + variantes). Les concepts s√©mantiquement similaires mais lexicalement diff√©rents (ex: "SAP S/4HANA" vs "S4H") ne seront pas fusionn√©s si `lex_key` et variantes diff√®rent. | Impl√©menter la strat√©gie 3 (cosine similarity sur embeddings) pour compl√©ter les strat√©gies lexicales. Le param√©trage est d√©j√† en place. |
| R3-2 | **Nom repr√©sentatif = premier concept (arbitraire)** | üü¢ | Le nom du `CanonicalConcept` est celui du premier concept du cluster (ordre d'insertion dans la boucle). Pas de s√©lection heuristique (ex: nom le plus court, le plus fr√©quent, ou le plus canonique). | Acceptable en MVP. √âvolution possible : s√©lection par fr√©quence d'apparition ou longueur optimale. |
| R3-3 | **Pas de purge avant retraitement batch** | üü° | Contrairement √† Pass 2 (`delete_pass2_data()`), Pass 3 n'a pas de m√©canisme de suppression des `CanonicalConcept` et `CanonicalTheme` existants avant un retraitement batch. Le `MERGE` sur `canonical_id` pr√©vient les doublons exacts, mais les clusters peuvent √©voluer entre deux ex√©cutions, laissant des canoniques obsol√®tes. | Ajouter une fonction `delete_pass3_data()` pour purger la couche canonique avant retraitement. Critique pour la fiabilit√© en production. |
| R3-4 | **Clustering de th√®mes trop strict (nom exact uniquement)** | üü° | Le clustering de th√®mes ne repose que sur le matching exact de noms normalis√©s. Des th√®mes s√©mantiquement identiques mais avec des formulations l√©g√®rement diff√©rentes (ex: "Architecture Cloud" vs "Cloud Architecture") ne seront pas align√©s. | Aligner la strat√©gie de clustering th√®mes sur celle des concepts (variantes + embeddings). |
| R3-5 | **Mode incr√©mental ne cr√©e jamais de nouveaux canoniques** | üü° | Le mode incr√©mental ne cr√©e pas de `CanonicalConcept` pour les concepts sans match. Ces concepts restent isol√©s jusqu'au prochain batch. Si le batch n'est jamais ex√©cut√©, le graphe canonique sera incomplet. | Le mode batch doit √™tre ex√©cut√© p√©riodiquement (cron ou d√©clenchement apr√®s N documents). Documenter cette contrainte op√©rationnelle. |
| R3-6 | **Persistance relation par relation (pas de batch)** | üü¢ | Le persister it√®re sur chaque `CanonicalConcept` et chaque `merged_from`, ex√©cutant une transaction par relation `SAME_AS`. Pour un corpus avec beaucoup de concepts fusionn√©s, cela pourrait √™tre lent. | Optimisation possible via `UNWIND` Cypher. Non critique si Pass 3 est ex√©cut√© en batch hors-ligne. |
| R3-7 | **D√©tecteur de contradictions non impl√©ment√©** | üî¥ | Le mod√®le `Contradiction` est d√©fini (6 natures, 4 niveaux de tension, s√©rialisation Neo4j) mais aucun composant du pipeline ne l'instancie. La d√©tection de contradictions cross-documents via ClaimKey + Value Contract est un objectif cl√© du MVP V1 Usage B ("Challenge de Texte") mais n'est pas encore cod√©. | Impl√©menter un `ContradictionDetector` qui parcourt les Informations par ClaimKey, compare les Value Contracts normalis√©s et cr√©e des n≈ìuds `Contradiction` dans Neo4j. Priorit√© haute pour le MVP. |
| R3-8 | **Pas de validation LLM des cas ambigus** | üü° | Le param√®tre `llm_client` est inject√© dans `EntityResolverV2` mais jamais utilis√© pour valider les cas de clustering ambigus. L'ADR pr√©voit une validation LLM pour les fusions incertaines (confidence entre 0.7 et 0.85). | Impl√©menter la validation LLM pour les clusters dont la similarit√© est entre le seuil heuristique et le seuil d'acceptation automatique. |

---

## 16. Orchestration Pipeline

Cette section d√©crit les m√©canismes d'orchestration qui pilotent l'ex√©cution du Pipeline V2, depuis la d√©tection de nouveaux fichiers jusqu'√† la finalisation du traitement. L'orchestration est transverse √† toutes les passes document√©es pr√©c√©demment.

### 16.1 S√©quencement global

Le pipeline V2 suit un s√©quencement lin√©aire en 5 √©tapes principales, pilot√© par le syst√®me de jobs RQ (Redis Queue) :

```
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  POINT D'ENTR√âE ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ API Upload ‚îÇ              ‚îÇ Folder      ‚îÇ
              ‚îÇ (FastAPI)  ‚îÇ              ‚îÇ Watcher     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                             ‚îÇ
                    ‚îÇ  POST /ingest               ‚îÇ  on_created / on_moved
                    ‚îÇ                             ‚îÇ  wait_for_file_stability()
                    ‚îÇ                             ‚îÇ  copy ‚Üí docs_in/
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   Dispatcher    ‚îÇ
                         ‚îÇ  (dispatcher.py)‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    enqueue_document_v2()
                    enqueue_excel_ingestion()
                                  ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   Redis Queue   ‚îÇ
                         ‚îÇ   (RQ Worker)   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   jobs_v2.py    ‚îÇ
                         ‚îÇ ingest_doc_v2   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                   ‚îÇ                   ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ 1. Extraction   ‚îÇ ‚îÇ 2. OSMOSE      ‚îÇ ‚îÇ 3. D√©duplication‚îÇ
     ‚îÇ V2 (Pass 0)     ‚îÇ ‚îÇ Agentique      ‚îÇ ‚îÇ Auto            ‚îÇ
     ‚îÇ Docling+Vision  ‚îÇ ‚îÇ (Pass 0S-3)    ‚îÇ ‚îÇ                 ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                   ‚îÇ                   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                   ‚îÇ                   ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ 4. Move to      ‚îÇ ‚îÇ 5. Notifier    ‚îÇ ‚îÇ Rollback si     ‚îÇ
     ‚îÇ docs_done/      ‚îÇ ‚îÇ Historique     ‚îÇ ‚îÇ Erreur          ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**D√©tail du s√©quencement dans `ingest_document_v2_job()` :**

| √âtape | Nom | Progression | D√©tail |
|-------|-----|-------------|--------|
| 0 | Initialisation | 0/5 | V√©rification existence fichier, d√©tection type, check mode Burst |
| 1 | Extraction V2 | 1/5 | `_run_extraction_v2()` ‚Äî ExtractionPipelineV2 (Docling + Vision Gating V4) |
| 2 | OSMOSE Agentique | 2/5 | `_run_osmose_processing()` ‚Äî OsmoseAgentiqueService (Pass 0S ‚Üí Pass 3) |
| 3 | D√©duplication | 3/5 | `auto_deduplicate_entities()` ‚Äî KnowledgeGraphService.deduplicate_entities_by_name |
| 4 | Finalisation | 4/5 | `shutil.move()` ‚Äî D√©placement fichier de `docs_in/` vers `docs_done/` |
| 5 | Compl√©t√© | 5/5 | Notification historique Redis ‚Äî statut "completed" |

### 16.2 Folder Watcher

**Fichier :** `src/knowbase/ingestion/folder_watcher.py`
**Classe principale :** `WatchHandler(FileSystemEventHandler)`

Le Folder Watcher est un processus autonome qui surveille le r√©pertoire `/data/watch/` via un `PollingObserver` (watchdog). Il constitue le point d'entr√©e alternatif √† l'upload API.

**Flux d√©taill√© :**

1. **D√©tection** : `on_created()` ou `on_moved()` d√©clench√© par la pr√©sence d'un nouveau fichier
2. **Stabilisation** : `wait_for_file_stability()` ‚Äî attente de 2 secondes pour s'assurer que le fichier est compl√®tement √©crit
3. **Copie** : Le fichier est copi√© vers `/data/docs_in/` (r√©pertoire d'entr√©e officiel du pipeline)
4. **Routage** : `enqueue_file()` d√©termine le type de fichier et appelle la fonction dispatcher appropri√©e
5. **Job ID** : G√©n√©ration d'un identifiant unique au format `watch-{filename}-{uuid}`

**Types support√©s :**

| Extension | Fonction dispatcher | Job cible |
|-----------|-------------------|-----------|
| `.pdf` | `enqueue_pdf_ingestion()` | `ingest_document_v2_job` |
| `.pptx` | `enqueue_pptx_ingestion()` | `ingest_document_v2_job` |
| `.docx` | `enqueue_document_v2()` | `ingest_document_v2_job` |
| `.xlsx` | `enqueue_excel_ingestion()` | `ingest_excel_job` |

### 16.3 Dispatcher

**Fichier :** `src/knowbase/ingestion/queue/dispatcher.py`
**Statut :** Pipeline V2 unifi√© ‚Äî Legacy V1 supprim√© (cleanup 2025-01-05)

Le dispatcher est le point central de routage des documents vers les jobs RQ. Depuis le cleanup de janvier 2025, **tous les formats** sont rout√©s vers le pipeline V2 unifi√©.

#### 16.3.1 Architecture post-cleanup

```
 enqueue_pptx_ingestion() ‚îÄ‚îÄ‚îê
                             ‚îú‚îÄ‚îÄ‚Üí enqueue_document_v2() ‚îÄ‚îÄ‚Üí jobs_v2.ingest_document_v2_job
 enqueue_pdf_ingestion()  ‚îÄ‚îÄ‚îò

 enqueue_excel_ingestion() ‚îÄ‚îÄ‚Üí jobs_v2.ingest_excel_job  (chemin s√©par√©)
 enqueue_fill_excel()      ‚îÄ‚îÄ‚Üí jobs_v2.fill_excel_job    (remplissage RFP)
```

**Points cl√©s :**

- **Unification V2** : `enqueue_pptx_ingestion()` et `enqueue_pdf_ingestion()` sont d√©sormais de simples wrappers qui d√©l√®guent √† `enqueue_document_v2()`. Les param√®tres legacy (`meta_path`, `use_vision`) sont accept√©s mais ignor√©s.
- **Excel s√©par√©** : L'ingestion Excel reste sur un chemin d√©di√© (`ingest_excel_job`) car le format Q/A RFP n'est pas encore dans ExtractionPipelineV2.
- **Metadata RQ** : Chaque job est enrichi avec des m√©tadonn√©es (`job_type`, `pipeline_version`, `document_type`, `source`) via `_register_meta()` pour le suivi.

#### 16.3.2 Configuration RQ

**Fichier :** `src/knowbase/ingestion/queue/connection.py`

| Param√®tre | Source | Valeur |
|-----------|--------|--------|
| `REDIS_URL` | Variable d'environnement | `redis://knowbase-redis:6379/0` (par d√©faut) |
| `DEFAULT_QUEUE_NAME` | Env `INGESTION_QUEUE` ou `"ingestion"` | Queue principale d'ingestion |
| `DEFAULT_JOB_TIMEOUT` | `settings.ingestion_job_timeout` | Configurable |
| `result_ttl` | `DEFAULT_JOB_TIMEOUT` | M√™me valeur que le timeout |
| `failure_ttl` | `DEFAULT_JOB_TIMEOUT` | M√™me valeur que le timeout |

#### 16.3.3 Cycle de vie d'un job

```
 ENQUEUED ‚Üí PROCESSING ‚Üí [EXTRACTION ‚Üí OSMOSE ‚Üí DEDUP ‚Üí MOVE] ‚Üí COMPLETED
                    ‚îÇ                                                  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ERREUR ‚Üí ROLLBACK ‚Üí FAILED ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Suivi de progression :**

- `mark_job_as_processing()` ‚Äî Enregistre le statut "processing" dans l'historique Redis
- `update_job_progress(step, progress, total_steps, message)` ‚Äî Met √† jour les m√©tadonn√©es du job RQ
- `send_worker_heartbeat()` ‚Äî Heartbeat p√©riodique avec `worker_id` (hostname:pid) et timestamp

**Gestion d'erreur et rollback :**

En cas d'exception dans `ingest_document_v2_job()` :

1. **Log** de l'erreur
2. **Suppression** des chunks partiels via `delete_import_completely(job.id)`
3. **Notification** historique Redis avec statut "failed" et message d'erreur
4. **Re-raise** de l'exception pour que RQ la marque comme √©chou√©e

### 16.4 Modes d'ex√©cution

Le pipeline V2 supporte plusieurs modes d'ex√©cution, principalement pour la **Pass 2** (enrichissement s√©mantique) qui est la plus co√ªteuse en temps.

#### 16.4.1 Modes configurables (Pass 2)

**Configuration :** `config/feature_flags.yaml` ‚Üí `phase_2_hybrid_anchor.pass2_config.mode`

| Mode | Description | Usage typique |
|------|-------------|---------------|
| `inline` | Pass 2 ex√©cut√©e imm√©diatement apr√®s Pass 1, dans le m√™me job | Mode Burst GPU ‚Äî latence faible, infrastructure d√©di√©e |
| `background` | Pass 2 enqueued comme job RQ asynchrone s√©par√© | **Mode par d√©faut** ‚Äî ne bloque pas l'ingestion principale |
| `scheduled` | Pass 2 ex√©cut√©e en batch p√©riodique (cron) | Corpus stable ‚Äî consolidation nocturne |
| `disabled` | Pass 2 non ex√©cut√©e | Debug/test ‚Äî extraction only |

**Valeur actuelle :** `"background"` (configur√© dans `feature_flags.yaml`)

#### 16.4.2 Phases Pass 2 activables

Chaque phase de Pass 2 peut √™tre activ√©e/d√©sactiv√©e individuellement via `pass2_config.enabled_phases` :

```yaml
enabled_phases:
  - "corpus_promotion"       # Pass 2.0: Promotion unifi√©e
  - "structural_topics"      # Pass 2a: Topics + HAS_TOPIC + COVERS
  - "classify_fine"          # Pass 2b-1: Classification fine concepts
  - "enrich_relations"       # Pass 2b-2: Extraction relations ADR-compliant
  - "normative_extraction"   # Pass 2c: NormativeRule + SpecFact
  - "semantic_consolidation" # Pass 3: Consolidation s√©mantique
  - "cross_doc"              # Linking cross-document (Entity Resolution)
```

### 16.5 Feature Flags et configuration

**Fichier YAML :** `config/feature_flags.yaml`
**Module Python :** `src/knowbase/config/feature_flags.py`

#### 16.5.1 Flags principaux du pipeline

| Flag | Section | Valeur | Impact |
|------|---------|--------|--------|
| `extraction_v2.enabled` | Extraction | `true` | Active le pipeline Docling + Vision Gating V4 |
| `stratified_pipeline_v2.enabled` | Pipeline V2 | `true` | Active le pipeline stratifi√© (lecture top-down) |
| `stratified_pipeline_v2.use_v2_endpoints` | API | `false` | Les endpoints V2 ne sont pas encore les principaux |
| `phase_2_hybrid_anchor.enabled` | Pass 2 | `true` | Active le mod√®le Hybrid Anchor |
| `phase_2_hybrid_anchor.pass2_mode` | Ex√©cution | `"background"` | Mode d'ex√©cution de Pass 2 |
| `phase_1_8.enable_llm_relation_enrichment` | Relations | `false` | D√©sactiv√© ‚Äî unifi√© sur Pass 2 ENRICH_RELATIONS |

#### 16.5.2 Gardes de frugalit√©

```yaml
stratified_pipeline_v2:
  max_concepts_per_document: 15     # Budget concept normal
  max_concepts_hostile: 5           # Budget concept r√©duit (doc hostile)
  max_relations_per_concept: 3      # Cap relations par concept
  strict_promotion: false           # CONDITIONAL + RARELY promues
  promotion_threshold: 0.7          # Seuil confidence minimum
  consolidation_similarity_threshold: 0.85  # Seuil Pass 3
```

#### 16.5.3 Architecture de d√©ploiement

OSMOSE utilise une architecture **"1 instance = 1 client"** :
- Chaque client a sa propre instance d√©di√©e (Neo4j, Qdrant, Redis)
- Le `tenant_id` reste `"default"` sur chaque instance
- Pas de multi-tenancy logique ‚Äî isolation totale des donn√©es

### 16.6 Burst Mode (EC2 Spot)

**Fichier :** `src/knowbase/ingestion/burst/orchestrator.py`
**Classe principale :** `BurstOrchestrator`

Le mode Burst est un m√©canisme d'acc√©l√©ration pour le traitement de gros volumes de documents. Il provisionne dynamiquement une instance EC2 Spot avec GPU pour ex√©cuter les mod√®les LLM et d'embeddings localement, r√©duisant les co√ªts API.

#### 16.6.1 Architecture Burst

```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ                    Container Local                       ‚îÇ
 ‚îÇ                                                         ‚îÇ
 ‚îÇ  BurstOrchestrator                                      ‚îÇ
 ‚îÇ  ‚îú‚îÄ‚îÄ prepare_batch(document_paths)                      ‚îÇ
 ‚îÇ  ‚îú‚îÄ‚îÄ start_infrastructure()                             ‚îÇ
 ‚îÇ  ‚îÇ     ‚îú‚îÄ‚îÄ CloudFormation deploy (ou scale-up fleet)    ‚îÇ
 ‚îÇ  ‚îÇ     ‚îú‚îÄ‚îÄ Wait for instance                            ‚îÇ
 ‚îÇ  ‚îÇ     ‚îú‚îÄ‚îÄ Wait for services (healthcheck)              ‚îÇ
 ‚îÇ  ‚îÇ     ‚îî‚îÄ‚îÄ Switch providers (LLM + Embeddings)          ‚îÇ
 ‚îÇ  ‚îú‚îÄ‚îÄ process_batch(callback)                            ‚îÇ
 ‚îÇ  ‚îÇ     ‚îú‚îÄ‚îÄ Process pending documents                    ‚îÇ
 ‚îÇ  ‚îÇ     ‚îú‚îÄ‚îÄ Check Spot interruption (toutes 30s)         ‚îÇ
 ‚îÇ  ‚îÇ     ‚îî‚îÄ‚îÄ Handle interruption ‚Üí resume                 ‚îÇ
 ‚îÇ  ‚îî‚îÄ‚îÄ teardown (scale-down fleet ou delete stack)        ‚îÇ
 ‚îÇ                                                         ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                  Provider Switch
                  (activate_burst_providers)
                        ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ              Instance EC2 Spot (GPU)                     ‚îÇ
 ‚îÇ                                                         ‚îÇ
 ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
 ‚îÇ  ‚îÇ vLLM Server     ‚îÇ  ‚îÇ Embeddings Server         ‚îÇ     ‚îÇ
 ‚îÇ  ‚îÇ Qwen 2.5 7B    ‚îÇ  ‚îÇ multilingual-e5-large     ‚îÇ     ‚îÇ
 ‚îÇ  ‚îÇ Port 8000       ‚îÇ  ‚îÇ Port 8001                 ‚îÇ     ‚îÇ
 ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
 ‚îÇ                                                         ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 16.6.2 Cycle de vie du Burst

| Phase | Statut | Description |
|-------|--------|-------------|
| Pr√©paration | `PREPARING` | Validation des documents, cr√©ation de l'√©tat initial |
| Infrastructure | `REQUESTING_SPOT` ‚Üí `WAITING_CAPACITY` ‚Üí `INSTANCE_STARTING` | Provisioning EC2 via CloudFormation |
| Services | `INSTANCE_STARTING` | Healthcheck vLLM + Embeddings (polling) |
| Pr√™t | `READY` | Providers bascul√©s, pr√™t pour traitement |
| Traitement | `PROCESSING` | Documents trait√©s via callback, monitoring Spot |
| Interruption | `INTERRUPTED` ‚Üí `RESUMING` | Interruption Spot d√©tect√©e, reprise automatique |
| Termin√© | `COMPLETED` | Providers restaur√©s, infrastructure teardown |

#### 16.6.3 Gestion des interruptions Spot

Le Burst Orchestrator impl√©mente une r√©silience compl√®te aux interruptions Spot :

1. **D√©tection proactive** : `_check_for_spot_interruption()` v√©rifie le health endpoint toutes les 30 secondes
2. **Arr√™t gracieux** : `initiate_graceful_shutdown()` sauvegarde l'√©tat dans `data/burst_state/burst_state_{batch_id}.json`
3. **Reprise automatique** : Le Spot Fleet maintient `TargetCapacity=1`, une nouvelle instance est provisionn√©e automatiquement
4. **Retry limit√©** : `max_interruption_retries` contr√¥le le nombre maximum de tentatives de reprise
5. **√âtat par document** : Chaque document a un statut individuel (`pending`, `processing`, `completed`, `failed`), les documents en cours sont remis en `pending` lors d'une interruption

#### 16.6.4 Optimisations

- **Fast Start** : R√©utilisation d'un Spot Fleet existant en veille (capacity=0 ‚Üí scale up √† 1). R√©duction du temps de d√©marrage de ~5-7 min √† ~1-2 min
- **Keep Fleet** : Teardown par d√©faut r√©duit la capacity √† 0 au lieu de supprimer la stack, conservant Security Group, IAM Roles et Fleet pour le prochain batch
- **Dual Logging** : Mode optionnel qui log les r√©sultats via OpenAI ET vLLM pour comparaison de qualit√©
- **Reconnexion** : `reconnect_to_stack()` permet de reprendre apr√®s un red√©marrage container

#### 16.6.5 Configuration Burst

**Source :** `BurstConfig.from_env()` (variables d'environnement)

| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `vllm_model` | `Qwen/Qwen2.5-7B-Instruct` | Mod√®le LLM sur EC2 |
| `embeddings_model` | `intfloat/multilingual-e5-large` | Mod√®le d'embeddings |
| `spot_max_price` | `0.80` | Prix maximum Spot ($/h) |
| `vllm_port` | `8000` | Port du serveur vLLM |
| `embeddings_port` | `8001` | Port du serveur Embeddings |
| `instance_boot_timeout` | Configurable | Timeout attente instance |
| `healthcheck_interval` | Configurable | Intervalle de healthcheck |
| `healthcheck_timeout` | Configurable | Timeout par healthcheck |
| `max_interruption_retries` | Configurable | Max tentatives de reprise |

### 16.7 Jobs sp√©cialis√©s

Outre le job principal `ingest_document_v2_job`, `jobs_v2.py` expose deux jobs sp√©cialis√©s :

#### 16.7.1 `ingest_excel_job`

**Usage :** Import de Q/A RFP depuis fichier Excel
**Pipeline :** `excel_pipeline.process_excel_rfp()` ‚Äî chemin s√©par√© du pipeline V2 unifi√©
**Particularit√©s :**
- Pas d'ExtractionPipelineV2 (format Q/A structur√©)
- D√©duplication automatique apr√®s import
- Notification historique Redis avec `chunks_inserted`

#### 16.7.2 `fill_excel_job`

**Usage :** Remplissage automatique d'un Excel RFP vide
**Pipeline :** `smart_fill_excel_pipeline.main()` avec callback de progression
**Particularit√©s :**
- G√©n√®re un fichier `{stem}_{uid}_filled.xlsx` dans le r√©pertoire de pr√©sentations
- Supprime le fichier meta apr√®s traitement
- Progression UI via callback (`pipeline_progress_callback`)

### 16.8 Reprocess Batch ‚Äî Isolation dans le Worker RQ (2026-02-02)

**Fichier job :** `src/knowbase/ingestion/queue/reprocess_job.py` ‚Äî fonction `reprocess_batch_job()`
**Endpoint API :** `POST /v2/reprocess/start` (dans `src/knowbase/stratified/api/router.py`)
**Worker :** `src/knowbase/ingestion/queue/worker.py` ‚Äî SimpleWorker √©coute les queues `ingestion` + `reprocess`

#### 16.8.1 Probl√®me r√©solu

Avant le 2026-02-02, le reprocess batch utilisait `FastAPI BackgroundTasks` dans le m√™me process Uvicorn que l'API. Les appels LLM bloquants + Neo4j + Qdrant saturaient les threads, rendant l'API totalement unresponsive pendant 30-120 minutes.

#### 16.8.2 Architecture actuelle

```
POST /v2/reprocess/start
  ‚Üí Validation + liste des documents depuis cache
  ‚Üí Initialise l'√©tat dans Redis (cl√© osmose:v2:reprocess:state)
  ‚Üí Enqueue dans la queue RQ "reprocess" (job_timeout=7200s)
  ‚Üí Retourne imm√©diatement (API libre)

Worker RQ (knowbase-worker, SimpleWorker):
  ‚Üí √âcoute les queues: ["ingestion", "reprocess"]
  ‚Üí Ex√©cute reprocess_batch_job() s√©quentiellement
  ‚Üí Tracking de progression via Redis (cross-container)
```

#### 16.8.3 Job `reprocess_batch_job()`

**Arguments s√©rialisables (pas d'objets Pydantic) :**

| Argument | Type | Description |
|----------|------|-------------|
| `documents` | `List[dict]` | Liste de dicts `{document_id, cache_path, ...}` |
| `run_pass1` | `bool` | Ex√©cuter Pass 1 |
| `run_pass2` | `bool` | Ex√©cuter Pass 2 |
| `run_pass3` | `bool` | Ex√©cuter Pass 3 (consolidation) |
| `tenant_id` | `str` | Tenant ID |

**S√©quence par document :**

1. `LOADING_CACHE` ‚Äî Charge le Pass0Result depuis le cache d'extraction
2. `PERSIST_PASS0` ‚Äî Persiste Pass 0 dans Neo4j (Document, Section, DocItem)
3. `LAYER_R_UPSERT` ou `LAYER_R_RECOMPUTE` ‚Äî Upsert des sub-chunks dans Qdrant (knowbase_chunks_v2)
4. `PASS_1` ‚Äî Lecture Stratifi√©e (V2.1 ou V2.2 selon feature flag)
5. `PASS_2` ‚Äî Enrichissement s√©mantique (relations inter-concepts)
6. `PASS_3` ‚Äî Consolidation corpus (si demand√©)

**Tracking de progression :**
- Redis cl√© `osmose:v2:reprocess:state` (TTL 1h)
- Polled par `GET /v2/reprocess/status` (non-bloquant)
- Annulation via `POST /v2/reprocess/cancel` (√©crit `status=cancelled` dans Redis, v√©rifi√© √† chaque document)

**Ce qui ne change pas :** Les endpoints status/cancel lisent/√©crivent Redis directement, fonctionnant cross-container sans modification.

### 16.9 Conformit√© ADR ‚Äî Orchestration

| # | Axe ADR | Statut | D√©tail |
|---|---------|--------|--------|
| AV2-5 | Pipeline V2 coexiste avec legacy | ‚úÖ | Le dispatcher a √©t√© simplifi√© : legacy V1 supprim√© (cleanup 2025-01-05). Tous les formats passent par V2. |
| AV2-8 | Dual storage (Neo4j + Qdrant) | ‚úÖ | Le job V2 orchestre extraction ‚Üí OSMOSE Agentique, qui persiste dans les deux stores. |
| AV2-9 | Pass 3 mode manuel + batch | ‚úÖ | Pass 3 n'est pas inline dans le job principal ‚Äî ex√©cut√©e via `enabled_phases` en mode background/scheduled. |
| NS-2 | LLM = Extracteur evidence-locked | ‚ö†Ô∏è | Le mode Burst permet d'utiliser un mod√®le local (Qwen 2.5 7B) potentiellement moins strict que les mod√®les cloud. La qualit√© doit √™tre valid√©e. |
| ‚Äî | Reprocess isol√© du process API | ‚úÖ | Le reprocess batch est ex√©cut√© dans le worker RQ d√©di√© (queue `reprocess`), lib√©rant l'API. (2026-02-02) |

### 16.10 Risques ‚Äî Orchestration

| ID | Risque | S√©v√©rit√© | Description | Mitigation |
|----|--------|----------|-------------|------------|
| RO-1 | **`asyncio.run()` dans job synchrone** | üü° | `ingest_document_v2_job` est une fonction synchrone qui appelle `asyncio.run()` deux fois (extraction puis OSMOSE). Si un event loop est d√©j√† actif dans le worker, cela l√®vera une `RuntimeError`. | Les workers RQ sont des processus isol√©s sans event loop pr√©-existant. Le risque n'existe que si le worker est int√©gr√© dans un contexte async (ex: tests pytest-asyncio). |
| RO-2 | **Rollback partiel possible** | üü° | `delete_import_completely(job.id)` tente de supprimer les chunks Qdrant mais si le rollback √©choue lui-m√™me, des donn√©es partielles persistent sans signalement clair (simple `logger.error`). | Monitoring des logs d'erreur de rollback. Un m√©canisme de garbage collection p√©riodique pourrait d√©tecter les documents partiels. |
| RO-3 | **Burst Mode ‚Äî mod√®le local vs cloud** | üü° | Le Qwen 2.5 7B instruct utilis√© en mode Burst peut produire des r√©sultats de qualit√© inf√©rieure aux mod√®les cloud (GPT-4o, Claude) pour les t√¢ches d'extraction fine (assertions, concepts). | Le mode dual-logging permet la comparaison qualitative. Les gardes de frugalit√© et la validation verbatim restent actifs quel que soit le mod√®le. |
| RO-4 | **Spot interruption pendant √©criture Neo4j** | üü° | Si une interruption Spot survient pendant la persistance Neo4j d'un document, les donn√©es peuvent √™tre dans un √©tat incoh√©rent (n≈ìuds cr√©√©s sans relations, ou inversement). | La reprise remet le document en `pending`. Le retraitement complet cr√©e les n≈ìuds avec `MERGE` (idempotent). Les donn√©es orphelines sont tol√©r√©es. |
| RO-5 | **Excel pas dans ExtractionPipelineV2** | üü¢ | L'ingestion Excel utilise toujours un pipeline s√©par√© (`excel_pipeline`). Le format Q/A structur√© ne b√©n√©ficie pas des am√©liorations Vision/Docling. | Le format Q/A Excel est structur√© par nature (colonnes = champs). L'extraction visuelle n'apporte pas de valeur ajout√©e. |
| RO-6 | **Watcher sans retry** | üü¢ | Si l'enqueue √©choue (Redis indisponible), le watcher ne r√©essaye pas. Le fichier reste dans `docs_in/` sans √™tre trait√©. | L'utilisateur peut relancer manuellement via l'API. Le monitoring Docker d√©tecte les services indisponibles. |

---

## 17. Mod√®le de donn√©es complet

Le mod√®le de donn√©es complet Neo4j V2 est document√© dans les sections par phase. Synth√®se des types de n≈ìuds :

| Type de n≈ìud | Phase de cr√©ation | Description | Propri√©t√©s cl√©s |
|--------------|------------------|-------------|-----------------|
| `Document` | Pass 0 Structural | Document source | `document_id`, `title`, `doc_hash`, `tenant_id` |
| `Section` | Pass 0 Structural | Section hi√©rarchique | `section_id`, `heading`, `level`, `path` |
| `DocItem` | Pass 0 Structural | Item atomique Docling | `item_id`, `type`, `text_preview`, `page` |
| `Subject` | Pass 1.1 | Sujet central du document | `subject_id`, `name`, `structure_type` |
| `Theme` | Pass 1.1 | Th√®me identifi√© | `theme_id`, `name`, `description` |
| `Concept` | Pass 1.2 | Concept situ√© frugal | `concept_id`, `name`, `triggers`, `lex_key` |
| `Information` | Pass 1.4 | Assertion promue | `info_id`, `claim`, `exact_quote`, `claimkey_id` |
| `AssertionLog` | Pass 1.4 | Log de d√©cision promotion | `assertion_id`, `status`, `reason` |
| `CanonicalConcept` | Pass 3 | Concept canonique (corpus-level) | `canonical_id`, `name`, `merged_from` |
| `CanonicalTheme` | Pass 3 | Th√®me canonique (corpus-level) | `canonical_id`, `name` |

**Total types :** 10 (vs 8 pr√©vus par AV2-2 ‚Äî les 2 suppl√©mentaires sont des superpositions corpus-level).

---

## 18. Synth√®se globale des risques

Cette section r√©capitule **tous les risques** identifi√©s dans les phases pr√©c√©dentes, consolid√©s et prioris√©s par gravit√©.

### 18.1 Risques critiques (üî¥)

| ID | Phase | Risque | Plan d'action |
|----|-------|--------|---------------|
| R13-6 | Pass 1.3 (Extraction assertions) | **Fallback heuristique en production** ‚Äî Si `allow_fallback=True`, assertions heuristiques (confiance 0.5, types approximatifs) polluent le graphe | V√©rifier que `allow_fallback=False` en production. Ajouter un check au d√©marrage du worker. |
| R3-7 | Pass 3 (Consolidation) | **D√©tecteur de contradictions non impl√©ment√©** ‚Äî Le mod√®le Contradiction est d√©fini (6 natures, 4 niveaux) mais aucun composant ne l'instancie. Objectif cl√© du MVP V1 Usage B. | Impl√©menter `ContradictionDetector` : parcours Informations par ClaimKey, comparaison Value Contracts normalis√©s, cr√©ation n≈ìuds Contradiction. **Priorit√© haute MVP.** |

### 18.2 Risques mod√©r√©s (üü°)

| ID | Phase | Risque | Plan d'action |
|----|-------|--------|---------------|
| R0-1 | Pass 0 (Extraction) | Shapes vectoriels non d√©tect√©s | Phase 2.6 ‚Äî Fallback VDS √† impl√©menter |
| R0-4 | Pass 0 (Extraction) | Seuils de gating non calibr√©s | Phase 7 ‚Äî Calibration sur corpus r√©el |
| R0-5 | Pass 0 (Extraction) | Table Summarizer ‚Äî hallucination LLM | Monitoring + validation manuelle des r√©sum√©s table |
| R0-6 | Pass 0 (Extraction) | DocContext faux positifs r√©siduels | Principe safe-by-default actif ‚Äî monitoring |
| R0S-2 | Pass 0 Structural | DocItems tr√®s nombreux (>6700 observ√©s) | Lazy persistence activ√©e (~50-200 DocItems en Neo4j) |
| R0S-4 | Pass 0 Structural | Cache v5 ‚Äî Sections non s√©rialis√©es | Re-build complet si sections critiques |
| R0S-6 | Pass 0 Structural | Deux sch√©mas Neo4j coexistants (legacy + V2) | Retrait code legacy apr√®s validation V2 |
| R05-1 | Pass 0.5 (Cor√©f√©rence) | D√©sactiv√©e en V2 ‚Äî pronoms non r√©solus | Refonte cor√©f√©rence V2 √† concevoir |
| R05-2 | Pass 0.5 (Cor√©f√©rence) | OOM FastCoref sur gros documents | Section batching avec overlap 3K chars |
| R05-3 | Pass 0.5 (Cor√©f√©rence) | Coreferee obsol√®te (dernier release 2022) | Swappable via interface ICorefEngine |
| R05-4 | Pass 0.5 (Cor√©f√©rence) | Offset lookup simpliste (TODO) | Non impactant en V2 (d√©sactiv√©) |
| R05-6 | Pass 0.5 (Cor√©f√©rence) | Pas d'int√©gration avec Pass 1.x | Pipeline V2 g√®re diff√©remment |
| R09-1 | Pass 0.9 (Global View) | Mode sync = toujours fallback (troncature) | Refactorer vers `build()` async |
| R09-2 | Pass 0.9 (Global View) | Pas de gestion budget tokens | Ajouter tiktoken ou r√©duire limite chars |
| R09-4 | Pass 0.9 (Global View) | D√©tection format r√©ponse LLM fragile | Fallback extraction garantit un r√©sum√© |
| R09-6 | Pass 0.9 (Global View) | Pas de cache des r√©sum√©s | Ajouter cache bas√© sur hash(section_text) |
| R11-1 | Pass 1.1 (Analyse doc) | Preview tronqu√© √† 4000 chars | Compens√© par meta-document Pass 0.9 |
| R11-3 | Pass 1.1 (Analyse doc) | Pas de validation crois√©e structure/contenu | Audit humain via champ justification |
| R11-5 | Pass 1.1 (Analyse doc) | Pas de d√©tection de langue robuste | Risque faible ‚Äî langues connues |
| R12-1 | Pass 1.2 (Concepts) | Budget √©tendu [20-40] vs frugalit√© ADR [5-15] | Croissance sub-lin√©aire + cap 50 |
| R12-2 | Pass 1.2 (Concepts) | Troncature JSON (LLM Contract) | D√©tection explicite + Structured Outputs |
| R12-3 | Pass 1.2 (Concepts) | Triggers trop permissifs petits documents | Fallback semi-rare et value patterns |
| R12-4 | Pass 1.2 (Concepts) | Pass 1.2b concepts de faible valeur | Crit√®re C2 + rendement d√©croissant |
| R13-1 | Pass 1.3 (Assertions) | Reformulation LLM (mode classique) | Mode pointer √©limine le risque |
| R13-2 | Pass 1.3 (Assertions) | Coexistence deux modes d'extraction | Convergence progressive vers pointer |
| R13-3 | Pass 1.3 (Assertions) | Seuil lexical Pointer Validator strict | Score value pattern compense |
| R14-1 | Pass 1.4 (Promotion) | ClaimKey Niveau B (LLM) absent | 15 patterns regex couvrent domaines fr√©quents |
| R14-2 | Pass 1.4 (Promotion) | Coexistence PromotionEngine V2 / PromotionPolicy MVP V1 | Convergence planifi√©e fin MVP |
| R14-3 | Pass 1.4 (Promotion) | Addressability non stricte (PROMOTED_UNLINKED) | Information-First prime + Pass 1.2b r√©cup√®re |
| R14-5 | Pass 1.4 (Promotion) | Fingerprint sensible au claimkey_id | Pass 3 = d√©duplication de second niveau |
| R2-1 | Pass 2 (Relations) | Label g√©n√©rique `CONCEPT_RELATION` | Migration labels dynamiques APOC si besoin |
| R2-2 | Pass 2 (Relations) | Garde-fou √† 3 relations arbitraire | Constante ajustable + monitoring filtrage |
| R2-3 | Pass 2 (Relations) | Heuristique de fallback peu fiable | D√©sactiv√© par d√©faut |
| R2-4 | Pass 2 (Relations) | Pas de distinction Scope vs Assertion | Taguer assertion_kind ‚Äî non bloquant MVP |
| R2-5 | Pass 2 (Relations) | Absence DefensibilityTier / EvidenceBundle | Objectif architectural ‚Äî MVP fonctionnel |
| R3-1 | Pass 3 (Consolidation) | Clustering par lex_key uniquement ‚Äî pas d'embeddings | Impl√©menter cosine similarity (param√©trage en place) |
| R3-3 | Pass 3 (Consolidation) | Pas de purge avant retraitement batch | Ajouter `delete_pass3_data()` ‚Äî **critique production** |
| R3-4 | Pass 3 (Consolidation) | Clustering th√®mes trop strict | Aligner sur strat√©gie concepts |
| R3-5 | Pass 3 (Consolidation) | Mode incr√©mental ne cr√©e jamais de canoniques | Ex√©cution batch p√©riodique requise |
| R3-8 | Pass 3 (Consolidation) | Pas de validation LLM cas ambigus | Impl√©menter validation (param√©trage en place) |
| RO-1 | Orchestration | `asyncio.run()` dans job synchrone | Workers RQ = processus isol√©s |
| RO-2 | Orchestration | Rollback partiel possible | Monitoring + garbage collection |
| RO-3 | Orchestration | Burst Mode ‚Äî mod√®le local vs cloud | Dual-logging + gardes de frugalit√© |
| RO-4 | Orchestration | Spot interruption pendant √©criture Neo4j | MERGE idempotent + retraitement complet |

### 18.3 Risques faibles (üü¢)

| ID | Phase | Risque |
|----|-------|--------|
| R0-2 | Pass 0 | Concurrence Vision non born√©e ‚Äî semaphore att√©nue |
| R0-3 | Pass 0 | Cache version mismatch ‚Äî invalidation automatique |
| R0-7 | Pass 0 | VisionSemanticReader placeholder ‚Äî fallback 3-tier |
| R0S-3 | Pass 0 Structural | Chunks NARRATIVE trop longs ‚Äî seuil 3000 chars configurable |
| R0S-5 | Pass 0 Structural | AssertionUnitIndexer import lazy ‚Äî log warning √©mis |
| R0S-7 | Pass 0 Structural | Hash de document non d√©terministe ‚Äî versionn√© v1: |
| R05-5 | Pass 0.5 | Named‚ÜîNamed gating faux rejets ‚Äî LLM Arbiter |
| R09-3 | Pass 0.9 | Perte info sections skip ‚Äî impact mineur |
| R09-5 | Pass 0.9 | Mod√®le LLM hardcod√© ‚Äî acceptable beta |
| R09-7 | Pass 0.9 | Fourchette taille plus large que ADR ‚Äî pragmatique |
| R11-2 | Pass 1.1 | Seuil HOSTILE fixe ‚Äî impact mineur |
| R11-4 | Pass 1.1 | Fallback analyse = donn√©es non fiables ‚Äî RuntimeError en prod |
| R12-5 | Pass 1.2 | Doublons LLM/raffinement ‚Äî d√©duplication impl√©ment√©e |
| R12-6 | Pass 1.2 | Pas de trigger_enricher s√©par√© ‚Äî fonctionnel en l'√©tat |
| R12-7 | Pass 1.2 | Nettoyage JSON fragile ‚Äî Structured Outputs √©limine |
| R13-4 | Pass 1.3 | Spray & Pray ‚Äî hard gate + soft gate + cap 5 |
| R13-5 | Pass 1.3 | Troncature texte 2000 chars ‚Äî d√©tectable |
| R13-7 | Pass 1.3 | Pr√©-filtres m√©ta-descriptions ‚Äî patterns EN+FR |
| R14-4 | Pass 1.4 | Theme Lint non impl√©ment√© ‚Äî post-MVP |
| R14-6 | Pass 1.4 | D√©tection fragments verbes connus ‚Äî extension multilingue possible |
| R14-7 | Pass 1.4 | Value Extractor limit√© 5 types ‚Äî couvre cas fr√©quents |
| R14-8 | Pass 1.4 | Patterns META YAML ‚Äî fallback 7 patterns minimal |
| R2-6 | Pass 2 | Pas de d√©duplication relations ‚Äî MERGE + purge |
| R2-7 | Pass 2 | Persistance relation par relation ‚Äî non critique MVP |
| R3-2 | Pass 3 | Nom repr√©sentatif arbitraire ‚Äî acceptable MVP |
| R3-6 | Pass 3 | Persistance relation par relation ‚Äî UNWIND possible |
| RO-5 | Orchestration | Excel pas dans ExtractionPipelineV2 ‚Äî Q/A structur√© |
| RO-6 | Orchestration | Watcher sans retry ‚Äî relance manuelle API |

### 18.4 Avertissements architecturaux (‚ö†Ô∏è)

| ID | Phase | Risque |
|----|-------|--------|
| R0-8 | Pass 0/0.5 | Pass 0.5 d√©sactiv√©e en mode V2 ‚Äî d√©cision architecturale consciente |

### 18.5 Statistiques consolid√©es

| S√©v√©rit√© | Nombre | Pourcentage |
|----------|--------|-------------|
| üî¥ Critique | 2 | 3% |
| üü° Mod√©r√© | 35 | 53% |
| üü¢ Faible | 28 | 42% |
| ‚ö†Ô∏è Architectural | 1 | 2% |
| **Total** | **66** | **100%** |

**Top 5 des actions prioritaires :**

1. **üî¥ R3-7** ‚Äî Impl√©menter le `ContradictionDetector` (MVP V1 Usage B)
2. **üî¥ R13-6** ‚Äî V√©rifier `allow_fallback=False` en production (check au d√©marrage)
3. **üü° R3-3** ‚Äî Ajouter `delete_pass3_data()` pour purge avant retraitement (critique production)
4. **üü° R3-1** ‚Äî Impl√©menter le clustering par embeddings (cosine similarity) pour Pass 3
5. **üü° R05-1** ‚Äî Concevoir la cor√©f√©rence V2 pour le pipeline stratifi√©

---

## 19. Diagramme d'architecture global

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    OSMOSIS Pipeline V2 ‚Äî Architecture Globale                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                                 ‚ïë
‚ïë  POINTS D'ENTR√âE                                                                ‚ïë
‚ïë  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                                ‚ïë
‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚ïë
‚ïë  ‚îÇ API Upload   ‚îÇ  ‚îÇ Folder       ‚îÇ                                             ‚ïë
‚ïë  ‚îÇ (FastAPI)    ‚îÇ  ‚îÇ Watcher      ‚îÇ                                             ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚ïë
‚ïë         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                    ‚ïë
‚ïë                  ‚ñº                                                              ‚ïë
‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚ïë
‚ïë  ‚îÇ Dispatcher (dispatcher.py)‚îÇ    ‚îÇ Redis Queue (RQ)                     ‚îÇ       ‚ïë
‚ïë  ‚îÇ enqueue_document_v2()     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ knowbase queue                       ‚îÇ       ‚ïë
‚ïë  ‚îÇ enqueue_excel_ingestion() ‚îÇ    ‚îÇ DEFAULT_JOB_TIMEOUT configurable     ‚îÇ       ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚ïë
‚ïë                                                    ‚ñº                            ‚ïë
‚ïë  PIPELINE D'INGESTION (jobs_v2.py ‚Äî RQ Worker)                                  ‚ïë
‚ïë  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                   ‚ïë
‚ïë                                                                                 ‚ïë
‚ïë  ‚îå‚îÄ Pass 0 ‚Äî EXTRACTION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Docling ‚îÄ‚îÄ‚ñ∂ Vision Gating V4 ‚îÄ‚îÄ‚ñ∂ GPT-4o Vision ‚îÄ‚îÄ‚ñ∂ Merge ‚îÄ‚îÄ‚ñ∂ Linearize   ‚îÇ  ‚ïë
‚ïë  ‚îÇ                   ‚îÇ                                                        ‚îÇ  ‚ïë
‚ïë  ‚îÇ              Feature Signals                                               ‚îÇ  ‚ïë
‚ïë  ‚îÇ              (TFS, SDS, VDS, DPS, TVR)                                     ‚îÇ  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  + DocContext Extraction    + Table Summarizer    + Cache Versionn√© (v5)    ‚îÇ  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë
‚ïë                                     ‚ñº                                           ‚ïë
‚ïë  ‚îå‚îÄ Pass 0 Structural ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚ïë
‚ïë  ‚îÇ  Document ‚îÄ‚îÄ‚ñ∂ Section (hi√©rarchie H1-H6) ‚îÄ‚îÄ‚ñ∂ DocItem (atomique)         ‚îÇ    ‚ïë
‚ïë  ‚îÇ  + TypeAwareChunks ‚îÄ‚îÄ‚ñ∂ Qdrant (knowwhere_proto)                         ‚îÇ    ‚ïë
‚ïë  ‚îÇ  + AssertionUnit Indexer                                                 ‚îÇ    ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ïë
‚ïë                                     ‚ñº                                           ‚ïë
‚ïë  ‚îå‚îÄ Pass 0.9 ‚Äî GLOBAL VIEW ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚ïë
‚ïë  ‚îÇ  Section Summaries (LLM/fallback) ‚îÄ‚îÄ‚ñ∂ Meta-Document (15-25K chars)      ‚îÇ    ‚ïë
‚ïë  ‚îÇ  + TOC enrichie + Section hierarchy + Coverage metrics                   ‚îÇ    ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ïë
‚ïë                                     ‚ñº                                           ‚ïë
‚ïë  ‚îå‚îÄ Pass 1 ‚Äî LECTURE STRATIFI√âE (Top-Down) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Pass 1.1: Document Analysis ‚îÄ‚îÄ‚ñ∂ Subject + Themes + Structure Type         ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚îÇ                                                                    ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚ñº                                                                    ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Pass 1.2: Concept Identification ‚îÄ‚îÄ‚ñ∂ 5-50 ConceptSitu√©s frugaux           ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚îÇ         + Pass 1.2b Refinement (it√©ratif)                          ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚ñº                                                                    ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Pass 1.3: Assertion Extraction ‚îÄ‚îÄ‚ñ∂ RawAssertions (verbatim + span)        ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚îÇ         + Mode Pointer (unit ‚Üí concept ‚Üí assertion)                ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚îÇ         + Pass 1.3b Anchor Resolution (assertion ‚Üí DocItem)        ‚îÇ  ‚ïë
‚ïë  ‚îÇ       ‚ñº                                                                    ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Pass 1.4: Promotion + Linking ‚îÄ‚îÄ‚ñ∂ Information PROMOTED                    ‚îÇ  ‚ïë
‚ïë  ‚îÇ                + Value Contract + ClaimKey + Fingerprint Dedup              ‚îÇ  ‚ïë
‚ïë  ‚îÇ                + AssertionLog (PROMOTED | ABSTAINED | REJECTED)             ‚îÇ  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë
‚ïë                                     ‚ñº                                           ‚ïë
‚ïë  ‚îå‚îÄ Pass 2 ‚Äî ENRICHISSEMENT (mode: background | inline | scheduled) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  2.0: Corpus Promotion      ‚îÄ‚îÄ‚ñ∂ ProtoConcept ‚Üí CanonicalConcept            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  2a:  Structural Topics     ‚îÄ‚îÄ‚ñ∂ HAS_TOPIC + COVERS relations               ‚îÇ  ‚ïë
‚ïë  ‚îÇ  2b-1: Classification fine  ‚îÄ‚îÄ‚ñ∂ Concept types enrichis                     ‚îÇ  ‚ïë
‚ïë  ‚îÇ  2b-2: Relations ADR        ‚îÄ‚îÄ‚ñ∂ CONCEPT_RELATION (segment-first)           ‚îÇ  ‚ïë
‚ïë  ‚îÇ  2c:  Normative Extraction  ‚îÄ‚îÄ‚ñ∂ NormativeRule + SpecFact                   ‚îÇ  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë
‚ïë                                     ‚ñº                                           ‚ïë
‚ïë  ‚îå‚îÄ Pass 3 ‚Äî CONSOLIDATION CORPUS (batch | incr√©mental) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Entity Resolution (lex_key + variantes) ‚îÄ‚îÄ‚ñ∂ CanonicalConcept (SAME_AS)    ‚îÇ  ‚ïë
‚ïë  ‚îÇ  Theme Alignment (nom normalis√©)          ‚îÄ‚îÄ‚ñ∂ CanonicalTheme (ALIGNED_TO)  ‚îÇ  ‚ïë
‚ïë  ‚îÇ  [√Ä impl√©menter: ContradictionDetector via ClaimKey + Value Contract]       ‚îÇ  ‚ïë
‚ïë  ‚îÇ                                                                            ‚îÇ  ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë
‚ïë                                                                                 ‚ïë
‚ïë  STOCKAGE DUAL                                                                  ‚ïë
‚ïë  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                                  ‚ïë
‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚ïë
‚ïë  ‚îÇ Neo4j                  ‚îÇ    ‚îÇ Qdrant                                     ‚îÇ    ‚ïë
‚ïë  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                  ‚îÇ    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                     ‚îÇ    ‚ïë
‚ïë  ‚îÇ Document, Section,     ‚îÇ    ‚îÇ Collection: knowwhere_proto                ‚îÇ    ‚ïë
‚ïë  ‚îÇ DocItem, Subject,      ‚îÇ    ‚îÇ TypeAwareChunks (NARRATIVE, TABLE,         ‚îÇ    ‚ïë
‚ïë  ‚îÇ Theme, Concept,        ‚îÇ    ‚îÇ KEY_VALUE, VISUAL, HEADING, LIST)          ‚îÇ    ‚ïë
‚ïë  ‚îÇ Information,           ‚îÇ    ‚îÇ Payload: anchored_concepts, metadata       ‚îÇ    ‚ïë
‚ïë  ‚îÇ AssertionLog,          ‚îÇ    ‚îÇ                                            ‚îÇ    ‚ïë
‚ïë  ‚îÇ CanonicalConcept,      ‚îÇ    ‚îÇ Collection: rfp_qa                        ‚îÇ    ‚ïë
‚ïë  ‚îÇ CanonicalTheme         ‚îÇ    ‚îÇ Q/A RFP (pipeline s√©par√©)                 ‚îÇ    ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ïë
‚ïë                                                                                 ‚ïë
‚ïë  MODE BURST (optionnel)                                                         ‚ïë
‚ïë  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                         ‚ïë
‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë
‚ïë  ‚îÇ EC2 Spot (GPU) ‚Äî CloudFormation managed                                   ‚îÇ  ‚ïë
‚ïë  ‚îÇ vLLM: Qwen 2.5 7B Instruct (:8000) + Embeddings: e5-large (:8001)        ‚îÇ  ‚ïë
‚ïë  ‚îÇ Provider switch transparent + Spot interruption resilience                ‚îÇ  ‚ïë
‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë
‚ïë                                                                                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

---

## 20. Conclusion

### 20.1 Synth√®se

Ce document constitue la **documentation technique exhaustive** du Pipeline d'Ingestion V2 d'OSMOSIS, couvrant les 11 passes du pipeline stratifi√©, de l'extraction brute (Pass 0) √† la consolidation corpus (Pass 3), en passant par l'orchestration, le mode Burst et la gestion des jobs.

**Chiffres cl√©s :**

| M√©trique | Valeur |
|----------|--------|
| Passes document√©es | 11 (Pass 0 ‚Üí Pass 3, incluant sous-passes) |
| Fichiers source analys√©s | ~30 modules Python |
| Types de n≈ìuds Neo4j | 10 (vs 8 pr√©vus par ADR ‚Äî 2 corpus-level ajout√©s) |
| Nodes estim√©s par document | ~195 (vs ~4700 legacy ‚Äî r√©duction 96%) |
| Risques identifi√©s | 66 (2 critiques, 35 mod√©r√©s, 28 faibles, 1 architectural) |
| ADR de r√©f√©rence | 8 documents normatifs |
| Axes de v√©rification appliqu√©s | 28+ axes syst√©matiquement v√©rifi√©s |

### 20.2 Maturit√© du pipeline

Le Pipeline V2 est **fonctionnel et op√©rationnel** pour l'ingestion de documents (PDF, PPTX, DOCX). Les principales r√©alisations :

- ‚úÖ **Extraction V2** unifi√©e (Docling + Vision Gating V4) avec cache versionn√©
- ‚úÖ **Lecture stratifi√©e** top-down (Document Analysis ‚Üí Concepts ‚Üí Assertions ‚Üí Promotion)
- ‚úÖ **Dual storage** Neo4j + Qdrant op√©rationnel
- ‚úÖ **Frugalit√©** : ~195 nodes/doc vs ~4700 legacy
- ‚úÖ **Promotion Policy** avec AssertionLog tra√ßable
- ‚úÖ **Mode Burst** EC2 Spot avec r√©silience aux interruptions
- ‚úÖ **Pass 2 en mode background** avec phases activables individuellement

### 20.3 Points d'attention prioritaires

1. **D√©tection de contradictions** (R3-7) ‚Äî Composant cl√© du MVP V1 Usage B non impl√©ment√©
2. **Cor√©f√©rence V2** (R05-1) ‚Äî Pronoms non r√©solus dans le pipeline V2
3. **Purge Pass 3** (R3-3) ‚Äî Risque de donn√©es obsol√®tes en production
4. **Clustering s√©mantique** (R3-1) ‚Äî Embeddings non utilis√©s dans la r√©solution d'entit√©s
5. **ClaimKey Niveau B** (R14-1) ‚Äî LLM assist√© pour couverture ClaimKey √©tendue

### 20.4 Prochaines √©tapes

- **MVP V1 Usage B** : Impl√©menter ContradictionDetector, valider le flux Challenge de Texte
- **Calibration** : Valider les seuils de gating (Phase 7) sur corpus r√©el client
- **Convergence** : Retirer le code legacy (sch√©ma Neo4j V1, PromotionPolicy V1)
- **Performance** : Batch UNWIND pour persistance Neo4j, cache r√©sum√©s Pass 0.9
- **Qualit√©** : Validation LLM pour clustering ambigus (Pass 3), cor√©f√©rence V2
