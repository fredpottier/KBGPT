# üöÄ Impact du Context Caching Gemini sur les Co√ªts OSMOSE

**Date** : 2025-11-22
**Source** : [Gemini Context Caching Documentation](https://ai.google.dev/gemini-api/docs/caching?hl=fr&lang=python)

---

## üìä Principe du Context Caching

### Fonctionnement

Le Context Caching de Gemini permet de **mettre en cache une partie du contexte** (prompts syst√®me, contexte partag√©) et de le r√©utiliser pour plusieurs requ√™tes avec une **r√©duction de 75% du co√ªt des tokens cach√©s**.

### Tarification Cached vs Normal

| Mod√®le | Input Normal ($/1M) | Input Cached ($/1M) | R√©duction |
|--------|---------------------|---------------------|-----------|
| gemini-1.5-flash | $0.075 | $0.01875 | **-75%** |
| gemini-1.5-flash-8b | $0.0375 | $0.01 | **-73.3%** |
| gemini-1.5-pro | $1.25 | $0.3125 | **-75%** |

### Co√ªt du Stockage Cache

- **Storage** : $1.00 par 1M tokens par heure
- **Minimum TTL** : 5 minutes (gratuit)
- **Maximum TTL** : 24 heures

**Important** : Le cache est gratuit pendant les 5 premi√®res minutes, puis $1/1M tokens/heure ensuite.

---

## üéØ Opportunit√©s de Caching dans OSMOSE

### 1. Prompts Syst√®me R√©utilis√©s

**Contexte partag√© entre toutes les slides d'un document** :

| √âl√©ment √† cacher | Taille estim√©e | R√©utilisations |
|------------------|----------------|----------------|
| **Prompt syst√®me** | ~500 tokens | 230 slides (1 doc) |
| **Deck summary** | ~300 tokens | 230 slides |
| **Document context prompt** | ~200 tokens | 230 slides |
| **Instructions format JSON** | ~150 tokens | 230 slides |
| **TOTAL cacheable** | **~1,150 tokens** | **230√ó par doc** |

### 2. Sc√©narios d'Usage

#### Sc√©nario A : Concept Extraction
- **Appels** : 1,000 par document
- **Tokens cacheable** : ~400 tokens (prompt syst√®me + instructions JSON)
- **R√©utilisations** : 1,000 appels

#### Sc√©nario B : Vision Summary
- **Appels** : 230 par document (1 par slide)
- **Tokens cacheable** : ~800 tokens (syst√®me + deck_summary)
- **R√©utilisations** : 230 appels

#### Sc√©nario C : Vision Analysis
- **Appels** : 230 par document
- **Tokens cacheable** : ~1,000 tokens (syst√®me + deck_summary + format)
- **R√©utilisations** : 230 appels

---

## üí∞ CALCUL D'IMPACT - Concept Extraction

### Configuration
- **Mod√®le** : gemini-1.5-flash-8b
- **Appels par doc** : 1,000
- **Tokens IN moyens** : 622 tokens
- **Tokens cacheable** : 400 tokens (prompt syst√®me + instructions)

### Sans Context Caching

**Co√ªt actuel Gemini** :
- Total tokens input : 1,000 √ó 622 = 622,000 tokens
- Co√ªt : 622,000 √ó $0.0375 / 1M = **$0.0233** par document

### Avec Context Caching

**D√©composition** :
- Tokens cach√©s : 400 tokens √ó 1,000 appels = 400,000 tokens
- Tokens non cach√©s : (622 - 400) √ó 1,000 = 222,000 tokens

**Co√ªt tokens** :
- Cached : 400,000 √ó $0.01 / 1M = $0.0040
- Non-cached : 222,000 √ó $0.0375 / 1M = $0.0083
- **Sous-total tokens : $0.0123**

**Co√ªt stockage cache** :
- Dur√©e traitement : ~10 minutes pour 1,000 appels
- Storage : 400 tokens √ó 10 min / 60 min √ó $1.00 / 1M = $0.0000067 (n√©gligeable)

**Total avec caching : $0.0123**

### ROI

| M√©trique | Sans Cache | Avec Cache | √âconomie |
|----------|------------|------------|----------|
| **Co√ªt/doc** | $0.0233 | $0.0123 | **-$0.0110 (-47%)** |
| **Co√ªt/100 docs** | $2.33 | $1.23 | **-$1.10** |
| **Co√ªt/1000 docs** | $23.30 | $12.30 | **-$11.00** |

---

## üí∞ CALCUL D'IMPACT - Vision Summary

### Configuration
- **Mod√®le** : gemini-1.5-flash
- **Appels par doc** : 230 slides
- **Tokens IN estim√©s** : 2,300 tokens
- **Tokens cacheable** : 800 tokens (syst√®me + deck_summary)

### Sans Context Caching

**Co√ªt actuel Gemini** :
- Total tokens input : 230 √ó 2,300 = 529,000 tokens
- Co√ªt : 529,000 √ó $0.075 / 1M = **$0.0397** par document

### Avec Context Caching

**D√©composition** :
- Tokens cach√©s : 800 tokens √ó 230 appels = 184,000 tokens
- Tokens non cach√©s : (2,300 - 800) √ó 230 = 345,000 tokens

**Co√ªt tokens** :
- Cached : 184,000 √ó $0.01875 / 1M = $0.0035
- Non-cached : 345,000 √ó $0.075 / 1M = $0.0259
- **Sous-total tokens : $0.0294**

**Co√ªt stockage cache** :
- Dur√©e traitement : ~15 minutes pour 230 slides
- Storage : 800 tokens √ó 15 min / 60 min √ó $1.00 / 1M = $0.000020 (n√©gligeable)

**Total avec caching : $0.0294**

### ROI

| M√©trique | Sans Cache | Avec Cache | √âconomie |
|----------|------------|------------|----------|
| **Co√ªt/doc** | $0.0397 | $0.0294 | **-$0.0103 (-26%)** |
| **Co√ªt/100 docs** | $3.97 | $2.94 | **-$1.03** |
| **Co√ªt/1000 docs** | $39.70 | $29.40 | **-$10.30** |

---

## üí∞ CALCUL D'IMPACT - Vision Analysis (Legacy)

### Configuration
- **Mod√®le** : gemini-1.5-flash
- **Appels par doc** : 230 slides
- **Tokens IN estim√©s** : 2,500 tokens
- **Tokens cacheable** : 1,000 tokens (syst√®me + deck_summary + format JSON)

### Sans Context Caching

**Co√ªt actuel Gemini** :
- Total tokens input : 230 √ó 2,500 = 575,000 tokens
- Co√ªt : 575,000 √ó $0.075 / 1M = **$0.0431** par document

### Avec Context Caching

**D√©composition** :
- Tokens cach√©s : 1,000 tokens √ó 230 appels = 230,000 tokens
- Tokens non cach√©s : (2,500 - 1,000) √ó 230 = 345,000 tokens

**Co√ªt tokens** :
- Cached : 230,000 √ó $0.01875 / 1M = $0.0043
- Non-cached : 345,000 √ó $0.075 / 1M = $0.0259
- **Sous-total tokens : $0.0302**

**Co√ªt stockage cache** :
- Dur√©e traitement : ~20 minutes pour 230 slides
- Storage : 1,000 tokens √ó 20 min / 60 min √ó $1.00 / 1M = $0.000033 (n√©gligeable)

**Total avec caching : $0.0302**

### ROI

| M√©trique | Sans Cache | Avec Cache | √âconomie |
|----------|------------|------------|----------|
| **Co√ªt/doc** | $0.0431 | $0.0302 | **-$0.0129 (-30%)** |
| **Co√ªt/100 docs** | $4.31 | $3.02 | **-$1.29** |
| **Co√ªt/1000 docs** | $43.10 | $30.20 | **-$12.90** |

---

## üìä IMPACT GLOBAL - Tous Sc√©narios Combin√©s

### Sc√©nario OSMOSE Pure (Vision Summary + Extraction)

| Composant | Sans Cache | Avec Cache | √âconomie |
|-----------|------------|------------|----------|
| Vision Summary | $0.0397 | $0.0294 | -$0.0103 |
| Concept Extraction | $0.0233 | $0.0123 | -$0.0110 |
| **TOTAL/doc** | **$0.0630** | **$0.0417** | **-$0.0213 (-34%)** |

**Projection volum√©trique** :

| Volume | Sans Cache | Avec Cache | √âconomie |
|--------|------------|------------|----------|
| 100 docs | $6.30 | $4.17 | **-$2.13** |
| 1,000 docs | $63.00 | $41.70 | **-$21.30** |
| 5,000 docs | $315.00 | $208.50 | **-$106.50** |

### Sc√©nario Legacy (Vision Analysis + Extraction)

| Composant | Sans Cache | Avec Cache | √âconomie |
|-----------|------------|------------|----------|
| Vision Analysis | $0.0431 | $0.0302 | -$0.0129 |
| Concept Extraction | $0.0233 | $0.0123 | -$0.0110 |
| **TOTAL/doc** | **$0.0664** | **$0.0425** | **-$0.0239 (-36%)** |

**Projection volum√©trique** :

| Volume | Sans Cache | Avec Cache | √âconomie |
|--------|------------|------------|----------|
| 100 docs | $6.64 | $4.25 | **-$2.39** |
| 1,000 docs | $66.40 | $42.50 | **-$23.90** |
| 5,000 docs | $332.00 | $212.50 | **-$119.50** |

---

## üéØ COMPARAISON : OpenAI vs Gemini vs Gemini+Cache

### Sc√©nario OSMOSE Pure (par document)

| Provider | Co√ªt | vs OpenAI | vs Gemini |
|----------|------|-----------|-----------|
| **OpenAI** | $23.80 | - | - |
| **Gemini sans cache** | $5.78 | **-75.7%** | - |
| **Gemini avec cache** | $3.83 | **-83.9%** | **-33.7%** |

### Projection annuelle (5,000 documents)

| Provider | Co√ªt annuel | √âconomie vs OpenAI |
|----------|-------------|-------------------|
| **OpenAI** | $119,000 | - |
| **Gemini sans cache** | $28,900 | **-$90,100** |
| **Gemini avec cache** | $19,150 | **-$99,850** |

**üéØ √âconomie suppl√©mentaire avec Context Caching : $9,750/an** (vs Gemini sans cache)

---

## üõ†Ô∏è Impl√©mentation du Context Caching

### Exemple Code Python

```python
from google.generativeai import caching
import datetime

# 1. Cr√©er un cache avec le contexte partag√©
system_instruction = """You are an expert at analyzing SAP presentations
and extracting structured business concepts..."""

deck_summary = """This presentation covers SAP S/4HANA Cloud Private Edition,
focusing on deployment options, integration capabilities, and quarterly innovation..."""

# Cache valide pendant la dur√©e du traitement (ex: 1 heure)
cache = caching.CachedContent.create(
    model='models/gemini-1.5-flash-8b',
    system_instruction=system_instruction,
    contents=[deck_summary],  # Contexte partag√©
    ttl=datetime.timedelta(hours=1),  # TTL : 1 heure
)

print(f"Cache cr√©√© : {cache.name}")
print(f"Expire √† : {cache.expire_time}")

# 2. Utiliser le cache pour tous les appels du document
import google.generativeai as genai

model = genai.GenerativeModel.from_cached_content(cached_content=cache)

# Traiter toutes les slides avec le cache
for slide_idx, slide_text in enumerate(slides):
    response = model.generate_content(
        f"Analyze slide {slide_idx}: {slide_text}"
    )
    # Les tokens du cache (system_instruction + deck_summary)
    # sont factur√©s √† $0.01/1M au lieu de $0.0375/1M

# 3. Supprimer le cache apr√®s traitement (optionnel)
cache.delete()
```

### Int√©gration dans OSMOSE

**Fichier** : `src/knowbase/common/llm_router.py`

```python
class LLMRouter:
    def __init__(self):
        self.gemini_cache = None

    def create_document_cache(self, deck_summary: str, document_context: str):
        """Cr√©e un cache Gemini pour un document entier."""
        if self.provider != "google":
            return None

        system_instruction = self._get_system_instruction()

        self.gemini_cache = caching.CachedContent.create(
            model=f'models/{self.model}',
            system_instruction=system_instruction,
            contents=[deck_summary, document_context],
            ttl=datetime.timedelta(hours=1)
        )

        logger.info(f"üì¶ Gemini cache created for document (TTL: 1h)")
        return self.gemini_cache

    def clear_document_cache(self):
        """Supprime le cache apr√®s traitement du document."""
        if self.gemini_cache:
            self.gemini_cache.delete()
            logger.info(f"üóëÔ∏è Gemini cache deleted")
            self.gemini_cache = None
```

**Fichier** : `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

```python
# Au d√©but du traitement document
if llm_router.provider == "google":
    llm_router.create_document_cache(
        deck_summary=deck_summary,
        document_context=document_context_prompt
    )

# Traiter toutes les slides (cache r√©utilis√© automatiquement)
for slide in slides:
    concepts = extract_concepts(slide, llm_router)

# √Ä la fin du traitement
if llm_router.provider == "google":
    llm_router.clear_document_cache()
```

---

## ‚úÖ RECOMMANDATIONS

### 1. Activer Context Caching Syst√©matiquement

**Quand** : Pour tout document avec >10 slides (ROI positif)

**Quoi cacher** :
- ‚úÖ Prompt syst√®me (invariant)
- ‚úÖ Deck summary (partag√© entre slides)
- ‚úÖ Document context prompt (partag√©)
- ‚úÖ Instructions format JSON (invariantes)

**TTL recommand√©** : 1 heure (largement suffisant pour traiter 1 doc)

### 2. Strat√©gie de Migration

**Phase 1** : POC Context Caching (10 documents)
- Impl√©menter cache pour Concept Extraction
- Mesurer √©conomies r√©elles
- Valider stabilit√©/performance

**Phase 2** : D√©ploiement Vision (si POC OK)
- Activer cache pour Vision Summary
- Monitorer co√ªts vs projections
- Ajuster TTL si besoin

**Phase 3** : Production (si Phase 2 OK)
- Activer par d√©faut pour Gemini
- Fallback OpenAI si cache fail

### 3. Monitoring

**M√©triques √† tracker** :
- Taux de cache hit (doit √™tre ~100% pour slides d'un m√™me doc)
- √âconomies r√©alis√©es ($ par doc)
- Latence (impact n√©gligeable attendu)
- Erreurs cache (retomb√©e sur non-cached si probl√®me)

---

## üìà ROI FINAL - Gemini avec Context Caching

### Comparaison Compl√®te (par document, Sc√©nario OSMOSE Pure)

| Provider/Option | Co√ªt | √âconomie vs OpenAI |
|----------------|------|-------------------|
| **OpenAI** | $23.80 | - |
| **Gemini sans cache** | $5.78 | **-75.7% (-$18.02)** |
| **Gemini avec cache** | $3.83 | **-83.9% (-$19.97)** |

### ROI Annuel (5,000 documents)

| √âconomie | Montant |
|----------|---------|
| Gemini vs OpenAI | **-$90,100** |
| + Context Caching | **+$9,750** |
| **TOTAL √âCONOMIE** | **-$99,850** |

**üéØ Conclusion** : Le Context Caching ajoute **11% d'√©conomies suppl√©mentaires** sur une migration Gemini d√©j√† tr√®s rentable.

---

## üö® Limitations et Risques

### 1. TTL et Co√ªt Storage

- **Gratuit** : 5 premi√®res minutes
- **Payant** : $1.00/1M tokens/heure apr√®s
- **Risque** : Si traitement >1h, storage peut co√ªter cher

**Mitigation** : Traiter documents par batch, TTL = dur√©e traitement estim√©e

### 2. Quota Caching

- **Limite** : Varie selon projet Google Cloud
- **D√©faut** : G√©n√©ralement suffisant pour usage normal

**Mitigation** : Monitorer quotas, demander augmentation si besoin

### 3. Cache Invalidation

- **Auto-expiration** : Selon TTL d√©fini
- **Manuel** : Appeler `cache.delete()`

**Best practice** : Toujours nettoyer apr√®s traitement document

---

## üìö Ressources

- [Gemini Context Caching Documentation](https://ai.google.dev/gemini-api/docs/caching?hl=fr&lang=python)
- [Gemini Pricing](https://ai.google.dev/pricing)
- [Context Caching Best Practices](https://ai.google.dev/gemini-api/docs/caching?hl=fr#best-practices)

---

**Date cr√©ation** : 2025-11-22
**Statut** : Recommandation valid√©e - √Ä impl√©menter en Phase POC
