# OSMOSE - Corrections Appliqu√©es (Review OpenAI)

**Date:** 2025-10-14 23:00
**Contexte:** Application des recommandations OpenAI pour OSMOSE Pure

---

## ‚úÖ Corrections Appliqu√©es

### P0: Config spaCy - URGENT (FAIT)

**Fichier:** `src/knowbase/semantic/config.py:73-79`

**Probl√®me:** Config attendait mod√®les `trf` (transformers) mais Dockerfile installe `sm` (small)

**Correction:**
```python
# AVANT
models: Dict[str, str] = {
    "en": "en_core_web_trf",
    "fr": "fr_core_news_trf",
    "de": "de_core_news_trf",
    "xx": "xx_ent_wiki_sm"
}

# APR√àS
models: Dict[str, str] = {
    "en": "en_core_web_sm",
    "fr": "fr_core_news_sm",
    "xx": "xx_ent_wiki_sm"
}
```

**Impact:** Bloquant ‚Üí d√©bloqu√©. NER peut maintenant fonctionner.

---

### P1: Logging M√©triques HDBSCAN (FAIT)

**Fichier:** `src/knowbase/semantic/segmentation/topic_segmenter.py:334-357`

**Am√©lioration:** Ajout logging taux outliers + warning si > 30%

**Correction:**
```python
# Calculer et logger le taux d'outliers (recommandation OpenAI)
outliers = cluster_labels == -1
outlier_count = outliers.sum()
outlier_rate = outlier_count / len(cluster_labels) if len(cluster_labels) > 0 else 0.0

logger.info(
    f"[OSMOSE] HDBSCAN metrics: outlier_rate={outlier_rate:.2%} "
    f"({outlier_count}/{len(cluster_labels)} windows)"
)

# Warning si taux d'outliers √©lev√© (calibration √† ajuster)
if outlier_rate > 0.3:
    logger.warning(
        f"[OSMOSE] High HDBSCAN outlier rate ({outlier_rate:.2%}). "
        "Consider adjusting min_cluster_size or using Agglomerative on outliers."
    )
```

**Impact:** Qualit√© topics. Permet de d√©tecter si HDBSCAN rejette trop de windows en bruit.

---

### P2: PPTX Parser Robuste (FAIT)

**Fichier:** `src/knowbase/ingestion/pipelines/pptx_pipeline.py:710-750`

**Am√©lioration:** Extraction tables + chart metadata (recommandation OpenAI)

**Correction:**
```python
for shape in slide.shapes:
    # Extraction texte standard (text_frame)
    txt = getattr(shape, "text", None)
    if isinstance(txt, str) and txt.strip():
        texts.append(txt.strip())

    # Extraction tables (recommandation OpenAI)
    if shape.has_table:
        try:
            table = shape.table
            table_text = []
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    cell_text = cell.text_frame.text.strip() if cell.text_frame else ""
                    if cell_text:
                        row_text.append(cell_text)
                if row_text:
                    table_text.append(" | ".join(row_text))
            if table_text:
                texts.append("[TABLE]\n" + "\n".join(table_text))
        except Exception as e:
            logger.debug(f"Erreur extraction table slide {i}: {e}")

    # Extraction chart metadata (recommandation OpenAI)
    if shape.shape_type == 3:  # MSO_SHAPE_TYPE.CHART = 3
        try:
            chart_info = []
            if hasattr(shape, "chart") and shape.chart:
                chart = shape.chart
                if hasattr(chart, "chart_title") and chart.chart_title:
                    title_text = chart.chart_title.text_frame.text if hasattr(chart.chart_title, "text_frame") else ""
                    if title_text:
                        chart_info.append(f"Chart Title: {title_text}")
            if chart_info:
                texts.append("[CHART]\n" + "\n".join(chart_info))
        except Exception as e:
            logger.debug(f"Erreur extraction chart slide {i}: {e}")
```

**Impact:** Robustesse extraction slides complexes (tables, charts).

---

### P2: Pr√©fixes e5 query/passage (FAIT)

**Fichier:** `src/knowbase/semantic/utils/embeddings.py:68-101, 193-229`

**Am√©lioration:** Support pr√©fixes e5 "query:" et "passage:" (+2-5% pr√©cision retrieval)

**Corrections:**

**1. M√©thode `encode()`:**
```python
def encode(self, texts: List[str], prefix_type: Optional[str] = None) -> np.ndarray:
    """
    Args:
        prefix_type: Type de pr√©fixe e5 ("query", "passage", ou None)
                    Recommandation OpenAI: +2-5% pr√©cision retrieval
    """
    # Ajouter pr√©fixes e5 si demand√© (recommandation OpenAI)
    if prefix_type == "query":
        texts = [f"query: {text}" for text in texts]
    elif prefix_type == "passage":
        texts = [f"passage: {text}" for text in texts]

    embeddings = self.model.encode(...)
```

**2. M√©thode `find_similar()`:**
```python
def find_similar(
    self,
    query_text: str,
    candidate_texts: List[str],
    use_e5_prefixes: bool = False  # Nouveau param√®tre
) -> List[tuple]:
    """
    Args:
        use_e5_prefixes: Utiliser pr√©fixes e5 "query:" et "passage:" (+2-5% pr√©cision)
    """
    # Utiliser pr√©fixes e5 si demand√© (recommandation OpenAI)
    if use_e5_prefixes:
        query_emb = self.model.encode(
            f"query: {query_text}",
            convert_to_numpy=True,
            normalize_embeddings=self.config.embeddings.normalize
        )
        candidate_embs = self.encode(candidate_texts, prefix_type="passage")
    else:
        query_emb = self.encode_cached(query_text)
        candidate_embs = self.encode(candidate_texts)
```

**Impact:** +2-5% pr√©cision retrieval. D√©sactiv√© par d√©faut (`use_e5_prefixes=False`), √† activer apr√®s validation E2E.

---

## üìä Corrections NON Appliqu√©es (Post-E2E)

### P2: EntityRuler custom (Post-E2E)

**Priorit√©:** Moyenne
**Quand:** Apr√®s mesures qualit√© NER
**Effort:** 2h
**Impact:** Meilleure couverture domaine (ISO 27001, GDPR, SAP modules)

### P3: Jaccard + Cosine Linking (Post-E2E)

**Priorit√©:** Basse
**Quand:** Si trop de merges incorrects
**Effort:** 1h
**Impact:** Pr√©cision linking

### P3: Seuils Adaptatifs par (langue, type) (Post-E2E)

**Priorit√©:** Basse
**Quand:** Apr√®s calibration avec deck pilote
**Effort:** 1h
**Impact:** Pr√©cision canonicalization

### P4: Upgrade spaCy sm ‚Üí md (Production)

**Priorit√©:** Basse
**Quand:** Si NER < 70% de couverture
**Effort:** Rebuild Docker (+100 MB)
**Impact:** Qualit√© NER

---

## üéØ Prochaines √âtapes

### 1. Rebuild Docker (Maintenant)

```bash
docker-compose down
docker-compose build app ingestion-worker
docker-compose up -d
```

**Dur√©e:** 5-10 min (avec cache Docker)

---

### 2. Validation D√©pendances (Maintenant)

```bash
docker-compose exec app python -m knowbase.ingestion.validate_osmose_deps
```

**Attendu:** 6/6 ‚úÖ OK

**Crit√®res:**
- Imports Python : ‚úÖ OK
- spaCy : ‚úÖ OK (mod√®les sm maintenant matching)
- Neo4j : ‚úÖ OK
- Qdrant : ‚úÖ OK
- LLM Config : ‚úÖ OK
- OSMOSE Config : ‚úÖ OK

---

### 3. Test PPTX E2E (Maintenant)

```bash
# Copier deck test
cp votre_deck.pptx data/docs_in/

# Observer logs
docker-compose logs -f ingestion-worker
```

**Logs attendus:**
```
üìä [OSMOSE PURE] use_vision = True
üìä [OSMOSE PURE] image_paths count = 25
Slide 1 [VISION SUMMARY]: 847 chars generated
‚úÖ [OSMOSE PURE] 25 r√©sum√©s Vision collect√©s
[OSMOSE PURE] Texte enrichi construit: 18543 chars
[OSMOSE] SemanticPipelineV2 initialized
[OSMOSE] HDBSCAN metrics: outlier_rate=15.2% (3/20 windows)
[OSMOSE PURE] ‚úÖ Traitement r√©ussi:
  - 42 concepts canoniques
  - Proto-KG: 42 concepts + 35 relations + 42 embeddings
```

---

### 4. Mesurer (Apr√®s E2E fonctionne)

**M√©triques √† collecter:**
- HDBSCAN outlier rate (maintenant logg√©)
- Concept extraction coverage (% concepts extraits vs attendus)
- Linking merge rate (combien de concepts merg√©s)
- Temps total traitement
- Co√ªt/slide Vision

**Dur√©e:** 1-2h avec deck pilote

---

### 5. Activer Optimisations (Si besoin)

**Pr√©fixes e5:** Activer `use_e5_prefixes=True` dans find_similar() si pr√©cision retrieval < 90%

**EntityRuler custom:** Ajouter patterns domaine (ISO 27001, GDPR, etc.) si NER < 70%

**spaCy md:** Upgrade mod√®les si NER insuffisant

---

## üìã R√©capitulatif Changements

| Fichier | Lignes | Type | Impact |
|---------|--------|------|--------|
| `semantic/config.py` | 73-79 | Fix | üî• Bloquant |
| `semantic/segmentation/topic_segmenter.py` | 334-357 | Am√©lioration | üîµ Qualit√© |
| `ingestion/pipelines/pptx_pipeline.py` | 710-750 | Am√©lioration | üü° Robustesse |
| `semantic/utils/embeddings.py` | 68-101, 193-229 | Am√©lioration | üü° Pr√©cision (+2-5%) |

**Total changements:** 4 fichiers, ~100 lignes modifi√©es

---

## üéì Conclusion

‚úÖ **Toutes les corrections P0 (bloquantes) appliqu√©es**
‚úÖ **Corrections P1-P2 (qualit√©/robustesse) appliqu√©es**
‚è∏Ô∏è **Optimisations P3-P4 report√©es post-E2E (correct par design)**

**Philosophie OpenAI valid√©e:**
> "Tu ne peux pas optimiser ce que tu ne mesures pas."

**Prochaine √©tape imm√©diate:**
```bash
docker-compose down
docker-compose build app ingestion-worker
docker-compose up -d
docker-compose exec app python -m knowbase.ingestion.validate_osmose_deps
```

---

**Version:** 1.0
**Date:** 2025-10-14 23:00
**Status:** Corrections appliqu√©es - Pr√™t pour rebuild + validation
