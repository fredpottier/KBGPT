# OSMOSE - Optimisation Vision Analysis PPTX

**Date**: 2025-10-30
**Statut**: Strat√©gie d'optimisation valid√©e - Impl√©mentation √† venir
**Contexte**: R√©duction du temps de traitement PPTX avec vision analysis (GPT-4o)

---

## üìä √âtat Actuel - Baseline

### Performance Mesur√©e
- **Document de r√©f√©rence**: Slide deck de 230 slides
- **Temps total ingestion**: ~1h30
  - Convert to PDF: ~5-10 min
  - Image generation: ~10-15 min
  - **Vision analysis**: ~25-30 min ‚ö†Ô∏è (goulot principal)
  - OSMOSE processing: ~20-30 min
- **Co√ªt par document**: 5-7‚Ç¨

### Configuration Actuelle
**Fichier**: `src/knowbase/ingestion/pipelines/pptx_pipeline.py:2108`
```python
MAX_WORKERS = 3  # Parall√©lisme limit√©
```

**Fonction Vision**: `ask_gpt_vision_summary()` (ligne 1494)
```python
raw_content = llm_router.complete(
    TaskType.VISION, msg,
    temperature=0.5,
    max_tokens=4000  # 1 slide = 1 appel = 4000 tokens max
)
```

**Mod√®le utilis√©**: GPT-4o (config/llm_models.yaml:10)
- Input: $2.50 / 1M tokens
- Output: $10.00 / 1M tokens

### Consommation Tokens (230 slides)
- **Input tokens**: 920K-1.2M (images base64 + prompts)
- **Output tokens**: 138K-230K (2-4 paragraphes par slide)
- **Co√ªt calcul√©**: ~6.61‚Ç¨ (coh√©rent avec observation 5-7‚Ç¨)

### Limites API GPT-4o
- **TPM** (Tokens Per Minute): 800,000
- **RPM** (Requests Per Minute): 5,000
- **TPD** (Tokens Per Day): 100,000,000

---

## üéØ Strat√©gie d'Optimisation

### Option 1: Augmentation des Workers (Gain Rapide)

**Principe**: Exploiter pleinement le parall√©lisme autoris√© par les limites API GPT-4o

#### Calculs de Dimensionnement

**Hypoth√®ses**:
- Temps moyen par appel: 25s (range 20-30s observ√©)
- Tokens moyens par appel: 5,000 tokens (4000 input image + 1000 output texte)

**Calcul limite TPM**:
```
800,000 tokens/min √∑ 5,000 tokens/call = 160 calls/min
160 calls/min √∑ 60s = 2.67 calls/sec
Avec 25s par call: 2.67 √ó 25 = ~67 workers max th√©orique (TPM)
```

**Calcul limite RPM**:
```
5,000 requests/min √∑ 60s = 83.3 requests/sec
Avec 25s par call: 83.3 √ó 25 = ~208 workers max th√©orique (RPM)
```

**Limite contraignante**: TPM (67 workers max)

**Recommandation avec marge de s√©curit√© (65%)**:
```
67 √ó 0.65 = ~44 workers recommand√©s
‚Üí Arrondi conservateur: MAX_WORKERS = 30
```

#### Machine Cible - Capacit√© Valid√©e

**Specs**: Ryzen 9 9950X3D
- 32 threads (16 cores)
- 64GB RAM
- SSD ultra rapide
- **Verdict**: Peut g√©rer 30-50 workers sans probl√®me

#### Gains Attendus (Option 1)

**Vision analysis**:
- Actuel: 230 slides √∑ 3 workers = ~77 slides/worker √ó 25s = 32 min
- Optimis√©: 230 slides √∑ 30 workers = ~8 slides/worker √ó 25s = **3.3 min**
- **Gain**: 25-30 min ‚Üí 2.5-3.5 min ‚úÖ (~10x plus rapide)

**Temps total ingestion**:
- Actuel: 1h30
- Optimis√©: 50-55 min
- **Gain**: ~40 min √©conomis√©s

**Co√ªt**: Inchang√© (5-7‚Ç¨) - m√™me nombre d'appels API

---

### Option 2: Batching 3 Slides + 30 Workers (Optimisation Avanc√©e)

**Principe**: R√©duire le nombre d'appels API en groupant 3 slides par image composite

#### Architecture Batching

**Cr√©ation Image Composite**:
```
+-------------------+-------------------+-------------------+
|                   |                   |                   |
|    SLIDE 1        |    SLIDE 2        |    SLIDE 3        |
|   [Image 1]       |   [Image 2]       |   [Image 3]       |
|                   |                   |                   |
+-------------------+-------------------+-------------------+
```

**Prompt adapt√©**:
```
Analysez cette image composite contenant 3 slides d'une pr√©sentation.

Pour chaque slide (SLIDE 1, SLIDE 2, SLIDE 3), fournissez une description
narrative d√©taill√©e (2-4 paragraphes) expliquant :
- Le message principal v√©hicul√©
- Les concepts cl√©s et leur organisation visuelle
- Les relations entre les √©l√©ments pr√©sent√©s
- Le contexte m√©tier ou technique

FORMAT DE R√âPONSE:
=== SLIDE 1 ===
[Votre analyse narrative...]

=== SLIDE 2 ===
[Votre analyse narrative...]

=== SLIDE 3 ===
[Votre analyse narrative...]
```

#### Calculs Batching

**R√©duction appels API**:
- Actuel: 230 slides = 230 appels
- Batching: 230 slides √∑ 3 = **77 appels** (76 batches de 3 + 1 batch de 2)
- **R√©duction**: 67% moins d'appels

**Tokens par appel batch√©**:
- Input: ~12,000 tokens (3 images composite + prompt)
- Output: ~3,000 tokens (3 descriptions de 2-4 paragraphes)
- **Total**: ~15,000 tokens/appel vs 5,000 actuellement

**Consommation totale (230 slides)**:
- Input: 77 √ó 12,000 = 924K tokens
- Output: 77 √ó 3,000 = 231K tokens
- **Co√ªt**: (924K √ó $2.50 + 231K √ó $10) / 1M = **$4.62** ‚úÖ

#### Gains Attendus (Option 2)

**Vision analysis**:
- 77 appels √∑ 30 workers = ~3 appels/worker √ó 25s = **1.25 min**
- **Gain vs actuel**: 25-30 min ‚Üí 1.25 min (~20x plus rapide)

**Temps total ingestion**:
- Actuel: 1h30
- Optimis√©: **45-50 min**
- **Gain**: ~45 min √©conomis√©s

**Co√ªt**:
- Actuel: 5-7‚Ç¨
- Optimis√©: **4-5.5‚Ç¨**
- **Gain**: ~1-2‚Ç¨ √©conomis√©s par document

**Avantages suppl√©mentaires**:
- Moins de pression r√©seau (77 uploads vs 230)
- Moins de stress sur les limites RPM
- Meilleure utilisation du contexte GPT-4o

---

## üõ†Ô∏è Plan d'Impl√©mentation

### Phase 1: Optimisation Rapide (Option 1)
**Priorit√©**: Haute
**Effort**: Faible (5 min)
**Gain imm√©diat**: 10x speedup vision analysis

#### Modifications Code

**Fichier 1**: `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

```python
# Ligne 2108 - AVANT
MAX_WORKERS = 3

# Ligne 2108 - APR√àS
MAX_WORKERS = 30  # Optimis√© pour GPT-4o TPM limits (800K)
```

**Validation**:
```bash
# Test sur document de 230 slides
docker-compose exec app python -m knowbase.ingestion.pipelines.pptx_pipeline \
    --file data/docs_in/test_230_slides.pptx

# V√©rifier logs - temps vision analysis devrait √™tre ~3 min
docker-compose logs -f app | grep "Vision analysis completed"
```

---

### Phase 2: Batching Intelligent (Option 2)
**Priorit√©**: Moyenne
**Effort**: Moyen (2-4h d√©veloppement + tests)
**Gain additionnel**: 2x speedup + √©conomies co√ªts

#### √âtape 2.1: POC Validation Qualit√©

**Objectif**: V√©rifier que GPT-4o analyse correctement 3 slides simultan√©ment

**Script POC**: `scripts/poc_batch_vision.py`
```python
"""
POC: Valider la qualit√© d'analyse batched (3 slides/image)
"""
from PIL import Image
import numpy as np
from knowbase.common.llm_router import llm_router, TaskType

def create_composite_image(slide_images, labels=None):
    """
    Cr√©e une image composite horizontale avec 3 slides

    Args:
        slide_images: List[PIL.Image] (1 √† 3 images)
        labels: List[str] optionnel (["SLIDE 1", "SLIDE 2", "SLIDE 3"])

    Returns:
        PIL.Image composite
    """
    width = sum(img.width for img in slide_images)
    height = max(img.height for img in slide_images)

    composite = Image.new('RGB', (width, height), 'white')
    x_offset = 0

    for i, img in enumerate(slide_images):
        composite.paste(img, (x_offset, 0))

        # Ajouter label si fourni
        if labels and i < len(labels):
            from PIL import ImageDraw, ImageFont
            draw = ImageDraw.Draw(composite)
            font = ImageFont.truetype("arial.ttf", 60)
            draw.text((x_offset + 20, 20), labels[i],
                     fill='red', font=font)

        x_offset += img.width

    return composite

def analyze_batch(composite_image_path, slide_count):
    """
    Analyse un batch de slides via GPT-4o vision
    """
    prompt = f"""Analysez cette image composite contenant {slide_count} slides d'une pr√©sentation.

Pour chaque slide (SLIDE 1, SLIDE 2, SLIDE 3), fournissez une description narrative d√©taill√©e (2-4 paragraphes) expliquant :
- Le message principal v√©hicul√©
- Les concepts cl√©s et leur organisation visuelle
- Les relations entre les √©l√©ments pr√©sent√©s
- Le contexte m√©tier ou technique

FORMAT DE R√âPONSE:
=== SLIDE 1 ===
[Votre analyse narrative...]

=== SLIDE 2 ===
[Votre analyse narrative...]

=== SLIDE 3 ===
[Votre analyse narrative...]"""

    response = llm_router.complete(
        TaskType.VISION,
        prompt,
        image_path=composite_image_path,
        temperature=0.5,
        max_tokens=12000  # 3x le max actuel
    )

    return response

def parse_batch_response(response_text):
    """
    Parse la r√©ponse GPT-4o pour extraire les 3 analyses

    Returns:
        Dict[int, str] - {1: "analyse slide 1", 2: "...", 3: "..."}
    """
    import re

    analyses = {}
    pattern = r"===\s*SLIDE\s+(\d+)\s*===\s*(.*?)(?====\s*SLIDE\s+\d+\s*===|$)"
    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)

    for slide_num, content in matches:
        analyses[int(slide_num)] = content.strip()

    return analyses

# Test POC
if __name__ == "__main__":
    # Charger 3 slides de test
    slide1 = Image.open("data/public/slides/test_001.png")
    slide2 = Image.open("data/public/slides/test_002.png")
    slide3 = Image.open("data/public/slides/test_003.png")

    # Cr√©er composite
    composite = create_composite_image(
        [slide1, slide2, slide3],
        labels=["SLIDE 1", "SLIDE 2", "SLIDE 3"]
    )
    composite.save("/tmp/batch_test.png")

    # Analyser
    response = analyze_batch("/tmp/batch_test.png", 3)
    print("=== R√âPONSE BRUTE GPT-4o ===")
    print(response)

    # Parser
    analyses = parse_batch_response(response)
    print("\n=== ANALYSES PARS√âES ===")
    for slide_num, content in analyses.items():
        print(f"\nSlide {slide_num}:")
        print(content[:200] + "...")

    # Validation qualit√© manuelle requise
    print("\n‚ö†Ô∏è VALIDATION MANUELLE:")
    print("1. V√©rifier que les 3 slides sont correctement identifi√©es")
    print("2. Comparer qualit√© vs analyse slide par slide actuelle")
    print("3. Valider que les concepts/relations ne sont pas m√©lang√©s")
```

**Crit√®res de validation**:
- ‚úÖ GPT-4o identifie correctement les 3 slides distinctes
- ‚úÖ Qualit√© narrative √©quivalente √† l'analyse slide-par-slide
- ‚úÖ Pas de confusion entre les concepts des diff√©rents slides
- ‚úÖ Parsing fiable des 3 sections de r√©ponse

#### √âtape 2.2: Modifications Configuration

**Fichier**: `config/llm_models.yaml`

```yaml
# Ligne 39-41 - AVANT
vision:
  temperature: 0.2
  max_tokens: 4000

# Ligne 39-41 - APR√àS
vision:
  temperature: 0.2
  max_tokens: 12000  # Support batching 3 slides (3 √ó 4000)
```

#### √âtape 2.3: Refactoring Pipeline

**Fichier**: `src/knowbase/ingestion/pipelines/pptx_pipeline.py`

**Nouvelle fonction** (ins√©rer apr√®s `ask_gpt_vision_summary`, ligne ~1650):

```python
def ask_gpt_vision_batch_summary(
    image_paths: List[str],
    slide_indices: List[int],
    source_name: str,
    texts: List[str] = None,
    notes: List[str] = None,
    retries: int = 2
) -> Dict[int, str]:
    """
    Analyse un batch de 2-3 slides via GPT-4o vision (mode optimis√©).

    Args:
        image_paths: Chemins vers les images de slides (2-3 max)
        slide_indices: Indices des slides dans le document
        source_name: Nom du document source
        texts: Textes extraits des slides (optionnel)
        notes: Notes speaker des slides (optionnel)
        retries: Nombre de tentatives en cas d'erreur

    Returns:
        Dict[int, str]: Mapping slide_index ‚Üí analyse narrative
    """
    from PIL import Image
    import tempfile

    batch_size = len(image_paths)
    if batch_size < 2 or batch_size > 3:
        raise ValueError(f"Batch size must be 2-3, got {batch_size}")

    # Cr√©er image composite
    slide_images = [Image.open(path) for path in image_paths]
    labels = [f"SLIDE {idx+1}" for idx in slide_indices]

    composite = create_composite_image(slide_images, labels)

    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        composite.save(tmp.name)
        composite_path = tmp.name

    # Construire prompt avec contexte textuel optionnel
    context_parts = []
    for i, idx in enumerate(slide_indices):
        parts = [f"**SLIDE {idx+1}**"]
        if texts and i < len(texts) and texts[i]:
            parts.append(f"Texte: {texts[i][:500]}")
        if notes and i < len(notes) and notes[i]:
            parts.append(f"Notes: {notes[i][:300]}")
        context_parts.append("\n".join(parts))

    context = "\n\n".join(context_parts) if context_parts else ""

    prompt = f"""Analysez cette image composite contenant {batch_size} slides de la pr√©sentation "{source_name}".

{context}

Pour chaque slide visible (SLIDE {slide_indices[0]+1}{"".join(f", SLIDE {idx+1}" for idx in slide_indices[1:])}), fournissez une description narrative D√âTAILL√âE (2-4 paragraphes) qui explique :

1. **Message principal** : Quelle est l'id√©e centrale v√©hicul√©e par ce slide ?
2. **Concepts cl√©s** : Quels sont les concepts, termes techniques ou entit√©s importantes pr√©sent√©s ?
3. **Organisation visuelle** : Comment l'information est-elle structur√©e visuellement (diagrammes, sch√©mas, tableaux, flux) ?
4. **Relations et dynamiques** : Quelles sont les relations, d√©pendances ou processus illustr√©s ?
5. **Contexte m√©tier/technique** : Quel est le domaine d'application et les implications pratiques ?

‚ö†Ô∏è IMPORTANT:
- Analysez chaque slide S√âPAR√âMENT et DISTINCTEMENT
- Ne confondez pas les concepts de diff√©rents slides
- Fournissez une analyse RICHE et NARRATIVE (pas une simple liste)

FORMAT DE R√âPONSE OBLIGATOIRE:
=== SLIDE {slide_indices[0]+1} ===
[Votre analyse narrative d√©taill√©e...]

=== SLIDE {slide_indices[1]+1} ===
[Votre analyse narrative d√©taill√©e...]
""" + (f"""
=== SLIDE {slide_indices[2]+1} ===
[Votre analyse narrative d√©taill√©e...]""" if batch_size == 3 else "")

    # Appel GPT-4o avec retry
    for attempt in range(retries + 1):
        try:
            response = llm_router.complete(
                TaskType.VISION,
                prompt,
                image_path=composite_path,
                temperature=0.5,
                max_tokens=12000
            )

            # Parser la r√©ponse
            analyses = parse_batch_response(response)

            # Valider qu'on a bien toutes les analyses
            expected_slides = set(idx + 1 for idx in slide_indices)
            received_slides = set(analyses.keys())

            if expected_slides != received_slides:
                missing = expected_slides - received_slides
                logger.warning(
                    f"[OSMOSE] Batch analysis incomplete - "
                    f"missing slides: {missing}. Retry {attempt+1}/{retries}"
                )
                if attempt < retries:
                    continue
                else:
                    # Fallback: retourner ce qu'on a
                    pass

            # Convertir les cl√©s pour matcher les indices originaux
            result = {}
            for slide_num, content in analyses.items():
                # slide_num est 1-based dans la r√©ponse
                # On cherche l'index correspondant
                for i, idx in enumerate(slide_indices):
                    if slide_num == idx + 1:  # idx est 0-based
                        result[idx] = content
                        break

            logger.info(
                f"[OSMOSE] Batch vision analysis completed - "
                f"{len(result)}/{batch_size} slides"
            )

            return result

        except Exception as e:
            logger.error(
                f"[OSMOSE] Batch vision analysis error (attempt {attempt+1}): {e}"
            )
            if attempt == retries:
                raise

    # Cleanup
    try:
        os.unlink(composite_path)
    except:
        pass


def create_composite_image(
    slide_images: List[Image.Image],
    labels: List[str] = None
) -> Image.Image:
    """
    Cr√©e une image composite horizontale avec 2-3 slides + labels.

    Args:
        slide_images: Liste de 2-3 images PIL
        labels: Labels optionnels ["SLIDE 1", "SLIDE 2", "SLIDE 3"]

    Returns:
        Image composite PIL
    """
    from PIL import ImageDraw, ImageFont

    # Calculer dimensions
    total_width = sum(img.width for img in slide_images)
    max_height = max(img.height for img in slide_images)

    # Cr√©er canvas blanc
    composite = Image.new('RGB', (total_width, max_height), 'white')

    # Coller les slides horizontalement
    x_offset = 0
    for i, img in enumerate(slide_images):
        composite.paste(img, (x_offset, 0))

        # Ajouter label rouge en haut √† gauche de chaque slide
        if labels and i < len(labels):
            draw = ImageDraw.Draw(composite)
            try:
                font = ImageFont.truetype("arial.ttf", 60)
            except:
                font = ImageFont.load_default()

            # Fond semi-transparent pour lisibilit√©
            label_bbox = draw.textbbox((0, 0), labels[i], font=font)
            label_width = label_bbox[2] - label_bbox[0]
            label_height = label_bbox[3] - label_bbox[1]

            draw.rectangle(
                [x_offset + 10, 10, x_offset + label_width + 30, label_height + 30],
                fill=(255, 0, 0, 180)
            )
            draw.text(
                (x_offset + 20, 20),
                labels[i],
                fill='white',
                font=font
            )

        x_offset += img.width

    return composite


def parse_batch_response(response_text: str) -> Dict[int, str]:
    """
    Parse la r√©ponse GPT-4o pour extraire les analyses individuelles.

    Format attendu:
    === SLIDE 1 ===
    Contenu...
    === SLIDE 2 ===
    Contenu...

    Returns:
        Dict[int, str]: {1: "analyse slide 1", 2: "analyse slide 2", ...}
    """
    import re

    analyses = {}

    # Pattern flexible pour capturer les sections
    pattern = r"===\s*SLIDE\s+(\d+)\s*===\s*(.*?)(?====\s*SLIDE\s+\d+\s*===|$)"
    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)

    for slide_num_str, content in matches:
        slide_num = int(slide_num_str)
        analyses[slide_num] = content.strip()

    return analyses
```

**Modification logique principale** (ligne ~2100-2200):

```python
# AVANT (traitement s√©quentiel slide par slide)
with ThreadPoolExecutor(max_workers=actual_workers) as executor:
    futures = {}
    for idx, img_path in enumerate(slide_image_paths):
        future = executor.submit(
            ask_gpt_vision_summary,
            img_path, idx, source_name,
            texts[idx] if idx < len(texts) else "",
            notes[idx] if idx < len(notes) else "",
            megaparse_content,
            retries=2
        )
        futures[future] = idx

# APR√àS (batching 3 slides)
BATCH_SIZE = 3  # Nombre de slides par batch
batches = []

# Cr√©er les batches de slides
for i in range(0, len(slide_image_paths), BATCH_SIZE):
    batch_end = min(i + BATCH_SIZE, len(slide_image_paths))
    batch = {
        'image_paths': slide_image_paths[i:batch_end],
        'slide_indices': list(range(i, batch_end)),
        'texts': texts[i:batch_end] if texts else None,
        'notes': notes[i:batch_end] if notes else None,
    }
    batches.append(batch)

logger.info(
    f"[OSMOSE] Processing {len(slide_image_paths)} slides in "
    f"{len(batches)} batches (batch_size={BATCH_SIZE})"
)

# Traiter les batches en parall√®le
vision_summaries = [""] * len(slide_image_paths)  # Pr√©-allouer

with ThreadPoolExecutor(max_workers=actual_workers) as executor:
    futures = {}
    for batch_idx, batch in enumerate(batches):
        future = executor.submit(
            ask_gpt_vision_batch_summary,
            batch['image_paths'],
            batch['slide_indices'],
            source_name,
            batch['texts'],
            batch['notes'],
            retries=2
        )
        futures[future] = batch_idx

    # Collecter les r√©sultats
    for future in as_completed(futures):
        batch_idx = futures[future]
        try:
            batch_results = future.result()  # Dict[int, str]

            # Ins√©rer les r√©sultats aux bons indices
            for slide_idx, summary in batch_results.items():
                vision_summaries[slide_idx] = summary

            logger.info(
                f"[OSMOSE] Batch {batch_idx+1}/{len(batches)} completed - "
                f"{len(batch_results)} slides analyzed"
            )
        except Exception as e:
            logger.error(f"[OSMOSE] Batch {batch_idx} failed: {e}")
            # On continue avec les autres batches

# V√©rifier qu'on a toutes les analyses
missing_indices = [i for i, s in enumerate(vision_summaries) if not s]
if missing_indices:
    logger.warning(
        f"[OSMOSE] Missing vision analyses for slides: {missing_indices}"
    )
```

---

## üìà Comparaison Options

| M√©trique | Actuel | Option 1 (30 workers) | Option 2 (Batch + 30w) |
|----------|--------|-----------------------|------------------------|
| **Vision analysis** | 25-30 min | 2.5-3.5 min | 1-1.5 min |
| **Temps total** | 1h30 | 50-55 min | 45-50 min |
| **Appels API** | 230 | 230 | 77 |
| **Co√ªt** | 5-7‚Ç¨ | 5-7‚Ç¨ | 4-5.5‚Ç¨ |
| **Speedup** | 1x | ~10x | ~20x |
| **Effort impl√©mentation** | - | 5 min | 2-4h |
| **Risque qualit√©** | Aucun | Aucun | Faible (POC requis) |

---

## ‚ö†Ô∏è Risques et Mitigations

### Option 1: Augmentation Workers

**Risques**:
1. **D√©passement limites API en production multi-utilisateurs**
   - *Mitigation*: Monitoring TPM/RPM, file d'attente si limite approch√©e

2. **Consommation r√©seau importante (30 uploads simultan√©s)**
   - *Mitigation*: Connexion fibre requise, sinon r√©duire √† 15-20 workers

3. **Charge CPU/RAM sur la machine**
   - *Mitigation*: Ryzen 9 9950X3D largement dimensionn√©, monitoring CPU/RAM

### Option 2: Batching

**Risques**:
1. **Qualit√© d'analyse d√©grad√©e (confusion entre slides)**
   - *Mitigation*: POC validation obligatoire avant d√©ploiement
   - *Fallback*: Revenir √† Option 1 si qualit√© insuffisante

2. **Parsing fragile des r√©ponses GPT-4o**
   - *Mitigation*: Regex robuste + retry si parsing √©choue
   - *Alternative*: Demander JSON structur√© au lieu de texte

3. **Labels "SLIDE X" non visible si images trop petites**
   - *Mitigation*: Font size adaptatif selon r√©solution, contraste √©lev√©

4. **Timeout sur gros batches (max_tokens=12000)**
   - *Mitigation*: Timeout API augment√©, retry automatique

---

## üß™ Protocole de Test

### Tests Option 1 (Workers)

**Test 1: Performance baseline**
```bash
# Document 230 slides
time docker-compose exec app python -m knowbase.ingestion.pipelines.pptx_pipeline \
    --file data/docs_in/test_230_slides.pptx

# V√©rifier logs
# - Temps vision analysis doit √™tre ~3 min
# - Pas d'erreurs rate limit
```

**Test 2: Stress test multi-docs**
```bash
# Lancer 3 ingestions simultan√©es
for i in {1..3}; do
    docker-compose exec app python -m knowbase.ingestion.pipelines.pptx_pipeline \
        --file data/docs_in/test_doc_$i.pptx &
done

# Monitorer logs pour rate limit errors
docker-compose logs -f app | grep -i "rate limit"
```

### Tests Option 2 (Batching)

**Test 1: POC qualit√© (3 slides)**
```bash
# Ex√©cuter script POC
docker-compose exec app python scripts/poc_batch_vision.py

# Validation manuelle:
# 1. Comparer analyse batch vs slide-by-slide (ground truth)
# 2. V√©rifier parsing correct des 3 sections
# 3. Tester avec slides vari√©s (texte, diagramme, tableau)
```

**Test 2: Regression compl√®te**
```bash
# Traiter document complet avec batching
docker-compose exec app python -m knowbase.ingestion.pipelines.pptx_pipeline \
    --file data/docs_in/test_230_slides.pptx \
    --batch-mode

# Comparer r√©sultats vs baseline:
# - Nombre de concepts extraits (~m√™me)
# - Nombre de relations d√©tect√©es (~m√™me)
# - Qualit√© narrative (validation manuelle √©chantillon)
```

**Test 3: Edge cases**
```bash
# Test avec nombre de slides non multiple de 3
# ‚Üí Dernier batch avec 1 ou 2 slides seulement
python scripts/poc_batch_vision.py --slides 228  # 76 batches de 3
python scripts/poc_batch_vision.py --slides 229  # 76 de 3 + 1 de 1
python scripts/poc_batch_vision.py --slides 230  # 76 de 3 + 1 de 2
```

---

## üìã Checklist D√©ploiement

### Option 1 - Ready to Deploy ‚úÖ

- [ ] Modifier `MAX_WORKERS = 30` dans pptx_pipeline.py:2108
- [ ] Tester sur doc 230 slides (temps ~3 min vision)
- [ ] V√©rifier logs - pas de rate limit errors
- [ ] Valider co√ªt inchang√© (5-7‚Ç¨)
- [ ] Commit + d√©ploiement

### Option 2 - Requires POC First ‚ö†Ô∏è

- [ ] D√©velopper `scripts/poc_batch_vision.py`
- [ ] Impl√©menter fonctions helpers (create_composite_image, parse_batch_response)
- [ ] Ex√©cuter POC sur 10 exemples vari√©s
- [ ] **VALIDATION MANUELLE**: Qualit√© √©quivalente slide-by-slide ? ‚úÖ/‚ùå
- [ ] Si ‚úÖ: Modifier llm_models.yaml (max_tokens: 12000)
- [ ] Si ‚úÖ: Refactorer pptx_pipeline.py (batching logic)
- [ ] Tests regression complets
- [ ] Si ‚ùå: Rester sur Option 1

---

## üéØ Recommandation Finale

### Court Terme (Semaine en cours)
**D√©ployer Option 1 (30 workers)** - Quick win garanti
- Gain 10x imm√©diat sur vision analysis
- Risque minimal (juste param√®tre)
- Valid√© par calculs API limits

### Moyen Terme (2-3 semaines)
**√âvaluer Option 2 (Batching)** - Si bandwidth disponible
- POC qualit√© d'abord (1 jour)
- Si concluant: impl√©mentation (1-2 jours)
- Gain additionnel 2x + √©conomies

### Alternative: Optimisation Hybride
Si Option 2 √©choue le POC qualit√©, explorer:
- **Batching s√©lectif**: Grouper seulement slides similaires (texte dense) mais pas les diagrammes complexes
- **Batching 2 slides**: Moins risqu√© que 3, toujours 50% r√©duction appels
- **Batching adaptatif**: D√©cider par slide (analyse complexit√© visuelle d'abord)

---

## üìö R√©f√©rences

**Code Source**:
- Pipeline PPTX: `src/knowbase/ingestion/pipelines/pptx_pipeline.py`
- LLM Router: `src/knowbase/common/llm_router.py`
- Config mod√®les: `config/llm_models.yaml`

**Documentation**:
- Limites API GPT-4o: https://platform.openai.com/docs/guides/rate-limits
- Vision API: https://platform.openai.com/docs/guides/vision
- ThreadPoolExecutor: https://docs.python.org/3/library/concurrent.futures.html

**Commits Historiques**:
- `69048d2`: Evolution max_tokens 2500‚Üí4000 (meilleure qualit√© narrative)
- `fa57394`: Impl√©mentation AsyncOpenAI (parall√©lisation LLM calls)

---

**Auteur**: Claude Code
**Validation**: √Ä valider avec POC avant d√©ploiement Option 2
**Prochaine √©tape**: D√©ploiement Option 1 (MAX_WORKERS=30)
