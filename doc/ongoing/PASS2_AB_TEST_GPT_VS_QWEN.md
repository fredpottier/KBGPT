# Test A/B Pass 2 : gpt-4o-mini vs Qwen-14B (vLLM)

**Date** : 2025-01
**Status** : PrÃªt pour exÃ©cution
**Objectif** : DÃ©terminer si Qwen-14B sur EC2 Spot offre un meilleur rapport qualitÃ©/prix que gpt-4o-mini pour l'extraction de relations Pass 2.

---

## Contexte

L'extraction de relations Pass 2 utilise actuellement gpt-4o-mini via l'API OpenAI. Cette phase est coÃ»teuse car elle traite segment par segment avec des prompts dÃ©taillÃ©s.

L'infrastructure Burst (EC2 Spot + vLLM) est dÃ©jÃ  opÃ©rationnelle pour l'ingestion de documents. On peut la rÃ©utiliser pour Pass 2.

### HypothÃ¨se

Qwen2-14B-Instruct-AWQ (7B params quantifiÃ©) pourrait offrir :
- **Meilleure qualitÃ©** : ModÃ¨le plus grand que gpt-4o-mini
- **CoÃ»t comparable** : ~1.20â‚¬/heure EC2 vs ~$0.50-1.00 OpenAI pour un batch
- **Latence acceptable** : vLLM sur GPU L4 est rapide malgrÃ© la distance rÃ©seau

---

## Architecture du Test

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TEST A/B PASS 2                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚    GROUPE A     â”‚        â”‚    GROUPE B     â”‚                    â”‚
â”‚  â”‚   (gpt-4o-mini) â”‚        â”‚   (Qwen-14B)    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                          â”‚                             â”‚
â”‚           â–¼                          â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  OpenAI API     â”‚        â”‚ EC2 Spot + vLLM â”‚                    â”‚
â”‚  â”‚  (dÃ©faut)       â”‚        â”‚ (Burst mode)    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                          â”‚                             â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                      â–¼                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚           â”‚ MÃªmes documents  â”‚                                     â”‚
â”‚           â”‚ MÃªmes segments   â”‚                                     â”‚
â”‚           â”‚ MÃªmes budgets    â”‚                                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©triques collectÃ©es

| MÃ©trique | Description |
|----------|-------------|
| **PrÃ©cision** | relations validÃ©es / relations proposÃ©es |
| **Latence** | Temps moyen par segment (ms) |
| **Distribution prÃ©dicats** | RÃ©partition des 12 prÃ©dicats ADR |
| **Fuzzy score moyen** | QualitÃ© des quotes extraites |
| **CoÃ»t** | OpenAI ($) vs EC2 runtime (â‚¬â†’$) |

---

## ProcÃ©dure d'ExÃ©cution

### 1. PrÃ©-requis

```bash
# VÃ©rifier que les services sont dÃ©marrÃ©s
./kw.ps1 status

# VÃ©rifier qu'on a des documents Ã  tester
docker-compose exec app python -c "
from knowbase.common.clients.neo4j_client import Neo4jClient
from knowbase.config.settings import get_settings
s = get_settings()
c = Neo4jClient(s.neo4j_uri, s.neo4j_user, s.neo4j_password)
with c.driver.session(database='neo4j') as session:
    r = session.run('MATCH (d:Document) RETURN count(d) AS count')
    print(f'Documents disponibles: {r.single()[\"count\"]}')
c.close()
"
```

### 2. Dry Run (recommandÃ©)

Tester le script sans exÃ©cuter rÃ©ellement :

```bash
docker-compose exec app python scripts/pass2_ab_test.py --documents 5 --dry-run
```

Sortie attendue :
```
[ABTest] Starting test ab_pass2_YYYYMMDD_HHMMSS
[ABTest] Max documents: 5, Dry run: True
[ABTest] Selected 5 documents for testing
[ABTest] === GROUP A: gpt-4o-mini (5 documents) ===
[ABTest] DRY RUN - Skipping actual extraction
[ABTest] === GROUP B: Qwen-14B/vLLM (5 documents) ===
[ABTest] DRY RUN - Skipping EC2 deployment and extraction
```

### 3. ExÃ©cution RÃ©elle

```bash
docker-compose exec app python scripts/pass2_ab_test.py --documents 20 --execute
```

**Attention** :
- EC2 Spot sera dÃ©ployÃ© (~2-5 min de dÃ©marrage)
- CoÃ»t estimÃ© : ~1.20â‚¬/heure EC2 + tokens OpenAI
- Les relations seront persistÃ©es dans Neo4j

### 4. Analyse des RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans `data/ab_tests/ab_pass2_XXXXXX.json`.

Exemple de sortie console :

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  TEST A/B PASS 2 - RÃ‰SULTATS
  Test ID: ab_pass2_20250101_143022
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Documents testÃ©s: 20

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique           â”‚ gpt-4o-mini      â”‚ Qwen-14B (vLLM)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Segments traitÃ©s   â”‚               85 â”‚               85 â”‚
â”‚ Relations extraitesâ”‚              312 â”‚              347 â”‚
â”‚ PrÃ©cision moyenne  â”‚            72.3% â”‚            78.1% â”‚
â”‚ Latence moyenne    â”‚           450 ms â”‚           680 ms â”‚
â”‚ CoÃ»t estimÃ©        â”‚           $0.75  â”‚           $1.30  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â±ï¸  Temps EC2 total: 2847s

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ˆ DiffÃ©rence qualitÃ©: +8.0% (Qwen-14B vs gpt-4o-mini)
ğŸ’° DiffÃ©rence coÃ»t: +73.3%

âœ… VERDICT: Qwen-14B offre un meilleur rapport qualitÃ©/prix
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## CoÃ»ts EstimÃ©s

### OpenAI (gpt-4o-mini)

| Composant | Prix | Estimation/segment |
|-----------|------|-------------------|
| Input tokens | $0.15 / 1M | ~2000 tokens |
| Output tokens | $0.60 / 1M | ~500 tokens |
| **Total/segment** | | ~$0.0006 |
| **20 docs Ã— 50 segments** | | ~$0.60 |

### EC2 Spot (Qwen-14B)

| Composant | Prix |
|-----------|------|
| g6e.xlarge Spot | ~$0.40-0.50/h |
| Startup/shutdown | ~5 min overhead |
| **Estimation 20 docs** | ~$1.00-1.50 |

---

## Points d'Attention

### Latence

La latence EC2 est plus Ã©levÃ©e que l'API OpenAI :
- RÃ©seau : ~50-100ms RTT vers eu-west-1
- vLLM batch : efficace mais pas instantanÃ©
- PremiÃ¨re requÃªte : warmup GPU

### QualitÃ©

Qwen-14B-AWQ a des caractÃ©ristiques diffÃ©rentes :
- Format instruction Qwen2 (pas OpenAI)
- Quantification AWQ (lÃ©ger impact qualitÃ©)
- Contexte 32K tokens

### Robustesse

Points de vigilance :
- Spot interruption (rare, handled par Burst)
- Timeout vLLM (augmentÃ© Ã  120s)
- Parse JSON (mÃªme format ADR)

---

## DÃ©cision Post-Test

### Si Qwen-14B gagne (qualitÃ© â‰¥ +5%)

1. Modifier `pass2_config.mode` pour supporter `gpu_burst`
2. CrÃ©er workflow automatisÃ© : dÃ©marrer EC2 â†’ Pass 2 â†’ arrÃªter EC2
3. ConsidÃ©rer batch nocturne pour optimiser coÃ»ts

### Si gpt-4o-mini gagne

1. Garder le mode actuel
2. ConsidÃ©rer gpt-4o (plus cher mais meilleur)
3. Explorer fine-tuning gpt-4o-mini sur corpus OSMOSE

### Si Ã©galitÃ© (< 5% diffÃ©rence)

1. PrÃ©fÃ©rer gpt-4o-mini (simplicitÃ©, pas d'infra Ã  gÃ©rer)
2. Garder EC2 pour les pics (mode Burst ingestion)

---

## Fichiers AssociÃ©s

| Fichier | Description |
|---------|-------------|
| `scripts/pass2_ab_test.py` | Script de test A/B |
| `src/knowbase/ingestion/burst/orchestrator.py` | Orchestration EC2 Spot |
| `src/knowbase/ingestion/burst/provider_switch.py` | Switch LLM/Embeddings |
| `src/knowbase/relations/segment_window_relation_extractor.py` | Extraction ADR-compliant |
| `data/ab_tests/*.json` | RÃ©sultats des tests |

---

## Historique

| Date | Action |
|------|--------|
| 2025-01-01 | CrÃ©ation du script et documentation |
| - | Premier test prÃ©vu |
