# Optimisations Performance Neo4j - 2025-11-17

## Contexte

Import d'un document 94 slides prenait **79 minutes**, principalement bloqu√© sur traitement ontologies.

---

## üî¥ OPTIMISATION CRITIQUE : D√©duplication O(n¬≤) ‚Üí O(n)

### Probl√®me Identifi√©

**Fichier:** `src/knowbase/common/clients/neo4j_client.py`
**Lignes:** 472-480 (avant fix)

D√©duplication des `chunk_ids` avec `REDUCE` O(n¬≤) :
```cypher
REDUCE(acc = [], chunk IN all_chunks_raw |
    CASE
        WHEN chunk IS NULL THEN acc
        WHEN chunk IN acc THEN acc  // ‚ö†Ô∏è Recherche lin√©aire O(n¬≤)
        ELSE acc + chunk
    END
)
```

**Impact Mesur√© :**
- **"SAP Cloud ERP"** : 42,070 chunks ‚Üí 1.77 milliards comparaisons ‚Üí **plusieurs minutes**
- **"GDPR"** : 14,267 chunks ‚Üí 203 millions comparaisons ‚Üí **30-60 secondes**
- **"Compliance"** : 14,103 chunks ‚Üí 199 millions comparaisons ‚Üí **30-60 secondes**

**R√©sultat :** Import bloqu√© 10-15 minutes sur certains concepts populaires.

### Solution Appliqu√©e

Remplacement par `UNWIND + COLLECT DISTINCT` O(n) :
```cypher
// D√©dupliquer avec UNWIND + COLLECT DISTINCT O(n) au lieu de REDUCE O(n¬≤)
// CRITIQUE: Avec 42,000 chunks, REDUCE O(n¬≤) = 1.77 milliards comparaisons!
// UNWIND + COLLECT DISTINCT = lin√©aire, quasi-instantan√©
UNWIND all_chunks_raw AS chunk_item
WITH proto, canonical, chunk_item
WHERE chunk_item IS NOT NULL
WITH proto, canonical, COLLECT(DISTINCT chunk_item) AS aggregated_chunks
```

**Gain Attendu :**
- **79 min ‚Üí 30-40 min** (~50% r√©duction)
- Concepts avec 40,000+ chunks : **plusieurs minutes ‚Üí <1 seconde**

---

## üü° OPTIMISATION : R√©duction Verbosit√© Logs

### Probl√®me 1 : Warning "NOT FOUND in ontology"

**Fichier:** `src/knowbase/ontology/entity_normalizer_neo4j.py`
**Ligne:** 202

**Avant :**
```python
logger.warning(
    f"[ONTOLOGY:Sandbox] ‚ùå NOT FOUND in ontology: '{raw_name}' "
)
```

**Apr√®s :**
```python
logger.debug(
    f"[ONTOLOGY:Sandbox] NOT FOUND in ontology: '{raw_name}' "
)
```

**Raison :** Comportement normal, pas une erreur (concepts non catalogu√©s sont attendus).

---

### Probl√®me 2 : Warning "Redis not available"

**Fichier:** `src/knowbase/common/clients/neo4j_client.py`
**Ligne:** 102

**Avant :**
```python
logger.warning(f"[NEO4J:Lock] Redis not available, skipping lock for '{lock_key}'")
```

**Apr√®s :**
```python
logger.debug(f"[NEO4J:Lock] Redis not configured, skipping distributed lock for '{lock_key}'")
```

**Raison :** Comportement normal si Redis non configur√© (d√©gradation gracieuse).

---

## üü¢ AM√âLIORATION : Configuration Redis pour Distributed Locks

**Fichier:** `src/knowbase/common/clients/neo4j_client.py`
**Lignes:** 860-888

**Avant :**
```python
_neo4j_client = Neo4jClient(
    uri=uri,
    user=user,
    password=password,
    database=database
    # ‚ùå redis_client JAMAIS pass√©
)
```

**Apr√®s :**
```python
# R√©cup√©rer Redis client pour distributed locks (P1.1)
redis_client = None
try:
    import redis
    from knowbase.config.settings import get_settings
    settings = get_settings()
    redis_client = redis.Redis(
        host=settings.redis_host,
        port=settings.redis_port,
        db=0,
        decode_responses=True
    )
    redis_client.ping()
    logger.debug(f"[NEO4J] Redis client connected for distributed locks")
except Exception as e:
    logger.debug(f"[NEO4J] Redis client not available: {e}")
    redis_client = None

_neo4j_client = Neo4jClient(
    uri=uri,
    user=user,
    password=password,
    database=database,
    redis_client=redis_client  # ‚úÖ Pass√© automatiquement
)
```

**B√©n√©fice :**
- Distributed locks activ√©s automatiquement si Redis disponible
- √âvite race conditions sur canonicalization cross-documents
- Pas de warnings si Redis configur√© correctement

---

## üìä R√©sum√© Impact

| Optimisation | Gain Temps | Impact % | Priorit√© |
|--------------|------------|----------|----------|
| D√©duplication O(n) | **~40 min** | **~50%** | üî¥ CRITIQUE |
| NER Singleton | **~6 min** | **~8%** | üü¢ IMPORTANT |
| Logs DEBUG | N/A | Lisibilit√© | üü° MOYEN |
| Redis Locks | Stabilit√© | Race conditions | üü¢ BONUS |

**Temps traitement attendu :**
- **Avant :** 79 min pour 94 slides
- **Apr√®s :** **25-35 min** pour 94 slides (~16-22 sec/slide)
- **Gain total :** **~46 minutes (~58% r√©duction)**

---

## üß™ Tests Recommand√©s

### Test 1 : V√©rifier D√©duplication O(n)
```bash
# Lancer import document 94 slides
# Surveiller logs pour concepts avec beaucoup de chunks
docker logs knowbase-worker -f | grep "aggregated.*chunks"

# Devrait voir des messages instantan√©s, pas de blocages 10+ minutes
```

### Test 2 : V√©rifier Redis Locks Actifs
```bash
# Check logs au d√©marrage
docker logs knowbase-worker --tail 50 | grep "Redis client"

# Devrait voir:
# [NEO4J] Redis client connected for distributed locks
# [NEO4J] Connected to ... (distributed_locks=ON)
```

### Test 3 : V√©rifier Absence Warnings
```bash
# Logs ne devraient PLUS contenir:
# - "‚ùå NOT FOUND in ontology" (pass√© en DEBUG)
# - "Redis not available" (pass√© en DEBUG si non configur√©)
```

---

## üü¢ OPTIMISATION : Chargement NER Singleton

### Probl√®me Identifi√©

**Fichier:** `src/knowbase/agents/extractor/orchestrator.py`
**Ligne:** 374 (avant fix)

Les mod√®les NER spaCy √©taient **recharg√©s √† chaque segment** au lieu d'utiliser le singleton existant :
```python
# AVANT (ligne 374)
ner_manager = MultilingualNER(semantic_config)  # ‚ùå Recharge 3 mod√®les !
```

**Impact Mesur√© :**
- **3 mod√®les spaCy recharg√©s** pour chaque segment (en, fr, xx)
- **~4 secondes perdues** par segment √ó 94 segments = **~6 minutes**
- Logs pollu√©s avec messages "‚úÖ NER model loaded" r√©p√©t√©s

**Observation logs :**
```
2025-11-17 19:36:13,184 INFO: [OSMOSE] ‚úÖ NER model loaded: en (en_core_web_md)
2025-11-17 19:36:14,497 INFO: [OSMOSE] ‚úÖ NER model loaded: fr (fr_core_news_md)
2025-11-17 19:36:15,361 INFO: [OSMOSE] ‚úÖ NER model loaded: xx (xx_ent_wiki_sm)
[... SE R√âP√àTE POUR CHAQUE SEGMENT ...]
```

### Solution Appliqu√©e

Utilisation du singleton existant `get_ner_manager()` :
```python
# APR√àS (ligne 374)
ner_manager = get_ner_manager(semantic_config)  # ‚úÖ Singleton !
```

**Changements :**
1. Ligne 366 : Import `get_ner_manager` au lieu de `MultilingualNER`
2. Ligne 374 : Appel `get_ner_manager()` au lieu de `MultilingualNER()`

**Gain Attendu :**
- **Chargement 1 seule fois** au d√©but du traitement
- **~6 minutes √©conomis√©es** sur 94 segments
- Logs propres (1 seul message de chargement)

---

## üìù Notes Impl√©mentation

**Date :** 2025-11-17
**Session :** Continuation apr√®s correction bugs refactoring pptx_pipeline

**Fichiers Modifi√©s :**
1. `src/knowbase/common/clients/neo4j_client.py` (lignes 100-104, 472-478, 860-888)
2. `src/knowbase/ontology/entity_normalizer_neo4j.py` (ligne 202)
3. `src/knowbase/agents/extractor/orchestrator.py` (lignes 366, 374)

**Commit Recommand√© :**
```bash
git add src/knowbase/common/clients/neo4j_client.py \
        src/knowbase/ontology/entity_normalizer_neo4j.py \
        src/knowbase/agents/extractor/orchestrator.py

git commit -m "perf(neo4j): Fix O(n¬≤) deduplication + NER singleton + reduce logs

- CRITICAL: Replace REDUCE O(n¬≤) with UNWIND+COLLECT DISTINCT O(n)
  - 42k chunks: 1.77B comparisons ‚Üí linear (several minutes ‚Üí <1s)
  - Expected gain: ~40 min (~50% reduction)

- IMPORTANT: Use NER singleton to avoid reloading models per segment
  - Fix orchestrator.py: get_ner_manager() instead of MultilingualNER()
  - 3 spaCy models (en, fr, xx) loaded once vs 94 times
  - Expected gain: ~6 min (~8% reduction)

- Reduce log verbosity: WARNING ‚Üí DEBUG for normal behaviors
  - ONTOLOGY NOT FOUND (expected for non-catalogued concepts)
  - Redis locks unavailable (graceful degradation)

- Auto-configure Redis client for distributed locks in get_neo4j_client()

**Total expected gain: 79min ‚Üí 25-35min (~58% reduction)**

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

---

## üü¢ R√âSOLUTION : Neo4j Driver Warnings (Ontologie Vide)

**Probl√®me Identifi√©** (2025-11-17 apr√®s optimisations)

Neo4j driver warnings persistants apr√®s passage logs en DEBUG :
```
warn: property key does not exist. The property `normalized` does not exist...
warn: relationship type does not exist. The relationship `HAS_ALIAS` does not exist...
```

**Cause Racine :**
```cypher
MATCH (ont:OntologyEntity) RETURN count(ont)
‚Üí 0 entit√©s (ontologie vide !)
```

L'ontologie Neo4j √©tait vide car jamais peupl√©e.

**Investigation :**
1. D√©couverte que `migrate_yaml_to_neo4j.py` peut migrer les anciens fichiers YAML
2. Migration temporaire effectu√©e ‚Üí 60 entit√©s + 208 aliases cr√©√©es
3. **MAIS** : les fichiers YAML `config/ontologies/*.yaml` sont de l'**ancien syst√®me** (avant Neo4j)
4. Le syst√®me actuel utilise **pure auto-learning** via `ontology_saver.py` (appel√© par `normalization_worker.py`)

**D√©cision Architecture :**
‚ùå Ne PAS utiliser les YAML comme bootstrap (ancien syst√®me)
‚úÖ Utiliser **pure auto-learning** : ontologie se construit dynamiquement lors des imports

**Solution Appliqu√©e :**

```bash
# 1. Cr√©er schema (constraints + indexes) - CONSERV√â
docker exec knowbase-app bash -c "cd /app && python src/knowbase/ontology/neo4j_schema.py"

# 2. Purger entit√©s migr√©es depuis YAML (ancien syst√®me)
docker exec knowbase-neo4j cypher-shell -u neo4j -p graphiti_neo4j_pass --format plain "
MATCH (ont:OntologyEntity {source: 'yaml_migrated'})-[:HAS_ALIAS]->(alias:OntologyAlias)
DETACH DELETE ont, alias
"
```

**R√©sultat Final :**
- ‚úÖ Schema Neo4j cr√©√© (constraints + indexes)
- ‚úÖ Ontologie vide (0 entit√©s, 0 aliases)
- ‚úÖ Pr√™te pour auto-learning lors des imports
- ‚ö†Ô∏è Warnings Neo4j vont **persister** jusqu'au premier import (comportement normal)

**Comment l'Ontologie se Remplit :**
1. Import document ‚Üí Extraction concepts via LLM
2. Normalisation via `normalization_worker.py` (merge concepts similaires)
3. Sauvegarde auto dans Neo4j via `ontology_saver.py` ligne 69-84
4. Ontologie grandit au fil des imports (auto-learning)

---

## üü¢ AM√âLIORATION : G√©n√©ration Acronymes dans Aliases (LLM Canonicalizer)

**Probl√®me Identifi√©** (2025-11-17 apr√®s investigation ontologie)

L'ontologie AdaptiveOntology se construit correctement (577 entr√©es apr√®s import), mais les **alias sont pauvres** :

```
"SAP Analytics Cloud" ‚Üí aliases: ["Analytics Cloud"]  ‚ùå Manque "SAC"
"Shared Governance" ‚Üí aliases: []  ‚ùå Aucun alias
```

**Cause Racine :**

Le prompt LLMCanonicalizer demandait d'**EXPAND** les acronymes (SLA ‚Üí Service Level Agreement), mais ne demandait PAS de **G√âN√âRER** les acronymes pour les noms longs.

**Direction manquante :**
- ‚úÖ "SLA" ‚Üí canonical: "Service Level Agreement", aliases: ["SLA"]
- ‚ùå "SAP Analytics Cloud" ‚Üí canonical: "SAP Analytics Cloud", aliases: [~~"SAC"~~] **MANQUANT**

**Solution Appliqu√©e :**

Enrichi le prompt `CANONICALIZATION_SYSTEM_PROMPT` et `CANONICALIZATION_BATCH_SYSTEM_PROMPT` dans `llm_canonicalizer.py` :

```python
5. **Aliases**: List ALL common aliases/variants including:
   - Common acronyms (CRITICAL for long names)
   - Short forms
   - Alternative names
   - Industry-standard abbreviations

   **CRITICAL for Products/Services**: If canonical name is multi-word, ALWAYS include commonly-used acronyms:
   - "SAP Analytics Cloud" ‚Üí MUST include "SAC"
   - "SAP Business Technology Platform" ‚Üí MUST include "BTP"
   - "General Data Protection Regulation" ‚Üí MUST include "GDPR"

   Ask yourself: "What acronym would professionals use in conversation or documentation?"
```

**Exemple ajout√© :**
```json
{
  "canonical_name": "SAP Analytics Cloud",
  "confidence": 0.98,
  "reasoning": "Official SAP product name, widely known by acronym SAC",
  "aliases": ["SAC", "Analytics Cloud"],  // ‚úÖ SAC inclus
  "concept_type": "Product",
  "domain": "enterprise_software"
}
```

**R√©sultat Attendu :**

Lors des prochains imports, le LLM va g√©n√©rer automatiquement UNIQUEMENT les acronymes **r√©els et connus** (GDPR, CRM, SLA, etc.), rendant l'ontologie de haute qualit√©.

**Correction Critique (2025-11-17 apr√®s feedback utilisateur) :**

Le prompt initial contenait des exemples SAP-sp√©cifiques, ce qui √©tait **une erreur architecturale**.
Le syst√®me doit √™tre **domain-agnostic** car il peut traiter des documents de n'importe quel domaine m√©tier (pas seulement SAP).

**Changements appliqu√©s** (lignes 684-810) :
- ‚ùå Supprim√© tous les exemples SAP-sp√©cifiques (SAC, BTP, SuccessFactors)
- ‚úÖ Remplac√© par exemples g√©n√©riques (GDPR, CRM, SLA)
- ‚úÖ Ajout√© principe clair : "Use your general knowledge base across ALL domains (not specific to any industry)"
- ‚úÖ Renforc√© : "When in doubt ‚Üí DO NOT include it. Better no alias than fake alias."
- ‚úÖ Mentionn√© : "Future refinement: Aliases will be refined later by specialized models trained on domain-specific data"

**Exemple d'am√©lioration :**
- **AVANT :** Prompt mentionne "SAP Analytics Cloud ‚Üí SAC" ‚Üí biais SAP
- **APR√àS :** Prompt mentionne "Customer Relationship Management ‚Üí CRM" ‚Üí universel

**Cas d'usage CRR (Customer Retention Rate) mentionn√© par utilisateur :**
Le LLM ne doit PAS inventer d'expansion si incertain. Si "CRR" apparait sans contexte, mieux vaut laisser brut que deviner "Change Request Record" ou autre interpr√©tation SAP-sp√©cifique.

**Note :** Cette am√©lioration s'applique aux **nouveaux concepts** cr√©√©s apr√®s ce changement. Les 577 entr√©es existantes gardent leurs alias actuels (pas de r√©troactivit√© automatique).

---

## üîÑ Prochaines Optimisations Possibles (Phase 2)

Voir analyse compl√®te dans `doc/ongoing/REFACTORING_ANALYSIS_REPORT.md` section "Recommandations".

**Quick Wins restants :**
1. Cache in-memory EntityNormalizer (~15 sec gain)
2. Cache candidats matching structurel (~7-10 min gain)

**Batching majeur :**
3. Batch Neo4j promote (~60 sec gain)
4. Batch Qdrant update (~20 sec gain)

**Gain total potentiel Phase 2 :** ~10-15 minutes suppl√©mentaires
