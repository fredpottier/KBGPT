# OSMOSE Phase 2.12 - Entity Resolution & Relation Discovery

## SpÃ©cification Architecture Cible

**Date**: 2025-12-25
**Phase**: 2.12 (aprÃ¨s 2.11a Claims MVP)
**Status**: âœ… VALIDATED - Ready for v1 Production Implementation
**Contributeurs**: Claude Code, ChatGPT (analyse croisÃ©e)
**Reviews**:
- ChatGPT v1 : 5 corrections intÃ©grÃ©es (blocking, co_occurrence, sous-types, auto-calibration, prÃ©cision>recall)
- ChatGPT v2 : Validation finale + scope v1 Production dÃ©fini (section 11)

---

## 1. Contexte et ProblÃ¨me Initial

### 1.1 Constat

AprÃ¨s import de documents dans OSMOSE, on observe dans Neo4j :
- Des concepts (CanonicalConcept) crÃ©Ã©s correctement
- Des relations (RawAssertion) entre concepts du **mÃªme document**
- **Beaucoup de concepts isolÃ©s** (degree=0) qui ne sont reliÃ©s Ã  rien

### 1.2 Cause Racine

L'extraction de relations actuelle est **document-centric** :

```
Document â†’ Extraction NER â†’ Concepts du document
                                    â†“
                    Catalogue fermÃ© (c1, c2, c3...)
                                    â†“
          LLM Relation Extractor (segment-level + doc-level)
                                    â†“
                    RawAssertions entre concepts
                    du MÃŠME document seulement
```

**Code concernÃ©** :
- `osmose_integration.py:268-274` : Catalogue construit uniquement avec concepts du document courant
- `supervisor.py:769-770` : `identify_bucket3_concepts` utilise `state.promoted` (document courant)
- `llm_relation_extractor.py:219-222` : Prompt LLM avec "CATALOGUE FERMÃ‰"

### 1.3 ConsÃ©quence

Si un concept `GDPR` apparaÃ®t dans le document A et un concept `Data Protection Officer` dans le document B, **aucune relation ne sera crÃ©Ã©e entre eux**, mÃªme s'ils sont sÃ©mantiquement liÃ©s.

---

## 2. Principes Architecturaux (State of the Art)

### 2.1 Invariant Fondamental

> **On ne crÃ©e JAMAIS les relations cross-document pendant l'ingestion primaire.**

Raisons :
- Le contexte sÃ©mantique est **local** (document-level)
- Les relations canoniques sont **globales** (graph-level)
- MÃ©langer les deux crÃ©e du bruit et rend le pipeline non dÃ©terministe

### 2.2 Pattern Standard (Google KG, Microsoft Turing, Neo4j Research)

```
1. Document Ingestion (per-doc)
   - Concepts locaux
   - Relations locales (fort signal)

2. Entity Resolution (global)
   - DÃ©duplication cross-doc
   - Fusion / Alias
   - Alignement sÃ©mantique

3. Relation Discovery (global, pÃ©riodique)
   - Cross-document
   - Evidence-based
   - TraÃ§able
```

### 2.3 Distinction Critique

| Phase 2 : Entity Resolution | Phase 3 : Relation Discovery |
|----------------------------|------------------------------|
| "Est-ce le **MÃŠME** concept ?" | "Ces concepts sont-ils **LIÃ‰S** ?" |
| Fusion / Alias / DÃ©doublonnage | CrÃ©ation de liens sÃ©mantiques |
| Doit Ãªtre fait **AVANT** Phase 3 | NÃ©cessite un graphe "propre" |

**Si Phase 2 est fragile, Phase 3 devient un amplificateur de bruit.**

---

## 3. Phase 0 : Identity Schema (Fondation)

### 3.1 ProblÃ¨me

Sans dÃ©finition de ce qui constitue "le mÃªme concept" par type, les seuils de merge sont arbitraires.

### 3.2 Solution : Types GÃ©nÃ©riques + Extension par Domaine

#### Niveau 1 : Types Universels (Built-in, Domain-Agnostic)

```yaml
ENTITY:
  description: "Chose nommÃ©e identifiable"
  identity_signals:
    - name_normalized (obligatoire)
    - type_match (obligatoire)
    - embedding_similarity (candidat)
  default_thresholds:
    auto: 0.98
    defer: 0.85

CONCEPT:
  description: "Notion abstraite, idÃ©e"
  identity_signals:
    - name_normalized
    - definition_similarity
    - usage_context_similarity
  default_thresholds:
    auto: 0.99  # Ultra-restrictif mais possible (voir AUTO_SAFE ci-dessous)
    defer: 0.80
  # AUTO autorisÃ© UNIQUEMENT si toutes ces conditions sont vraies :
  auto_safe_conditions:
    - exact_normalized_match: true
    - definition_fingerprint_match: true  # MÃªme hash de dÃ©finition
    - stable_across_n_docs: 3  # ConfirmÃ© dans N+ documents

ROLE:
  description: "Fonction, responsabilitÃ©"
  identity_signals:
    - label_normalized
    - defining_context
  default_thresholds:
    auto: 0.95
    defer: 0.80

ORGANIZATION:
  description: "EntitÃ© organisationnelle"
  identity_signals:
    - name_normalized
    - location (si disponible)
    - org_type
  default_thresholds:
    auto: 0.95 (si location match)
    defer: 0.85

DOCUMENT:
  description: "Source documentaire"
  identity_signals:
    - title_normalized
    - identifier (si disponible)
    - date
  default_thresholds:
    auto: 0.98 (si identifier exact)
    defer: 0.85

STANDARD:
  description: "Norme, rÃ©fÃ©rentiel"
  identity_signals:
    - name_normalized
    - issuer
    - version
  default_thresholds:
    auto: 0.95 (si version match)
    defer: 0.85
```

#### Niveau 1b : Sous-Types Optionnels (HiÃ©rarchie LÃ©gÃ¨re)

Pour affiner le comportement sans casser le domain-agnostic :

```yaml
# Sous-types de ROLE (optionnels, dÃ©tectÃ©s automatiquement ou via Domain Context)
ROLE/HUMAN:
  parent: ROLE
  description: "RÃ´le humain (DPO, CEO, Security Officer...)"
  identity_boost: "same org + same title = higher confidence"

ROLE/SYSTEM:
  parent: ROLE
  description: "RÃ´le applicatif (API Gateway, Message Broker...)"
  identity_boost: "same tech stack context"

ROLE/ORGANIZATIONAL:
  parent: ROLE
  description: "Fonction organisationnelle (Compliance Team, Legal Dept...)"
  identity_boost: "same org structure"

# Sous-types de ENTITY (optionnels)
ENTITY/NORMATIVE:
  parent: ENTITY
  description: "EntitÃ© dÃ©finie par une norme (Article 5, Clause 3.2...)"
  identity_signals_extra:
    - parent_standard
    - section_number
  auto_threshold: 0.90  # Plus permissif car structurÃ©

ENTITY/TECHNICAL:
  parent: ENTITY
  description: "EntitÃ© technique (Protocol, Algorithm, System...)"
  identity_boost: "version + vendor match"

# DÃ©tection automatique du sous-type
subtype_detection:
  method: "pattern matching + LLM classification (cached)"
  fallback: "use parent type policy"
  confidence_required: 0.80  # Sinon, utiliser type parent
```

#### Niveau 2 : Signaux d'IdentitÃ© GÃ©nÃ©riques

```yaml
LEXICAL_SIGNALS:
  exact_match:
    weight: 1.0
    description: "Noms identiques aprÃ¨s normalisation"

  acronym_expansion:
    weight: 0.9
    description: "Acronyme â†” forme longue"
    example: "GDPR" â†” "General Data Protection Regulation"

  alias_overlap:
    weight: 0.85
    description: "Surface forms partagÃ©es"

SEMANTIC_SIGNALS:
  embedding_similarity:
    weight: configurable
    threshold: 0.85
    description: "ProximitÃ© vectorielle (Qdrant)"

  context_similarity:
    weight: 0.7
    description: "Contextes d'usage similaires"

STRUCTURAL_SIGNALS:
  same_document:
    weight: 0.3
    description: "Boost si apparus dans le mÃªme doc"

  # âš ï¸ co_occurrence RETIRÃ‰ de Phase 2
  # Raison: C'est un signal de RELATION, pas d'IDENTITY
  # Un concept peut co-apparaÃ®tre frÃ©quemment avec un autre sans Ãªtre le mÃªme
  # Exemple: "GDPR" et "DPO" co-apparaissent souvent mais ne sont pas identiques
  # â†’ RÃ©servÃ© Ã  Phase 3 (Relation Discovery) uniquement
```

#### Niveau 3 : Domain Context (Extension Optionnelle)

Le Domain Context existant dans OSMOSE peut enrichir avec des types spÃ©cialisÃ©s :

```yaml
# Exemple: chargÃ© dynamiquement pour domaine "privacy_regulation"
domain: privacy_regulation

extends_types:
  REGULATION:
    parent_type: DOCUMENT
    additional_signals:
      - jurisdiction
      - year
      - official_reference
    identity_rule: "jurisdiction + acronym + year"

  ARTICLE:
    parent_type: ENTITY
    additional_signals:
      - number
      - parent_document
    identity_rule: "number + parent_document"
```

---

## 4. ModÃ¨le de DÃ©cision : AUTO / DEFER / REJECT

### 4.1 Principe Fondamental

> **Aucune dette opÃ©rationnelle humaine**

Le systÃ¨me doit Ãªtre autonome. L'intervention humaine est exceptionnelle et budgetÃ©e, pas un workflow permanent.

### 4.2 Les Trois Ã‰tats

```
AUTO    â†’ Action immÃ©diate (haute prÃ©cision garantie)
          Merge ou crÃ©ation de lien effectuÃ© automatiquement

DEFER   â†’ Pas assez de signal maintenant
          RÃ©Ã©valuation automatique future quand plus de donnÃ©es
          PAS une queue humaine

REJECT  â†’ Confiance trop faible
          On ignore cette paire
```

### 4.3 DiffÃ©rence avec NEEDS_REVIEW

| Ancien modÃ¨le (NEEDS_REVIEW) | Nouveau modÃ¨le (DEFER) |
|------------------------------|------------------------|
| File d'attente humaine | Ã‰tat temporaire systÃ¨me |
| Croissance infinie | BornÃ© (expire aprÃ¨s N jours) |
| Humain = valideur permanent | Humain = oracle ponctuel |
| Bloquant | Non-bloquant |

### 4.4 L'Humain comme Oracle Ponctuel

```yaml
Human Review:
  role: "Source de labels pour calibration des seuils"
  frequency: "Exceptionnelle, budgetÃ©e"
  cap: "~20 dÃ©cisions / semaine / tenant maximum"

  selection_strategy:
    - Cas les plus frÃ©quents en DEFER (impact fort)
    - Cas ambigus mais rÃ©currents
    - Cas qui dÃ©bloquent un cluster entier

  purpose: "Ajuster seuils/rÃ¨gles, PAS vider une inbox"

  optional: true  # SystÃ¨me doit fonctionner sans
```

### 4.5 Auto-Calibration Sans Labels Humains

```yaml
Signaux d'apprentissage autonome:

  cohÃ©rence_graphe:
    description: "Un merge qui augmente les contradictions est pÃ©nalisÃ©"
    signal: "Nombre d'incohÃ©rences post-merge"

  stabilitÃ©_temporelle:
    description: "Alias confirmÃ© sur N documents = confiance monte"
    signal: "Nombre de docs oÃ¹ la paire co-apparaÃ®t"

  evidence_accumulation:
    description: "Plus de preuves textuelles = plus de confiance"
    signal: "Nombre de chunks avec co-prÃ©sence"

  pattern_consistency:
    description: "Merge cohÃ©rent avec patterns existants"
    signal: "SimilaritÃ© avec merges dÃ©jÃ  validÃ©s (AUTO)"
```

### 4.6 Cadre AutoCalibration (FormalisÃ©)

Comment les signaux ajustent concrÃ¨tement les seuils :

```yaml
AutoCalibration:
  # FrÃ©quence d'exÃ©cution
  cadence: "weekly"  # Batch job hebdomadaire
  scope: "per_type"  # Calibration sÃ©parÃ©e par type de concept

  # MÃ©triques de feedback utilisÃ©es
  feedback_signals:
    merge_stability:
      description: "% de merges AUTO qui restent stables (non-annulÃ©s)"
      healthy_threshold: "> 98%"
      action_if_below: "augmenter threshold_auto de 0.01"

    defer_resolution_rate:
      description: "% de DEFER qui deviennent AUTO (vs EXPIRED)"
      healthy_threshold: "> 40%"
      action_if_below: "baisser threshold_defer de 0.01"

    graph_coherence:
      description: "Contradictions crÃ©Ã©es par les merges rÃ©cents"
      measurement: "Claims CONFLICTING post-merge"
      action_if_high: "augmenter threshold_auto de 0.02"

  # Ajustements automatiques
  adjustments:
    threshold_auto:
      direction: "+/- 0.01 per cycle"
      bounds: [0.90, 1.0]  # Jamais en dessous de 0.90
      constraint: "never lower if precision < target"

    threshold_defer:
      direction: "+/- 0.01 per cycle"
      bounds: [0.70, 0.95]  # Ni trop permissif ni trop restrictif

  # Garde-fous (hard limits)
  guardrails:
    precision_floor: 0.95  # Jamais sacrifier la prÃ©cision
    max_adjustment_per_cycle: 0.02  # Pas de changement brutal
    require_n_samples: 100  # Minimum de dÃ©cisions pour ajuster
    rollback_if_degradation: true  # Annuler si mÃ©triques se dÃ©gradent

  # Logging et audit
  audit:
    log_every_adjustment: true
    store_threshold_history: true
    alert_on_unusual_drift: true
```

**Exemple concret** :
```
Cycle 1 (Semaine 1):
- ENTITY threshold_auto = 0.98
- 150 merges AUTO, 148 stables (98.7%) âœ“
- Pas d'ajustement

Cycle 2 (Semaine 2):
- 200 merges AUTO, 190 stables (95%) âš ï¸
- 10 merges ont crÃ©Ã© des contradictions
- Action: threshold_auto â†’ 0.99

Cycle 3 (Semaine 3):
- 180 merges AUTO, 178 stables (98.9%) âœ“
- StabilisÃ© Ã  nouveau
```

---

## 5. Phase 2 : Entity Resolution Cross-Document

### 5.1 Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENTITY RESOLUTION PIPELINE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ CandidateFinder  â”‚                                            â”‚
â”‚  â”‚                  â”‚  1. Qdrant top-K PAR TYPE                  â”‚
â”‚  â”‚                  â”‚     (entityâ†”entity, standardâ†”standard)     â”‚
â”‚  â”‚                  â”‚  2. Lexical (acronyme/expansion)           â”‚
â”‚  â”‚                  â”‚  3. Surface form overlap                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚ Paires candidates                                    â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚PairSimilarityScorerâ”‚  Cross-encoder pairwise                  â”‚
â”‚  â”‚                  â”‚  + Signaux lexicaux                        â”‚
â”‚  â”‚                  â”‚  + Signaux structurels                     â”‚
â”‚  â”‚                  â”‚  Output: score + breakdown par signal      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚           IDENTITY DECISION ROUTER                â”‚            â”‚
â”‚  â”‚                                                   â”‚            â”‚
â”‚  â”‚  Charger policy pour type(A) et type(B)           â”‚            â”‚
â”‚  â”‚                                                   â”‚            â”‚
â”‚  â”‚  IF score > threshold_auto AND explicit_evidence: â”‚            â”‚
â”‚  â”‚     â†’ AUTO (merge maintenant)                     â”‚            â”‚
â”‚  â”‚                                                   â”‚            â”‚
â”‚  â”‚  ELIF score > threshold_defer:                    â”‚            â”‚
â”‚  â”‚     â†’ DEFER (stocker pour rÃ©Ã©valuation)           â”‚            â”‚
â”‚  â”‚                                                   â”‚            â”‚
â”‚  â”‚  ELSE:                                            â”‚            â”‚
â”‚  â”‚     â†’ REJECT                                      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                    â”‚                                 â”‚
â”‚           â–¼                    â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚IdentityResolverâ”‚   â”‚  DeferredStore  â”‚                        â”‚
â”‚  â”‚             â”‚      â”‚                 â”‚                        â”‚
â”‚  â”‚ â€¢ Alias â†’   â”‚      â”‚ â€¢ pair_id       â”‚                        â”‚
â”‚  â”‚   surface_  â”‚      â”‚ â€¢ score         â”‚                        â”‚
â”‚  â”‚   forms     â”‚      â”‚ â€¢ signals       â”‚                        â”‚
â”‚  â”‚ â€¢ Relations â”‚      â”‚ â€¢ created_at    â”‚                        â”‚
â”‚  â”‚   migrÃ©es   â”‚      â”‚ â€¢ doc_count     â”‚                        â”‚
â”‚  â”‚ â€¢ Provenanceâ”‚      â”‚ â€¢ expires_at    â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                 â”‚
â”‚                                â–¼                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚ DeferredReevaluator â”‚                       â”‚
â”‚                    â”‚    (batch job)      â”‚                       â”‚
â”‚                    â”‚                     â”‚                       â”‚
â”‚                    â”‚ PÃ©riodiquement:     â”‚                       â”‚
â”‚                    â”‚ 1. RÃ©cupÃ©rer DEFER  â”‚                       â”‚
â”‚                    â”‚ 2. Recalculer score â”‚                       â”‚
â”‚                    â”‚ 3. Promouvoirâ†’AUTO  â”‚                       â”‚
â”‚                    â”‚    ou Expirerâ†’REJECTâ”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Blocking Strategy (Ã‰viter O(NÂ²))

> **Point critique** : Sans blocking intelligent, Phase 2 devient O(NÂ²) dÃ©guisÃ©. MÃªme avec Qdrant top-K, on risque de scorer trop de paires et le coÃ»t cross-encoder explose.

Le blocking **rÃ©duit l'espace de dÃ©cision** AVANT le scoring coÃ»teux.

```yaml
Blocking Strategies:

  # Niveau 1 : Filtre lexical rapide (O(1) lookup)
  lexical_block:
    same_first_token:
      description: "MÃªme premier mot aprÃ¨s normalisation"
      example: "Data Protection" â†” "Data Controller"
      cost: "trÃ¨s faible"

    acronym_family:
      description: "Acronyme et ses expansions connues"
      example: "GDPR" dans mÃªme block que "General Data Protection Regulation"
      implementation: "Lookup table acronymes â†’ expansions"

    normalized_prefix:
      description: "MÃªme prÃ©fixe normalisÃ© (3+ chars)"
      example: "Ransomware" â†” "Ransomware Attack"

  # Niveau 2 : Filtre structurel (graph-based)
  structural_block:
    same_document_family:
      description: "Concepts d'une mÃªme famille documentaire"
      example: "Concepts de GDPR Chapter 1, 2, 3..."
      signal: "Forte probabilitÃ© de relation si mÃªme source"

    same_domain_context:
      description: "Concepts du mÃªme Domain Context"
      example: "privacy_regulation" concepts ensemble
      implementation: "Tag domain_context sur CanonicalConcept"

  # Niveau 3 : Filtre sÃ©mantique cheap (embedding)
  semantic_block:
    embedding_threshold:
      description: "Seuil bas pour candidats Qdrant"
      threshold: 0.75  # Cheap filter, pas le scoring final
      purpose: "Ã‰liminer paires clairement non-liÃ©es"
      note: "Ce n'est PAS le seuil de merge, juste un prÃ©-filtre"

  # Ordre d'application (pipeline)
  blocking_pipeline:
    1. lexical_block      # Le plus rapide
    2. structural_block   # Graph lookup
    3. semantic_block     # Qdrant top-K avec threshold 0.75

  # MÃ©triques blocking
  blocking_metrics:
    reduction_target: "> 95%"  # RÃ©duire 95% des paires avant scoring
    false_negative_tolerance: "< 1%"  # Accepter de rater 1% pour performance
```

**Exemple chiffrÃ©** :
- 10,000 concepts â†’ 50M paires possibles (O(NÂ²))
- AprÃ¨s blocking : ~50,000 paires candidates (0.1%)
- Cross-encoder sur 50K = viable
- Cross-encoder sur 50M = impossible

### 5.3 Contraintes Dures (Non NÃ©gociables)

```yaml
Entity Resolution Constraints:

  no_embedding_only_merge:
    description: "Pas de merge basÃ© SEULEMENT sur embedding + cross-encoder"
    minimum_required: "surface_form match OU acronym_expansion OU definition_match"

  no_transitive_auto_merge:
    description: "Si A~B et B~C, ne pas dÃ©duire A=C automatiquement"
    rule: "Chaque paire Ã©valuÃ©e indÃ©pendamment"

  type_compatibility:
    description: "Ne jamais comparer types incompatibles"
    rule: "ENTITYâ†”ENTITY, CONCEPTâ†”CONCEPT, pas ROLEâ†”DOCUMENT"

  provenance_mandatory:
    description: "Tout merge doit Ãªtre traÃ§able"
    stored: ["merged_from", "merge_reason", "merge_method", "merge_timestamp"]
```

### 5.3 Structure de DonnÃ©es : DeferredMergeCandidate

```python
class DeferredMergeCandidate:
    pair_id: str                    # Hash unique de la paire
    concept_a_id: str
    concept_b_id: str
    concept_type: str               # Type commun

    # Scores
    similarity_score: float         # Cross-encoder
    signal_breakdown: Dict[str, float]  # Score par signal

    # MÃ©tadonnÃ©es
    created_at: datetime
    last_evaluated_at: datetime
    evaluation_count: int           # Nombre de rÃ©Ã©valuations

    # Signaux accumulÃ©s
    doc_count_a: int                # Docs oÃ¹ A apparaÃ®t
    doc_count_b: int                # Docs oÃ¹ B apparaÃ®t
    shared_surface_forms: int       # Surface forms partagÃ©es (alias communs)

    # Expiration
    expires_at: datetime            # Auto-REJECT aprÃ¨s cette date

    # Status
    status: Literal["DEFER", "AUTO", "REJECT", "EXPIRED"]
```

---

## 6. Phase 3 : Relation Discovery Cross-Document

### 6.1 PrÃ©requis

Phase 3 ne s'exÃ©cute que sur un graphe "propre" (post Phase 2).

### 6.2 Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 RELATION DISCOVERY PIPELINE                      â”‚
â”‚            (Post Phase 2 - graphe "propre")                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ CandidateGeneratorâ”‚                                           â”‚
â”‚  â”‚                  â”‚  1. Concepts isolÃ©s (degree < N)           â”‚
â”‚  â”‚                  â”‚  2. Embedding proximity (Qdrant top-K)     â”‚
â”‚  â”‚                  â”‚  3. Type compatibility matrix              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚ Paires (concept_A, concept_B)                        â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚EvidenceRetriever â”‚  OBLIGATOIRE - pas de lien sans preuve     â”‚
â”‚  â”‚                  â”‚                                            â”‚
â”‚  â”‚  Types d'evidence (par force):                                â”‚
â”‚  â”‚  1. CO_PRESENCE (score 1.0)                                   â”‚
â”‚  â”‚     â†’ A et B dans le mÃªme chunk                               â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  2. NORMATIVE_REFERENCE (score 0.95)                          â”‚
â”‚  â”‚     â†’ A cite explicitement B                                  â”‚
â”‚  â”‚     â†’ Patterns: "defined in", "pursuant to", "under"          â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  3. PATH_EVIDENCE (score 0.80)                                â”‚
â”‚  â”‚     â†’ A...X...B dans le mÃªme doc (chaÃ®ne â‰¤3 hops)             â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  4. CROSS_DOC_PATH (score 0.70)                               â”‚
â”‚  â”‚     â†’ Doc A: Aâ†’X, Doc B: Xâ†’B                                  â”‚
â”‚  â”‚     â†’ NÃ©cessite validation LLM stricte                        â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  5. EMBEDDING_ONLY (score 0.0)                                â”‚
â”‚  â”‚     â†’ SimilaritÃ© sans preuve textuelle                        â”‚
â”‚  â”‚     â†’ SKIP (pas de relation crÃ©Ã©e)                            â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  Si aucune evidence â‰¥ 0.70 â†’ SKIP cette paire                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚ Paires + evidence_objects                            â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  LLMValidator    â”‚  RÃ´le: VALIDATOR + LABELER                 â”‚
â”‚  â”‚                  â”‚  PAS gÃ©nÃ©rateur de relations               â”‚
â”‚  â”‚                  â”‚                                            â”‚
â”‚  â”‚  Prompt strict:                                               â”‚
â”‚  â”‚  "Voici 2 concepts et des extraits oÃ¹ ils apparaissent.       â”‚
â”‚  â”‚   Existe-t-il une relation factuelle entre eux ?              â”‚
â”‚  â”‚   Si oui, quel type parmi: [SET FERMÃ‰]                        â”‚
â”‚  â”‚   Si non, rÃ©ponds 'NO_RELATION'"                              â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  Set fermÃ© initial (Core):                                    â”‚
â”‚  â”‚  REQUIRES, ENABLES, PART_OF, APPLIES_TO, DEFINES              â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  Set Ã©tendu (exploration/annotation):                         â”‚
â”‚  â”‚  + DEPENDS_ON, PREVENTS, CAUSES, SUPERSEDES, RELATED_TO       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  RelationWriter  â”‚                                            â”‚
â”‚  â”‚                  â”‚  RawAssertion avec:                        â”‚
â”‚  â”‚                  â”‚  â€¢ origin = "discovery"                    â”‚
â”‚  â”‚                  â”‚  â€¢ evidence_type = "CO_PRESENCE|PATH|..."  â”‚
â”‚  â”‚                  â”‚  â€¢ evidence_chunk_ids = [...]              â”‚
â”‚  â”‚                  â”‚  â€¢ evidence_doc_ids = [...]                â”‚
â”‚  â”‚                  â”‚  â€¢ maturity = CANDIDATE                    â”‚
â”‚  â”‚                  â”‚  â€¢ confidence = LLM score                  â”‚
â”‚  â”‚                  â”‚  â€¢ validation_method = "llm_gpt4o"         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 Contraintes Dures (Non NÃ©gociables)

```yaml
Relation Discovery Constraints:

  evidence_mandatory:
    description: "Pas de relation cross-doc sans evidence"
    minimum_evidence_score: 0.70

  llm_is_validator:
    description: "LLM valide et labellise, ne gÃ©nÃ¨re pas"
    rule: "Evidence d'abord, LLM ensuite"

  closed_relation_set:
    description: "Types de relations contrÃ´lÃ©s"
    core_set: [REQUIRES, ENABLES, PART_OF, APPLIES_TO, DEFINES]
    extended_set: [DEPENDS_ON, PREVENTS, CAUSES, SUPERSEDES, RELATED_TO]
    rule: "Core en production, Extended en exploration"

  related_to_cap:
    description: "Limiter les relations gÃ©nÃ©riques"
    rule: "RELATED_TO < 20% des relations crÃ©Ã©es"
```

### 6.4 Choix Architectural : PrÃ©cision > Recall

> **Choix assumÃ©** : On privilÃ©gie la **prÃ©cision** Ã  la **complÃ©tude**.

```yaml
Precision_over_Recall:
  statement: |
    Le seuil evidence â‰¥ 0.70 peut sous-connecter le graphe sur certains domaines.
    Certaines relations rÃ©elles mais structurelles (non explicites dans le texte)
    ne seront pas dÃ©couvertes.

  rationale:
    - Faux positifs = bruit difficile Ã  nettoyer
    - Faux nÃ©gatifs = relations manquantes, dÃ©tectables plus tard
    - Un graphe prÃ©cis est exploitable, un graphe bruitÃ© ne l'est pas
    - L'utilisateur peut toujours suggÃ©rer des relations manuellement

  trade_off:
    precision_target: "> 90%"
    recall_accepted: "60-70%"  # Acceptable pour un systÃ¨me autonome

  mitigations:
    - Relations structurelles lÃ©gÃ¨res (MENTIONED_IN, CO_OCCURS_IN_DOC) crÃ©Ã©es automatiquement
    - UI permet suggestion de relations par l'utilisateur (oracle ponctuel)
    - Phase 3 peut Ãªtre re-exÃ©cutÃ©e quand nouveaux documents arrivent
    - Ajuster threshold_evidence Ã  la baisse si domaine bien connu
```

Ce choix est **explicite et assumÃ©**, pas un bug ou une limitation.

### 6.5 Structure Evidence Object

```python
class EvidenceObject:
    evidence_type: Literal[
        "CO_PRESENCE",
        "NORMATIVE_REFERENCE",
        "PATH_EVIDENCE",
        "CROSS_DOC_PATH"
    ]

    strength_score: float           # 0.70 - 1.0

    # Sources
    chunk_ids: List[str]
    doc_ids: List[str]

    # Contenu
    snippets: List[str]             # Extraits textuels
    path_description: Optional[str]  # Pour PATH_EVIDENCE

    # MÃ©thode
    retrieval_method: str           # "qdrant_search", "graph_traversal", etc.
```

---

## 7. Outils et Librairies

### 7.1 Verdict par Outil

| Outil | Verdict | Usage | Timing |
|-------|---------|-------|--------|
| **Qdrant** | âœ… DÃ©jÃ  en place | Candidate generation (top-K) | Maintenant |
| **Cross-encoder** | âœ… Ã€ ajouter | PairSimilarityScorer | Phase 2 |
| **Neo4j GDS** | â³ Plus tard | Node Similarity, Link Prediction | Quand graphe densifiÃ© |
| **Splink/Dedupe** | ðŸ¤” Optionnel | Entity Resolution structurÃ©e | Si on "records-ifie" les concepts |

### 7.2 Neo4j GDS : Quand et Comment

```yaml
Neo4j GDS:
  prerequisite: "Graphe suffisamment connectÃ©"

  early_use_possible:
    - Relations structurelles simples: MENTIONED_IN, CO_OCCURS_IN_DOC
    - Permet d'avoir un voisinage exploitable sans inventer des relations sÃ©mantiques

  later_use:
    - Node Similarity (Jaccard/Overlap sur voisinages)
    - Link Prediction pipelines (si exemples gold disponibles)

  not_a_silver_bullet:
    - Ne "comprend" pas le texte
    - Fournit candidats et scoring structurel
    - La vÃ©ritÃ© reste: evidence in text + provenance
```

---

## 8. CritÃ¨res d'Acceptation

### 8.1 PropriÃ©tÃ© Fondamentale

> **Aucune dette opÃ©rationnelle humaine**

### 8.2 MÃ©triques

```yaml
Metrics:

  defer_queue_bounded:
    description: "Taille file DEFER ne croÃ®t pas indÃ©finiment"
    rule: "Expire aprÃ¨s 30 jours OU 100 nouveaux docs sans changement"
    target: "< 1000 paires DEFER par tenant"

  auto_rate:
    description: "Taux de dÃ©cisions automatiques"
    target: "> 70%"

  defer_auto_resolution:
    description: "Taux de DEFER rÃ©solus automatiquement (â†’AUTO ou â†’EXPIRED)"
    target: "> 90%"

  human_intervention:
    description: "Volume d'intervention humaine"
    target: "< 20/semaine (optionnel, systÃ¨me fonctionne sans)"

  system_autonomous:
    description: "SystÃ¨me utile sans AUCUNE review humaine"
    target: "OUI"
```

### 8.3 QualitÃ©

```yaml
Quality Metrics:

  merge_precision:
    description: "PrÃ©cision des AUTO merges"
    measurement: "Ã‰chantillonnage + validation manuelle pÃ©riodique"
    target: "> 95%"

  relation_precision:
    description: "PrÃ©cision des relations dÃ©couvertes"
    measurement: "Ã‰chantillonnage + validation manuelle pÃ©riodique"
    target: "> 90%"

  evidence_coverage:
    description: "% de relations avec evidence textuelle"
    target: "100% (contrainte dure)"
```

---

## 9. RÃ©sumÃ© ExÃ©cutif

### Ce qui existe dÃ©jÃ  dans OSMOSE

- âœ… Extraction NER (concepts)
- âœ… Relations intra-document (RawAssertion)
- âœ… Normalisation pour dÃ©dup intra-doc (`normalize_canonical_key`)
- âœ… Domain Context (extensibilitÃ© par domaine)
- âœ… Maturity system (CANDIDATE, VALIDATED, CONFLICTING)
- âœ… Qdrant pour embeddings

### Ce qui manque

- âŒ Entity Resolution cross-document (Phase 2)
- âŒ Relation Discovery cross-document (Phase 3)
- âŒ Identity Policy par type
- âŒ ModÃ¨le AUTO/DEFER/REJECT
- âŒ Cross-encoder pour scoring pairwise
- âŒ DeferredReevaluator (batch job)

### Ordre d'implÃ©mentation recommandÃ©

1. **Phase 0** : DÃ©finir Identity Schema par type gÃ©nÃ©rique
2. **Phase 2** : Entity Resolution (CandidateFinder â†’ Scorer â†’ Router â†’ Resolver)
3. **Phase 3** : Relation Discovery (post Phase 2 uniquement)

### Principes Non NÃ©gociables

1. **Domain-agnostic** : Types gÃ©nÃ©riques, Domain Context pour extension
2. **Evidence-first** : Pas de merge/relation sans preuve explicable
3. **Autonome** : DEFER â‰  queue humaine, auto-calibration
4. **TraÃ§able** : Provenance sur tout (merge_reason, evidence, origin)
5. **BornÃ©** : Aucune file d'attente infinie

---

## 10. Questions Ouvertes pour Review

### RÃ©solues par Review ChatGPT v1

1. ~~Blocking strategy manquante~~ â†’ âœ… Section 5.2 ajoutÃ©e
2. ~~co_occurrence = signal d'identitÃ©~~ â†’ âœ… RetirÃ© de Phase 2, rÃ©servÃ© Phase 3
3. ~~Policy par type trop plate~~ â†’ âœ… Sous-types optionnels ajoutÃ©s (Niveau 1b)
4. ~~Auto-calibration conceptuelle~~ â†’ âœ… Section 4.6 formalisÃ©e avec cadence/garde-fous
5. ~~PrÃ©cision vs Recall implicite~~ â†’ âœ… Section 6.4 explicite le choix assumÃ©

### Questions restantes

1. Les types gÃ©nÃ©riques + sous-types optionnels sont-ils suffisants comme base ?
   â†’ **RÃ©ponse probable** : Oui, valider en implÃ©mentation

2. Les seuils par dÃ©faut (auto=0.98, defer=0.85) sont-ils raisonnables ?
   â†’ **RÃ©ponse** : Oui, avec auto-calibration qui ajustera

3. Faut-il un mÃ©canisme de "promotion" des relations Extended â†’ Core ?
   â†’ **Ã€ dÃ©cider** aprÃ¨s observation en production

4. Quelle granularitÃ© pour le blocking ? (per-type, per-domain, global)
   â†’ **Suggestion** : per-type avec override par Domain Context

---

## 11. Scope v1 Production

> **Objectif** : Solution dÃ©ployable en production, pas un MVP minimal.

### 11.1 Obligatoire v1

| Composant | Description | CriticitÃ© |
|-----------|-------------|-----------|
| **Identity Schema** | 6 types gÃ©nÃ©riques avec seuils par type | Fondation |
| **Blocking Pipeline** | Lexical (acronym, prefix) + Semantic (embedding > 0.75) | Performance O(NÂ²) â†’ O(N) |
| **PairSimilarityScorer** | Cross-encoder + signaux lexicaux (exact_match, acronym_expansion) | QualitÃ© scoring |
| **Cache Scores Redis** | Cache des scores pairwise pour Ã©viter re-calcul | CoÃ»t opÃ©rationnel |
| **Decision Router** | AUTO/DEFER/REJECT avec seuils fixes par type | Architecture dÃ©cision |
| **DeferredStore** | Stockage DEFER (Neo4j ou Redis) avec TTL 30 jours | Gestion temporalitÃ© |
| **DeferredReevaluator** | Batch job quotidien minimum | **CRITIQUE** - Ã‰vite accumulation infinie |
| **MÃ©triques** | Logs structurÃ©s + endpoint `/api/entity-resolution/stats` | Monitoring production |
| **Provenance** | TraÃ§abilitÃ© complÃ¨te (merge_reason, evidence, timestamps) | AuditabilitÃ© |

### 11.2 DiffÃ©rÃ© (avec justification)

| Composant | Justification du report | Condition d'activation |
|-----------|------------------------|------------------------|
| **Sous-types optionnels** | NÃ©cessite observation des patterns rÃ©els en production. Les types gÃ©nÃ©riques fonctionnent, les sous-types optimisent. | AprÃ¨s 2-4 semaines de data, quand patterns identifiÃ©s |
| **Blocking structural** | Optimisation. Lexical + semantic rÃ©duisent dÃ©jÃ  >90% des paires. | Quand "familles documentaires" identifiÃ©es |
| **Auto-calibration** | Impossible sans historique. Seuils fixes bien choisis en v1. | AprÃ¨s 4-6 semaines de dÃ©cisions loguÃ©es |
| **Dashboard graphique** | Logs structurÃ©s + API stats suffisent pour monitoring initial. | Quand besoin de visualisation avancÃ©e |

### 11.3 Seuils v1 (fixes, par type)

```yaml
# Seuils initiaux conservateurs (ajustables manuellement aprÃ¨s observation)
ENTITY:
  threshold_auto: 0.98
  threshold_defer: 0.85

CONCEPT:
  threshold_auto: 0.99  # Ultra-restrictif
  threshold_defer: 0.80

ROLE:
  threshold_auto: 0.95
  threshold_defer: 0.80

ORGANIZATION:
  threshold_auto: 0.95
  threshold_defer: 0.85

DOCUMENT:
  threshold_auto: 0.98
  threshold_defer: 0.85

STANDARD:
  threshold_auto: 0.95
  threshold_defer: 0.85
```

### 11.4 Ordre d'implÃ©mentation recommandÃ©

```
1. Infrastructure
   â”œâ”€â”€ DeferredStore (Redis ou Neo4j node type)
   â”œâ”€â”€ Cache scores Redis
   â””â”€â”€ Endpoint /api/entity-resolution/stats

2. Core Pipeline
   â”œâ”€â”€ CandidateFinder (blocking lexical + semantic)
   â”œâ”€â”€ PairSimilarityScorer (cross-encoder + signaux)
   â””â”€â”€ IdentityDecisionRouter (AUTO/DEFER/REJECT)

3. Resolution
   â”œâ”€â”€ IdentityResolver (merge avec provenance)
   â””â”€â”€ DeferredReevaluator (batch job)

4. IntÃ©gration
   â”œâ”€â”€ Hook post-ingestion (dÃ©clencher Entity Resolution)
   â””â”€â”€ Logs structurÃ©s + mÃ©triques
```

---

*Document finalisÃ© aprÃ¨s review croisÃ©e Claude Code / ChatGPT v2*
*ValidÃ© pour implÃ©mentation Phase 2.12 - v1 Production*
