# ‚ö†Ô∏è MIGRATION POST-IMPORT : Qdrant 1024D ‚Üí 768D

**Date**: 2025-11-22
**Statut**: IMPORT EN COURS - NE PAS EX√âCUTER MAINTENANT
**Action required**: Apr√®s fin de l'import actuel

---

## üéØ Objectif

Migrer les collections Qdrant de **1024D** (multilingual-e5-large) vers **768D** (text-multilingual-embedding-002 Vertex AI) pour :
- ‚úÖ **R√©duire co√ªts embeddings de 80.8%** (Vertex AI vs OpenAI)
- ‚úÖ **Optimiser stockage** (-25%)
- ‚úÖ **Am√©liorer performance recherche** (-20% latence)

---

## ‚ö†Ô∏è IMPORTANT - ATTENDEZ FIN DE L'IMPORT

**NE PAS EX√âCUTER CES COMMANDES MAINTENANT**

L'import actuel utilise encore les collections 1024D. La migration vers 768D n√©cessite :
1. Purge compl√®te des collections Qdrant
2. Modification config dimensions
3. Re-embedding de tout le corpus

**Timing** :
- ‚úÖ Modifications code : FAITES (sans impact import actuel)
- ‚è∏Ô∏è Migration dimensions : **APR√àS l'import** en cours
- ‚è∏Ô∏è Re-embedding : **APR√àS l'import** en cours

---

## üìã Proc√©dure de Migration (Post-Import)

### √âtape 1 : V√©rifier Fin de l'Import

```bash
# V√©rifier qu'aucun worker n'est actif
docker exec knowbase-worker rq info

# V√©rifier statut import
curl http://localhost:8000/documents/status

# Attendre que tous les jobs soient "completed"
```

### √âtape 2 : Backup (Optionnel mais Recommand√©)

```bash
# Snapshot Qdrant avant purge (au cas o√π)
curl -X POST "http://localhost:6333/collections/knowbase/snapshots"
curl -X POST "http://localhost:6333/collections/concepts_proto/snapshots"

# Les snapshots seront dans /qdrant/storage/snapshots/
```

### √âtape 3 : Configuration Vertex AI

**A. Cr√©er Service Account Google Cloud**

1. Aller sur [Google Cloud Console](https://console.cloud.google.com)
2. Cr√©er projet ou utiliser existant
3. Activer Vertex AI API
4. Cr√©er Service Account avec r√¥le "Vertex AI User"
5. T√©l√©charger cl√© JSON

**B. Configurer credentials**

```bash
# Copier cl√© JSON dans le projet
cp ~/Downloads/service-account-key.json C:/Projects/SAP_KB/config/gcp-service-account.json

# Ajouter au .env
echo "GCP_PROJECT_ID=your-project-id" >> .env
echo "GOOGLE_APPLICATION_CREDENTIALS=/app/config/gcp-service-account.json" >> .env
```

**C. Ajouter volume Docker pour credentials**

Modifier `docker-compose.yml` :

```yaml
services:
  app:
    volumes:
      - ./config:/app/config  # Ajouter si pas d√©j√† pr√©sent
```

### √âtape 4 : Modifier Configuration Dimensions

**A. Modifier `src/knowbase/semantic/config.py`** (ligne 139)

```python
# AVANT
vector_size: int = 1024  # multilingual-e5-large

# APR√àS
vector_size: int = 768  # text-multilingual-embedding-002 (Vertex AI)
```

**B. Installer SDK Vertex AI**

```bash
# Depuis le conteneur app
docker exec knowbase-app pip install google-cloud-aiplatform
```

### √âtape 5 : Purger Collections Qdrant

```bash
# Purge compl√®te (collections 1024D incompatibles avec 768D)
docker exec knowbase-app python scripts/purge_system.py --yes
```

V√©rifier purge :
```bash
curl "http://localhost:6333/collections/knowbase"
# Devrait retourner: {"status":"error","message":"collection not found"}
```

### √âtape 6 : Recr√©er Infrastructure 768D

```bash
# Recr√©er collections Qdrant + indexes Neo4j
docker exec knowbase-app python scripts/reset_proto_kg.py --full

# V√©rifier nouvelles dimensions
curl "http://localhost:6333/collections/knowbase" | jq '.result.config.params.vectors.size'
# Devrait retourner: 768
```

### √âtape 7 : Re-importer Documents

**Option A : Re-import complet** (recommand√©)

```bash
# Les fichiers .knowcache.json sont pr√©serv√©s
# Seuls les embeddings seront r√©g√©n√©r√©s (via Vertex AI)

# 1. V√©rifier que cache extraction existe
ls data/extraction_cache/*.knowcache.json

# 2. Relancer import
# Les documents utiliseront le cache pour extraction LLM
# Embeddings seront g√©n√©r√©s via Vertex AI (768D)
```

**Option B : Migration manuelle via script**

```python
# scripts/migrate_to_768d.py (√† cr√©er si besoin)
# Lit cache extraction existant
# R√©g√©n√®re embeddings 768D via Vertex AI
# R√©injecte dans Qdrant + Neo4j
```

### √âtape 8 : Validation

**A. V√©rifier dimensions Qdrant**

```bash
curl "http://localhost:6333/collections/knowbase" | jq '.result.config.params.vectors'

# Attendu:
# {
#   "size": 768,
#   "distance": "Cosine"
# }
```

**B. Tester recherche s√©mantique**

```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "SAP S/4HANA Cloud authentication mechanisms",
    "top_k": 5
  }'

# V√©rifier que r√©sultats sont coh√©rents
```

**C. V√©rifier embeddings Vertex AI**

```bash
# Chercher dans logs app
docker logs knowbase-app --tail 100 | grep "VertexAIEmbedder"

# Devrait voir:
# [OSMOSE:VertexAIEmbedder] ‚úÖ Encoded 450 texts ‚Üí (450, 768)
```

**D. Comparer qualit√© recherche**

```bash
# Tester quelques requ√™tes types
# Comparer recall@5 vs baseline OpenAI 1024D (si data dispo)
```

---

## üîÑ Rollback (Si Probl√®me)

**Si migration 768D pose probl√®me** :

```bash
# 1. Revenir config 1024D
# src/knowbase/semantic/config.py : vector_size = 1024

# 2. Purge + recr√©ation
docker exec knowbase-app python scripts/purge_system.py --yes
docker exec knowbase-app python scripts/reset_proto_kg.py --full

# 3. Re-import avec OpenAI embeddings
# Modifier cloud_embeddings.py pour r√©utiliser OpenAI text-embedding-3-large

# 4. Re-importer documents
# Temps: ~1-2h selon volume
```

---

## üìä Estimations Temps et Co√ªts

### Temps Migration

| √âtape | Dur√©e |
|-------|-------|
| Backup Qdrant | 5 min |
| Config + purge | 5 min |
| Recr√©ation infra | 2 min |
| Re-import 1000 docs | 15 min (embeddings Vertex AI) |
| Validation | 10 min |
| **TOTAL** | **~40 min** |

### Co√ªts Re-embedding

**Pour 1000 documents (13M chunks)** :

| Provider | Co√ªt |
|----------|------|
| OpenAI text-embedding-3-large | $715 |
| Vertex AI text-multilingual-embedding-002 | **$138** |
| **√âconomie one-time** | **-$577 (-80.8%)** |

**ROI** : Break-even d√®s 8 documents post-migration

---

## ‚úÖ Checklist Migration

**Avant de commencer** :
- [ ] Import actuel termin√© (v√©rifier `docker logs knowbase-worker`)
- [ ] Service Account GCP cr√©√© + cl√© JSON t√©l√©charg√©e
- [ ] GCP_PROJECT_ID + GOOGLE_APPLICATION_CREDENTIALS dans .env
- [ ] SDK Vertex AI install√© (`pip install google-cloud-aiplatform`)
- [ ] Backup Qdrant effectu√© (optionnel)

**Modifications config** :
- [ ] `src/knowbase/semantic/config.py` : `vector_size = 768`
- [ ] Vertex AI credentials mont√©es dans Docker

**Migration** :
- [ ] Purge Qdrant (`scripts/purge_system.py --yes`)
- [ ] Recr√©ation infra 768D (`scripts/reset_proto_kg.py --full`)
- [ ] V√©rification dimensions (`curl collections/knowbase`)
- [ ] Re-import documents (utilise cache extraction)

**Validation** :
- [ ] Dimensions Qdrant = 768
- [ ] Recherche s√©mantique fonctionne
- [ ] Logs montrent Vertex AI embeddings
- [ ] Qualit√© recherche acceptable (tests manuels)

---

## üìö Ressources

- [Vertex AI Text Embeddings Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)
- [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)
- [Analyse Compl√®te 768D vs 3072D](./GEMINI_MIGRATION_AND_EMBEDDINGS_DIMENSIONS_ANALYSIS.md)
- [Qdrant Migration Guide](https://qdrant.tech/documentation/guides/migrate/)

---

**üö® RAPPEL : NE PAS EX√âCUTER MAINTENANT - ATTENDEZ FIN DE L'IMPORT EN COURS**

Une fois l'import termin√©, suivre cette proc√©dure √©tape par √©tape pour migrer vers 768D Vertex AI.
