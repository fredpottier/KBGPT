# ğŸ§  StratÃ©gie de Canonicalisation Auto-Apprenante - Phase 1.5

**Date**: 2025-10-16
**Objectif**: Minimiser intervention admin pour canonicalisation/rationalisation
**Approche**: Hybride intelligent (rÃ¨gles + fuzzy + LLM ponctuel + auto-learning)

---

## ğŸ¯ ProblÃ©matique IdentifiÃ©e

### Workflow Historique (Intervention Admin Lourde)

```
1. Import documents
   â””â”€> Extraction brute â†’ Neo4j CanonicalConcepts
   â””â”€> "SAP" Ã— 5, "S/4HANA PCE", "S/4 Private Cloud", etc.

2. Admin Frontend (page Normalisation)
   â””â”€> Visualise toutes les entitÃ©s brutes
   â””â”€> MANUELLEMENT:
       - Canonicalise: "S/4HANA PCE" â†’ "SAP S/4HANA Cloud, Private Edition"
       - Rationalise (merge): "S/4HANA PCE" + "S/4 Private Cloud" â†’ mÃªme entitÃ©
   â””â”€> Sauvegarde ontologie â†’ OntologyEntity + OntologyAlias

3. Prochains imports
   â””â”€> EntityNormalizerNeo4j lookup â†’ Trouve ontologie
   â””â”€> Concepts correctement canonicalisÃ©s
```

**ProblÃ¨me**: Admin doit SYSTÃ‰MATIQUEMENT intervenir aprÃ¨s chaque import de nouveau domaine.

**Objectif Phase 1.5**: Automatiser 80-90% de la canonicalisation/rationalisation, admin intervient seulement pour edge cases.

---

## ğŸ§© Composants Existants (RÃ©utilisables)

### 1. EntityNormalizerNeo4j (Lookup Ontologie)
**Fichier**: `src/knowbase/ontology/entity_normalizer_neo4j.py`

```python
def normalize_entity_name(
    raw_name: str,
    entity_type_hint: Optional[str] = None,
    tenant_id: str = "default"
) -> Tuple[Optional[str], str, Optional[str], bool]:
    """
    Lookup ontologie Neo4j via index normalized.

    Returns:
        (entity_id, canonical_name, entity_type, is_cataloged)
    """
```

**FonctionnalitÃ©s**:
- âœ… Lookup O(1) via index Neo4j normalized
- âœ… Correction automatique type si LLM se trompe
- âœ… Support multi-tenant
- âœ… Domaine-agnostic (pas de fichiers statiques)

**Utilisation**: Lookup avant crÃ©ation CanonicalConcept pour trouver ontologie existante.

---

### 2. FuzzyMatcherService (SimilaritÃ© Textuelle)
**Fichier**: `src/knowbase/api/services/fuzzy_matcher_service.py`

```python
def match_entity_to_ontology(
    entity_name: str,
    ontology_entry: Dict
) -> Tuple[bool, float, str]:
    """
    Fuzzy matching via fuzzywuzzy.

    Seuils:
    - >= 90%: Auto-match (haute confiance)
    - 75-89%: Match suggÃ©rÃ© (confirmation manuelle)
    - < 75%: Pas de match
    """
```

**FonctionnalitÃ©s**:
- âœ… SimilaritÃ© Levenshtein (fuzz.ratio)
- âœ… Test canonical_name + tous aliases
- âœ… Seuils adaptatifs (auto vs manuel)
- âœ… Preview merge_groups pour admin

**Utilisation**: DÃ©tecter doublons/variantes AVANT crÃ©ation CanonicalConcept.

---

### 3. OntologySaver (Persistance Ontologie)
**Fichier**: `src/knowbase/ontology/ontology_saver.py`

```python
def save_ontology_to_neo4j(
    merge_groups: List[Dict],
    entity_type: str,
    tenant_id: str = "default",
    source: str = "llm_generated"
):
    """
    Sauvegarde ontologie validÃ©e dans Neo4j.

    Workflow:
    1. CrÃ©er OntologyEntity (canonical_name, entity_id)
    2. CrÃ©er OntologyAlias pour chaque variante
    3. Lien OntologyEntity -[:HAS_ALIAS]-> OntologyAlias
    """
```

**FonctionnalitÃ©s**:
- âœ… Stockage OntologyEntity + OntologyAlias
- âœ… Support source = "llm_generated" | "manual" | "auto_learned"
- âœ… Auto-merge aliases

**Utilisation**: Sauvegarder automatiquement les normalisations dÃ©couvertes.

---

### 4. EmbeddingsContextualScorer (SimilaritÃ© SÃ©mantique)
**Fichier**: `src/knowbase/agents/gatekeeper/embeddings_contextual_scorer.py`

```python
# ModÃ¨le: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
# FonctionnalitÃ©s:
# - Embeddings multilingues (FR/EN/DE/ES)
# - Cosine similarity entre concepts
# - DÃ©tection rÃ´le (PRIMARY, COMPETITOR, SECONDARY)
```

**FonctionnalitÃ©s**:
- âœ… Embeddings sÃ©mantiques multilingues
- âœ… DÃ©tection similaritÃ© contextuelle
- âœ… <200ms, 100% offline, $0 coÃ»t

**Utilisation**: DÃ©tecter concepts sÃ©mantiquement proches mÃªme si orthographe diffÃ©rente.

---

## ğŸš€ StratÃ©gie Hybride Auto-Apprenante (ProposÃ©e)

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase A: Import Real-Time (AUTOMATIQUE)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Extraction concepts â†’ ProtoConcepts                          â”‚
â”‚ 2. Pour chaque ProtoConcept:                                    â”‚
â”‚    a) SÃ©lection canonicalisation (heuristique)                  â”‚
â”‚    b) Lookup ontologie existante (EntityNormalizerNeo4j)        â”‚
â”‚    c) Fuzzy matching variants (FuzzyMatcherService â‰¥90%)        â”‚
â”‚    d) LLM lÃ©ger canonicalization (GPT-4o-mini, ~$0.0001/call)  â”‚
â”‚    e) RÃ¨gles heuristiques simples (acronymes, noms propres)    â”‚
â”‚    f) Fallback: Garde tel quel si incertain                    â”‚
â”‚ 3. DÃ©duplication CanonicalConcepts (mÃªme canonical_name)        â”‚
â”‚ 4. Promotion Proto â†’ Canonical avec canonical_name normalisÃ©    â”‚
â”‚                                                                  â”‚
â”‚ âœ… 90-92% automatiquement corrects (avec LLM lÃ©ger)             â”‚
â”‚ âš ï¸ 8-10% nÃ©cessitent apprentissage (nouveaux domaines)         â”‚
â”‚ ğŸ’° CoÃ»t: ~$0.006/import (60 concepts Ã— GPT-4o-mini)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase B: Post-Import Auto-Learning (PONCTUEL - 1x/semaine)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. DÃ©tecter concepts "non cataloguÃ©s" accumulÃ©s                 â”‚
â”‚ 2. Clustering automatique:                                      â”‚
â”‚    - Fuzzy matching (75-89% similaritÃ©)                         â”‚
â”‚    - Embeddings similarity (cosine â‰¥0.85)                       â”‚
â”‚ 3. LLM batch normalization (GPT-4o-mini):                       â”‚
â”‚    - Input: Clusters dÃ©tectÃ©s                                   â”‚
â”‚    - Output: canonical_name + merge_groups                      â”‚
â”‚    - CoÃ»t: ~$0.50 pour 200 concepts                            â”‚
â”‚ 4. Sauvegarde automatique ontologie (OntologySaver)            â”‚
â”‚ 5. Logging pour review admin (optionnel)                       â”‚
â”‚                                                                  â”‚
â”‚ âœ… +20-30% concepts normalisÃ©s automatiquement                  â”‚
â”‚ âš ï¸ 0-5% edge cases nÃ©cessitent validation admin                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase C: Admin Review (OPTIONNEL - si doute)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Frontend Admin affiche concepts "low confidence"             â”‚
â”‚ 2. Admin valide/corrige merge_groups                            â”‚
â”‚ 3. Sauvegarde ontologie avec source="manual"                    â”‚
â”‚                                                                  â”‚
â”‚ âœ… Admin intervient seulement si nÃ©cessaire (5-10% cas)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Algorithme DÃ©taillÃ© - Phase A (Import Real-Time)

### Modification Gatekeeper._promote_concepts_tool()

**Fichier**: `src/knowbase/agents/gatekeeper/gatekeeper.py`

```python
def _promote_concepts_tool(self, tool_input: PromoteConceptsInput) -> ToolOutput:
    """
    Promeut concepts avec canonicalisation auto-apprenante.

    Workflow:
    1. SÃ©lection: Concepts "importants" uniquement
    2. Normalisation: Lookup ontologie + fuzzy + rÃ¨gles
    3. DÃ©duplication: Ã‰viter doublons CanonicalConcepts
    4. Promotion: Proto â†’ Canonical avec canonical_name normalisÃ©
    5. Auto-learning: Logger concepts non cataloguÃ©s
    """

    concepts = tool_input.concepts
    tenant_id = tool_input.tenant_id

    promoted = []
    canonical_cache = {}  # {canonical_name: canonical_id}
    uncataloged_concepts = []  # Pour auto-learning diffÃ©rÃ©

    for concept in concepts:
        concept_name = concept.get("name", "")
        concept_type = concept.get("type", "Unknown")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 1: DÃ©cider si canonicalisation nÃ©cessaire
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        if not self._should_canonicalize(concept_name, concept_type):
            # Terme basique/langage commun â†’ Garde tel quel
            canonical_name = concept_name.strip()
            is_cataloged = False
            source = "basic_term"

        else:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 2: Tentative normalisation automatique
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

            canonical_name, is_cataloged, source = self._normalize_concept_auto(
                concept_name=concept_name,
                concept_type=concept_type,
                tenant_id=tenant_id
            )

            # Logger concepts non cataloguÃ©s pour auto-learning
            if not is_cataloged:
                uncataloged_concepts.append({
                    "name": concept_name,
                    "type": concept_type,
                    "canonical_name": canonical_name,
                    "segment_id": concept.get("segment_id"),
                    "confidence": concept.get("confidence", 0.0)
                })

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 3: DÃ©duplication CanonicalConcepts
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        if canonical_name in canonical_cache:
            # CanonicalConcept existe dÃ©jÃ  â†’ RÃ©utiliser
            canonical_id = canonical_cache[canonical_name]

            # CrÃ©er ProtoConcept et lier Ã  Canonical existant
            proto_concept_id = self.neo4j_client.create_proto_concept(...)

            self.neo4j_client.link_proto_to_canonical(
                proto_concept_id=proto_concept_id,
                canonical_id=canonical_id
            )

            logger.debug(
                f"âœ… DÃ©dupliquÃ©: '{concept_name}' â†’ Canonical existant '{canonical_name}'"
            )

        else:
            # Nouveau CanonicalConcept â†’ CrÃ©er
            proto_concept_id = self.neo4j_client.create_proto_concept(
                tenant_id=tenant_id,
                concept_name=concept_name,
                concept_type=concept_type,
                segment_id=concept.get("segment_id", "unknown"),
                document_id=concept.get("document_id", "unknown"),
                extraction_method=concept.get("extraction_method", "NER"),
                confidence=concept.get("confidence", 0.0),
                metadata={
                    "original_name": concept_name,
                    "is_cataloged": is_cataloged,
                    "normalization_source": source
                }
            )

            canonical_id = self.neo4j_client.promote_to_published(
                tenant_id=tenant_id,
                proto_concept_id=proto_concept_id,
                canonical_name=canonical_name,
                unified_definition=concept.get("definition", ""),
                quality_score=concept.get("confidence", 0.0),
                metadata={
                    "is_cataloged": is_cataloged,
                    "normalization_source": source
                }
            )

            # Mettre en cache
            canonical_cache[canonical_name] = canonical_id

            if is_cataloged:
                logger.info(
                    f"âœ… CataloguÃ©: '{concept_name}' â†’ '{canonical_name}' "
                    f"(source={source})"
                )
            else:
                logger.debug(
                    f"âš ï¸ Non cataloguÃ©: '{concept_name}' â†’ '{canonical_name}' "
                    f"(Ã  apprendre)"
                )

        promoted.append({
            "concept_id": proto_concept_id,
            "canonical_id": canonical_id,
            "canonical_name": canonical_name,
            "is_cataloged": is_cataloged
        })

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 4: Logger concepts non cataloguÃ©s pour auto-learning
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if len(uncataloged_concepts) > 0:
        self._log_uncataloged_for_learning(
            uncataloged_concepts=uncataloged_concepts,
            tenant_id=tenant_id
        )

        logger.info(
            f"ğŸ“ {len(uncataloged_concepts)} concepts non cataloguÃ©s "
            f"loggÃ©s pour auto-learning"
        )

    return PromoteConceptsOutput(
        success=True,
        message=f"Promoted {len(promoted)} concepts "
                f"({len([p for p in promoted if p['is_cataloged']])} cataloged, "
                f"{len(uncataloged_concepts)} to learn)",
        promoted_concepts=promoted
    )


def _should_canonicalize(self, concept_name: str, concept_type: str) -> bool:
    """
    DÃ©termine si concept doit Ãªtre canonicalisÃ©.

    CritÃ¨res:
    1. Type "important": SOLUTION, PRODUCT, COMPANY, TECHNOLOGY, ACRONYM
    2. OU Nom propre: commence par majuscule + > 1 mot
    3. OU Contient acronyme: mots en MAJUSCULES (SAP, ERP)
    4. OU Contient caractÃ¨res spÃ©ciaux: /, -, _

    Exclure:
    - Concepts gÃ©nÃ©riques: "management", "system", "process"
    - Langage commun: "customer", "data", "report"
    """
    IMPORTANT_TYPES = {
        "SOLUTION", "PRODUCT", "COMPONENT", "MODULE",
        "COMPANY", "VENDOR", "PARTNER",
        "TECHNOLOGY", "PLATFORM", "TOOL", "FRAMEWORK",
        "ACRONYM", "STANDARD", "PROTOCOL", "API"
    }

    # Type important
    if concept_type in IMPORTANT_TYPES:
        return True

    # Nom propre (capital + multi-words)
    words = concept_name.split()
    if len(words) > 1 and words[0][0].isupper():
        return True

    # Contient acronyme (2+ majuscules consÃ©cutives)
    if re.search(r'[A-Z]{2,}', concept_name):
        return True

    # Contient caractÃ¨res spÃ©ciaux
    if re.search(r'[/\-_]', concept_name):
        return True

    # Sinon: terme gÃ©nÃ©rique
    return False


def _normalize_concept_auto(
    self,
    concept_name: str,
    concept_type: str,
    tenant_id: str
) -> Tuple[str, bool, str]:
    """
    Normalisation automatique multi-stratÃ©gies.

    StratÃ©gies (ordre de prioritÃ©):
    1. Lookup ontologie Neo4j (EntityNormalizerNeo4j)
    2. Fuzzy matching variantes (FuzzyMatcherService â‰¥90%)
    3. LLM lÃ©ger canonicalization (GPT-4o-mini, ~$0.0001/concept)
    4. RÃ¨gles heuristiques (acronymes, casse)
    5. Fallback: Garde tel quel

    Returns:
        (canonical_name, is_cataloged, source)
        - canonical_name: Nom normalisÃ©
        - is_cataloged: True si trouvÃ© dans ontologie
        - source: "ontology" | "fuzzy" | "llm" | "heuristic" | "fallback"
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # StratÃ©gie 1: Lookup Ontologie Existante (Prioritaire)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    entity_id, canonical_name, real_type, is_cataloged = \
        self.entity_normalizer.normalize_entity_name(
            raw_name=concept_name,
            entity_type_hint=concept_type,
            tenant_id=tenant_id
        )

    if is_cataloged:
        # TrouvÃ© dans ontologie â†’ Utiliser canonical_name
        return (canonical_name, True, "ontology")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # StratÃ©gie 2: Fuzzy Matching (Seuil 90% auto-match)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # RÃ©cupÃ©rer toutes les OntologyEntities du mÃªme type
    ontology_entries = self._get_ontology_entries_by_type(
        entity_type=concept_type,
        tenant_id=tenant_id
    )

    for ontology_entry in ontology_entries:
        is_match, score, matched_name = self.fuzzy_matcher.match_entity_to_ontology(
            entity_name=concept_name,
            ontology_entry=ontology_entry
        )

        if score >= 90:  # Auto-match haute confiance
            return (
                ontology_entry["canonical_name"],
                True,
                f"fuzzy:{score}"
            )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # StratÃ©gie 3: LLM LÃ©ger Canonicalization (GPT-4o-mini)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # Seulement pour concepts "importants" (pas langage commun)
    # Et si budget LLM SMALL disponible
    if self._is_important_concept(concept_name, concept_type):
        if self.state.budget_remaining.get("SMALL", 0) > 0:
            try:
                canonical_from_llm = self._llm_canonicalize_single(
                    concept_name=concept_name,
                    concept_type=concept_type
                )

                if canonical_from_llm:
                    # LLM a proposÃ© normalisation
                    logger.info(
                        f"ğŸ¤– LLM canonicalisÃ©: '{concept_name}' â†’ '{canonical_from_llm}'"
                    )

                    # DÃ©crÃ©menter budget SMALL
                    self.state.budget_remaining["SMALL"] -= 1
                    self.state.llm_calls_count["SMALL"] += 1

                    return (canonical_from_llm, False, "llm:gpt-4o-mini")

            except Exception as e:
                logger.warning(
                    f"[GATEKEEPER] LLM canonicalization failed for '{concept_name}': {e}"
                )
                # Continue vers stratÃ©gies suivantes

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # StratÃ©gie 4: RÃ¨gles Heuristiques Simples
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # RÃ¨gle: Acronymes en MAJUSCULES (SAP, ERP, CRM, etc.)
    if concept_name.isupper() and len(concept_name) >= 2:
        return (concept_name.upper(), False, "heuristic:acronym")

    # RÃ¨gle: Noms propres avec casse prÃ©servÃ©e
    if concept_name[0].isupper():
        # PrÃ©server casse originale (Ã©viter .title())
        return (concept_name.strip(), False, "heuristic:proper_noun")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # StratÃ©gie 5: Fallback (Garde tel quel)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return (concept_name.strip(), False, "fallback")


def _is_important_concept(self, concept_name: str, concept_type: str) -> bool:
    """
    DÃ©termine si concept mÃ©rite un appel LLM pour canonicalization.

    CritÃ¨res:
    - Types SOLUTION, PRODUCT, COMPANY, TECHNOLOGY, ACRONYM
    - OU Noms propres (commence par majuscule)
    - OU Contient acronyme (SAP, ERP)
    - OU Contient caractÃ¨res spÃ©ciaux (/, -, _)

    Exclure:
    - Termes basiques: "management", "system", "process"
    - Langage commun: "customer", "data", "report"
    """
    IMPORTANT_TYPES = {
        "SOLUTION", "PRODUCT", "COMPONENT", "MODULE",
        "COMPANY", "VENDOR", "PARTNER",
        "TECHNOLOGY", "PLATFORM", "TOOL", "FRAMEWORK",
        "ACRONYM", "STANDARD", "PROTOCOL", "API"
    }

    # Type important
    if concept_type in IMPORTANT_TYPES:
        return True

    # Nom propre (capital + multi-words)
    words = concept_name.split()
    if len(words) > 1 and words[0][0].isupper():
        return True

    # Contient acronyme (2+ majuscules consÃ©cutives)
    if re.search(r'[A-Z]{2,}', concept_name):
        return True

    # Contient caractÃ¨res spÃ©ciaux
    if re.search(r'[/\-_]', concept_name):
        return True

    # Sinon: terme gÃ©nÃ©rique, pas important
    return False


def _llm_canonicalize_single(
    self,
    concept_name: str,
    concept_type: str
) -> Optional[str]:
    """
    Canonicalisation LLM lÃ©ger pour un concept individuel.

    Utilise GPT-4o-mini (task: "canonicalization") pour normaliser.

    Prompt:
    "Given this entity: 'S/4HANA PCE' (type: SOLUTION),
     what is the official canonical name? Reply ONLY with the canonical name,
     or 'UNKNOWN' if uncertain."

    Returns:
        Canonical name ou None si LLM incertain
    """
    prompt = f"""You are an expert in entity normalization.

Given this entity:
- Name: "{concept_name}"
- Type: {concept_type}

Task: Provide the official canonical name for this entity.

Rules:
1. If it's a well-known product/company/technology, use its official name
2. Preserve proper casing (e.g., "SAP" not "Sap", "S/4HANA" not "S/4hana")
3. Use full official names when available (e.g., "SAP S/4HANA Cloud, Private Edition" not "S/4HANA PCE")
4. If uncertain or it's a generic term, reply with "UNKNOWN"

Reply ONLY with the canonical name (or "UNKNOWN"), nothing else.

Example:
Input: "S/4HANA PCE" (SOLUTION)
Output: SAP S/4HANA Cloud, Private Edition

Input: "management" (CONCEPT)
Output: UNKNOWN

Your turn:
Input: "{concept_name}" ({concept_type})
Output:"""

    try:
        # Appel LLM via dispatcher (utilise config canonicalization: gpt-4o-mini, temp=0, max_tokens=100)
        response = self.llm_client.call_llm(
            task="canonicalization",
            messages=[{"role": "user", "content": prompt}]
        )

        canonical = response["content"].strip()

        if canonical == "UNKNOWN" or canonical == concept_name:
            # LLM incertain ou pas de changement
            return None

        return canonical

    except Exception as e:
        logger.error(f"[GATEKEEPER] LLM call failed: {e}")
        return None


def _log_uncataloged_for_learning(
    self,
    uncataloged_concepts: List[Dict],
    tenant_id: str
):
    """
    Logger concepts non cataloguÃ©s pour auto-learning diffÃ©rÃ©.

    Options:
    1. Logger simple (fichier/DB)
    2. CrÃ©er nodes :UncatalogedConcept dans Neo4j
    3. Accumuler dans Redis queue pour batch LLM
    """

    # Option 2: CrÃ©er nodes temporaires Neo4j pour tracking
    for concept in uncataloged_concepts:
        self.neo4j_client.log_uncataloged_concept(
            concept_name=concept["name"],
            concept_type=concept["type"],
            canonical_name=concept["canonical_name"],
            segment_id=concept["segment_id"],
            confidence=concept["confidence"],
            tenant_id=tenant_id
        )
```

---

## ğŸ“‹ Algorithme DÃ©taillÃ© - Phase B (Auto-Learning Ponctuel)

### Service Auto-Learning Batch (Nouveau)

**Fichier**: `src/knowbase/ontology/auto_learning_service.py`

```python
class AutoLearningService:
    """
    Service d'auto-apprentissage ponctuel via LLM batch.

    Workflow:
    1. DÃ©tecter concepts non cataloguÃ©s accumulÃ©s
    2. Clustering automatique (fuzzy + embeddings)
    3. LLM batch normalization (GPT-4o-mini)
    4. Sauvegarde automatique ontologie
    5. Notification admin pour review (optionnel)
    """

    def __init__(
        self,
        neo4j_client,
        fuzzy_matcher,
        embeddings_scorer,
        llm_client
    ):
        self.neo4j_client = neo4j_client
        self.fuzzy_matcher = fuzzy_matcher
        self.embeddings_scorer = embeddings_scorer
        self.llm_client = llm_client

    def run_auto_learning_batch(
        self,
        tenant_id: str = "default",
        min_concepts: int = 20,
        llm_model: str = "gpt-4o-mini"
    ) -> Dict:
        """
        ExÃ©cute batch auto-learning sur concepts non cataloguÃ©s.

        Args:
            tenant_id: Tenant ID
            min_concepts: Minimum concepts pour dÃ©clencher learning
            llm_model: ModÃ¨le LLM (gpt-4o-mini recommandÃ©, coÃ»t faible)

        Returns:
            Dict avec rÃ©sultats:
            {
                "concepts_analyzed": 47,
                "clusters_detected": 12,
                "ontology_entries_created": 12,
                "cost_usd": 0.52,
                "time_seconds": 15.3,
                "admin_review_required": ["CLUSTER_23", "CLUSTER_45"]
            }
        """

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 1: RÃ©cupÃ©rer concepts non cataloguÃ©s
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        uncataloged_concepts = self.neo4j_client.get_uncataloged_concepts(
            tenant_id=tenant_id,
            limit=500
        )

        if len(uncataloged_concepts) < min_concepts:
            logger.info(
                f"[AUTO-LEARNING] Seulement {len(uncataloged_concepts)} concepts, "
                f"attendu {min_concepts} minimum. Skip."
            )
            return {"concepts_analyzed": 0}

        logger.info(
            f"[AUTO-LEARNING] Traitement {len(uncataloged_concepts)} concepts "
            f"non cataloguÃ©s..."
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 2: Clustering Automatique
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        clusters = self._cluster_similar_concepts(
            concepts=uncataloged_concepts,
            fuzzy_threshold=75,
            embeddings_threshold=0.85
        )

        logger.info(f"[AUTO-LEARNING] {len(clusters)} clusters dÃ©tectÃ©s")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 3: LLM Batch Normalization
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        ontology_entries = []
        low_confidence_clusters = []
        total_cost = 0.0

        for cluster in clusters:
            # LLM normalization pour cluster
            result = self._normalize_cluster_with_llm(
                cluster=cluster,
                llm_model=llm_model
            )

            if result["confidence"] >= 0.85:
                # Haute confiance â†’ Auto-sauvegarde
                ontology_entries.append(result["ontology_entry"])
                total_cost += result["cost_usd"]
            else:
                # Basse confiance â†’ Admin review
                low_confidence_clusters.append(cluster["cluster_id"])

        logger.info(
            f"[AUTO-LEARNING] {len(ontology_entries)} ontologies crÃ©Ã©es, "
            f"{len(low_confidence_clusters)} nÃ©cessitent review admin"
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 4: Sauvegarde Automatique Ontologie
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        for ontology_entry in ontology_entries:
            save_ontology_to_neo4j(
                merge_groups=[ontology_entry],
                entity_type=ontology_entry["entity_type"],
                tenant_id=tenant_id,
                source="auto_learned"
            )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 5: Marquer Concepts Comme Appris
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        for ontology_entry in ontology_entries:
            for entity_name in ontology_entry["entities"]:
                self.neo4j_client.mark_concept_as_learned(
                    concept_name=entity_name,
                    tenant_id=tenant_id
                )

        return {
            "concepts_analyzed": len(uncataloged_concepts),
            "clusters_detected": len(clusters),
            "ontology_entries_created": len(ontology_entries),
            "cost_usd": total_cost,
            "admin_review_required": low_confidence_clusters
        }

    def _cluster_similar_concepts(
        self,
        concepts: List[Dict],
        fuzzy_threshold: int = 75,
        embeddings_threshold: float = 0.85
    ) -> List[Dict]:
        """
        Clustering automatique via fuzzy + embeddings.

        StratÃ©gies:
        1. Fuzzy matching (Levenshtein â‰¥75%)
        2. Embeddings similarity (cosine â‰¥0.85)
        3. Transitive closure (si A~B et B~C alors A~C)

        Returns:
            Liste clusters:
            [
                {
                    "cluster_id": "CLUSTER_1",
                    "concepts": ["S/4HANA PCE", "S/4 Private Cloud", ...],
                    "concept_type": "SOLUTION",
                    "similarity_scores": [0.92, 0.87, ...]
                }
            ]
        """
        # ImplÃ©menter clustering (union-find ou graph clustering)
        pass

    def _normalize_cluster_with_llm(
        self,
        cluster: Dict,
        llm_model: str
    ) -> Dict:
        """
        Normalisation cluster via LLM.

        Prompt LLM:
        "Given these product variants: ['S/4HANA PCE', 'S/4 Private Cloud', 'SAP S4 HANA Private'],
         what is the official canonical name? Provide confidence score."

        Returns:
            {
                "ontology_entry": {
                    "canonical_key": "SAP_S4HANA_CLOUD_PRIVATE",
                    "canonical_name": "SAP S/4HANA Cloud, Private Edition",
                    "entities": ["S/4HANA PCE", "S/4 Private Cloud", ...],
                    "entity_type": "SOLUTION"
                },
                "confidence": 0.95,
                "cost_usd": 0.004
            }
        """
        # Appel LLM avec structured output
        pass
```

---

## ğŸ›ï¸ Configuration et DÃ©clenchement

### Option 1: Cron Job (RecommandÃ©)

```bash
# Tous les dimanches Ã  3h du matin
0 3 * * 0 docker-compose exec app python -m knowbase.ontology.auto_learning_batch

# Script auto_learning_batch.py
from knowbase.ontology.auto_learning_service import AutoLearningService

service = AutoLearningService(...)
result = service.run_auto_learning_batch(
    tenant_id="default",
    min_concepts=20,
    llm_model="gpt-4o-mini"
)

print(f"âœ… Auto-learning terminÃ©: {result}")

if len(result["admin_review_required"]) > 0:
    # Envoyer notification admin
    send_admin_notification(result)
```

### Option 2: Trigger Manuel Admin

```python
# Frontend Admin: Bouton "Apprendre Concepts"
POST /api/admin/auto-learning/trigger
{
    "tenant_id": "default",
    "min_concepts": 20,
    "llm_model": "gpt-4o-mini"
}

# Backend route
@router.post("/api/admin/auto-learning/trigger")
async def trigger_auto_learning(request: AutoLearningRequest):
    service = AutoLearningService(...)
    result = await service.run_auto_learning_batch(...)
    return result
```

### Option 3: Automatique Post-Import

```python
# Dans osmose_agentique.py, aprÃ¨s traitement document

if concepts_count > 0:
    # Check si seuil atteint
    uncataloged_count = neo4j_client.count_uncataloged_concepts(tenant_id)

    if uncataloged_count >= 50:
        logger.info(
            f"[AUTO-LEARNING] {uncataloged_count} concepts accumulÃ©s, "
            "dÃ©clenchement auto-learning..."
        )

        service = AutoLearningService(...)
        result = service.run_auto_learning_batch(tenant_id)

        logger.info(f"[AUTO-LEARNING] RÃ©sultat: {result}")
```

---

## ğŸ“Š Estimation Impact et CoÃ»t

### ScÃ©nario Typique: Import 10 Documents SAP

#### Avant (Intervention Admin Lourde)
```
Import 10 docs â†’ 500 concepts extraits
â”œâ”€> 300 doublons (mÃªme concept plusieurs fois)
â”œâ”€> 150 variantes non normalisÃ©es ("S/4HANA PCE" vs "SAP S/4HANA Cloud Private")
â””â”€> Admin passe 2-3 heures Ã  normaliser manuellement
```

#### AprÃ¨s (Auto-Learning Hybride avec LLM Phase A)
```
Import 10 docs â†’ 500 concepts extraits

Phase A (Import Real-Time avec LLM lÃ©ger):
â”œâ”€> 350 concepts trouvÃ©s dans ontologie (70%) â†’ Automatique âœ…
â”œâ”€> 50 concepts normalisÃ©s via fuzzy â‰¥90% (10%) â†’ Automatique âœ…
â”œâ”€> 60 concepts canonicalisÃ©s via LLM SMALL (12%) â†’ Automatique âœ… (~$0.006)
â”œâ”€> 100 doublons Ã©vitÃ©s via dÃ©duplication â†’ Automatique âœ…
â”œâ”€> 40 concepts non cataloguÃ©s restants (8%) â†’ LoggÃ©s pour learning âš ï¸

Phase B (Auto-Learning Post-Import - optionnel):
â”œâ”€> 40 concepts â†’ 10 clusters dÃ©tectÃ©s
â”œâ”€> LLM normalization â†’ 8 ontologies crÃ©Ã©es (confiance â‰¥85%) âœ…
â”œâ”€> 2 clusters ambigus â†’ Admin review âš ï¸
â””â”€> CoÃ»t LLM: ~$0.40 (gpt-4o-mini batch)

RÃ©sultat:
â”œâ”€> 98% automatiquement corrects (490/500)
â”œâ”€> 2% nÃ©cessitent review admin (10/500, ~10 minutes)
â””â”€> Gain temps: 2h45 â†’ 10 minutes (94% rÃ©duction)
â””â”€> CoÃ»t LLM total: $0.006 (Phase A) + $0.40 (Phase B) = ~$0.41/import
```

### DÃ©tail CoÃ»ts LLM

#### Phase A (Real-Time LLM Canonicalization)
```
60 concepts Ã— GPT-4o-mini (task: canonicalization)
â”œâ”€> Input: ~80 tokens/concept (prompt + concept)
â”œâ”€> Output: ~20 tokens/concept (canonical name)
â”œâ”€> Total: 60 Ã— 100 tokens = 6,000 tokens
â””â”€> CoÃ»t: $0.15/1M input + $0.60/1M output â‰ˆ $0.006

Budget SMALL: 120 appels/document (dÃ©fini dans AgentState)
â””â”€> Permet jusqu'Ã  120 canonicalisations LLM sans surcoÃ»t
```

#### Phase B (Batch LLM Normalization)
```
40 concepts â†’ 10 clusters
â”œâ”€> 10 appels LLM (1 par cluster)
â”œâ”€> Input: ~200 tokens/cluster (variantes + context)
â”œâ”€> Output: ~50 tokens/cluster (canonical + aliases)
â””â”€> CoÃ»t: 10 Ã— 250 tokens â‰ˆ $0.40
```

### CoÃ»ts EstimÃ©s Comparatifs

| StratÃ©gie | CoÃ»t LLM/import | Temps Admin/import | QualitÃ© | ROI |
|-----------|-----------------|-------------------|---------|-----|
| **Historique (100% admin)** | $0 | 2-3h | 100% | Baseline |
| **Phase A sans LLM** | $0 | 30min | 80% | +75% temps |
| **Phase A avec LLM** | $0.01 | 20min | 92% | +85% temps |
| **Phase A + B (complet)** | $0.41 | 10min | 98% | **+94% temps** |

**CoÃ»t admin @ $50/h**: Ã‰conomie 2h30 = **$125/import**
**CoÃ»t LLM Phase A+B**: $0.41/import
**ROI net**: **$124.59/import (99.7% Ã©conomie)**

**Recommandation**: Phase A avec LLM + Phase B hebdomadaire.

---

### Justification LLM Phase A

**Pourquoi ajouter LLM en Phase A ?**

1. **CoÃ»t nÃ©gligeable** : $0.006/import (60 concepts Ã— $0.0001)
2. **AmÃ©lioration qualitÃ©** : +12% prÃ©cision (80% â†’ 92%)
3. **RÃ©duction Phase B** : Moins de concepts Ã  apprendre en batch
4. **Real-time** : Admin voit rÃ©sultats corrects immÃ©diatement
5. **Budget contrÃ´lÃ©** : Max 120 appels SMALL/document (hard cap)

**Trade-off acceptable** :
- âœ… +$0.006 coÃ»t LLM
- âœ… +12% qualitÃ© immÃ©diate
- âœ… -50% concepts Ã  apprendre en Phase B
- âœ… -10 minutes temps admin

**Alternative si budget serrÃ©** : DÃ©sactiver LLM Phase A, utiliser seulement Phase B hebdomadaire.

---

## ğŸš¦ Plan d'ImplÃ©mentation

### P0: Phase A (Import Real-Time) - 4-5 jours

1. **Jour 1-2**: IntÃ©grer `EntityNormalizerNeo4j` + `FuzzyMatcherService` dans Gatekeeper
   - Modifier `_promote_concepts_tool()`
   - ImplÃ©menter `_should_canonicalize()`
   - ImplÃ©menter `_normalize_concept_auto()`

2. **Jour 3**: DÃ©duplication CanonicalConcepts
   - Cache en mÃ©moire `{canonical_name: canonical_id}`
   - MÃ©thode `neo4j_client.link_proto_to_canonical()`

3. **Jour 4**: Logging concepts non cataloguÃ©s
   - CrÃ©er nodes `:UncatalogedConcept` dans Neo4j
   - Logger mÃ©tadonnÃ©es pour clustering

4. **Jour 5**: Tests et validation
   - Import document test â†’ VÃ©rifier canonicalisation
   - VÃ©rifier dÃ©duplication fonctionne
   - VÃ©rifier concepts loggÃ©s

### P1: Phase B (Auto-Learning) - 5-6 jours

1. **Jour 6-7**: Clustering automatique
   - ImplÃ©menter fuzzy clustering
   - ImplÃ©menter embeddings clustering
   - Transitive closure

2. **Jour 8-9**: LLM batch normalization
   - Prompt engineering pour normalisation
   - Structured output (JSON)
   - Gestion confiance/seuils

3. **Jour 10**: Sauvegarde automatique
   - IntÃ©grer `OntologySaver`
   - Marquer concepts comme appris
   - Notification admin si low confidence

4. **Jour 11**: Tests et dÃ©ploiement
   - Test cron job
   - Test manuel trigger
   - Validation rÃ©sultats

### P2: Frontend Admin Review (Optionnel) - 3-4 jours

1. **Jour 12-13**: Page Admin "Auto-Learning Review"
   - Liste clusters low confidence
   - Preview merge_groups
   - Validation/correction manuelle

2. **Jour 14-15**: IntÃ©gration workflow complet
   - Tests end-to-end
   - Documentation admin

---

## âœ… Validation CritÃ¨res de SuccÃ¨s

### CritÃ¨res Quantitatifs
- âœ… â‰¥90% concepts automatiquement normalisÃ©s (sans admin)
- âœ… â‰¥95% doublons Ã©vitÃ©s via dÃ©duplication
- âœ… â‰¤10% concepts nÃ©cessitent review admin
- âœ… CoÃ»t LLM â‰¤$1 pour 200 concepts
- âœ… Temps admin rÃ©duit de â‰¥80% (3h â†’ 30min)

### CritÃ¨res Qualitatifs
- âœ… Domaine-agnostic (fonctionne pour SAP, Finance, IT, etc.)
- âœ… Auto-apprentissage progressif (amÃ©lioration continue)
- âœ… Transparence (logs, confidence scores)
- âœ… Admin garde contrÃ´le (validation finale possible)

---

## ğŸ“ Conclusion

Cette stratÃ©gie hybride combine:

1. **Real-time** (Phase A): Normalisation immÃ©diate via ontologie existante + fuzzy + rÃ¨gles
2. **Batch learning** (Phase B): LLM ponctuel pour apprendre nouveaux domaines
3. **Admin review** (Phase C): Optionnel, seulement pour edge cases

**Avantages**:
- âœ… 90-95% automatisation (vs 0% actuellement)
- âœ… CoÃ»t LLM faible (~$0.50/batch)
- âœ… Domaine-agnostic (auto-learning continu)
- âœ… Admin garde contrÃ´le final

**Next Steps**: Prioriser P0 (Phase A) pour valider approche, puis P1 (Phase B) pour auto-learning.

