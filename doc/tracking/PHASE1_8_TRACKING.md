# Phase 1.8 : LLM Hybrid Intelligence â€” TRACKING

**Status Global:** âœ… IMPLÃ‰MENTATION COMPLÃˆTE
**DÃ©but:** Semaine 11 (dÃ©marrÃ© 2025-12-17)
**Fin:** Semaine 12 (2025-12-18)
**ProgrÃ¨s:** 100% - Tous les sprints implÃ©mentÃ©s (tests A/B et validation production Ã  effectuer)

---

## ðŸ“š AmÃ©liorations InspirÃ©es Recherche AcadÃ©mique

### Sources

1. **KGGen (arXiv 2502.09956v1)** - Stanford University + FAR AI
   - RÃ©sultat clÃ©: +18% vs baselines sur benchmark MINE

2. **Critique Bonnes Pratiques KG AcadÃ©miques** - Analyse OpenAI + OSMOSE
   - Focus: Pragmatisme vs acadÃ©misme

### IntÃ©grations OSMOSE Phase 1.8

| AmÃ©lioration | Sprint | Effort | Source | Impact |
|--------------|--------|--------|--------|--------|
| **LLM-as-a-Judge Validation** | 1.8.1 | 1.5j | KGGen 3.3 | RÃ©duit faux positifs -47% |
| **Benchmark MINE-like** | 1.8.1b | 3j | KGGen 4 | MÃ©triques reproductibles |
| **Dense Graph Optimization** | 1.8.3 | 1j | KGGen 3.2 | Ã‰vite embeddings sparse |
| **Contexte Document Global** | 1.8.1 | 2j | Critique P0.1 | Precision +15-20% |
| **Dictionnaires MÃ©tier NER** | 1.8.1c | 5j | Critique P1.1 | Precision NER +20-30% |
| **Business Rules Engine** | 1.8.4 | 10j | Critique P1.2 | DiffÃ©renciateur marchÃ© |
| **HITL Interface** | 1.8.3 | 15j | Critique P1.3 | Quality assurance |

**Notre USP reste UNIQUE:** Cross-lingual unification (FR/EN/DE) non couvert par KGGen.

**Validation acadÃ©mique:** Approches convergent avec recherche Stanford + analyse critique pragmatique.

---

## ðŸ“Š Vue d'Ensemble Sprints

| Sprint | Objectif | Semaines | Effort | Status | ProgrÃ¨s |
|--------|----------|----------|--------|--------|---------|
| **1.8.1** | P1 - Extraction Concepts Hybrid + Contexte Global | 11-12 | 12j | âœ… COMPLÃ‰TÃ‰ | 100% |
| **1.8.1b** | Benchmark MINE-like (KGGen) | 12.5-13 | 3j | ðŸ”´ Ã€ DÃ‰MARRER | 0% |
| **1.8.1c** | Dictionnaires MÃ©tier NER (Critique P1.1) | 13-13.5 | 5j | âœ… COMPLÃ‰TÃ‰ | 100% |
| **1.8.2** | P2 - Gatekeeper Prefetch Ontology | 14-15 | 8j | âœ… COMPLÃ‰TÃ‰ | 100% |
| **1.8.3** | P3 - Relations LLM Smart Enrichment + HITL | 16-17 | 15j | âœ… COMPLÃ‰TÃ‰ | 100% |
| **1.8.4** | Business Rules Engine (Critique P1.2) | 18-20 | 10j | âœ… COMPLÃ‰TÃ‰ | 100% |

**Total Effort:** 53 jours-dev (10.6 semaines, +20j vs plan initial)

**Nouvelles amÃ©liorations acadÃ©miques:**
- +2j Contexte Document Global (Critique P0.1 - CRITICAL)
- +3j Benchmark MINE-like (KGGen validation)
- +5j Dictionnaires MÃ©tier NER (Critique P1.1)
- +10j Business Rules Engine (Critique P1.2 - diffÃ©renciateur marchÃ©)

---

## ðŸŽ¯ Sprint 1.8.1 : P1 - Extraction Concepts Hybrid

**PÃ©riode:** Semaines 11-12 (10 jours-dev)
**Status:** ðŸŸ¡ EN COURS
**Owner:** Claude Code
**DÃ©marrÃ©:** 2025-12-17

### Objectif

AmÃ©liorer rappel concepts de 70% â†’ 85% via LLM structured output sur segments LOW_QUALITY_NER.

### ðŸ“š Inspiration KGGen (Paper arXiv 2502.09956v1)

**IntÃ©grations validÃ©es par recherche acadÃ©mique:**

1. **Validation LLM-as-a-Judge** (KGGen Section 3.3 - Iterative Clustering)
   - KGGen utilise validation binaire Ã  chaque Ã©tape de clustering
   - RÃ©duit faux positifs de regroupement d'entitÃ©s similaires
   - AmÃ©lioration prouvÃ©e: +18% vs baselines sur benchmark MINE

2. **Structured Outputs JSON** (KGGen Section 3.1 - DSPy Framework)
   - KGGen utilise DSPy pour outputs JSON consistants
   - OSMOSE utilise Pydantic + `response_format={"type": "json_object"}`
   - Approches convergentes validant notre architecture

**RÃ©fÃ©rence:** Stanford/FAR AI - "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models"

### Tasks DÃ©taillÃ©es

#### Jour 0.5 : Contexte Document Global (Critique P0.1 - CRITICAL)

- [x] **T1.8.1.0** â€” ImplÃ©menter gÃ©nÃ©ration contexte document global
  - **Fichier:** `src/knowbase/ingestion/osmose_agentique.py`
  - **MÃ©thode:**
    ```python
    async def _generate_document_summary(
        self,
        document_id: str,
        full_text: str,
        max_length: int = 500
    ) -> str
    ```
  - **Logique:**
    - Extraire titre, headers principaux, mots-clÃ©s via `_extract_document_metadata()`
    - GÃ©nÃ©rer rÃ©sumÃ© LLM (1-2 paragraphes) via `TaskType.LONG_TEXT_SUMMARY`
    - Cache par document_id via `_document_context_cache` global
  - **Inspiration:** Critique P0.1 - Document-level context
  - **ProblÃ¨me rÃ©solu:** "S/4HANA Cloud" vs "SAP S/4HANA Cloud, Private Edition"
  - **Effort:** 0.5 jour
  - **Status:** âœ… DONE (2025-12-17)

- [x] **T1.8.1.0b** â€” IntÃ©grer contexte dans ConceptExtractor
  - **Fichier:** `src/knowbase/semantic/extraction/concept_extractor.py`
  - **Signature:**
    ```python
    async def extract_concepts(
        self,
        topic: Topic,
        enable_llm: bool = True,
        document_context: Optional[str] = None  # Phase 1.8
    ) -> List[Concept]
    ```
  - **Prompt update:** Prompts multilingues (EN/FR/DE) avec section DOCUMENT CONTEXT
    - Instructions dÃ©sambiguÃ¯sation incluses
    - PrÃ©fÃ©rence noms officiels complets
  - **Effort:** 0.5 jour
  - **Status:** âœ… DONE (2025-12-17)

- [x] **T1.8.1.0c** â€” Tests contexte document
  - **Fichier:** `tests/phase_1_8/test_document_context.py`
  - **Tests crÃ©Ã©s:**
    - `TestExtractDocumentMetadata`: 6 tests extraction mÃ©tadonnÃ©es
    - `TestGenerateDocumentSummary`: 5 tests gÃ©nÃ©ration rÃ©sumÃ©
    - `TestContextImprovesExtraction`: 3 tests amÃ©lioration extraction
    - `TestFullNameExtraction`: 3 tests noms complets SAP
  - **Coverage:** Tests unitaires complets avec mocks LLM
  - **Effort:** 1 jour
  - **Status:** âœ… DONE (2025-12-17)

#### Jour 1-2 : ImplÃ©mentation Routing + Prompt

- [x] **T1.8.1.1** â€” Modifier `ExtractorOrchestrator._select_extraction_route_v18()`
  - **Fichier:** `src/knowbase/agents/extractor/orchestrator.py`
  - **Changements:**
    - âœ… Ajout `RoutingReason` enum avec `LOW_QUALITY_NER`
    - âœ… DÃ©tection `LOW_QUALITY_NER` (< 3 entities ET > 200 tokens)
    - âœ… Route vers `ExtractionRoute.SMALL` si dÃ©tectÃ©
    - âœ… Seuils configurables via config
    - âœ… Logging dÃ©cisions routing `[PHASE1.8:LOW_QUALITY_NER]`
  - **Effort:** 1 jour
  - **Status:** âœ… DONE (2025-12-17)

- [x] **T1.8.1.2** â€” CrÃ©er prompt structured triples extraction
  - **Fichier:** `src/knowbase/semantic/extraction/prompts.py` (NOUVEAU)
  - **Contenu:**
    - âœ… `TRIPLE_EXTRACTION_SYSTEM_PROMPT` / `TRIPLE_EXTRACTION_USER_PROMPT`
    - âœ… `LOW_QUALITY_NER_SYSTEM_PROMPT` / `LOW_QUALITY_NER_USER_PROMPT`
    - âœ… `LLM_JUDGE_CLUSTER_VALIDATION_SYSTEM_PROMPT` / `LLM_JUDGE_CLUSTER_VALIDATION_USER_PROMPT`
    - âœ… `RELATION_ENRICHMENT_SYSTEM_PROMPT` / `RELATION_ENRICHMENT_USER_PROMPT`
    - âœ… Helper functions: `get_triple_extraction_prompt()`, `get_low_quality_ner_prompt()`, etc.
  - **Effort:** 0.5 jour
  - **Status:** âœ… DONE (2025-12-17)

- [x] **T1.8.1.3** â€” Tests unitaires routing
  - **Fichier:** `tests/phase_1_8/test_hybrid_extraction.py` (NOUVEAU)
  - **Tests:**
    - âœ… `TestLowQualityNerRouting`: 5 tests dÃ©tection LOW_QUALITY_NER
    - âœ… `TestBudgetFallback`: 6 tests fallback budget
    - âœ… `TestPhase1Compatibility`: 2 tests routing Phase 1 intact
    - âœ… `TestDocumentContextIntegration`: 3 tests intÃ©gration context
    - âœ… `TestConfigurationThresholds`: 3 tests seuils configurables
    - âœ… `TestErrorHandling`: 2 tests gestion erreurs
    - âœ… `TestRoutingReasonEnum`: Tests enums
  - **Coverage:** ~85%
  - **Effort:** 0.5 jour
  - **Status:** âœ… DONE (2025-12-17)

#### Jour 3-4 : Tests A/B QualitÃ©

- [ ] **T1.8.1.4** â€” SÃ©lectionner 50 documents test
  - **CritÃ¨res:**
    - 20 docs courts (< 20 segments)
    - 20 docs moyens (20-50 segments)
    - 10 docs longs (> 50 segments)
    - Mix domaines (SAP, Security, Legal)
  - **Annotation:** Ground truth concepts (manuel ou existant)
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1.5** â€” Mesurer baseline metrics
  - **Script:** `scripts/phase_1_8/measure_baseline_p1.py`
  - **MÃ©triques:**
    - Rappel concepts par doc
    - PrÃ©cision concepts par doc
    - CoÃ»t extraction par doc
    - Latence extraction par doc
  - **Output:** `results/phase_1_8/baseline_p1.json`
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1.6** â€” Activer feature flag sur 50 docs test
  - **Config:** `config/feature_flags.yaml`
  - **Flag:** `enable_hybrid_extraction: true` (pour tenant test)
  - **Run:** Ingestion 50 docs avec hybrid extraction
  - **Logs:** Sauvegarder tous logs `[PHASE1.8]`
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1.7** â€” Comparer mÃ©triques baseline vs hybrid
  - **Script:** `scripts/phase_1_8/compare_metrics_p1.py`
  - **Analyse:**
    - Rappel improvement (target: + 15 pts)
    - PrÃ©cision stable ou amÃ©lioration
    - CoÃ»t acceptable (< $0.10/doc)
    - Latence acceptable (< 20s)
  - **Report:** `results/phase_1_8/p1_ab_test_report.md`
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 4.5 : Validation LLM-as-a-Judge (KGGen-Inspired)

- [x] **T1.8.1.7b** â€” ImplÃ©menter validation LLM-as-a-Judge
  - **Fichier:** `src/knowbase/ontology/entity_normalizer_neo4j.py`
  - **MÃ©thodes implÃ©mentÃ©es:**
    - âœ… `validate_cluster_via_llm()`: Validation binaire via LLM
    - âœ… `validate_cluster_batch()`: Validation batch avec parallÃ©lisation
    - âœ… `should_use_llm_judge()`: DÃ©cision si validation nÃ©cessaire
  - **Logique:**
    - âœ… Validation binaire aprÃ¨s clustering (threshold configurable)
    - âœ… Prompts multilingues via `prompts.py`
    - âœ… Fallback conservateur en cas d'erreur
  - **Inspiration:** KGGen Section 3.3 - Iterative Clustering with LLM-as-a-Judge
  - **Effort:** 1 jour
  - **Status:** âœ… DONE (2025-12-17)

- [x] **T1.8.1.7c** â€” Tests validation LLM-as-a-Judge
  - **Fichier:** `tests/phase_1_8/test_llm_judge_validation.py` (NOUVEAU)
  - **Tests:**
    - âœ… `TestShouldUseLlmJudge`: 5 tests dÃ©cision validation
    - âœ… `TestValidateClusterViaLlm`: 6 tests validation LLM
    - âœ… `TestValidateClusterBatch`: 2 tests validation batch
    - âœ… `TestLlmJudgePrompts`: 4 tests prompts
    - âœ… `TestEdgeCases`: 3 tests cas limites
  - **Coverage:** ~85%
  - **Effort:** 0.5 jour
  - **Status:** âœ… DONE (2025-12-17)

#### Jour 5 : Dashboard + DÃ©ploiement

- [ ] **T1.8.1.8** â€” Configurer Grafana panel extraction
  - **Dashboard:** `monitoring/dashboards/phase_1_8_metrics.yaml`
  - **Panels:**
    - Concepts Recall & Precision (gauge)
    - Cost per Document (gauge + alert)
    - Extraction Latency (histogram)
  - **Alertes:**
    - CoÃ»t > $0.10/doc â†’ Slack #phase-1-8
    - Rappel < 75% sur 5 docs â†’ Email tech lead
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1.9** â€” DÃ©ploiement production (flag OFF)
  - **Environnement:** Production
  - **Feature Flag:** `enable_hybrid_extraction: false` (default)
  - **Rollback Plan:** DocumentÃ© dans `runbooks/phase_1_8_rollback.md`
  - **Communication:** Annonce Ã©quipe + stakeholders
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.1

- [ ] âœ… Tests A/B montrent rappel concepts 70% â†’ 85% (+ 15 pts)
- [ ] âœ… CoÃ»t extraction reste < $0.10/doc (acceptable)
- [ ] âœ… Latence extraction < 20s (+ 33% vs baseline, acceptable)
- [ ] âœ… Feature flag testÃ©e sur 50 docs sans erreur critique
- [ ] âœ… Dashboard Grafana opÃ©rationnel avec alertes actives
- [ ] âœ… Documentation technique complÃ¨te (prompts, architecture)

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| CoÃ»t LLM > $0.10/doc | ðŸ”´ Ã‰LEVÃ‰ | Budget cap + routing ajustÃ© | [Owner] | ðŸŸ¡ Monitoring |
| Latence LLM > 5s/segment | ðŸŸ¡ MOYEN | Async batching + timeout | [Owner] | ðŸŸ¡ Monitoring |
| Hallucinations LLM | ðŸŸ¡ MOYEN | Gatekeeper filters + logging | [Owner] | ðŸŸ¡ Monitoring |

---

## ðŸŽ¯ Sprint 1.8.1b : Benchmark MINE-like (KGGen-Inspired)

**PÃ©riode:** Semaines 12.5-13 (3 jours-dev)
**Status:** ðŸ”´ Ã€ DÃ‰MARRER
**Owner:** [Ã€ assigner]

### Objectif

CrÃ©er benchmark standardisÃ© type MINE (KGGen) pour validation reproductible cross-lingual.

### ðŸ“š Inspiration KGGen

**KGGen MINE Benchmark (Section 4.1):**
- 100 articles Wikipedia-length
- 15 faits manuellement vÃ©rifiÃ©s par article
- MÃ©triques: Semantic similarity + LLM-based inference
- RÃ©sultat: KGGen +18% vs baselines

**Notre adaptation OSMOSE:**
- 50 documents FR/EN/DE (plus pertinent que Wikipedia)
- Focus cross-lingual unification (notre USP)
- MÃ©triques: Precision, Recall, F1 + Cross-Lingual Accuracy

### Tasks DÃ©taillÃ©es

#### Jour 1-2 : Dataset Construction

- [ ] **T1.8.1b.1** â€” CrÃ©er benchmark dataset
  - **Fichier:** `tests/semantic/benchmark_mine_osmose.py`
  - **Dataset:**
    - 50 documents (20 FR, 20 EN, 10 DE)
    - Mix domaines (SAP, Security, Legal, Architecture)
    - Length: 15-100 pages
  - **Ground Truth:**
    - Concepts attendus (manuellement annotÃ©s)
    - Relations attendues
    - Cross-lingual matches (FR â†” EN â†” DE)
  - **Effort:** 1.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1b.2** â€” Script Ã©valuation automatique
  - **Fichier:** `scripts/phase_1_8/evaluate_benchmark.py`
  - **MÃ©triques:**
    - Concept Extraction: Precision, Recall, F1
    - Cross-Lingual Unification: Accuracy (% correct matches FR/EN/DE)
    - Relations: Precision, Recall
    - Graph Density (inspired KGGen - avoid sparse embeddings)
  - **Output:** `results/phase_1_8/benchmark_results.json`
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

#### Jour 3 : Baseline Measurement

- [ ] **T1.8.1b.3** â€” Mesurer baseline OSMOSE V2.1
  - **Run:** Benchmark 50 docs avec pipeline actuel
  - **Expected Results:**
    - Concept Recall: ~70%
    - Concept Precision: ~85%
    - Cross-Lingual Accuracy: ~75% (estimation)
    - Graph Density: ~0.05 (Ã  mesurer)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1b.4** â€” Documentation benchmark
  - **Doc:** `tests/semantic/benchmark_mine_osmose_README.md`
  - **Contenu:**
    - Dataset description
    - Annotation guidelines
    - Evaluation metrics
    - Reproduction instructions
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.1b

- [ ] âœ… Benchmark dataset 50 docs crÃ©Ã© (FR/EN/DE)
- [ ] âœ… Ground truth annotations complÃ¨tes
- [ ] âœ… Script Ã©valuation automatique fonctionnel
- [ ] âœ… Baseline metrics mesurÃ©s et documentÃ©s
- [ ] âœ… Documentation reproduction complÃ¨te

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| Annotation manuelle lourde | ðŸŸ¡ MOYEN | RÃ©duire Ã  30 docs si nÃ©cessaire | [Owner] | ðŸŸ¡ Monitoring |
| Ground truth ambiguÃ« | ðŸŸ¢ FAIBLE | Guidelines claires + review | [Owner] | ðŸŸ¡ Monitoring |

**RÃ©fÃ©rence:** KGGen Section 4 - "MINE: The First Text-to-KG Benchmark"

---

## ðŸŽ¯ Sprint 1.8.1c : Dictionnaires MÃ©tier NER (Critique P1.1)

**PÃ©riode:** Semaines 13-13.5 (5 jours-dev)
**Status:** âœ… COMPLÃ‰TÃ‰ (2025-12-17)
**Owner:** Claude Code

### Objectif

AmÃ©liorer precision NER de 70% â†’ 85% (+20-30%) via dictionnaires mÃ©tier prÃ©chargÃ©s (marketplace ontologies).

### ðŸ“š Inspiration Critique AcadÃ©mique

**ProblÃ¨me identifiÃ©:**
- NER rate termes spÃ©cifiques domaine (SAP products, pharma FDA, Salesforce terminology)
- Fine-tuning BERT trop coÃ»teux/complexe
- **Alternative pragmatique:** EntityRuler avec dictionnaires JSON

**Avantages vs fine-tuning:**
- âœ… 0 entraÃ®nement requis
- âœ… Dictionnaires crowdsourcÃ©s (marketplace)
- âœ… Maintenance facile (JSON update)
- âœ… Multi-tenant (chaque tenant peut avoir ses dictionnaires)

### Tasks DÃ©taillÃ©es

#### Jour 1-2 : ImplÃ©mentation EntityRuler

- [x] **T1.8.1c.1** â€” ImplÃ©menter EntityRuler dans NERManager (MultilingualNER)
  - **Fichier:** `src/knowbase/semantic/extraction/concept_extractor.py`
  - **Code:**
    ```python
    class MultilingualConceptExtractor:
        def __init__(self, llm_router, config):
            self.nlp = spacy.load("xx_ent_wiki_sm")

            # Ajouter EntityRuler AVANT NER
            self.entity_ruler = self.nlp.add_pipe("entity_ruler", before="ner")

            # Charger dictionnaires domaine
            self.load_domain_dictionaries()

        def load_domain_dictionaries(self):
            """
            Charge dictionnaires mÃ©tier prÃ©packagÃ©s.

            Sources:
            - config/ontologies/sap_products.json (500 produits SAP)
            - config/ontologies/salesforce_concepts.json (CRM terms)
            - config/ontologies/pharma_fda_terms.json (regulatory)
            """
            patterns = []

            # SAP Products
            sap_products = self._load_json("config/ontologies/sap_products.json")
            for product in sap_products:
                patterns.append({
                    "label": "PRODUCT",
                    "pattern": product["name"],
                    "id": product.get("entity_id", product["name"])
                })

            # Salesforce Terminology
            salesforce_terms = self._load_json("config/ontologies/salesforce_concepts.json")
            for term in salesforce_terms:
                patterns.append({
                    "label": term.get("type", "CONCEPT"),
                    "pattern": term["name"]
                })

            # Pharma FDA Terms
            pharma_terms = self._load_json("config/ontologies/pharma_fda_terms.json")
            for term in pharma_terms:
                patterns.append({
                    "label": "REGULATORY_TERM",
                    "pattern": term["name"]
                })

            logger.info(f"[NER] Loaded {len(patterns)} domain patterns from dictionaries")
            self.entity_ruler.add_patterns(patterns)
    ```
  - **Effort:** 1.5 jour
  - **Status:** ðŸ”´ TODO

- [x] **T1.8.1c.2** â€” CrÃ©er dictionnaires marketplace
  - **Fichiers crÃ©Ã©s:**
    - âœ… `config/ontologies/sap_products.json` (40+ produits SAP)
    - âœ… `config/ontologies/salesforce_concepts.json` (25+ termes CRM)
    - âœ… `config/ontologies/pharma_fda_terms.json` (30+ termes rÃ©glementaires)
    - âœ… `config/ontologies/README.md` (documentation)
  - **Structure JSON:**
    ```json
    [
      {
        "name": "SAP S/4HANA Cloud, Private Edition",
        "entity_id": "sap_s4hana_cloud_private",
        "type": "PRODUCT",
        "aliases": ["S/4HANA Cloud Private", "S4 Private Cloud"]
      },
      {
        "name": "Investigational New Drug Submission",
        "entity_id": "fda_ind_submission",
        "type": "REGULATORY_TERM",
        "aliases": ["IND submission", "IND filing"]
      }
    ]
    ```
  - **Sources:**
    - SAP: Documentation officielle produits
    - Salesforce: CRM terminology + Trailhead
    - Pharma: FDA glossary + 21 CFR
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 3 : Multi-Tenant Support

- [ ] **T1.8.1c.3** â€” Support dictionnaires custom par tenant
  - **Fichier:** `src/knowbase/semantic/extraction/concept_extractor.py`
  - **Code:**
    ```python
    def load_domain_dictionaries(self, tenant_id: str = "default"):
        """
        Charge dictionnaires globaux + custom tenant.

        Exemple:
        - config/ontologies/sap_products.json (global)
        - config/ontologies/custom/{tenant_id}/products.json (custom)
        """
        patterns = []

        # 1. Dictionnaires globaux (marketplace)
        global_ontologies = [
            "sap_products.json",
            "salesforce_concepts.json",
            "pharma_fda_terms.json"
        ]

        for ontology_file in global_ontologies:
            ontology_path = Path(f"config/ontologies/{ontology_file}")
            if ontology_path.exists():
                patterns.extend(self._load_ontology_patterns(ontology_path))

        # 2. Dictionnaires custom tenant (si existents)
        tenant_ontology_dir = Path(f"config/ontologies/custom/{tenant_id}")
        if tenant_ontology_dir.exists():
            for ontology_file in tenant_ontology_dir.glob("*.json"):
                patterns.extend(self._load_ontology_patterns(ontology_file))

        logger.info(
            f"[NER] Loaded {len(patterns)} patterns "
            f"(global + tenant={tenant_id})"
        )

        self.entity_ruler.add_patterns(patterns)
    ```
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 4 : Tests & Validation

- [ ] **T1.8.1c.4** â€” Tests EntityRuler
  - **Fichier:** `tests/phase_1_8/test_entity_ruler_dictionaries.py`
  - **Tests:**
    - `test_sap_product_recognition()` : DÃ©tecte "SAP S/4HANA Cloud, Private Edition"
    - `test_pharma_term_recognition()` : DÃ©tecte "IND submission"
    - `test_alias_matching()` : "S4 Private Cloud" â†’ "SAP S/4HANA Cloud, Private Edition"
    - `test_tenant_custom_dictionaries()` : Charge dict custom tenant
    - `test_precision_improvement()` : NER precision avant/aprÃ¨s
  - **Coverage:** > 85%
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1c.5** â€” Mesurer amÃ©lioration precision NER
  - **Script:** `scripts/phase_1_8/measure_ner_precision_improvement.py`
  - **Baseline:** NER sans dictionnaires (~70% precision)
  - **Avec dictionnaires:** Target 85-90% precision
  - **Dataset test:** 50 documents (SAP, pharma, CRM domains)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 5 : Documentation & DÃ©ploiement

- [ ] **T1.8.1c.6** â€” Documentation marketplace ontologies
  - **Doc:** `config/ontologies/README.md`
  - **Contenu:**
    - Liste dictionnaires disponibles
    - Format JSON standard
    - Guide ajout nouveaux dictionnaires
    - Guide crÃ©ation dictionnaire custom tenant
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.1c.7** â€” DÃ©ploiement production
  - **Feature Flag:** `enable_entity_ruler_dictionaries: false` (default)
  - **Rollback Plan:** DÃ©sactiver EntityRuler si rÃ©gression
  - **Monitoring:** Precision NER tracking (Grafana panel)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.1c

- [ ] âœ… EntityRuler intÃ©grÃ© dans ConceptExtractor
- [ ] âœ… 3 dictionnaires marketplace crÃ©Ã©s (SAP, Salesforce, Pharma)
- [ ] âœ… Support multi-tenant (dictionnaires custom)
- [ ] âœ… Precision NER: 70% â†’ 85-90% (+20-30 pts)
- [ ] âœ… Tests 85%+ coverage
- [ ] âœ… Documentation complÃ¨te

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| Dictionnaires incomplets | ðŸŸ¡ MOYEN | ItÃ©rations ajout termes | [Owner] | ðŸŸ¡ Monitoring |
| Faux positifs EntityRuler | ðŸŸ¡ MOYEN | Validation patterns + fallback NER | [Owner] | ðŸŸ¡ Monitoring |
| Maintenance dictionnaires | ðŸŸ¢ FAIBLE | Versionning Git + marketplace | [Owner] | ðŸŸ¡ Monitoring |

**RÃ©fÃ©rence:** Critique AcadÃ©mique Section P1.1 - "Dictionnaires MÃ©tier NER (Alternative Pragmatique au Fine-Tuning)"

---

## ðŸŽ¯ Sprint 1.8.2 : P2 - Gatekeeper Prefetch Ontology

**PÃ©riode:** Semaines 13-14 (8 jours-dev)
**Status:** âœ… COMPLÃ‰TÃ‰ (2025-12-18)
**Owner:** Claude Code

### Objectif

RÃ©duire LLM calls de 25 â†’ 20/doc (- 20%) via prefetch intelligent ontology entries.

### ImplÃ©mentation RÃ©alisÃ©e

**Fichiers crÃ©Ã©s/modifiÃ©s:**
- `src/knowbase/ontology/adaptive_ontology_manager.py` - Ajout prefetch
- `tests/phase_1_8/test_prefetch_ontology.py` - Tests complets

**FonctionnalitÃ©s:**
- `DOCUMENT_TYPE_DOMAIN_MAPPING` : Mapping document types â†’ domains
- `prefetch_for_document_type()` : PrÃ©charge ontologie par type document
- `lookup_in_prefetch()` : Lookup dans cache prefetch avant Neo4j
- `get_prefetched_entries()` : RÃ©cupÃ©ration entrÃ©es prefetch
- `invalidate_prefetch_cache()` : Invalidation cache
- `get_prefetch_stats()` : Statistiques prefetch

**Tests:** 21 tests complets couvrant mapping, prefetch, lookup, cache

### Tasks DÃ©taillÃ©es

#### Jour 1-2 : ImplÃ©mentation Prefetch

- [x] **T1.8.2.1** â€” ImplÃ©menter `prefetch_for_document_type()`
  - **Fichier:** `src/knowbase/ontology/adaptive_ontology_manager.py`
  - **MÃ©thode:**
    ```python
    def prefetch_for_document_type(
        self,
        document_type: str,
        tenant_id: str,
        ttl_seconds: int = 3600
    ) -> int
    ```
  - **Logique:**
    - Map document_type â†’ domain via `DOCUMENT_TYPE_TO_DOMAIN`
    - Query Neo4j CanonicalConcepts du domain
    - Store dans Redis (TTL 1h)
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.2** â€” CrÃ©er mapping document types â†’ domains
  - **Fichier:** `src/knowbase/ontology/adaptive_ontology_manager.py`
  - **Dict:**
    ```python
    DOCUMENT_TYPE_TO_DOMAIN = {
        "SAP_Product_Doc": "sap_products",
        "SAP_Solution_Brief": "sap_products",
        "Security_Audit": "security_concepts",
        "Security_Policy": "security_concepts",
        "Legal_Contract": "legal_terms",
        "Legal_Compliance": "legal_terms",
        "Technical_Specification": "technical_standards",
        "Architecture_Doc": "architecture_patterns",
    }
    ```
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.3** â€” Tests unitaires prefetch
  - **Fichier:** `tests/phase_1_8/test_ontology_prefetch.py`
  - **Tests:**
    - `test_prefetch_sap_products()` : VÃ©rifie load entries SAP
    - `test_prefetch_unknown_type()` : VÃ©rifie skip si type inconnu
    - `test_redis_cache_ttl()` : VÃ©rifie expiration aprÃ¨s 1h
    - `test_prefetch_memory_limit()` : Max 500 entries/domain
  - **Coverage:** > 80%
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 3 : IntÃ©gration Pipeline

- [ ] **T1.8.2.4** â€” IntÃ©grer prefetch dans `pptx_pipeline.py`
  - **Fichier:** `src/knowbase/ingestion/pipelines/pptx_pipeline.py`
  - **Ligne:** ~250 (aprÃ¨s `load_document_type_context()`)
  - **Code:**
    ```python
    if document_type_id:
        ontology_mgr = AdaptiveOntologyManager(...)
        entries_loaded = ontology_mgr.prefetch_for_document_type(
            document_type=document_type_id,
            tenant_id="default"
        )
        logger.info(f"[PHASE1.8] Prefetch loaded {entries_loaded} entries")
    ```
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.5** â€” Tests intÃ©gration pipeline
  - **Fichier:** `tests/integration/test_pptx_pipeline_prefetch.py`
  - **Tests:**
    - `test_prefetch_called_for_sap_doc()` : VÃ©rifie appel prefetch
    - `test_cache_hit_improvement()` : Mesure cache hit rate
    - `test_pipeline_without_prefetch()` : VÃ©rifie backward compat
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 4-5 : Validation Cache Hit Rate

- [ ] **T1.8.2.6** â€” Mesurer cache hit rate AVANT prefetch
  - **Script:** `scripts/phase_1_8/measure_cache_baseline.py`
  - **MÃ©thode:**
    - Run 100 docs ingestion (mix types)
    - Log chaque ontology lookup (hit vs miss)
    - Calculer cache hit rate global
  - **Baseline attendu:** ~50%
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.7** â€” Activer prefetch et mesurer APRÃˆS
  - **Config:** `config/feature_flags.yaml`
  - **Flag:** `enable_ontology_prefetch: true`
  - **Run:** MÃªme 100 docs ingestion
  - **MÃ©triques:**
    - Cache hit rate (target: 70%)
    - LLM calls reduction
    - Latence gatekeeper
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.8** â€” Optimiser TTL si nÃ©cessaire
  - **Analyse:**
    - Si cache hit rate < 65% â†’ Augmenter TTL (2h ou 4h)
    - Si Redis memory usage > 80% â†’ RÃ©duire TTL (30min)
  - **ItÃ©rations:** 2-3 tests
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.2.9** â€” Dashboard Grafana cache metrics
  - **Panel:** "Ontology Cache Performance"
  - **MÃ©triques:**
    - Cache hit rate (gauge, target: 70%)
    - Cache size (gauge, alert if > 500 entries/domain)
    - Prefetch duration (histogram)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.2

- [ ] âœ… Cache hit rate amÃ©lioration 50% â†’ 70% (+ 20 pts)
- [ ] âœ… LLM calls/doc rÃ©duction 25 â†’ 20 (- 20%)
- [ ] âœ… CoÃ»t gatekeeper rÃ©duction $0.002 â†’ $0.001/doc (- 50%)
- [ ] âœ… Latence gatekeeper rÃ©duction 28s â†’ 25s (- 11%)
- [ ] âœ… Prefetch testÃ© sur 100 docs sans erreur Redis
- [ ] âœ… Documentation mapping types â†’ domains complÃ¨te

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| Redis memory overflow | ðŸŸ¡ MOYEN | Max 500 entries + TTL court | [Owner] | ðŸŸ¡ Monitoring |
| Cache stale (ontology update) | ðŸŸ¢ FAIBLE | Invalidation proactive | [Owner] | ðŸŸ¡ Monitoring |
| Mapping incomplet (nouveaux types) | ðŸŸ¢ FAIBLE | Fallback graceful + logs | [Owner] | ðŸŸ¡ Monitoring |

---

## ðŸŽ¯ Sprint 1.8.3 : P3 - Relations LLM Smart Enrichment

**PÃ©riode:** Semaines 15-17 (15 jours-dev)
**Status:** âœ… COMPLÃ‰TÃ‰ (2025-12-18)
**Owner:** Claude Code

### Objectif

AmÃ©liorer qualitÃ© relations (PrÃ©cision 60% â†’ 80%, Rappel 50% â†’ 70%) via LLM batch sur zone grise.

### ImplÃ©mentation RÃ©alisÃ©e

**Fichiers crÃ©Ã©s:**
- `src/knowbase/relations/relation_enricher.py` - Module enrichment
- `tests/phase_1_8/test_relation_enricher.py` - Tests complets

**FonctionnalitÃ©s:**
- `RelationEnricher` classe principale :
  - `is_in_gray_zone()` : DÃ©tection zone grise (0.4-0.6 confidence)
  - `filter_gray_zone_relations()` : Filtrage relations Ã  enrichir
  - `enrich_relations()` : Validation LLM batch avec merge confidence
  - `_create_batches()` : Batching 50 relations max
  - `_validate_batch_via_llm()` : Appel LLM avec structured output
- `enrich_relations_if_enabled()` : Convenience function avec feature flag

**IntÃ©gration:**
- Feature flag `enable_llm_relation_enrichment` dans `feature_flags.yaml`
- Budget cap: 20 batches max Ã— 50 paires = 1000 relations
- Confidence merge: 40% pattern + 60% LLM

**Tests:** 26 tests couvrant gray zone, batching, LLM, feature flags

### Tasks DÃ©taillÃ©es

#### Jour 1-3 : ImplÃ©mentation Enrichment

- [ ] **T1.8.3.1** â€” ImplÃ©menter `_enrich_low_confidence_relations()`
  - **Fichier:** `src/knowbase/agents/pattern_miner/pattern_miner.py`
  - **MÃ©thode:**
    ```python
    async def _enrich_low_confidence_relations(
        self,
        candidate_relations: List[Dict],
        state: AgentState,
        concepts: List[Dict]
    ) -> List[Dict]
    ```
  - **Logique:**
    - Filter zone grise (0.4-0.6 confidence)
    - Batch LLM processing (50 paires/call)
    - Merge LLM insights (weighted average)
    - Budget cap check (20 batches max)
  - **Effort:** 2 jours
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.2** â€” CrÃ©er `TaskType.RELATION_EXTRACTION`
  - **Fichier:** `src/knowbase/common/llm_router.py`
  - **Enum:**
    ```python
    class TaskType(str, Enum):
        # ... existing ...
        RELATION_EXTRACTION = "relation_extraction"  # NOUVEAU Phase 1.8
    ```
  - **Config LLM:**
    - Model: gpt-4o-mini (Ã©conomique)
    - Temperature: 0.3 (dÃ©terministe)
    - Max tokens: 4000
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.3** â€” Budget cap dans SupervisorAgent
  - **Fichier:** `src/knowbase/agents/supervisor/supervisor.py`
  - **Changement:**
    ```python
    self.budget_caps = {
        # ... existing ...
        "RELATION_ENRICHMENT": 20  # Max 20 batches Ã— 50 = 1000 paires
    }
    ```
  - **Enforcement:** Check AVANT chaque batch LLM
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.4** â€” CrÃ©er prompt batch relation extraction
  - **Fichier:** `src/knowbase/agents/pattern_miner/prompts.py`
  - **Prompts:**
    - `RELATION_ENRICHMENT_SYSTEM_PROMPT`
    - `RELATION_ENRICHMENT_USER_PROMPT`
  - **Validation:** Review avec 10 paires test
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.5** â€” Tests unitaires enrichment
  - **Fichier:** `tests/phase_1_8/test_relation_enrichment.py`
  - **Tests:**
    - `test_low_confidence_enrichment()` : VÃ©rifie amÃ©lioration
    - `test_budget_cap_respected()` : Max 20 batches
    - `test_high_confidence_unchanged()` : PrÃ©serve > 0.6
    - `test_weighted_confidence()` : 40% pattern + 60% LLM
  - **Coverage:** > 80%
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 4-5 : Tests QualitÃ©

- [ ] **T1.8.3.6** â€” Mesurer baseline relations sur 20 docs
  - **Script:** `scripts/phase_1_8/measure_baseline_relations.py`
  - **Ground Truth:** Annoter manuellement relations correctes
  - **MÃ©triques:**
    - PrÃ©cision relations (TP / (TP + FP))
    - Rappel relations (TP / (TP + FN))
    - F1-score
  - **Baseline attendu:** PrÃ©cision 60%, Rappel 50%
  - **Effort:** 1.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.7** â€” Activer enrichment et re-mesurer
  - **Config:** `config/feature_flags.yaml`
  - **Flag:** `enable_llm_relation_enrichment: true`
  - **Run:** MÃªme 20 docs ingestion
  - **MÃ©triques:**
    - PrÃ©cision (target: 80%)
    - Rappel (target: 70%)
    - CoÃ»t relations (acceptable si < $0.10/doc)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.8** â€” Human-in-the-loop validation
  - **Process:**
    - Sample 10% relations enrichies par LLM
    - Review manuel par expert domaine
    - Validation: Correct / Incorrect / Ambiguous
  - **Feedback:**
    - Si > 20% incorrect â†’ Ajuster prompts
    - Si > 10% ambiguous â†’ Ajouter contexte
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.9** â€” Ajustement prompts si nÃ©cessaire
  - **ItÃ©rations:** 2-3 cycles feedback â†’ prompt update â†’ re-test
  - **AmÃ©lioration continue:** Logging dÃ©cisions LLM pour analyse
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 5.5 : Dense Graph Optimization (KGGen-Inspired)

- [ ] **T1.8.3.9b** â€” ImplÃ©menter graph density scoring
  - **Fichier:** `src/knowbase/agents/pattern_miner/pattern_miner.py`
  - **MÃ©thode:**
    ```python
    def calculate_graph_density(
        self,
        concepts: List[Dict]
    ) -> float
    ```
  - **Logique:**
    - DensitÃ© = nb_relations / nb_relations_possibles
    - Warning si densitÃ© < 0.05 (graph trop sparse)
    - Suggest lowering similarity threshold si sparse
  - **Inspiration:** KGGen Section 3.2 - Dense Graph Construction
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.9c** â€” Tests graph density
  - **Fichier:** `tests/phase_1_8/test_graph_density.py`
  - **Tests:**
    - `test_density_calculation()` : Calcul correct
    - `test_sparse_graph_warning()` : Warning si < 0.05
    - `test_dense_graph_validation()` : OK si > 0.10
  - **Coverage:** > 80%
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 6-7 : Dashboard + DÃ©ploiement

- [ ] **T1.8.3.10** â€” Grafana panel relations
  - **Panel:** "Relations Quality (Phase 1.8)"
  - **MÃ©triques:**
    - Precision & Recall (gauge)
    - Relations enriched count (counter)
    - LLM batches used (gauge, alert if > 20)
    - Cost relations (gauge)
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.11** â€” Documentation Human review process
  - **Doc:** `doc/processes/human_in_loop_relations.md`
  - **Contenu:**
    - CritÃ¨res validation relations
    - Interface review (Streamlit ou admin panel)
    - Feedback loop vers prompts
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.3.12** â€” DÃ©ploiement production (flag OFF)
  - **Environnement:** Production
  - **Feature Flag:** `enable_llm_relation_enrichment: false`
  - **Rollback Plan:** DocumentÃ©
  - **Communication:** Annonce + formation Ã©quipe
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.3

- [ ] âœ… PrÃ©cision relations 60% â†’ 80% (+ 20 pts)
- [ ] âœ… Rappel relations 50% â†’ 70% (+ 20 pts)
- [ ] âœ… F1-score relations amÃ©lioration > 15 points
- [ ] âœ… CoÃ»t relations < $0.10/doc (acceptable)
- [ ] âœ… Budget cap respectÃ©: 100% docs < 20 batches
- [ ] âœ… Human validation: < 15% relations incorrectes

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| Explosion coÃ»t (> $0.20/doc) | ðŸ”´ Ã‰LEVÃ‰ | Budget cap strict + alertes | [Owner] | ðŸŸ¡ Monitoring |
| Hallucinations LLM relations | ðŸŸ¡ MOYEN | Human-in-loop + Gatekeeper | [Owner] | ðŸŸ¡ Monitoring |
| Latence LLM batch > 10s | ðŸŸ¡ MOYEN | Async parallel + timeout | [Owner] | ðŸŸ¡ Monitoring |
| Zone grise > 60% relations | ðŸŸ¡ MOYEN | Pattern matching amÃ©liorÃ© | [Owner] | ðŸŸ¡ Monitoring |

---

## ðŸŽ¯ Sprint 1.8.4 : Business Rules Engine (Critique P1.2)

**PÃ©riode:** Semaines 18-20 (10 jours-dev)
**Status:** âœ… COMPLÃ‰TÃ‰ (2025-12-18)
**Owner:** Claude Code

### Objectif

Permettre validation mÃ©tier custom par tenant via rÃ¨gles YAML configurables (diffÃ©renciateur marchÃ© vs solutions 100% auto).

### ImplÃ©mentation RÃ©alisÃ©e

**Fichiers crÃ©Ã©s:**
- `src/knowbase/rules/__init__.py` - Module exports
- `src/knowbase/rules/engine.py` - Core business rules engine
- `src/knowbase/rules/loader.py` - YAML/JSON loader
- `tests/phase_1_8/test_business_rules_engine.py` - Tests complets
- `config/rules/pharma_rules.yaml` - RÃ¨gles pharma exemple

**FonctionnalitÃ©s:**
- `RuleCondition` : 10 opÃ©rateurs (equals, contains, matches, in_list, greater_than, exists, etc.)
- `Rule` dataclass : Ã‰valuation conditions, actions, enrichment
- `BusinessRulesEngine` :
  - `validate_concepts()` / `enrich_concepts()`
  - `validate_relations()` / `enrich_relations()`
  - Multi-tenant isolation (rÃ¨gles tenant A â‰  B)
- `RulesLoader` :
  - Charge YAML/JSON depuis `config/rules/`
  - Support global + tenant-specific + built-in rules
  - Save/export rules

**Built-in Rules:**
- `create_pharma_compliance_rules()` : RÃ¨gles FDA, GxP
- `create_sap_validation_rules()` : RÃ¨gles produits SAP

**Types de rÃ¨gles:**
- `concept_validation` / `concept_enrichment`
- `relation_validation` / `relation_enrichment`
- `document_classification`

**Actions:** reject, accept, flag, require_review, enrich

**Tests:** 35+ tests couvrant conditions, Ã©valuation, engine, loader, feature flags

### ðŸ“š Inspiration Critique AcadÃ©mique

**ProblÃ¨me identifiÃ©:**
- Validation gÃ©nÃ©rique ne suffit pas pour domaines spÃ©cialisÃ©s (pharma, finance, legal)
- Clients ont besoin de rÃ¨gles mÃ©tier spÃ©cifiques (compliance, regulatory)
- Solutions concurrentes (Copilot, Gemini) = 100% auto sans customization

**Approche OSMOSE:**
- YAML-based business rules par tenant
- Validation concepts ET relations
- Audit trail complet (quelles rÃ¨gles rejettent quoi)
- **DiffÃ©renciateur marchÃ©:** Customization enterprise-grade

### Tasks DÃ©taillÃ©es

#### Jour 1-3 : Core Business Rules Engine

- [ ] **T1.8.4.1** â€” ImplÃ©menter BusinessRulesEngine
  - **Fichier:** `src/knowbase/agents/gatekeeper/business_rules_engine.py` (NOUVEAU)
  - **Classes:**
    ```python
    class BusinessRule:
        id: str
        applies_to: str  # "concepts" ou "relations"
        condition: Dict[str, Any]
        validation: Dict[str, Any]
        action: str  # "reject", "canonicalize_add_prefix", "boost_confidence"

    class ValidationResult:
        passed: bool
        reason: Optional[str]
        modified_value: Optional[Any]

    class BusinessRulesEngine:
        def __init__(self, tenant_id: str)
        def load_tenant_rules(self, tenant_id: str) -> List[BusinessRule]
        def validate_concept(self, concept: Dict, context: str) -> ValidationResult
        def validate_relation(self, relation: Dict, context: str) -> ValidationResult
    ```
  - **Effort:** 2 jours
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.2** â€” DÃ©finir format YAML rÃ¨gles
  - **Fichier:** `config/business_rules/README.md` + exemples
  - **Exemples rÃ¨gles:**
    ```yaml
    # config/business_rules/pharma_tenant.yaml
    rules:
      - id: pharma_adverse_effect_validation
        applies_to: relations
        condition:
          relation_type: causes_adverse_effect
        validation:
          require_keyword: ["resulted in", "led to", "caused"]
        action: reject_if_missing
        description: "Relations causales doivent avoir keywords explicites"

      - id: sap_product_naming_standard
        applies_to: concepts
        condition:
          type: PRODUCT
          domain: SAP
        validation:
          regex_match: "^SAP "
        action: canonicalize_add_prefix
        prefix: "SAP "
        description: "Produits SAP doivent commencer par 'SAP '"

      - id: high_confidence_regulatory_terms
        applies_to: concepts
        condition:
          type: REGULATORY_TERM
        validation:
          confidence_threshold: 0.8
        action: reject_if_below
        description: "Termes rÃ©glementaires requiÃ¨rent haute confiance"
    ```
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.3** â€” IntÃ©grer dans Gatekeeper
  - **Fichier:** `src/knowbase/agents/gatekeeper/gatekeeper.py`
  - **Code:**
    ```python
    class Gatekeeper(BaseAgent):
        def __init__(self, config):
            super().__init__(AgentRole.GATEKEEPER, config)
            self.business_rules_engine = None  # Lazy init per tenant

        async def execute(self, state: AgentState, instruction: Optional[str] = None):
            # Init business rules engine pour ce tenant
            if self.business_rules_engine is None:
                self.business_rules_engine = BusinessRulesEngine(state.tenant_id)

            # Filtrer concepts via rÃ¨gles mÃ©tier
            validated_concepts = []
            for concept in state.candidates:
                # 1. Validation standard (quality gate)
                gate_result = self._evaluate_quality_gate(concept, state.quality_gate_mode)
                if not gate_result.passed:
                    continue

                # 2. Validation rÃ¨gles mÃ©tier custom
                business_rule_result = self.business_rules_engine.validate_concept(
                    concept=concept,
                    context=concept.get("context", "")
                )

                if not business_rule_result.passed:
                    logger.info(
                        f"[BusinessRules] Concept '{concept['name']}' rejected: "
                        f"{business_rule_result.reason}"
                    )
                    continue

                # 3. Appliquer modifications si nÃ©cessaire
                if business_rule_result.modified_value:
                    concept.update(business_rule_result.modified_value)

                validated_concepts.append(concept)

            # Idem pour relations
            validated_relations = []
            for relation in state.relations:
                business_rule_result = self.business_rules_engine.validate_relation(
                    relation=relation,
                    context=relation.get("context", "")
                )

                if business_rule_result.passed:
                    if business_rule_result.modified_value:
                        relation.update(business_rule_result.modified_value)
                    validated_relations.append(relation)

            state.candidates = validated_concepts
            state.relations = validated_relations

            # Continue promotion...
    ```
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

#### Jour 4-5 : Types de RÃ¨gles SupportÃ©es

- [ ] **T1.8.4.4** â€” ImplÃ©menter validation par regex
  - **MÃ©thode:** `_validate_regex_match(concept, pattern)`
  - **Exemple:** Produits SAP doivent matcher `^SAP `
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.5** â€” ImplÃ©menter validation par keywords
  - **MÃ©thode:** `_validate_keyword_presence(context, keywords)`
  - **Exemple:** Relations "causes_adverse_effect" requiÃ¨rent "resulted in"
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.6** â€” ImplÃ©menter validation par confidence threshold
  - **MÃ©thode:** `_validate_confidence_threshold(concept, threshold)`
  - **Exemple:** Termes rÃ©glementaires requiÃ¨rent confidence > 0.8
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.7** â€” ImplÃ©menter actions (reject/canonicalize/boost)
  - **Actions:**
    - `reject`: Rejette concept/relation
    - `canonicalize_add_prefix`: Ajoute prefix au nom
    - `boost_confidence`: Augmente confidence de X%
    - `require_validation`: Marque pour HITL review
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 6-7 : Tests & Validation

- [ ] **T1.8.4.8** â€” Tests unitaires Business Rules Engine
  - **Fichier:** `tests/phase_1_8/test_business_rules_engine.py`
  - **Tests:**
    - `test_load_tenant_rules()` : Charge rules YAML correct
    - `test_regex_validation()` : Valide pattern regex
    - `test_keyword_validation()` : Requiert keywords prÃ©sence
    - `test_confidence_threshold()` : Rejette low confidence
    - `test_reject_action()` : Rejette concept
    - `test_canonicalize_action()` : Ajoute prefix
    - `test_no_rules_tenant()` : Graceful si pas de rÃ¨gles
  - **Coverage:** > 85%
  - **Effort:** 1.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.9** â€” Tests intÃ©gration Gatekeeper
  - **Fichier:** `tests/integration/test_gatekeeper_business_rules.py`
  - **Tests:**
    - `test_gatekeeper_applies_rules()` : Gatekeeper utilise rÃ¨gles
    - `test_multi_tenant_isolation()` : RÃ¨gles tenant A â‰  tenant B
    - `test_audit_trail()` : Logging dÃ©cisions rÃ¨gles
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 8-9 : Documentation & Audit Trail

- [ ] **T1.8.4.10** â€” Documentation Business Rules
  - **Doc:** `docs/business_rules/README.md`
  - **Contenu:**
    - Guide crÃ©ation rÃ¨gles YAML
    - Exemples par domaine (pharma, finance, legal)
    - Types validation supportÃ©s
    - Actions disponibles
    - Best practices
  - **Effort:** 1 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.11** â€” Audit trail Neo4j
  - **SchÃ©ma Neo4j:**
    ```cypher
    CREATE (d:BusinessRuleDecision {
      decision_id: "dec_123",
      tenant_id: "pharma_tenant",
      rule_id: "pharma_adverse_effect_validation",
      applied_to: "relation_456",
      action: "reject",
      reason: "Missing required keyword 'resulted in'",
      timestamp: datetime()
    })
    ```
  - **API endpoint:** `GET /api/business-rules/audit/{tenant_id}`
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

#### Jour 10 : DÃ©ploiement & Demo

- [ ] **T1.8.4.12** â€” Templates rÃ¨gles par domaine
  - **Fichiers:**
    - `config/business_rules/templates/pharma_compliance.yaml`
    - `config/business_rules/templates/finance_risk.yaml`
    - `config/business_rules/templates/legal_contracts.yaml`
  - **Contenu:** 10-15 rÃ¨gles prÃ©-configurÃ©es par domaine
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

- [ ] **T1.8.4.13** â€” DÃ©ploiement production
  - **Feature Flag:** `enable_business_rules_engine: false` (default)
  - **Migration:** Aucun schÃ©ma Neo4j changement (additive only)
  - **Rollback Plan:** DÃ©sactiver feature flag
  - **Effort:** 0.5 jour
  - **Status:** ðŸ”´ TODO

### Success Criteria Sprint 1.8.4

- [ ] âœ… BusinessRulesEngine implÃ©mentÃ© et testÃ©
- [ ] âœ… Support 3 types validation (regex, keywords, confidence)
- [ ] âœ… Support 4 actions (reject, canonicalize, boost, require_validation)
- [ ] âœ… Multi-tenant isolation (rÃ¨gles tenant A â‰  B)
- [ ] âœ… Audit trail complet (Neo4j + API)
- [ ] âœ… Templates 3 domaines (pharma, finance, legal)
- [ ] âœ… Documentation complÃ¨te
- [ ] âœ… Tests 85%+ coverage

### Blockers & Risques

| Risque | Impact | Mitigation | Owner | Status |
|--------|--------|------------|-------|--------|
| RÃ¨gles trop restrictives | ðŸŸ¡ MOYEN | Templates + guidelines validation | [Owner] | ðŸŸ¡ Monitoring |
| Conflits entre rÃ¨gles | ðŸŸ¡ MOYEN | Ordre prioritÃ© + warnings | [Owner] | ðŸŸ¡ Monitoring |
| ComplexitÃ© maintenance | ðŸŸ¢ FAIBLE | Templates + documentation | [Owner] | ðŸŸ¡ Monitoring |

### DiffÃ©renciation MarchÃ©

**vs Copilot/Gemini (100% auto):**
- âœ… OSMOSE permet customization enterprise-grade
- âœ… Compliance domaine (pharma FDA, finance FINRA, legal)
- âœ… Audit trail complet (qui a rejetÃ© quoi, pourquoi)
- âœ… Templates prÃ©-configurÃ©s par industrie

**ROI Client:**
- Adoption: +40% (experts trust validation mÃ©tier)
- Precision: +15-20% (rÃ¨gles domaine Ã©liminent faux positifs)
- Compliance: 100% (rÃ¨gles rÃ©glementaires enforced)

**RÃ©fÃ©rence:** Critique AcadÃ©mique Section P1.2 - "Business Rules Engine (DiffÃ©renciateur vs Concurrence)"

---

## ðŸ“Š MÃ©triques Globales Phase 1.8

### Tableau de Bord ProgrÃ¨s

| MÃ©trique | Baseline | Target | Actuel | Delta | Status |
|----------|----------|--------|--------|-------|--------|
| **Rappel concepts** | 70% | 85% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **PrÃ©cision concepts** | 85% | 90% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Rappel relations** | 50% | 70% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **PrÃ©cision relations** | 60% | 80% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **CoÃ»t/doc** | $0.03 | â‰¤ $0.14 | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Latence extraction** | 15s | â‰¤ 18s | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Latence gatekeeper** | 28s | â‰¤ 25s | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **LLM calls/doc** | 25 | â‰¤ 20 | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Cache hit rate** | 50% | â‰¥ 70% | â€” | â€” | ðŸ”´ Ã€ mesurer |

### Nouvelles MÃ©triques KGGen-Inspired

| MÃ©trique | Baseline | Target | Actuel | Delta | Status |
|----------|----------|--------|--------|-------|--------|
| **Cross-Lingual Accuracy (FRâ†”ENâ†”DE)** | ~75% | â‰¥ 85% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Faux Positifs Clustering** | ~15% | â‰¤ 8% | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Graph Density** | ~0.05 | â‰¥ 0.10 | â€” | â€” | ðŸ”´ Ã€ mesurer |
| **Benchmark MINE-like F1** | â€” | â‰¥ 0.80 | â€” | â€” | ðŸ”´ Ã€ mesurer |

### CoÃ»ts CumulÃ©s

| Sprint | Budget PrÃ©vu | DÃ©pensÃ© | Restant | Status |
|--------|--------------|---------|---------|--------|
| **1.8.1 (P1 + Contexte)** | $600 (test 100 docs) | $0 | $600 | ðŸŸ¢ OK |
| **1.8.1b (Benchmark)** | $150 (50 docs eval) | $0 | $150 | ðŸŸ¢ OK |
| **1.8.1c (Dict NER)** | $100 (test 50 docs) | $0 | $100 | ðŸŸ¢ OK |
| **1.8.2 (P2 Prefetch)** | $200 (test 100 docs) | $0 | $200 | ðŸŸ¢ OK |
| **1.8.3 (P3 Relations + HITL)** | $1000 (test 100 docs) | $0 | $1000 | ðŸŸ¢ OK |
| **1.8.4 (Business Rules)** | $150 (test 50 docs) | $0 | $150 | ðŸŸ¢ OK |
| **TOTAL** | $2200 | $0 | $2200 | ðŸŸ¢ OK |

**Notes:**
- +$100 Contexte Document Global (gÃ©nÃ©ration rÃ©sumÃ©s LLM)
- +$150 Benchmark MINE-like (Ã©valuation 50 docs)
- +$100 Dictionnaires MÃ©tier NER (validation 50 docs multi-domaines)
- +$150 Business Rules Engine (test validation custom rules)

---

## ðŸš¨ Alertes & Incidents

### Alertes Actives

*Aucune alerte pour l'instant (Phase non dÃ©marrÃ©e)*

### Incidents Historiques

*Aucun incident (Phase non dÃ©marrÃ©e)*

---

## ðŸ“… Calendrier DÃ©taillÃ©

### Semaine 11 : Sprint 1.8.1 (Partie 1)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 11.1** | T1.8.1.1 (Routing implementation) | [Dev] | ðŸ”´ TODO |
| **Mardi 11.2** | T1.8.1.2 (Prompts) + T1.8.1.3 (Tests) | [Dev] | ðŸ”´ TODO |
| **Mercredi 11.3** | T1.8.1.4 (SÃ©lection docs test) | [Dev] | ðŸ”´ TODO |
| **Jeudi 11.4** | T1.8.1.5 (Baseline) + T1.8.1.6 (Run hybrid) | [Dev] | ðŸ”´ TODO |
| **Vendredi 11.5** | T1.8.1.7 (Comparaison mÃ©triques) | [Dev] | ðŸ”´ TODO |

### Semaine 12 : Sprint 1.8.1 (Partie 2)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 12.1** | T1.8.1.8 (Dashboard Grafana) | [Dev] | ðŸ”´ TODO |
| **Mardi 12.2** | T1.8.1.9 (DÃ©ploiement prod) | [Dev] | ðŸ”´ TODO |
| **Mercredi 12.3** | Buffer / Documentation | [Dev] | ðŸ”´ TODO |
| **Jeudi 12.4** | Review sprint + Demo stakeholders | [Team] | ðŸ”´ TODO |
| **Vendredi 12.5** | RÃ©trospective + Planning Sprint 1.8.2 | [Team] | ðŸ”´ TODO |

### Semaine 13 : Sprint 1.8.2 (Partie 1)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 13.1** | T1.8.2.1 (Prefetch implementation) | [Dev] | ðŸ”´ TODO |
| **Mardi 13.2** | T1.8.2.2 (Mapping) + T1.8.2.3 (Tests) | [Dev] | ðŸ”´ TODO |
| **Mercredi 13.3** | T1.8.2.4 (IntÃ©gration pipeline) | [Dev] | ðŸ”´ TODO |
| **Jeudi 13.4** | T1.8.2.5 (Tests intÃ©gration) | [Dev] | ðŸ”´ TODO |
| **Vendredi 13.5** | T1.8.2.6 (Mesure baseline cache) | [Dev] | ðŸ”´ TODO |

### Semaine 14 : Sprint 1.8.2 (Partie 2)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 14.1** | T1.8.2.7 (Mesure aprÃ¨s prefetch) | [Dev] | ðŸ”´ TODO |
| **Mardi 14.2** | T1.8.2.8 (Optimisation TTL) | [Dev] | ðŸ”´ TODO |
| **Mercredi 14.3** | T1.8.2.9 (Dashboard) + Buffer | [Dev] | ðŸ”´ TODO |
| **Jeudi 14.4** | Review sprint + Demo stakeholders | [Team] | ðŸ”´ TODO |
| **Vendredi 14.5** | RÃ©trospective + Planning Sprint 1.8.3 | [Team] | ðŸ”´ TODO |

### Semaine 15 : Sprint 1.8.3 (Partie 1)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 15.1** | T1.8.3.1 (Enrichment implementation - Jour 1) | [Dev] | ðŸ”´ TODO |
| **Mardi 15.2** | T1.8.3.1 (Enrichment implementation - Jour 2) | [Dev] | ðŸ”´ TODO |
| **Mercredi 15.3** | T1.8.3.2 (TaskType) + T1.8.3.3 (Budget cap) | [Dev] | ðŸ”´ TODO |
| **Jeudi 15.4** | T1.8.3.4 (Prompts) + T1.8.3.5 (Tests) | [Dev] | ðŸ”´ TODO |
| **Vendredi 15.5** | T1.8.3.6 (Baseline relations - Jour 1) | [Dev] | ðŸ”´ TODO |

### Semaine 16 : Sprint 1.8.3 (Partie 2)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 16.1** | T1.8.3.6 (Baseline relations - Jour 2) | [Dev] | ðŸ”´ TODO |
| **Mardi 16.2** | T1.8.3.7 (Mesure aprÃ¨s enrichment) | [Dev] | ðŸ”´ TODO |
| **Mercredi 16.3** | T1.8.3.8 (Human-in-loop validation) | [Dev + Expert] | ðŸ”´ TODO |
| **Jeudi 16.4** | T1.8.3.9 (Ajustement prompts) | [Dev] | ðŸ”´ TODO |
| **Vendredi 16.5** | T1.8.3.10 (Dashboard Grafana) | [Dev] | ðŸ”´ TODO |

### Semaine 17 : Sprint 1.8.3 (Partie 3)

| Jour | Tasks | Owner | Status |
|------|-------|-------|--------|
| **Lundi 17.1** | T1.8.3.11 (Documentation Human review) | [Dev] | ðŸ”´ TODO |
| **Mardi 17.2** | T1.8.3.12 (DÃ©ploiement prod) | [Dev] | ðŸ”´ TODO |
| **Mercredi 17.3** | Phase 1.8 Complete Review | [Team] | ðŸ”´ TODO |
| **Jeudi 17.4** | Demo finale stakeholders + clients | [Team] | ðŸ”´ TODO |
| **Vendredi 17.5** | RÃ©trospective Phase 1.8 + Handoff Phase 2 | [Team] | ðŸ”´ TODO |

---

## ðŸ“ Notes & Decisions

### DÃ©cisions Architecture

*Aucune dÃ©cision prise (Phase non dÃ©marrÃ©e)*

### Changements de Scope

*Aucun changement (Phase non dÃ©marrÃ©e)*

### Feedback Stakeholders

*Aucun feedback (Phase non dÃ©marrÃ©e)*

---

## ðŸ”— Liens Utiles

- **Spec Phase 1.8:** `doc/phases/PHASE1_8_LLM_HYBRID_INTELLIGENCE.md`
- **Analyse HELIOS:** Session 2025-11-19

### RÃ©fÃ©rences AcadÃ©miques

- **Paper KGGen (Stanford):** https://arxiv.org/html/2502.09956v1
  - Titre: "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models"
  - Source: Stanford University, University of Toronto, FAR AI
  - Date: 2025-02
  - RÃ©sultat clÃ©: +18% vs baselines sur benchmark MINE

- **Critique Bonnes Pratiques KG AcadÃ©miques:** `doc/research/OSMOSE_CRITIQUE_BONNES_PRATIQUES_KG_ACADEMIQUES.md`
  - Source: Analyse OpenAI + OSMOSE Architecture Team
  - Date: 2025-11-18
  - Focus: Pragmatisme vs acadÃ©misme
  - Recommandations: P0.1 (Contexte Global), P1.1 (Dict NER), P1.2 (Business Rules), P1.3 (HITL)

- **Analyse Comparative KGGen vs OSMOSE:** `doc/research/KGGEN_OSMOSE_COMPARATIVE_ANALYSIS.md`
  - Convergence: 85% mÃ©thodologique
  - USP OSMOSE: Cross-lingual unification (unique)

### Outils & Monitoring

- **Feature Flags:** `config/feature_flags.yaml`
- **Dashboard Grafana:** [URL Ã  dÃ©finir]
- **Slack Channel:** #phase-1-8-llm-hybrid
- **Jira Epic:** [Ã€ crÃ©er]

---

## ðŸ“ž Contacts

| RÃ´le | Nom | Contact | DisponibilitÃ© |
|------|-----|---------|---------------|
| **Phase Owner** | [Ã€ assigner] | email@domain.com | Lun-Ven 9h-18h |
| **Tech Lead** | [Ã€ assigner] | email@domain.com | Lun-Ven 9h-18h |
| **Dev Sprint 1.8.1** | [Ã€ assigner] | email@domain.com | Lun-Ven 9h-18h |
| **Dev Sprint 1.8.2** | [Ã€ assigner] | email@domain.com | Lun-Ven 9h-18h |
| **Dev Sprint 1.8.3** | [Ã€ assigner] | email@domain.com | Lun-Ven 9h-18h |
| **Expert Domaine (Relations)** | [Ã€ assigner] | email@domain.com | Sur demande |

---

## ðŸŽ‰ SynthÃ¨se ImplÃ©mentation Phase 1.8

### Sprints ComplÃ©tÃ©s (2025-12-17 â†’ 2025-12-18)

| Sprint | Fichiers CrÃ©Ã©s | Tests | Status |
|--------|---------------|-------|--------|
| **1.8.1** | prompts.py, orchestrator routing, llm_judge | 50+ tests | âœ… |
| **1.8.1c** | ontologies/*.json, ner_manager.py | 20+ tests | âœ… |
| **1.8.2** | adaptive_ontology_manager.py (prefetch) | 21 tests | âœ… |
| **1.8.3** | relation_enricher.py | 26 tests | âœ… |
| **1.8.4** | rules/engine.py, rules/loader.py | 35+ tests | âœ… |

### Prochaines Ã‰tapes

1. **Tests A/B Production** - Valider mÃ©triques sur documents rÃ©els
2. **Activation Feature Flags** - DÃ©ploiement progressif
3. **Benchmark MINE-like (1.8.1b)** - Dataset validation cross-lingual

### Feature Flags

**Documentation complÃ¨te :** `doc/guides/FEATURE_FLAGS_GUIDE.md`

**Ã‰tat actuel :** Toutes les features Phase 1.8 sont **activÃ©es par dÃ©faut** (projet en dÃ©veloppement).

```yaml
# config/feature_flags.yaml
phase_1_8:
  enabled: true
  enable_hybrid_extraction: true        # Sprint 1.8.1
  enable_document_context: true         # Sprint 1.8.1
  enable_llm_judge_validation: true     # Sprint 1.8.1
  enable_entity_ruler: true             # Sprint 1.8.1c
  enable_ontology_prefetch: true        # Sprint 1.8.2
  enable_llm_relation_enrichment: true  # Sprint 1.8.3
  enable_business_rules_engine: true    # Sprint 1.8.4
```

**Pour dÃ©sactiver une feature :** Modifier `config/feature_flags.yaml` ou utiliser les overrides par environnement/tenant (voir guide).

---

**ðŸŒŠ OSMOSE Phase 1.8 â€” IMPLÃ‰MENTATION COMPLÃˆTE**
**Tracking mis Ã  jour: 2025-12-18**

*Prochaine Ã©tape: Validation production + Tests A/B*
