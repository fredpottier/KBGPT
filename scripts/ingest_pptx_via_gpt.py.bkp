# ingest_pptx_via_gpt.py
# Version: 2025-09-03 — + OCR Tesseract, rendu HD, extraction riche

import base64
import debugpy  # ok même si inactif
import json
import logging
import os
import shutil
import subprocess
import time
import uuid
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any

from import_logging import setup_logging

from langdetect import detect, DetectorFactory
from openai import OpenAI
from pdf2image import convert_from_path
from pptx import Presentation
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, PointStruct, VectorParams
from sentence_transformers import SentenceTransformer


# =========================
# Path resolution (simplifiée et robuste)
# =========================
def get_project_root() -> Path:
    # Utilise le dossier parent du script comme racine projet
    return Path(__file__).resolve().parent.parent


PROJECT_ROOT = get_project_root()

DOCS_IN = PROJECT_ROOT / "docs_in"
DOCS_DONE = PROJECT_ROOT / "public_files" / "presentations"
SLIDES_PNG = PROJECT_ROOT / "public_files" / "slides"
STATUS_DIR = PROJECT_ROOT / "status"
LOGS_DIR = PROJECT_ROOT / "logs"
MODELS_DIR = PROJECT_ROOT / "models"

os.environ.setdefault("HF_HOME", str(MODELS_DIR))

# =============================
# Configuration & initialisation
# =============================
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION", "sap_kb")
GPT_MODEL = os.getenv("GPT_MODEL", "gpt-4o")
# Alignement écosystème RAG sur E5
MODEL_NAME = os.getenv("EMB_MODEL_NAME", "intfloat/multilingual-e5-base")

MAX_WORKERS = int(
    os.getenv("MAX_WORKERS", "2")
)  # paralléliser raisonnablement les slides
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OCR_ENABLED = os.getenv("OCR_ENABLED", "1") not in {
    "0",
    "false",
    "False",
}  # toggle rapide

# Logging
logger = setup_logging(LOGS_DIR, "ingest_pptx_debug.log")

# Langdetect determinisme
DetectorFactory.seed = 0


# =============================
# Helpers système
# =============================
def ensure_dirs():
    for d in [DOCS_IN, DOCS_DONE, SLIDES_PNG, STATUS_DIR, LOGS_DIR, MODELS_DIR]:
        d.mkdir(parents=True, exist_ok=True)


def normalize_public_url(url: str) -> str:
    if not url:
        return ""
    u = url.strip().rstrip("/")
    if not (u.startswith("http://") or u.startswith("https://")):
        u = "https://" + u
    return u


def resolve_soffice_path() -> str:
    cand = os.getenv("SOFFICE_PATH", "").strip()
    if cand and Path(cand).exists():
        return cand
    found = shutil.which("soffice") or shutil.which("libreoffice")
    return found or "/usr/bin/soffice"


def run_cmd(cmd: List[str], timeout: int = 120) -> bool:
    try:
        subprocess.run(cmd, check=True, timeout=timeout)
        return True
    except subprocess.TimeoutExpired:
        logger.error(f"❌ Timeout: {' '.join(cmd)}")
    except subprocess.CalledProcessError as e:
        logger.error(f"❌ Command failed ({e.returncode}): {' '.join(cmd)}")
    except Exception as e:
        logger.error(f"❌ Command exception: {e}")
    return False


PUBLIC_URL = normalize_public_url(os.getenv("PUBLIC_URL", "sapkb.ngrok.app"))
SOFFICE_PATH = resolve_soffice_path()


def banner_paths():
    def exists_dir(p: Path) -> str:
        return f"{p}  (exists={p.exists()}, is_dir={p.is_dir()})"

    logger.info("=== PPTX INGEST START ===")
    logger.info(f"PROJECT_ROOT: {exists_dir(PROJECT_ROOT)}")
    logger.info(f"DOCS_IN:      {exists_dir(DOCS_IN)}")
    logger.info(f"DOCS_DONE:    {exists_dir(DOCS_DONE)}")
    logger.info(f"SLIDES_PNG:   {exists_dir(SLIDES_PNG)}")
    logger.info(f"STATUS_DIR:   {exists_dir(STATUS_DIR)}")
    logger.info(f"LOGS_DIR:     {exists_dir(LOGS_DIR)}")
    logger.info(f"MODELS_DIR:   {exists_dir(MODELS_DIR)}")
    logger.info(f"SOFFICE_PATH: {SOFFICE_PATH}  (exists={Path(SOFFICE_PATH).exists()})")
    logger.info(f"PUBLIC_URL:   {PUBLIC_URL}")
    logger.info(f"MAX_WORKERS:  {MAX_WORKERS}")
    logger.info(f"OCR_ENABLED:  {OCR_ENABLED}")
    # Vérifier présence poppler & tesseract
    for bin_name in ("pdftotext", "pdftoppm", "tesseract"):
        logger.info(f"{bin_name}: {shutil.which(bin_name) or 'NOT FOUND in PATH'}")


ensure_dirs()
banner_paths()

# ===================
# Clients & Modèles
# ===================
if not OPENAI_API_KEY:
    logger.error("❌ OPENAI_API_KEY manquant dans l'environnement")
client = OpenAI(api_key=OPENAI_API_KEY)

try:
    qdrant = QdrantClient(url=os.getenv("QDRANT_URL", "http://qdrant:6333"))
    logger.info("✅ Qdrant client initialized")
except Exception as e:
    logger.error(f"❌ Qdrant init failed: {e}")
    raise

try:
    model = SentenceTransformer(MODEL_NAME)
    EMB_SIZE = int(model.get_sentence_embedding_dimension() or 768)
    logger.info(f"✅ Embedding model loaded: {MODEL_NAME} (dim={EMB_SIZE})")
except Exception as e:
    logger.error(f"❌ Embedding model load failed: {e}")
    raise

try:
    if not qdrant.collection_exists(COLLECTION_NAME):
        qdrant.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=EMB_SIZE, distance=Distance.COSINE),
        )
        logger.info(f"✅ Collection '{COLLECTION_NAME}' created")
    else:
        logger.info(f"ℹ️ Collection '{COLLECTION_NAME}' already exists")
except Exception as e:
    logger.error(f"❌ Qdrant collection check/create failed: {e}")
    raise


# =============
# Utilitaires
# =============
def clean_gpt_response(raw: str) -> str:
    s = (raw or "").strip()
    if s.startswith("```json"):
        s = s[len("```json") :].strip()
    if s.startswith("```"):
        s = s[len("```") :].strip()
    if s.endswith("```"):
        s = s[:-3].strip()
    return s


def encode_image_base64(img_path: Path) -> str:
    with open(img_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def get_language_iso2(text: str) -> str:
    try:
        code = detect(text)
        return code  # "fr", "en", ...
    except Exception:
        return "en"  # fallback neutre


def embed_texts(texts: List[str]) -> List[List[float]]:
    # E5 convention: "passage: " pour les documents
    batched = [f"passage: {t}" for t in texts]
    return model.encode(batched, normalize_embeddings=True, convert_to_numpy=False)


# =========
# OCR & rendu
# =========
def has_tesseract() -> bool:
    return shutil.which("tesseract") is not None


def maybe_ocr_image(img_path: Path) -> str:
    """
    OCR léger si OCR_ENABLED et tesseract dispo. Retourne '' si indisponible.
    """
    if not OCR_ENABLED or not has_tesseract():
        return ""
    try:
        import pytesseract
        from PIL import Image

        txt = pytesseract.image_to_string(Image.open(img_path))
        txt = (txt or "").strip()
        if len(txt) > 10000:
            txt = txt[:10000] + "…"
        return txt
    except Exception as e:
        logger.warning(f"⚠️ OCR failed on {img_path.name}: {e}")
        return ""


def render_pdf_to_pngs(pdf_path: Path, outdir: Path, dpi: int = 240) -> dict[int, Path]:
    """
    Rend chaque page du PDF en PNG haute définition.
    """
    logger.info(f"🖼️ Rendu PNG (dpi={dpi}): {pdf_path.name}")
    outdir.mkdir(parents=True, exist_ok=True)
    images = convert_from_path(str(pdf_path), dpi=dpi, output_folder=str(outdir))
    mapping = {}
    for i, img in enumerate(images, start=1):
        img_path = outdir / f"{pdf_path.stem}_slide_{i}.png"
        img.save(img_path, "PNG")
        mapping[i] = img_path
    return mapping


# ==================
# Étapes de pipeline
# ==================
def convert_pptx_to_pdf(pptx_path: Path, output_dir: Path) -> Path:
    output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"📄 Conversion PPTX→PDF: {pptx_path.name}")
    ok = run_cmd(
        [
            SOFFICE_PATH,
            "--headless",
            "--convert-to",
            "pdf",
            "--outdir",
            str(output_dir),
            str(pptx_path),
        ],
        timeout=180,
    )
    pdf_path = output_dir / (pptx_path.stem + ".pdf")
    if not ok or not pdf_path.exists():
        raise RuntimeError("LibreOffice conversion failed or PDF missing")
    logger.debug(f"PDF path: {pdf_path} (exists={pdf_path.exists()})")
    return pdf_path


def extract_text_from_pdf(pdf_path: Path) -> str:
    txt_output = pdf_path.with_suffix(".txt")
    logger.info(f"📑 pdftotext: {pdf_path.name}")
    ok = run_cmd(["pdftotext", str(pdf_path), str(txt_output)], timeout=60)
    if not ok or not txt_output.exists():
        logger.warning("⚠️ pdftotext non disponible ou extraction vide")
        return ""
    try:
        text = txt_output.read_text(encoding="utf-8", errors="ignore")
        logger.debug(f"Extracted text length: {len(text)}")
        return text
    except Exception as e:
        logger.warning(f"⚠️ Could not read {txt_output}: {e}")
        return ""


def extract_notes_and_text(pptx_path: Path) -> List[Dict[str, Any]]:
    logger.info(f"📊 Extraction texte+notes du PPTX: {pptx_path.name}")
    prs = Presentation(str(pptx_path))
    slides_data = []
    for i, slide in enumerate(prs.slides, start=1):
        # Notes
        notes = ""
        if getattr(slide, "has_notes_slide", False):
            notes_slide = getattr(slide, "notes_slide", None)
            if notes_slide and hasattr(notes_slide, "notes_text_frame"):
                tf = notes_slide.notes_text_frame
                if tf and hasattr(tf, "text"):
                    notes = (tf.text or "").strip()

        # Textes
        texts = []
        for shape in slide.shapes:
            txt = getattr(shape, "text", None)
            if isinstance(txt, str) and txt.strip():
                texts.append(txt.strip())

        slides_data.append(
            {
                "slide_index": i,
                "text": "\n".join(texts),
                "notes": notes,
            }
        )
    logger.debug(f"Slides parsed: {len(slides_data)}")
    return slides_data


# ===== GPT: métadonnées doc =====
def analyze_pdf_metadata(pdf_text: str, source_name: str) -> dict:
    logger.info(f"🔍 GPT: analyse des métadonnées — {source_name}")
    user_content = (
        f"You're analyzing a PowerPoint document converted to PDF: '{source_name}'.\n"
        f"Below is a raw text excerpt extracted from it (may be noisy):\n\n{pdf_text[:8000]}\n\n"
        "Extract the following high-level metadata and return a single JSON object with fields:\n"
        "- title\n- objective\n- main_solution\n- supporting_solutions\n"
        "- mentioned_solutions\n- document_type\n- audience\n- source_date\n- language\n\n"
        "IMPORTANT:\n"
        "- For 'main_solution', always use the official SAP canonical solution name as published by SAP.\n"
        "- Do not use acronyms, abbreviations, or local variants.\n"
        "- If you are unsure, **leave 'main_solution' empty**.\n"
        "Examples of non-canonical names to leave empty: 'S/4 PCE RISE', 'SAP IBP APO'."
    )
    try:
        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "You are a precise metadata extraction assistant.",
                },
                {"role": "user", "content": user_content},
            ],
            temperature=0.1,
            max_tokens=1024,
        )
        raw = getattr(response.choices[0].message, "content", "") or ""
        cleaned = clean_gpt_response(raw)
        meta = json.loads(cleaned) if cleaned else {}
        if not isinstance(meta, dict):
            meta = {}
        logger.debug(f"META (keys): {list(meta.keys()) if meta else 'n/a'}")
        return meta
    except Exception as e:
        logger.error(f"❌ GPT metadata error: {e}")
        return {}


# ===== GPT: classification & extraction riche =====
def parse_json_array(raw: str) -> List[Dict[str, Any]]:
    try:
        cleaned = clean_gpt_response(raw)
        data = json.loads(cleaned)
        if isinstance(data, list):
            out = []
            for it in data:
                if isinstance(it, dict) and isinstance(it.get("text"), str):
                    meta = it.get("meta") if isinstance(it.get("meta"), dict) else {}
                    text = it["text"].strip()
                    if text:
                        if len(text) > 4000:
                            text = text[:4000] + "…"
                        out.append({"text": text, "meta": meta})
            return out
    except Exception:
        pass
    return []


def classify_slide_type(image_b64: str, slide_text: str) -> str:
    """
    Retourne un type de slide simple: diagram | table | list | chart | title_cover | mixed | other
    """
    try:
        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": "Classify slide type strictly."},
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/png;base64,{image_b64}"},
                        },
                        {
                            "type": "text",
                            "text": "Given the slide image and optional text, choose exactly one type:\n"
                            "diagram | table | list | chart | title_cover | mixed | other.\n"
                            "Return only the type string.",
                        },
                    ],
                },
            ],
            temperature=0.0,
            max_tokens=10,
        )
        t = (response.choices[0].message.content or "").strip().lower()
        if t not in {
            "diagram",
            "table",
            "list",
            "chart",
            "title_cover",
            "mixed",
            "other",
        }:
            t = "other"
        return t
    except Exception as e:
        logger.warning(f"⚠️ classify_slide_type error: {e}")
        return "other"


def build_extraction_instruction(slide_type: str, doc_meta: dict) -> str:
    guide = ""
    main_sol = (doc_meta or {}).get("main_solution") or (doc_meta or {}).get(
        "doc_meta", {}
    ).get("main_solution")
    if main_sol:
        guide = f"\nContext hint: the main SAP solution in this deck is likely '{main_sol}'. Prioritize insights relevant to it."

    common = (
        "Extract 3–8 rich, self-contained content blocks capturing the *meaning* of the slide beyond plain text. "
        "Each block must include entities and, when relevant, relationships or metrics.\n"
        "Use this JSON array schema STRICTLY (no trailing text):\n"
        "[\n"
        "  {\n"
        '    "text": "...",\n'
        '    "meta": {\n'
        '      "type": "insight|key_point|process_step|relationship|metric|table_row|title|risk|action|assumption",\n'
        '      "topic": "short-tag",\n'
        '      "level": "slide|section|global",\n'
        '      "entities": [{"name":"...","kind":"solution|product|system|role|org|data|platform|other"}],\n'
        '      "relations": [{"subject":"...","predicate":"...","object":"...","qualifiers": {}}],\n'
        '      "metrics": [{"name":"...","value":"...","unit":"%|ms|€|$|..."}],\n'
        '      "evidence": ["visual","text","notes"],\n'
        '      "confidence": 0.0,\n'
        '      "diagram_graph": {"nodes":[], "edges":[]}\n'
        "    }\n"
        "  }\n"
        "]\n"
        "Rules:\n"
        "- Keep each `text` concise (<= 600 chars) but complete.\n"
        "- If the slide contains arrows/flows, add at least one `relationship` with subject/predicate/object.\n"
        "- For tables/charts, emit `metric` or `table_row` blocks with normalized values.\n"
        "- No explanations outside JSON. Strict JSON.\n"
    ) + guide

    if slide_type in ("diagram", "mixed"):
        return (
            "This is likely a diagram or mixed-content slide. Focus on flows, responsibilities and component interactions.\n"
            + common
        )
    if slide_type == "table":
        return (
            "This is likely a table. Capture each relevant row as a `table_row` or `metric`. Normalize units and numbers.\n"
            + common
        )
    if slide_type == "chart":
        return (
            "This is likely a chart. Capture trends and numeric highlights as `metric` plus 1–2 `insight`.\n"
            + common
        )
    if slide_type == "list":
        return (
            "This is likely a bullet/list slide. Consolidate bullets into `key_point`/`insight`. Merge duplicates.\n"
            + common
        )
    if slide_type == "title_cover":
        return (
            "This is likely a title/cover/section slide. Extract only `title` and at most 2 `key_point` blocks.\n"
            + common
        )
    return (
        "Unknown/misc slide. Extract the most meaningful insights, relationships, or metrics available.\n"
        + common
    )


def ask_gpt_slide_analysis_rich(
    image_path: Path,
    slide_text: str,
    slide_notes: str,
    source_name: str,
    slide_index: int,
    doc_meta: dict,
    retries: int = 3,
    backoff_s: float = 1.5,
) -> List[Dict[str, Any]]:
    logger.info(f"🧠 GPT rich extraction: slide {slide_index}")
    # 1) Base64
    try:
        image_b64 = encode_image_base64(image_path)
    except Exception as e:
        logger.error(f"❌ Base64 slide {slide_index} error: {e}")
        return []

    # 2) Classify
    s_type = classify_slide_type(image_b64, slide_text)
    instruction = build_extraction_instruction(s_type, doc_meta)

    # 3) Payloads
    user_payload = [
        {
            "type": "image_url",
            "image_url": {"url": f"data:image/png;base64,{image_b64}"},
        },
        {
            "type": "text",
            "text": f"Slide #{slide_index} from '{source_name}'.\n"
            f"Slide text (may be partial or OCR):\n{slide_text}\n\n"
            f"Speaker notes (if any):\n{slide_notes}\n\n" + instruction,
        },
    ]

    # 4) Retry JSON strict
    for attempt in range(1, retries + 1):
        try:
            response = client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "You return ONLY strict JSON arrays following the schema. No commentary.",
                    },
                    {"role": "user", "content": user_payload},
                ],
                temperature=0.2,
                max_tokens=1800,
            )
            raw = getattr(response.choices[0].message, "content", "") or ""
            data = parse_json_array(raw)
            if data:
                # Post-traitement léger: clamp confidence & evidence
                for d in data:
                    m = d.get("meta", {})
                    if isinstance(m.get("confidence"), (int, float)):
                        c = float(m["confidence"])
                        m["confidence"] = max(0.0, min(1.0, c))
                    ev = m.get("evidence")
                    if not isinstance(ev, list):
                        m["evidence"] = ["visual"]
                logger.debug(
                    f"Slide {slide_index}: chunks returned = {len(data)} (type={s_type})"
                )
                return data
            else:
                logger.warning(
                    f"⚠️ Slide {slide_index}: JSON vide/invalid (attempt {attempt}/{retries}, type={s_type})"
                )
        except Exception as e:
            logger.warning(
                f"⚠️ GPT rich call failed slide {slide_index} (attempt {attempt}/{retries}): {e}"
            )
        time.sleep(backoff_s * attempt)
    logger.error(f"❌ GPT rich extraction failed after retries (slide {slide_index})")
    return []


# ===== Ingestion Qdrant (batch embeddings + payload namespacé) =====
def ingest_chunks(
    chunks: List[Dict[str, Any]],
    doc_metadata: Dict[str, Any],
    file_uid: str,
    slide_index: int,
):
    # Filtrer et préparer textes
    valid = []
    for ch in chunks:
        text = (ch.get("text") or "").strip()
        if not text or len(text) < 20:
            continue
        valid.append(ch)

    if not valid:
        logger.info(f"ℹ️ Slide {slide_index}: aucun chunk valide")
        return

    try:
        embs = embed_texts([c["text"].strip() for c in valid])
    except Exception as e:
        logger.error(f"❌ Embedding batch failed (slide {slide_index}): {e}")
        return

    points = []
    for ch, emb in zip(valid, embs):
        text = ch["text"].strip()
        meta = ch.get("meta", {}) or {}
        lang = get_language_iso2(text)

        payload = {
            "text": text,
            "language": lang,  # "fr", "en", etc.
            "ingested_at": datetime.now(timezone.utc).isoformat(timespec="seconds"),
            "gpt_chunked": True,
            "slide_index": slide_index,
            "slide_image_url": f"{PUBLIC_URL}/static/slides/{file_uid}_slide_{slide_index}.png",
            "source_file_url": f"{PUBLIC_URL}/static/presentations/{file_uid}.pptx",
            "source_name": f"{file_uid}.pptx",
            "source_type": "pptx",
            "doc_meta": doc_metadata,  # Métadonnées document → isolées
            "chunk_meta": meta,  # Métadonnées chunk GPT → isolées
        }

        try:
            points.append(
                PointStruct(id=str(uuid.uuid4()), vector=emb, payload=payload)
            )
        except Exception as e:
            logger.warning(f"⚠️ Point build error (slide {slide_index}): {e}")

    if not points:
        logger.warning(f"⚠️ Aucun point prêt à l'upsert (slide {slide_index})")
        return

    try:
        qdrant.upsert(collection_name=COLLECTION_NAME, points=points)
        logger.info(f"✅ Slide {slide_index}: {len(points)} chunk(s) ingérés")
    except Exception as e:
        logger.error(f"❌ Qdrant upsert failed (slide {slide_index}): {e}")


# ===== Pipeline document =====
def process_pptx(pptx_path: Path):
    logger.info(f"🚀 Traitement: {pptx_path.name}")
    status_file = STATUS_DIR / f"{pptx_path.stem}.status"
    try:
        status_file.write_text("processing")

        # Meta utilisateur facultative
        meta_path = pptx_path.with_suffix(".meta.json")
        user_meta = {}
        if meta_path.exists():
            try:
                user_meta = json.loads(meta_path.read_text(encoding="utf-8"))
                logger.info("📎 Meta utilisateur détectée")
            except Exception as e:
                logger.warning(f"⚠️ Meta invalide: {e}")

        # PPTX→PDF
        pdf_path = convert_pptx_to_pdf(pptx_path, SLIDES_PNG)

        # Texte brut (pour GPT meta)
        pdf_text = extract_text_from_pdf(pdf_path)

        # GPT métadonnées haut niveau
        gpt_meta = analyze_pdf_metadata(pdf_text, pptx_path.name)
        doc_meta = {**user_meta, **gpt_meta}

        # PNG slides HD
        image_paths = render_pdf_to_pngs(pdf_path, SLIDES_PNG, dpi=240)

        # Texte + notes PPTX
        slides_data = extract_notes_and_text(pptx_path)

        # OCR ciblé si texte PPTX pauvre
        for s in slides_data:
            idx = s["slide_index"]
            if len((s.get("text") or "").strip()) < 40:
                ocr_txt = maybe_ocr_image(image_paths.get(idx))
                if ocr_txt:
                    s["text"] = ((s.get("text") or "") + "\n" + ocr_txt).strip()

        # Parallélisation contrôlée des analyses de slide
        total_chunks = 0
        tasks = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
            for slide in slides_data:
                idx = slide["slide_index"]
                if image_paths.get(idx):
                    logger.info(
                        f"📸 Slide {idx}/{len(slides_data)} — en file d'attente"
                    )
                    tasks.append(
                        ex.submit(
                            ask_gpt_slide_analysis_rich,
                            image_paths[idx],
                            slide["text"],
                            slide["notes"],
                            pptx_path.name,
                            idx,
                            doc_meta,
                        )
                    )
                else:
                    logger.warning(f"⚠️ PNG manquant pour slide {idx}")

            # Collect & ingest au fil de l’eau
            for future, slide in zip(as_completed(tasks), slides_data):
                try:
                    chunks = future.result()
                except Exception as e:
                    logger.error(f"❌ Future slide error: {e}")
                    chunks = []
                idx = slide["slide_index"]
                logger.info(f"🧩 Slide {idx}: chunks générés = {len(chunks)}")
                ingest_chunks(chunks, doc_meta, pptx_path.stem, idx)
                total_chunks += len(chunks)

        # Déplacement fichiers source+meta
        try:
            DOCS_DONE.mkdir(parents=True, exist_ok=True)
            shutil.move(str(pptx_path), str(DOCS_DONE / f"{pptx_path.stem}.pptx"))
            if meta_path.exists():
                shutil.move(
                    str(meta_path), str(DOCS_DONE / f"{pptx_path.stem}.meta.json")
                )
        except Exception as e:
            logger.warning(f"⚠️ Déplacement terminé avec avertissement: {e}")

        status_file.write_text("done")
        logger.info(f"✅ Terminé: {pptx_path.name} — total chunks: {total_chunks}")

    except Exception as e:
        logger.error(f"❌ Erreur durant {pptx_path.name}: {e}")
        try:
            status_file.write_text("error")
        except Exception:
            pass


def main():
    ensure_dirs()
    logger.info("🔎 Scan du dossier DOCS_IN")
    if not DOCS_IN.exists():
        logger.error(f"❌ DOCS_IN n'existe pas: {DOCS_IN}")
        return

    files = sorted(DOCS_IN.glob("*.pptx"))
    logger.info(f"📦 Fichiers .pptx détectés: {len(files)}")
    if not files:
        logger.info("ℹ️ Aucun .pptx à traiter")
        return

    for file in files:
        logger.info(f"➡️ Fichier détecté: {file.name}")
        process_pptx(file)


if __name__ == "__main__":
    main()
