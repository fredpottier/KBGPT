"""
Service pour analyser des documents samples et sugg√©rer entity types.

Phase 6 - Document Types Management
"""
import json
import base64
from typing import List, Dict, Optional
from fastapi import UploadFile
from pathlib import Path
import tempfile

from knowbase.common.llm_router import LLMRouter, TaskType
from knowbase.config.settings import get_settings
from knowbase.common.logging import setup_logging

settings = get_settings()
logger = setup_logging(settings.logs_dir, "document_sample_analyzer.log")


class DocumentSampleAnalyzerService:
    """Service pour analyser documents samples et sugg√©rer entity types."""

    def __init__(self, llm_router: Optional[LLMRouter] = None, db_session=None):
        """
        Initialize service.

        Args:
            llm_router: Router LLM (optionnel, cr√©√© si None)
            db_session: Session DB pour r√©cup√©rer entity types existants
        """
        self.llm_router = llm_router or LLMRouter()
        self.db_session = db_session

    async def analyze_document_sample(
        self,
        file: UploadFile,
        context_prompt: Optional[str] = None,
        model_preference: str = "claude-sonnet",
        tenant_id: str = "default"
    ) -> Dict:
        """
        Analyser un document sample PDF pour sugg√©rer entity types.

        Args:
            file: Fichier PDF upload√©
            context_prompt: Contexte additionnel pour guider le LLM
            model_preference: Mod√®le LLM √† utiliser (doit √™tre Claude)
            tenant_id: Tenant ID pour r√©cup√©rer entity types existants

        Returns:
            Dict avec suggested_types, document_summary, pages_analyzed
        """
        logger.info(f"üìÑ Analyse document sample: {file.filename}")

        # V√©rifier que c'est bien un PDF
        file_ext = Path(file.filename).suffix.lower()
        if file_ext != ".pdf":
            raise ValueError(f"Format non support√©: {file_ext}. Seul PDF est accept√©.")

        # R√©cup√©rer entity types existants approuv√©s
        existing_types = self._get_existing_entity_types(tenant_id)
        logger.info(f"üìã {len(existing_types)} entity types existants trouv√©s")

        # Lire le PDF en base64
        pdf_content = await file.read()
        pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
        logger.info(f"üì¶ PDF encod√©: {len(pdf_base64)} caract√®res base64")

        # Construire prompt pour LLM
        prompt_text = self._build_analysis_prompt_for_pdf(context_prompt, existing_types)

        # Appeler Claude avec PDF natif
        # IMPORTANT: Le format 'document' PDF est sp√©cifique √† Anthropic Claude
        # On doit bypasser le router et appeler directement Claude
        try:
            from knowbase.common.clients import get_anthropic_client

            anthropic_client = get_anthropic_client()

            # Format Anthropic pour PDF natif
            # Utiliser le mod√®le long_text de settings (Claude Sonnet)
            model_name = settings.model_long_text
            logger.info(f"ü§ñ Utilisation mod√®le Claude: {model_name}")

            response = anthropic_client.messages.create(
                model=model_name,
                max_tokens=4000,
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "document",
                                "source": {
                                    "type": "base64",
                                    "media_type": "application/pdf",
                                    "data": pdf_base64
                                }
                            },
                            {
                                "type": "text",
                                "text": prompt_text
                            }
                        ]
                    }
                ]
            )

            # Extraire contenu de la r√©ponse Claude
            llm_response = response.content[0].text if response.content else ""

            # Log tokens
            if response.usage:
                logger.info(f"[TOKENS] Claude PDF Analysis - Input: {response.usage.input_tokens}, Output: {response.usage.output_tokens}")

            # Parser r√©ponse LLM
            result = self._parse_llm_response(llm_response, existing_types)

            logger.info(
                f"‚úÖ Analyse termin√©e: {len(result['suggested_types'])} types sugg√©r√©s"
            )

            return result

        except Exception as e:
            logger.error(f"‚ùå Erreur analyse LLM: {e}")
            raise

    def _get_existing_entity_types(self, tenant_id: str = "default") -> List[str]:
        """
        R√©cup√©rer les entity types existants approuv√©s depuis la base.

        Args:
            tenant_id: Tenant ID

        Returns:
            Liste des noms de types approuv√©s
        """
        if not self.db_session:
            logger.warning("‚ö†Ô∏è Pas de session DB, impossible de r√©cup√©rer entity types existants")
            return []

        try:
            from knowbase.db import EntityTypeRegistry

            # Requ√™te pour r√©cup√©rer types approuv√©s
            types = self.db_session.query(EntityTypeRegistry).filter(
                EntityTypeRegistry.tenant_id == tenant_id,
                EntityTypeRegistry.status == "approved"
            ).all()

            return [t.type_name for t in types]

        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration entity types existants: {e}")
            return []

    def _build_analysis_prompt_for_pdf(
        self,
        context_prompt: Optional[str] = None,
        existing_types: Optional[List[str]] = None
    ) -> str:
        """
        Construire prompt LLM pour analyse de PDF.

        Args:
            context_prompt: Contexte additionnel
            existing_types: Liste des entity types d√©j√† existants en base

        Returns:
            Prompt format√©
        """
        # Formater liste types existants
        existing_types_section = ""
        if existing_types:
            types_list = ", ".join(existing_types)
            existing_types_section = f"""
**TYPES D'ENTIT√âS D√âJ√Ä EXISTANTS** (√† privil√©gier si pertinents):
{types_list}

IMPORTANT: Si un type existe d√©j√† dans cette liste, utilise-le tel quel (m√™me nom exact).
Propose de NOUVEAUX types uniquement si aucun type existant ne convient.
"""

        context_section = ""
        if context_prompt:
            context_section = f"**CONTEXTE ADDITIONNEL**:\n{context_prompt}\n\n"

        prompt = f"""Tu es un expert en analyse de documents et mod√©lisation d'entit√©s.

**T√ÇCHE**: Analyser le document PDF fourni et identifier les types d'entit√©s pertinents pour l'extraction automatique.
{existing_types_section}
{context_section}
**INSTRUCTIONS**:
1. Analyse le document PDF complet (texte + images + mise en page)
2. **EN PRIORIT√â**: V√©rifie si des types EXISTANTS (list√©s ci-dessus) sont pertinents
3. Propose de NOUVEAUX types uniquement si n√©cessaire
4. Pour chaque type identifi√©:
   - Donne un nom en MAJUSCULES (ex: SOLUTION, PRODUCT, INFRASTRUCTURE)
   - Estime une confidence (0.0 √† 1.0) selon la fr√©quence et l'importance
   - Fournis 2-4 exemples concrets trouv√©s dans le document
   - Donne une br√®ve description du type (1 phrase)
   - Indique "is_existing": true si le type est dans la liste existante, false sinon

5. **R√àGLES CRITIQUES**:
   - R√©utilise les types existants EXACTEMENT (m√™me nom, m√™me casse)
   - Ne propose que des types **r√©ellement pr√©sents** dans le document
   - Privil√©gie les types avec forte occurrence (confidence > 0.6)
   - √âvite les types trop g√©n√©riques (ex: "INFORMATION", "ELEMENT")
   - Maximum 15 types sugg√©r√©s

6. **R√âSUM√â**: Fournis aussi un r√©sum√© du document en 2-3 phrases

**FORMAT DE SORTIE JSON**:
{{
  "document_summary": "Ce document pr√©sente...",
  "suggested_types": [
    {{
      "name": "SOLUTION",
      "confidence": 0.95,
      "examples": ["SAP HANA", "SAP S/4HANA Cloud"],
      "description": "Solutions logicielles SAP mentionn√©es",
      "is_existing": true
    }},
    {{
      "name": "DEPLOYMENT_MODEL",
      "confidence": 0.85,
      "examples": ["Cloud Native", "Hybrid Deployment"],
      "description": "Mod√®les de d√©ploiement mentionn√©s",
      "is_existing": false
    }}
  ]
}}

Retourne UNIQUEMENT le JSON, sans texte avant/apr√®s.
"""
        return prompt

    def _parse_llm_response(self, llm_response: str, existing_types: Optional[List[str]] = None) -> Dict:
        """
        Parser r√©ponse LLM.

        Args:
            llm_response: R√©ponse brute LLM
            existing_types: Liste des types existants pour validation

        Returns:
            Dict avec suggested_types, document_summary, pages_analyzed
        """
        existing_types_set = set(existing_types) if existing_types else set()
        try:
            # Nettoyer r√©ponse (supprimer markdown code blocks si pr√©sents)
            clean_response = llm_response.strip()
            if clean_response.startswith("```json"):
                clean_response = clean_response[7:]
            if clean_response.startswith("```"):
                clean_response = clean_response[3:]
            if clean_response.endswith("```"):
                clean_response = clean_response[:-3]

            clean_response = clean_response.strip()

            # Parser JSON
            data = json.loads(clean_response)

            # Valider structure
            suggested_types = data.get("suggested_types", [])
            document_summary = data.get("document_summary", "")

            # Valider chaque type sugg√©r√©
            validated_types = []
            for item in suggested_types:
                if not isinstance(item, dict):
                    continue

                # Champs requis
                if "name" not in item or "confidence" not in item:
                    continue

                # Normaliser nom (UPPERCASE)
                item["name"] = item["name"].upper().strip()

                # Valider confidence
                try:
                    item["confidence"] = float(item["confidence"])
                    if not (0.0 <= item["confidence"] <= 1.0):
                        item["confidence"] = 0.5
                except (TypeError, ValueError):
                    item["confidence"] = 0.5

                # Assurer que examples est une liste
                if "examples" not in item or not isinstance(item["examples"], list):
                    item["examples"] = []

                # Assurer que description existe
                if "description" not in item:
                    item["description"] = ""

                # Valider et forcer is_existing bas√© sur existing_types_set
                # (pour √©viter que le LLM ne se trompe)
                if item["name"] in existing_types_set:
                    item["is_existing"] = True
                else:
                    item["is_existing"] = False

                validated_types.append(item)

            # Trier par confidence d√©croissant
            validated_types.sort(key=lambda x: x["confidence"], reverse=True)

            logger.info(f"‚úÖ {len(validated_types)} types valid√©s depuis r√©ponse LLM")

            return {
                "suggested_types": validated_types,
                "document_summary": document_summary,
                "pages_analyzed": 10  # Max pages analys√©es
            }

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON LLM: {e}")
            logger.error(f"R√©ponse LLM: {llm_response[:500]}")
            raise ValueError(f"LLM response is not valid JSON: {e}")

        except Exception as e:
            logger.error(f"‚ùå Erreur parsing r√©ponse LLM: {e}")
            raise


__all__ = ["DocumentSampleAnalyzerService"]
