"""
üß† OSMOSE Phase 2.5 - Intelligent Summarizer

G√©n√®re des comptes-rendus m√©tier structur√©s √† partir de sessions de conversation.
Pas une simple transcription, mais une synth√®se exploitable pour d√©cideurs.

Features:
- Extraction automatique des topics principaux
- Identification des points cl√©s avec sources
- D√©tection des actions mentionn√©es
- G√©n√©ration via LLM avec format configurable
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from knowbase.common.llm_router import TaskType, get_llm_router
from knowbase.common.logging import setup_logging
from knowbase.config.settings import get_settings
from knowbase.db.models import Session, SessionMessage

settings = get_settings()
logger = setup_logging(settings.logs_dir, "intelligent_summarizer.log")


class SummaryFormat(str, Enum):
    """Format de sortie du r√©sum√©."""
    BUSINESS = "business"      # Orient√© d√©cideur, points cl√©s et actions
    TECHNICAL = "technical"    # D√©tails techniques, r√©f√©rences pr√©cises
    EXECUTIVE = "executive"    # Ultra-concis, 3-5 bullet points


@dataclass
class ExtractedData:
    """Donn√©es extraites de la session avant g√©n√©ration du r√©sum√©."""
    topics: List[str] = field(default_factory=list)
    key_concepts: List[str] = field(default_factory=list)
    sources_used: List[str] = field(default_factory=list)
    actions_mentioned: List[str] = field(default_factory=list)
    questions_asked: List[str] = field(default_factory=list)
    documents_referenced: List[str] = field(default_factory=list)
    question_count: int = 0
    answer_count: int = 0


@dataclass
class SessionSummary:
    """R√©sum√© structur√© d'une session."""
    session_id: str
    title: str
    generated_at: datetime
    format: SummaryFormat

    # Sections du r√©sum√©
    context: str                          # Objectif/contexte de recherche identifi√©
    key_points: List[Dict[str, Any]]      # Points cl√©s avec sources
    actions: List[str]                    # Actions identifi√©es
    unexplored_areas: List[str]           # Zones non explor√©es sugg√©r√©es

    # M√©tadonn√©es
    question_count: int
    sources_count: int
    duration_minutes: Optional[int] = None
    concepts_explored: List[str] = field(default_factory=list)

    # R√©sum√© texte complet
    full_text: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "session_id": self.session_id,
            "title": self.title,
            "generated_at": self.generated_at.isoformat(),
            "format": self.format.value,
            "context": self.context,
            "key_points": self.key_points,
            "actions": self.actions,
            "unexplored_areas": self.unexplored_areas,
            "question_count": self.question_count,
            "sources_count": self.sources_count,
            "duration_minutes": self.duration_minutes,
            "concepts_explored": self.concepts_explored,
            "full_text": self.full_text
        }


# Prompts par format
SUMMARY_PROMPTS = {
    SummaryFormat.BUSINESS: """Tu es un assistant qui g√©n√®re des synth√®ses professionnelles de sessions de recherche documentaire.

CONTEXTE DE LA SESSION:
- Titre: {title}
- Date: {session_date}
- Nombre de questions: {question_count}
- Documents consult√©s: {sources_count}

CONVERSATION:
{conversation_transcript}

CONSIGNES:
1. G√©n√®re une synth√®se M√âTIER, pas une transcription
2. Structure en sections claires avec des titres markdown ##:

   ## Contexte
   Objectif de recherche identifi√© en 1-2 phrases.

   ## Points Cl√©s
   - 3-5 insights principaux, chacun avec sa source entre parenth√®ses

   ## Actions Recommand√©es
   - Actions concr√®tes identifi√©es ou sugg√©r√©es (si pertinent)

   ## Zones √† Explorer
   - Sujets pertinents non abord√©s qui m√©riteraient investigation

3. Cite les sources entre parenth√®ses (Source: nom_document)
4. Utilise un ton professionnel et factuel
5. Maximum 400 mots

G√©n√®re la synth√®se:""",

    SummaryFormat.TECHNICAL: """Tu es un assistant technique qui g√©n√®re des rapports d√©taill√©s de sessions de recherche.

CONTEXTE:
- Session: {title}
- Date: {session_date}
- Questions: {question_count}
- Sources: {sources_count}

CONVERSATION:
{conversation_transcript}

CONSIGNES:
1. G√©n√®re un rapport TECHNIQUE d√©taill√©
2. Structure:

   ## P√©rim√®tre de Recherche
   Contexte technique et objectifs.

   ## R√©sultats D√©taill√©s
   Pour chaque question pos√©e, r√©sume la r√©ponse avec r√©f√©rences exactes.

   ## Sources Utilis√©es
   Liste exhaustive des documents cit√©s.

   ## Points d'Attention Techniques
   Probl√®mes ou limitations identifi√©s.

   ## Recommandations
   Prochaines √©tapes techniques sugg√©r√©es.

3. Sois pr√©cis sur les r√©f√©rences (document, slide/page si disponible)
4. Maximum 600 mots

G√©n√®re le rapport:""",

    SummaryFormat.EXECUTIVE: """Tu es un assistant qui g√©n√®re des synth√®ses ex√©cutives ultra-concises.

SESSION: {title}
DATE: {session_date}
QUESTIONS: {question_count}

CONVERSATION:
{conversation_transcript}

CONSIGNES:
1. G√©n√®re une synth√®se EXECUTIVE en 5 bullet points maximum
2. Format:

   ## Synth√®se
   ‚Ä¢ Point 1 (une phrase)
   ‚Ä¢ Point 2 (une phrase)
   ‚Ä¢ Point 3 (une phrase)

   ## Action Prioritaire
   Une seule action cl√© si identifi√©e.

3. Chaque point = 1 phrase impactante
4. Maximum 150 mots

G√©n√®re la synth√®se:"""
}


class IntelligentSummarizer:
    """G√©n√®re des r√©sum√©s intelligents de sessions de conversation."""

    def __init__(self):
        self.router = get_llm_router()

        # Patterns pour extraction
        self._action_patterns = [
            r"il (faut|faudrait|faudra)\s+(.+?)(?:\.|$)",
            r"on (doit|devra|devrait)\s+(.+?)(?:\.|$)",
            r"√† faire\s*:\s*(.+?)(?:\.|$)",
            r"action[s]?\s*:\s*(.+?)(?:\.|$)",
            r"recommand[√©e]?[s]?\s*:\s*(.+?)(?:\.|$)",
            r"pr√©voir de\s+(.+?)(?:\.|$)",
            r"pensez √†\s+(.+?)(?:\.|$)",
            r"n'oubliez pas de\s+(.+?)(?:\.|$)",
        ]

        logger.info("[IntelligentSummarizer] Initialized")

    def generate_summary(
        self,
        session: Session,
        messages: List[SessionMessage],
        format: SummaryFormat = SummaryFormat.BUSINESS
    ) -> SessionSummary:
        """
        G√©n√®re un r√©sum√© intelligent d'une session.

        Args:
            session: Session √† r√©sumer
            messages: Messages de la session
            format: Format de sortie souhait√©

        Returns:
            SessionSummary structur√©
        """
        logger.info(
            f"[SUMMARIZER] Generating {format.value} summary for session {session.id}"
        )

        # 1. Extraire les donn√©es structur√©es
        extracted = self._extract_session_data(session, messages)

        # 2. Construire le transcript format√©
        transcript = self._format_conversation_transcript(messages)

        # 3. Calculer la dur√©e si possible
        duration = None
        if messages:
            first_msg = messages[0]
            last_msg = messages[-1]
            if first_msg.created_at and last_msg.created_at:
                delta = last_msg.created_at - first_msg.created_at
                duration = int(delta.total_seconds() / 60)

        # 4. G√©n√©rer via LLM
        summary_text = self._generate_with_llm(
            session=session,
            extracted=extracted,
            transcript=transcript,
            format=format
        )

        # 5. Parser et structurer
        summary = self._parse_summary(
            session_id=str(session.id),
            title=session.title or "Session sans titre",
            raw_text=summary_text,
            extracted=extracted,
            format=format,
            duration=duration
        )

        logger.info(
            f"[SUMMARIZER] Generated summary: {len(summary.key_points)} key points, "
            f"{len(summary.actions)} actions"
        )

        return summary

    def _extract_session_data(
        self,
        session: Session,
        messages: List[SessionMessage]
    ) -> ExtractedData:
        """Extrait les donn√©es structur√©es de la session."""

        extracted = ExtractedData()

        sources = set()
        questions = []

        for msg in messages:
            if msg.role == "user":
                questions.append(msg.content)
                extracted.question_count += 1
            else:
                extracted.answer_count += 1

                # Extraire les sources mentionn√©es
                if msg.documents_referenced:
                    for doc in msg.documents_referenced:
                        if doc:
                            sources.add(doc)

                # Extraire les actions via patterns
                for pattern in self._action_patterns:
                    matches = re.findall(pattern, msg.content, re.IGNORECASE)
                    for match in matches:
                        if isinstance(match, tuple):
                            action_text = match[-1].strip()
                        else:
                            action_text = match.strip()
                        if len(action_text) > 10:  # Filtrer les trop courts
                            extracted.actions_mentioned.append(action_text)

        extracted.questions_asked = questions
        extracted.sources_used = list(sources)

        # Extraire topics via analyse simple des questions
        extracted.topics = self._identify_topics(questions)

        return extracted

    def _identify_topics(self, questions: List[str]) -> List[str]:
        """Identifie les topics principaux des questions."""
        topics = set()

        # Mots-cl√©s indicateurs de topics
        topic_keywords = {
            "migration": ["migration", "migrer", "upgrade", "mise √† jour"],
            "s√©curit√©": ["s√©curit√©", "security", "authentification", "autorisation", "rbac"],
            "performance": ["performance", "optimisation", "lent", "rapide"],
            "int√©gration": ["int√©gration", "api", "connecteur", "interface"],
            "formation": ["formation", "apprendre", "documentation", "guide"],
            "co√ªt": ["co√ªt", "prix", "licence", "budget", "roi"],
            "architecture": ["architecture", "infrastructure", "d√©ploiement"],
            "donn√©es": ["donn√©es", "data", "base de donn√©es", "stockage"],
        }

        all_text = " ".join(questions).lower()

        for topic, keywords in topic_keywords.items():
            if any(kw in all_text for kw in keywords):
                topics.add(topic)

        return list(topics)[:5]  # Max 5 topics

    def _format_conversation_transcript(
        self,
        messages: List[SessionMessage]
    ) -> str:
        """Formate la conversation pour le prompt LLM."""
        lines = []

        for msg in messages:
            role_label = "UTILISATEUR" if msg.role == "user" else "ASSISTANT"

            # Tronquer les messages tr√®s longs
            content = msg.content
            if len(content) > 800:
                content = content[:800] + "... [tronqu√©]"

            lines.append(f"**{role_label}:** {content}")

        return "\n\n".join(lines)

    def _generate_with_llm(
        self,
        session: Session,
        extracted: ExtractedData,
        transcript: str,
        format: SummaryFormat
    ) -> str:
        """G√©n√®re le r√©sum√© via LLM."""

        prompt_template = SUMMARY_PROMPTS.get(format, SUMMARY_PROMPTS[SummaryFormat.BUSINESS])

        # Formater la date
        session_date = "Non sp√©cifi√©e"
        if session.created_at:
            session_date = session.created_at.strftime("%d/%m/%Y √† %H:%M")

        prompt = prompt_template.format(
            title=session.title or "Session de recherche",
            session_date=session_date,
            question_count=extracted.question_count,
            sources_count=len(extracted.sources_used),
            conversation_transcript=transcript
        )

        messages = [
            {
                "role": "system",
                "content": "Tu es un assistant expert en synth√®se documentaire. "
                          "Tu g√©n√®res des r√©sum√©s clairs, structur√©s et exploitables."
            },
            {"role": "user", "content": prompt}
        ]

        try:
            response = self.router.complete(
                task_type=TaskType.LONG_TEXT_SUMMARY,
                messages=messages,
                temperature=0.3,
                max_tokens=1500
            )
            return response.strip()

        except Exception as e:
            logger.error(f"[SUMMARIZER] LLM generation failed: {e}")
            return self._generate_fallback_summary(extracted)

    def _generate_fallback_summary(self, extracted: ExtractedData) -> str:
        """G√©n√®re un r√©sum√© de secours sans LLM."""
        lines = ["## Contexte", "Session de recherche documentaire.", ""]

        lines.append("## Points Cl√©s")
        if extracted.questions_asked:
            for i, q in enumerate(extracted.questions_asked[:5], 1):
                lines.append(f"- Question {i}: {q[:100]}...")
        else:
            lines.append("- Aucune question identifi√©e")
        lines.append("")

        if extracted.sources_used:
            lines.append("## Sources Consult√©es")
            for src in extracted.sources_used[:5]:
                lines.append(f"- {src}")

        return "\n".join(lines)

    def _parse_summary(
        self,
        session_id: str,
        title: str,
        raw_text: str,
        extracted: ExtractedData,
        format: SummaryFormat,
        duration: Optional[int]
    ) -> SessionSummary:
        """Parse le texte LLM en structure SessionSummary."""

        # Extraire les sections du markdown
        context = self._extract_section(raw_text, ["Contexte", "P√©rim√®tre", "Context"])
        key_points_text = self._extract_section(
            raw_text,
            ["Points Cl√©s", "Points cl√©s", "R√©sultats", "Key Points", "Synth√®se"]
        )
        actions_text = self._extract_section(
            raw_text,
            ["Actions", "Recommandations", "Action Prioritaire", "Prochaines √©tapes"]
        )
        unexplored_text = self._extract_section(
            raw_text,
            ["Zones √† Explorer", "Non explor√©es", "Points d'Attention", "√Ä investiguer"]
        )

        # Parser les bullet points
        key_points = self._parse_bullet_points(key_points_text)
        actions = self._parse_bullet_list(actions_text)
        unexplored = self._parse_bullet_list(unexplored_text)

        # Combiner avec les actions extraites automatiquement
        all_actions = list(set(actions + extracted.actions_mentioned[:3]))

        return SessionSummary(
            session_id=session_id,
            title=title,
            generated_at=datetime.utcnow(),
            format=format,
            context=context or "Session de recherche documentaire.",
            key_points=key_points,
            actions=all_actions[:5],  # Max 5 actions
            unexplored_areas=unexplored[:3],  # Max 3 zones
            question_count=extracted.question_count,
            sources_count=len(extracted.sources_used),
            duration_minutes=duration,
            concepts_explored=extracted.topics,
            full_text=raw_text
        )

    def _extract_section(self, text: str, headers: List[str]) -> str:
        """Extrait le contenu d'une section markdown."""
        for header in headers:
            # Pattern pour trouver la section
            pattern = rf"##\s*{re.escape(header)}[^\n]*\n(.*?)(?=##|\Z)"
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1).strip()
        return ""

    def _parse_bullet_points(self, text: str) -> List[Dict[str, Any]]:
        """Parse des bullet points en liste structur√©e avec sources."""
        points = []

        # Pattern pour bullet points (-, *, ‚Ä¢)
        lines = re.findall(r"[-*‚Ä¢]\s*(.+?)(?:\n|$)", text)

        for line in lines:
            line = line.strip()
            if len(line) < 10:
                continue

            # Extraire la source si pr√©sente
            source = None
            source_match = re.search(r"\((?:Source\s*:\s*)?([^)]+)\)$", line)
            if source_match:
                source = source_match.group(1).strip()
                line = line[:source_match.start()].strip()

            points.append({
                "point": line,
                "source": source
            })

        return points[:5]  # Max 5 points

    def _parse_bullet_list(self, text: str) -> List[str]:
        """Parse une liste simple de bullet points."""
        items = []

        lines = re.findall(r"[-*‚Ä¢]\s*(.+?)(?:\n|$)", text)

        for line in lines:
            line = line.strip()
            if len(line) > 10:
                items.append(line)

        return items


# Singleton instance
_summarizer: Optional[IntelligentSummarizer] = None


def get_intelligent_summarizer() -> IntelligentSummarizer:
    """Retourne l'instance du summarizer (cr√©√©e si n√©cessaire)."""
    global _summarizer
    if _summarizer is None:
        _summarizer = IntelligentSummarizer()
    return _summarizer


__all__ = [
    "IntelligentSummarizer",
    "get_intelligent_summarizer",
    "SessionSummary",
    "SummaryFormat",
    "ExtractedData"
]
