"""
üåä OSMOSE Semantic Intelligence V2.2 - Concept Density Detector

D√©tecte la densit√© conceptuelle d'un texte pour optimiser la m√©thode d'extraction.

**Probl√®me R√©solu:**
- spaCy NER sous-performe sur vocabulaire technique dense (SDOL, BISO, DPCE, etc.)
- Perte de temps/tokens √† tenter NER sur texte dense ‚Üí mieux aller directement au LLM

**Heuristiques:**
1. Acronymes (ISO XXXX, RFC XXXX, SAP XXX, etc.)
2. Termes techniques (patterns sp√©cialis√©s)
3. Vocabulaire rare (absents dictionnaire courant)
4. Ratio entit√©s NER rapide / tokens

**D√©cision:**
- LOW density (0.0-0.3): NER_ONLY (rapide, efficace)
- MEDIUM density (0.3-0.6): NER_LLM_HYBRID (flow standard)
- HIGH density (0.6-1.0): LLM_FIRST (skip NER inefficace)

Phase 1 V2.2 - Semaine 10+ (Optimisation Extraction)
"""

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re
import logging
from collections import Counter

logger = logging.getLogger(__name__)


class ExtractionMethod(str, Enum):
    """M√©thode d'extraction recommand√©e."""
    NER_ONLY = "NER_ONLY"              # Texte simple, NER suffit
    NER_LLM_HYBRID = "NER_LLM_HYBRID"  # Standard flow (NER + LLM si insuffisant)
    LLM_FIRST = "LLM_FIRST"            # Texte dense, LLM d'embl√©e


@dataclass
class DensityProfile:
    """Profil de densit√© conceptuelle d'un texte."""

    density_score: float  # 0-1 (0=faible, 1=tr√®s dense)
    recommended_method: ExtractionMethod
    confidence: float  # 0-1 (confiance dans la recommandation)

    # Indicateurs d√©taill√©s
    acronym_density: float  # Acronymes par 100 mots
    technical_pattern_count: int  # Patterns techniques d√©tect√©s
    rare_vocab_ratio: float  # Ratio mots rares / total
    ner_preview_ratio: float  # Entit√©s NER sur √©chantillon / tokens

    # M√©tadonn√©es
    sample_length: int  # Longueur √©chantillon analys√©
    indicators: Dict[str, any]  # Signaux d√©tect√©s


class ConceptDensityDetector:
    """
    D√©tecteur de densit√© conceptuelle pour optimisation extraction.

    Analyse rapide (< 100ms) d'un √©chantillon de texte pour d√©terminer
    la m√©thode d'extraction optimale (NER vs LLM).

    **Usage:**
    ```python
    detector = ConceptDensityDetector()
    profile = detector.analyze_density(topic_text[:2000])

    if profile.recommended_method == ExtractionMethod.LLM_FIRST:
        # Skip NER, aller direct au LLM
        concepts = await self._extract_via_llm(topic, language)
    else:
        # Flow standard NER + LLM hybrid
        concepts = await self._extract_via_ner(topic, language)
    ```
    """

    # Patterns techniques g√©n√©riques (domain-agnostic)
    # D√©tecte les structures formelles communes √† tous les domaines techniques
    TECHNICAL_PATTERNS = [
        r'\b[A-Z]{2,}[-/][A-Z0-9]+\b',          # Acronymes compos√©s: ERP/CRM, CI/CD, COVID-19
        r'\b[A-Z]{3,}\b(?=\s|$|[,.])',          # Acronymes 3+ lettres: SAST, FDA, HANA
        r'\b[A-Z]+\s+\d{4,}(?:-\d+)?\b',        # Standards avec num√©ros: ISO 27001, RFC 2616
        r'\b\d+\.\d+(?:\.\d+)?\b',              # Versions/num√©ros: 2.0, 3.1.4
        r'\b[A-Z][a-z]+(?:[A-Z][a-z]+)+\b',     # CamelCase: SuccessFactors, NetWeaver
    ]

    # Mots g√©n√©riques indiquant un texte technique (domain-agnostic)
    # Ces mots sont communs √† TOUS les domaines techniques, pas sp√©cifiques √† un vertical
    TECHNICAL_KEYWORDS = {
        # Structure documentaire technique
        "implementation", "configuration", "integration", "specification",
        "architecture", "infrastructure", "optimization", "documentation",

        # Processus/M√©thodologie g√©n√©rique
        "methodology", "framework", "compliance", "governance", "workflow",
        "procedure", "protocol", "standard", "requirement", "specification",

        # Analyse/√âvaluation g√©n√©rique
        "analysis", "assessment", "evaluation", "validation", "verification",
        "benchmark", "performance", "metrics", "criteria", "threshold",
    }

    def __init__(self, ner_manager=None):
        """
        Initialise le d√©tecteur.

        Args:
            ner_manager: (Optionnel) NERManager pour test NER preview
        """
        self.ner_manager = ner_manager

        # Compiler patterns pour performance
        self.compiled_patterns = [
            re.compile(pattern, re.IGNORECASE)
            for pattern in self.TECHNICAL_PATTERNS
        ]

        logger.info("[OSMOSE] ConceptDensityDetector initialized")

    def analyze_density(
        self,
        text: str,
        sample_size: int = 2000,
        language: str = "en",
        technical_density_hint: float = 0.0
    ) -> DensityProfile:
        """
        Analyse la densit√© conceptuelle d'un texte.

        Phase 1.8.2: Int√®gre technical_density_hint du LLM (domain-agnostic).
        Le hint LLM permet d'ajuster la d√©tection pour n'importe quel domaine
        sans avoir √† maintenir des patterns sp√©cifiques par vertical m√©tier.

        Args:
            text: Texte √† analyser (utilise √©chantillon d√©but)
            sample_size: Taille √©chantillon (chars)
            language: Langue du texte
            technical_density_hint: Hint LLM 0-1 (0=simple, 1=tr√®s technique)

        Returns:
            DensityProfile avec recommandation m√©thode extraction
        """
        # √âchantillon d√©but du texte (concepts cl√©s souvent au d√©but)
        sample = text[:sample_size]

        if len(sample) < 200:
            # Texte trop court ‚Üí analyse non fiable, utiliser hybrid
            # Mais si hint LLM fort, respecter le hint
            if technical_density_hint >= 0.6:
                logger.debug("[OSMOSE] Text too short but LLM hint is high, using LLM_FIRST")
                return DensityProfile(
                    density_score=technical_density_hint,
                    recommended_method=ExtractionMethod.LLM_FIRST,
                    confidence=0.7,
                    acronym_density=0.0,
                    technical_pattern_count=0,
                    rare_vocab_ratio=0.0,
                    ner_preview_ratio=0.0,
                    sample_length=len(sample),
                    indicators={"reason": "text_too_short_but_llm_hint_high", "llm_hint": technical_density_hint}
                )
            logger.debug("[OSMOSE] Text too short for density analysis, defaulting to HYBRID")
            return DensityProfile(
                density_score=0.5,
                recommended_method=ExtractionMethod.NER_LLM_HYBRID,
                confidence=0.3,
                acronym_density=0.0,
                technical_pattern_count=0,
                rare_vocab_ratio=0.0,
                ner_preview_ratio=0.0,
                sample_length=len(sample),
                indicators={"reason": "text_too_short"}
            )

        # 1. Acronym Density
        acronym_density = self._calculate_acronym_density(sample)

        # 2. Technical Patterns
        technical_pattern_count = self._count_technical_patterns(sample)

        # 3. Rare Vocabulary Ratio
        rare_vocab_ratio = self._calculate_rare_vocab_ratio(sample)

        # 4. NER Preview (si NER disponible)
        ner_preview_ratio = self._test_ner_preview(sample, language) if self.ner_manager else 0.0

        # Calcul score densit√© (pond√©ration des indicateurs heuristiques)
        heuristic_score = self._calculate_density_score(
            acronym_density=acronym_density,
            technical_pattern_count=technical_pattern_count,
            rare_vocab_ratio=rare_vocab_ratio,
            ner_preview_ratio=ner_preview_ratio
        )

        # Phase 1.8.2: Combiner score heuristique avec hint LLM
        # Si hint > 0, il a √©t√© fourni par le LLM lors de l'analyse document
        # Pond√©ration: 40% heuristique + 60% LLM hint (le LLM comprend mieux le domaine)
        if technical_density_hint > 0:
            density_score = (0.4 * heuristic_score) + (0.6 * technical_density_hint)
            logger.info(
                f"[OSMOSE] Density score combined: heuristic={heuristic_score:.2f} + "
                f"LLM_hint={technical_density_hint:.2f} ‚Üí final={density_score:.2f}"
            )
        else:
            density_score = heuristic_score

        # Recommandation m√©thode
        recommended_method, confidence = self._recommend_method(density_score)

        # Construire profil
        profile = DensityProfile(
            density_score=density_score,
            recommended_method=recommended_method,
            confidence=confidence,
            acronym_density=acronym_density,
            technical_pattern_count=technical_pattern_count,
            rare_vocab_ratio=rare_vocab_ratio,
            ner_preview_ratio=ner_preview_ratio,
            sample_length=len(sample),
            indicators={
                "acronym_density": acronym_density,
                "technical_patterns": technical_pattern_count,
                "rare_vocab_ratio": rare_vocab_ratio,
                "ner_preview_ratio": ner_preview_ratio,
                "llm_hint": technical_density_hint,
                "heuristic_score": heuristic_score
            }
        )

        logger.info(
            f"[OSMOSE] Density Analysis: score={density_score:.2f}, "
            f"method={recommended_method.value}, confidence={confidence:.2f}"
        )
        logger.debug(
            f"[OSMOSE] Indicators: acronyms={acronym_density:.1f}/100w, "
            f"tech_patterns={technical_pattern_count}, rare_vocab={rare_vocab_ratio:.2f}, "
            f"ner_preview={ner_preview_ratio:.2f}, llm_hint={technical_density_hint:.2f}"
        )

        return profile

    def _calculate_acronym_density(self, text: str) -> float:
        """
        Calcule densit√© acronymes (acronymes par 100 mots).

        D√©tecte:
        - Mots 3+ majuscules cons√©cutives (SAST, ISO, ERP)
        - Mots avec chiffres (S/4HANA, RFC2616)
        """
        # Tokeniser mots simples
        words = re.findall(r'\b\w+\b', text)

        if not words:
            return 0.0

        # D√©tecter acronymes
        acronym_pattern = re.compile(r'^[A-Z]{3,}$|^[A-Z]+\d+[A-Z]*$|^[A-Z]+[-/][A-Z0-9]+$')
        acronyms = [w for w in words if acronym_pattern.match(w)]

        # Acronymes par 100 mots
        density = (len(acronyms) / len(words)) * 100

        return density

    def _count_technical_patterns(self, text: str) -> int:
        """
        Compte patterns techniques (ISO XXXX, RFC XXXX, etc.).
        """
        count = 0
        for pattern in self.compiled_patterns:
            matches = pattern.findall(text)
            count += len(matches)

        return count

    def _calculate_rare_vocab_ratio(self, text: str) -> float:
        """
        Calcule ratio vocabulaire rare / total.

        "Rare" = mots longs (8+ chars) ou absents liste mots courants.
        Approximation simple sans dictionnaire externe pour performance.
        """
        words = re.findall(r'\b[a-zA-Z]{3,}\b', text.lower())

        if not words:
            return 0.0

        # Mots "rares" = 8+ caract√®res (souvent techniques)
        # + pr√©sence dans TECHNICAL_KEYWORDS
        rare_words = [
            w for w in words
            if len(w) >= 8 or w in self.TECHNICAL_KEYWORDS
        ]

        ratio = len(rare_words) / len(words)

        return ratio

    def _test_ner_preview(self, sample: str, language: str) -> float:
        """
        Test NER sur √©chantillon court (500 chars) pour estimer efficacit√©.

        Returns:
            Ratio entit√©s d√©tect√©es / tokens (0-1)
        """
        if not self.ner_manager:
            return 0.0

        # Prendre sous-√©chantillon pour rapidit√©
        test_sample = sample[:500]

        try:
            # Extraction NER rapide
            entities = self.ner_manager.extract_entities(test_sample, language=language)

            # Compter tokens
            words = re.findall(r'\b\w+\b', test_sample)

            if not words:
                return 0.0

            # Ratio entit√©s / tokens
            ratio = len(entities) / len(words)

            return ratio

        except Exception as e:
            logger.warning(f"[OSMOSE] NER preview failed: {e}")
            return 0.0

    def _calculate_density_score(
        self,
        acronym_density: float,
        technical_pattern_count: int,
        rare_vocab_ratio: float,
        ner_preview_ratio: float
    ) -> float:
        """
        Calcule score densit√© global (0-1).

        Pond√©ration:
        - Acronym density: 30%
        - Technical patterns: 25%
        - Rare vocab: 25%
        - NER preview: 20%
        """
        # Normaliser inputs
        # Acronym density: 0-15 acronymes/100w ‚Üí 0-1
        norm_acronym = min(acronym_density / 15.0, 1.0)

        # Technical patterns: 0-10 patterns ‚Üí 0-1
        norm_patterns = min(technical_pattern_count / 10.0, 1.0)

        # Rare vocab: d√©j√† 0-1
        norm_rare_vocab = rare_vocab_ratio

        # NER preview: faible ratio ‚Üí haute densit√© (inverse)
        # Si NER trouve < 10% entit√©s ‚Üí texte dense
        norm_ner = 1.0 - (ner_preview_ratio * 10)  # Inverser + amplifier
        norm_ner = max(0.0, min(norm_ner, 1.0))

        # Score pond√©r√©
        score = (
            0.30 * norm_acronym +
            0.25 * norm_patterns +
            0.25 * norm_rare_vocab +
            0.20 * norm_ner
        )

        return score

    def _recommend_method(
        self,
        density_score: float
    ) -> Tuple[ExtractionMethod, float]:
        """
        Recommande m√©thode extraction bas√©e sur density score.

        Seuils (Phase 1.8.2 - Optimis√© pour docs techniques/scientifiques):
        - 0.0-0.25: NER_ONLY (texte tr√®s simple, marketing, etc.)
        - 0.25-0.40: NER_LLM_HYBRID (standard business docs)
        - 0.40-1.0: LLM_FIRST (texte technique/scientifique) ‚Üê ABAISS√â de 0.55

        Rationale: Les documents techniques (m√©dicaux, scientifiques, SAP) ont
        souvent une densit√© > 0.40 et NER spaCy sous-performe sur ce vocabulaire.
        Mieux vaut aller au LLM directement pour meilleur recall.

        Returns:
            (method, confidence)
        """
        if density_score < 0.25:  # Abaiss√© de 0.30
            # Faible densit√© ‚Üí NER efficace (textes simples)
            confidence = 0.8 + (0.25 - density_score) * 0.6
            return ExtractionMethod.NER_ONLY, confidence

        elif density_score < 0.40:  # Abaiss√© de 0.55 √† 0.40
            # Densit√© moyenne ‚Üí Hybrid standard
            distance_from_center = abs(density_score - 0.325)  # Center of 0.25-0.40
            confidence = 0.6 + distance_from_center  # 0.6-0.75
            return ExtractionMethod.NER_LLM_HYBRID, confidence

        else:
            # Haute densit√© ‚Üí LLM first (textes techniques/scientifiques)
            # Seuil abaiss√© de 0.55 √† 0.40 pour capturer plus de textes techniques
            confidence = 0.75 + (density_score - 0.40) * 0.4
            return ExtractionMethod.LLM_FIRST, confidence
