"""
Quarantine Processor: Job automatique pour traiter merges en quarantine
Ex√©cute backfill Qdrant apr√®s d√©lai quarantine (d√©faut 24h)
"""

import logging
from datetime import datetime
from typing import List, Dict, Any

from knowbase.audit.audit_logger import AuditLogger, MergeAuditEntry
from knowbase.tasks.backfill import QdrantBackfillService
from knowbase.common.redis_lock import create_lock

logger = logging.getLogger(__name__)


class QuarantineProcessor:
    """
    Processor pour merges en quarantine

    Fonctionnement:
    1. R√©cup√®re merges avec quarantine_until d√©pass√©
    2. Applique backfill Qdrant pour chaque merge
    3. Met √† jour status ‚Üí approved
    4. Logger audit trail

    Job pr√©vu pour ex√©cution toutes les heures (configurable)
    """

    def __init__(self):
        """Initialize quarantine processor"""
        self.audit_logger = AuditLogger()
        self.backfill_service = QdrantBackfillService()

    async def process_quarantine_merges(self) -> Dict[str, Any]:
        """
        Traite tous les merges pr√™ts √† sortir de quarantine

        P0.2 PROTECTION: Lock distribu√© Redis pr√©vient traitement concurrent

        Returns:
            Statistiques traitement (processed, approved, failed)

        Raises:
            TimeoutError: Si lock non acquis (processor d√©j√† en cours ailleurs)
        """
        logger.info("üîÑ D√©marrage traitement quarantine merges")

        # P0.2: Acqu√©rir lock distribu√© pour √©viter processing concurrent
        # TTL 30min (processing peut prendre plusieurs minutes si 100+ merges)
        lock = create_lock(
            redis_url="redis://redis:6379/5",
            lock_key="quarantine:processor:global",
            ttl_seconds=1800  # 30min
        )

        with lock.context(timeout=30):
            logger.info("üîí Lock quarantine processor acquis - d√©but traitement")

            try:
                # R√©cup√©rer merges pr√™ts
                ready_merges = self.audit_logger.get_quarantine_ready_merges()

                if not ready_merges:
                    logger.info("‚úÖ Aucun merge en quarantine ready (quarantine vide)")
                    logger.info("üîì Lock quarantine processor lib√©r√©")
                    return {
                        "status": "completed",
                        "processed": 0,
                        "approved": 0,
                        "failed": 0,
                        "duration_seconds": 0
                    }

                logger.info(f"üìã {len(ready_merges)} merges pr√™ts pour backfill Qdrant")

                # Traiter chaque merge
                approved_count = 0
                failed_count = 0

                start_time = datetime.utcnow()

                for merge in ready_merges:
                    try:
                        await self._process_single_merge(merge)
                        approved_count += 1

                    except Exception as e:
                        logger.error(
                            f"Erreur traitement merge {merge.merge_id[:12]}...: {e}",
                            exc_info=True
                        )
                        failed_count += 1

                end_time = datetime.utcnow()
                duration = (end_time - start_time).total_seconds()

                result = {
                    "status": "completed",
                    "processed": len(ready_merges),
                    "approved": approved_count,
                    "failed": failed_count,
                    "duration_seconds": round(duration, 2)
                }

                logger.info(
                    f"‚úÖ Quarantine processing termin√©: "
                    f"{approved_count} approved, {failed_count} failed "
                    f"(dur√©e {duration:.2f}s)"
                )
                logger.info("üîì Lock quarantine processor lib√©r√© automatiquement")

                return result

            except Exception as e:
                logger.error(f"Erreur critique quarantine processor: {e}", exc_info=True)
                logger.info("üîì Lock quarantine processor lib√©r√© automatiquement (apr√®s erreur)")
                return {
                    "status": "failed",
                    "error": str(e),
                    "processed": 0,
                    "approved": 0,
                    "failed": 0
                }

    async def _process_single_merge(self, merge: MergeAuditEntry) -> None:
        """
        Traite un merge individuel

        Args:
            merge: Entr√©e audit merge √† traiter

        Raises:
            Exception: Si traitement √©choue
        """
        merge_id = merge.merge_id
        canonical_id = merge.canonical_entity_id
        candidates = merge.candidate_ids

        logger.info(
            f"üîÑ Traitement merge {merge_id[:12]}... "
            f"(canonical={canonical_id[:8]}..., {len(candidates)} candidates)"
        )

        # Appeler QdrantBackfillService pour backfill r√©el
        backfill_result = await self.backfill_service.backfill_canonical_entity(
            canonical_entity_id=canonical_id,
            candidate_ids=candidates,
            merge_id=merge_id
        )

        # V√©rifier succ√®s backfill
        if backfill_result["status"] not in ["completed", "skipped"]:
            raise RuntimeError(
                f"Backfill √©chou√© pour merge {merge_id}: "
                f"status={backfill_result['status']} "
                f"success_rate={backfill_result.get('success_rate', 0)}%"
            )

        logger.info(
            f"üì¶ Backfill termin√©: {backfill_result['chunks_updated']} chunks updated "
            f"(p95={backfill_result.get('p95_latency_ms', 0)}ms)"
        )

        # Mettre √† jour status ‚Üí approved
        success = self.audit_logger.update_merge_status(merge_id, "approved")

        if not success:
            raise RuntimeError(f"√âchec mise √† jour status merge {merge_id}")

        logger.info(f"‚úÖ Merge {merge_id[:12]}... approved (backfill appliqu√©)")

    def _simulate_qdrant_backfill(self, canonical_id: str, candidate_ids: List[str]) -> None:
        """
        Simule backfill Qdrant (Phase 0)

        En Phase 0.5, sera remplac√© par appel QdrantBackfillService r√©el:
        - R√©cup√©rer chunks li√©s aux candidates
        - Mettre √† jour metadata canonical_entity_id
        - Batching 100 chunks/requ√™te
        - Retries exponentiels

        Args:
            canonical_id: ID entit√© canonique
            candidate_ids: IDs candidates √† backfiller
        """
        logger.info(
            f"üî® [SIMUL√â] Backfill Qdrant: "
            f"canonical={canonical_id[:8]}..., candidates={len(candidate_ids)}"
        )

        # Simulation: ne fait rien en Phase 0
        # En Phase 0.5:
        # backfill_service = QdrantBackfillService()
        # await backfill_service.backfill_canonical_entity(canonical_id, candidate_ids)

    def get_quarantine_stats(self) -> Dict[str, Any]:
        """
        R√©cup√®re statistiques quarantine actuelle

        Returns:
            Statistiques (total, ready, waiting)
        """
        try:
            ready_merges = self.audit_logger.get_quarantine_ready_merges()

            # TODO: Compter merges still waiting (quarantine_until > now)
            # Pour l'instant, retourne seulement ready count

            return {
                "quarantine_ready": len(ready_merges),
                "quarantine_waiting": 0,  # TODO: Impl√©menter count waiting
                "last_check": datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"Erreur stats quarantine: {e}", exc_info=True)
            return {
                "quarantine_ready": 0,
                "quarantine_waiting": 0,
                "error": str(e)
            }
