# √âvaluation DeepSeek-OCR pour OSMOSE

**Objectif**: √âvaluer si DeepSeek-OCR peut r√©soudre le probl√®me de performance (1h30 pour 230 slides) tout en pr√©servant l'USP cross-lingual d'OSMOSE.

**Documentation compl√®te**: `doc/ongoing/OSMOSE_DEEPSEEK_OCR_EVALUATION_PLAN.md`

---

## üéØ Vue d'Ensemble

### Probl√®me √† R√©soudre
- **Performance bloquante**: 1h30 pour traiter 230 slides PPTX
- **Goulot principal**: Vision extraction GPT-4V (5-10 min sur 90 min total)

### Solution Potentielle
- **DeepSeek-OCR**: 10x compression via vision tokens
- **Gain attendu**: 1h30 ‚Üí 20-30 min (3-5x improvement)
- **Risque**: Pr√©server cross-lingual canonicalization (USP critique)

### Validation en 3 Phases
1. **Phase 1**: Faisabilit√© hardware (RTX 5070 TI compatible?)
2. **Phase 2**: Benchmark performance (gain r√©el?)
3. **Phase 3**: USP validation (cross-lingual pr√©serv√©?) ‚Üê **CRITIQUE**

---

## üìÅ Structure

```
tests/eval_deepseek/
‚îú‚îÄ‚îÄ README.md                        # Ce fichier
‚îú‚îÄ‚îÄ test_01_hello_world.py           # Phase 1: Faisabilit√©
‚îú‚îÄ‚îÄ test_02_benchmark_230_slides.py  # Phase 2: Performance
‚îú‚îÄ‚îÄ test_03_cross_lingual.py         # Phase 3: USP Validation
‚îÇ
‚îú‚îÄ‚îÄ fixtures/                        # Test data
‚îÇ   ‚îú‚îÄ‚îÄ cross_lingual/               # Slides EN/FR/DE
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crr_definition_en.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crr_definition_fr.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crr_definition_de.png
‚îÇ   ‚îî‚îÄ‚îÄ real_230_slides.pptx         # Document test r√©el
‚îÇ
‚îî‚îÄ‚îÄ results/                         # R√©sultats JSON
    ‚îú‚îÄ‚îÄ phase1_feasibility.json
    ‚îú‚îÄ‚îÄ phase2_performance.json
    ‚îî‚îÄ‚îÄ phase3_cross_lingual.json
```

---

## üöÄ Quick Start

### Pr√©requis

#### Hardware
- ‚úÖ RTX 5070 TI (16GB VRAM) ou √©quivalent
- ‚úÖ CUDA 11.8+ drivers install√©s
- ‚úÖ 32GB RAM syst√®me recommand√©

#### Software - Installation

```bash
# 1. Environnement Python
conda create -n deepseek-ocr python=3.10
conda activate deepseek-ocr

# 2. PyTorch + CUDA
pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. DeepSeek-OCR dependencies
pip install transformers>=4.51.1
pip install flash-attn==2.7.3
pip install vllm==0.8.5

# 4. OSMOSE pipeline dependencies (pour Phase 3)
pip install sentence-transformers
pip install spacy
python -m spacy download en_core_web_lg
python -m spacy download fr_core_news_lg
python -m spacy download de_core_news_lg

# 5. Autres
pip install scikit-learn pillow python-pptx
```

#### Clone DeepSeek-OCR Repo

```bash
git clone https://github.com/deepseek-ai/DeepSeek-OCR.git
cd DeepSeek-OCR
pip install -e .
```

---

## üìä Ex√©cution des Tests

### Phase 1: Faisabilit√© Hardware (5-10 min)

**Objectif**: Valider que RTX 5070 TI peut charger et ex√©cuter DeepSeek-OCR

```bash
cd tests/eval_deepseek
python test_01_hello_world.py
```

**M√©triques de succ√®s**:
- ‚úÖ VRAM peak < 14GB
- ‚úÖ Mod√®le charge sans erreur
- ‚úÖ Inference basique fonctionne

**Si FAIL** (VRAM insuffisante):
```python
# Le script retentera automatiquement en mode 4-bit quantization
# Ou forcer manuellement:
from test_01_hello_world import Phase1FeasibilityTest
tester = Phase1FeasibilityTest()
results = tester.run_phase1(use_4bit=True)
```

**Decision Gate**: Si FAIL m√™me en 4-bit ‚Üí STOP (hardware insuffisant)

---

### Phase 2: Benchmark Performance (30-60 min)

**Objectif**: Mesurer gain performance r√©el sur 230 slides

```bash
python test_02_benchmark_230_slides.py
```

**Pr√©-requis**:
- Fournir PPTX de test (230 slides) dans:
  - `data/docs_in/test_230_slides.pptx` OU
  - `tests/eval_deepseek/fixtures/real_230_slides.pptx`
- Si absent: script g√©n√®re estimations bas√©es specs

**M√©triques de succ√®s**:
- ‚úÖ Vision extraction < 5 min (vs 10 min baseline GPT-4V)
- ‚úÖ Pipeline total estim√© < 30 min (vs 1h30 baseline)
- ‚úÖ Gain total ‚â• 3x

**Decision Gate**:
- Gain ‚â• 3x ‚Üí **PASS** - GO Phase 3
- Gain 2-3x ‚Üí **PARTIAL** - Envisager hybrid approach
- Gain < 2x ‚Üí **FAIL** - Pas worth it (mais continuer Phase 3 pour learning)

---

### Phase 3: Validation USP Cross-Lingual (1-2h) ‚ö†Ô∏è CRITIQUE

**Objectif**: Valider que cross-lingual canonicalization fonctionne toujours

```bash
python test_03_cross_lingual.py
```

**Pr√©-requis**: Cr√©er fixtures cross-lingual (voir section suivante)

**M√©triques de succ√®s**:
- ‚úÖ Similarity EN-FR ‚â• 0.85
- ‚úÖ Similarity EN-DE ‚â• 0.85
- ‚úÖ Similarity FR-DE ‚â• 0.85

**Decision Gate**:
- **PASS** ‚Üí ‚úÖ USP pr√©serv√© - **RECOMMANDER Sc√©nario A**
- **FAIL** ‚Üí ‚ùå USP compromis - **ABANDONNER DeepSeek-OCR**

**Note**: Ce test est **NON-N√âGOCIABLE** - USP cross-lingual est diff√©renciation critique OSMOSE

---

## üé® Cr√©er Fixtures Cross-Lingual

Les fixtures sont n√©cessaires pour Phase 3. Cr√©er slides PPTX simples avec m√™me concept en 3 langues.

### Option 1: Automatique (Python Script)

```python
# Script: create_cross_lingual_fixtures.py
from pptx import Presentation
from pptx.util import Inches, Pt

def create_crr_slide(lang: str, text: str, output_path: str):
    """Cr√©er slide simple avec d√©finition CRR"""
    prs = Presentation()
    prs.slide_width = Inches(10)
    prs.slide_height = Inches(7.5)

    # Blank slide
    slide = prs.slides.add_slide(prs.slide_layouts[6])

    # Title
    title_box = slide.shapes.add_textbox(
        Inches(0.5), Inches(0.5),
        Inches(9), Inches(1)
    )
    title_frame = title_box.text_frame
    title_frame.text = {
        "en": "Customer Retention Rate (CRR)",
        "fr": "Taux de R√©tention Client (CRR)",
        "de": "Kundenbindungsrate (CRR)"
    }[lang]
    title_frame.paragraphs[0].font.size = Pt(32)
    title_frame.paragraphs[0].font.bold = True

    # Definition
    text_box = slide.shapes.add_textbox(
        Inches(0.5), Inches(2),
        Inches(9), Inches(4)
    )
    text_frame = text_box.text_frame
    text_frame.text = text
    text_frame.paragraphs[0].font.size = Pt(18)

    prs.save(output_path)

# Cr√©er 3 slides
create_crr_slide(
    "en",
    "The Customer Retention Rate (CRR) measures the percentage of customers "
    "retained over a specific period. Formula: CRR = ((E-N)/S) √ó 100",
    "fixtures/cross_lingual/crr_definition_en.pptx"
)

create_crr_slide(
    "fr",
    "Le Taux de R√©tention Client (CRR) mesure le pourcentage de clients "
    "conserv√©s sur une p√©riode donn√©e. Formule: CRR = ((E-N)/S) √ó 100",
    "fixtures/cross_lingual/crr_definition_fr.pptx"
)

create_crr_slide(
    "de",
    "Die Kundenbindungsrate (CRR) misst den Prozentsatz der Kunden, "
    "die √ºber einen bestimmten Zeitraum gehalten werden. Formel: CRR = ((E-N)/S) √ó 100",
    "fixtures/cross_lingual/crr_definition_de.pptx"
)
```

Puis convertir PPTX ‚Üí PNG:
```bash
# Utiliser LibreOffice headless ou pdf2image
libreoffice --headless --convert-to png crr_definition_en.pptx
```

### Option 2: Manuel (PowerPoint)

1. Ouvrir PowerPoint
2. Cr√©er 3 fichiers PPTX identiques sauf texte:
   - `crr_definition_en.pptx`
   - `crr_definition_fr.pptx`
   - `crr_definition_de.pptx`
3. Exporter chaque slide en PNG
4. Placer dans `fixtures/cross_lingual/`

**Contenu sugg√©r√©**:

**EN**:
```
Title: Customer Retention Rate (CRR)

Definition: The Customer Retention Rate (CRR) measures the percentage
of customers retained over a specific period.

Formula: CRR = ((E-N)/S) √ó 100
Where:
- E = customers at end of period
- N = new customers during period
- S = customers at start of period
```

**FR**:
```
Titre: Taux de R√©tention Client (CRR)

D√©finition: Le Taux de R√©tention Client (CRR) mesure le pourcentage
de clients conserv√©s sur une p√©riode donn√©e.

Formule: CRR = ((E-N)/S) √ó 100
O√π:
- E = clients en fin de p√©riode
- N = nouveaux clients pendant la p√©riode
- S = clients au d√©but de p√©riode
```

**DE**:
```
Titel: Kundenbindungsrate (CRR)

Definition: Die Kundenbindungsrate (CRR) misst den Prozentsatz der Kunden,
die √ºber einen bestimmten Zeitraum gehalten werden.

Formel: CRR = ((E-N)/S) √ó 100
Wobei:
- E = Kunden am Ende des Zeitraums
- N = neue Kunden w√§hrend des Zeitraums
- S = Kunden zu Beginn des Zeitraums
```

---

## üìà Interpr√©tation des R√©sultats

### Sc√©nario A: PASS toutes phases ‚úÖ

**Conditions**:
- Phase 1: ‚úÖ Hardware compatible
- Phase 2: ‚úÖ Gain ‚â• 3x (pipeline < 30 min)
- Phase 3: ‚úÖ Cross-lingual similarity > 0.85

**Decision**: **RECOMMANDER Sc√©nario A - DeepSeek comme optimisation vision**

**Action**:
1. Int√©grer DeepSeek-OCR dans `src/knowbase/ingestion/pipelines/pptx_vision_pipeline.py`
2. Remplacer GPT-4V par DeepSeek-OCR pour extraction vision
3. Garder pipeline OSMOSE downstream (NER, embeddings, canonicalization)
4. Mesurer performance end-to-end

**Gains attendus**:
- Performance: 1h30 ‚Üí 20-30 min (3-5x)
- Co√ªts: R√©duction appels GPT-4V vision
- USP: Pr√©serv√© (cross-lingual canonicalization intact)

---

### Sc√©nario B: PARTIAL Phase 2, PASS Phase 3 ‚ö†Ô∏è

**Conditions**:
- Phase 1: ‚úÖ
- Phase 2: ‚ö†Ô∏è Gain 2-3x seulement
- Phase 3: ‚úÖ

**Decision**: **HYBRID APPROACH**

**Action**:
- DeepSeek-OCR pour slides simples (texte majoritaire)
- GPT-4V pour slides complexes (diagrams, charts)
- Classifier slide complexity en preprocessing

---

### Sc√©nario C: FAIL Phase 3 ‚ùå

**Conditions**:
- Phase 3: ‚ùå Cross-lingual similarity < 0.85

**Decision**: **ABANDONNER DeepSeek-OCR**

**Raison**: USP cross-lingual compromise = perte diff√©renciation vs ChatGPT/Copilot

**Alternatives**:
1. Optimiser pipeline actuel (profiling, batch processing)
2. Parall√©liser vision extraction (multi-GPU)
3. Chercher autres vision models (Claude 3.5 Sonnet vision?)

---

### Sc√©nario D: FAIL Phase 1 ‚ùå

**Conditions**:
- Phase 1: ‚ùå Hardware insuffisant (m√™me en 4-bit)

**Decision**: **STOP √©valuation**

**Action**:
- Upgrade hardware (ex: cloud GPU A100)
- Ou abandonner DeepSeek-OCR

---

## üîß Troubleshooting

### Erreur: CUDA Out of Memory

```python
# Solution 1: Mode 4-bit quantization
results = tester.run_phase1(use_4bit=True)

# Solution 2: Batch size plus petit
# (√† impl√©menter dans test_02_benchmark)

# Solution 3: Clear cache entre runs
import torch
torch.cuda.empty_cache()
```

### Erreur: spaCy models manquants

```bash
python -m spacy download en_core_web_lg
python -m spacy download fr_core_news_lg
python -m spacy download de_core_news_lg
```

### Erreur: Flash Attention compilation

```bash
# Si installation flash-attn √©choue:
# Option 1: Pre-built wheels
pip install flash-attn==2.7.3 --no-build-isolation

# Option 2: Skip flash attention (perf impact)
# Modifier load_kwargs dans scripts:
# Remove: _attn_implementation='flash_attention_2'
```

### Performance plus lente que attendu

**Causes possibles**:
1. RTX 5070 TI perf < A100 (normal)
2. CPU bottleneck (conversion PPTX ‚Üí images)
3. Batch size non optimal

**Debug**:
```python
# Profiler chaque √©tape
import time

start = time.time()
# ... operation ...
print(f"Elapsed: {time.time() - start:.2f}s")
```

---

## üìä R√©sultats Attendus

### Estimations Bas√©es Specs

**Hardware**: RTX 5070 TI (16GB VRAM)

| M√©trique | A100-40G (paper) | RTX 5070 TI (estim√©) |
|----------|------------------|----------------------|
| Tokens/s | 2,500 | 1,500 (60% A100) |
| VRAM usage | ~12GB | ~12GB |
| 230 slides (Base mode) | ~24s | ~40s |

**Pipeline Total**:

| √âtape | Actuel | Avec DeepSeek | Gain |
|-------|--------|---------------|------|
| Vision extraction | 5-10 min | <1 min | 5-10x |
| NER spaCy | 15-20 min | 15-20 min | 1x |
| Embeddings e5 | 10-15 min | 10-15 min | 1x |
| HDBSCAN | 5-10 min | 5-10 min | 1x |
| LLM extraction | 20-30 min | 20-30 min | 1x |
| **TOTAL** | **~90 min** | **~50 min** | **~2x** |

**Note**: Gain total < gain vision seul car autres √©tapes non optimis√©es

---

## üìù Prochaines √âtapes

Apr√®s √©valuation compl√®te:

### Si PASS ‚Üí Impl√©mentation

1. **Integration Planning**:
   - Lire `doc/phases/PHASE1_SEMANTIC_CORE.md`
   - Identifier points d'int√©gration dans pipeline
   - Cr√©er branch `feat/deepseek-ocr-integration`

2. **Refactoring**:
   - Extraire vision extraction en module s√©par√©
   - Cr√©er interface abstraction (GPT-4V vs DeepSeek)
   - Permettre switch A/B testing

3. **Testing**:
   - Tests end-to-end sur corpus complet
   - Validation qualit√© extraction vs baseline
   - Performance profiling production

4. **Documentation**:
   - Mettre √† jour architecture docs
   - Ajouter guide configuration DeepSeek
   - Performance benchmarks

### Si FAIL ‚Üí Alternatives

1. **Profiling Pipeline Actuel**:
   - Identifier goulots exacts
   - Optimiser sans changer architecture

2. **Autres Optimisations**:
   - Batch processing
   - Parallel workers
   - Caching strat√©gique

3. **Autres Vision Models**:
   - Claude 3.5 Sonnet vision
   - Gemini Pro Vision
   - LLaVA (open-source)

---

## üîó R√©f√©rences

- **Plan Complet**: `doc/ongoing/OSMOSE_DEEPSEEK_OCR_EVALUATION_PLAN.md`
- **DeepSeek-OCR Paper**: `C:\Users\I502446\Downloads\DeepSeek_OCR_paper.pdf`
- **DeepSeek-OCR GitHub**: https://github.com/deepseek-ai/DeepSeek-OCR
- **DeepSeek-OCR Blog**: https://deepseek.ai/blog/deepseek-ocr-context-compression
- **OSMOSE Phase 1 Spec**: `doc/phases/PHASE1_SEMANTIC_CORE.md`
- **OSMOSE Pivot Analysis**: `doc/ongoing/OSMOSE_PIVOT_LEARNING_KG.md`

---

**Status**: üìã Scripts pr√™ts - En attente ex√©cution
**Contact HELIOS**: Mode analytique activ√© pour suivi √©valuation
